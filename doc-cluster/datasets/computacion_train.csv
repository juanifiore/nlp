id,sentence,subject_label,label_id
0,Gamification has the potential to improve the quality of learning by better engaging students with learning activities.,background,0
1,"Our objective in this study is to evaluate a gamified learning activity along the dimensions of learning, engagement, and enjoyment.",objective,1
2,The activity made use of a gamified multiple choice quiz implemented as a software tool and was trialled in three undergraduate IT-related courses.,method,2
3,"A questionnaire survey was used to collect data to gauge levels of learning, engagement, and enjoyment.",method,2
4,Results show that there was some degree of engagement and enjoyment.,result,3
5,The majority of participants (77.63 per cent) reported that they were engaged enough to want to complete the quiz and 46.05 per cent stated they were happy while playing the quiz.,result,3
6,"In terms of learning, the overall results were positive since 60.53 per cent of students stated that it enhanced their learning effectiveness.",result,3
7,A limitation of the work is that the results are self-reported and the activity was used over a short period of time.,result,3
8,"Thus, future work should include longer trial periods and evaluating improvements to learning using alternative approaches to self-reported data.",result,3
9,We propose a novel 3D face recognition algorithm using a deep convolutional neural network (DCNN) and a 3D face expression augmentation technique.,background,0
10,The performance of 2D face recognition algorithms has significantly increased by leveraging the representational power of deep neural networks and the use of large-scale labeled training data.,method,2
11,"In this paper, we show that transfer learning from a CNN trained on 2D face images can effectively work for 3D face recognition by fine-tuning the CNN with an extremely small number of 3D facial scans.",objective,1
12,We also propose a 3D face expression augmentation technique which synthesizes a number of different facial expressions from a single 3D face scan.,method,2
13,"Our proposed method shows excellent recognition results on Bosphorus, BU-3DFE, and 3D-TEC datasets without using hand-crafted features.",method,2
14,The 3D face identification using our deep features also scales well for large databases.,result,3
15,The automotive industry is regarded as one of the most important and strategic industry in manufacturing sector.,background,0
16,It is the largest manufacturing enterprise in the world and one of the most resource intensive industries of all major industrial system.,background,0
17,"However, its products and processes are a significant source of environmental impact.",background,0
18,"Thus, there is a need to evaluate sustainable manufacturing performance in this industry.",objective,1
19,"This paper proposes a set of initial key performance indicators (KPIs) for sustainable manufacturing evaluation believed to be appropriate to automotive companies, consisting of three factors divided into nine dimensions and a total of 41 sub-dimensions.",method,2
20,A survey will be conducted to confirm the adaptability of the initial KPIs with the industry practices.,method,2
21,Future research will focus on developing an evaluation tool to assess sustainable manufacturing performance in automotive companies.,result,3
22,In this paper we describe a general passivity based framework for the control of flexible joint robots.,background,0
23,"Herein the recent DLR results on torque-, position-, as well as impedance control of flexible joint robots are summarized, and the relations between the individual contributions are highlighted.",background,0
24,It is shown that an inner torque feedback loop can be incorporated into a passivity based analysis by interpreting torque feedback in terms of shaping of the motor inertia.,method,2
25,"This result, which implicitly was already included in our earlier works on torqueand position control, can also be seized for the design of impedance controllers.",method,2
26,"For impedance control, furthermore, potential shaping is of special interest.",method,2
27,"It is shown how, based only on the motor angles, a potential function can be designed which simultaneously incorporates gravity compensation and a desired Cartesian stiffness relation for the link angles.",method,2
28,All the presented controllers were experimentally evaluated on the DLR light-weight robots and proved their performance and robustness with respect to uncertain model parameters.,result,3
29,"Herein, an impact experiment is presented briefly, and an overview of several applications is given in which the controllers have been applied.",result,3
30,"Head pose monitoring is an important task for driver assistance systems, since it is a key indicator for human attention and behavior.",background,0
31,"However, current head pose datasets either lack complexity or do not adequately represent the conditions that occur while driving.",background,0
32,"Therefore, we introduce DriveAHead, a novel dataset designed to develop and evaluate head pose monitoring algorithms in real driving conditions.",objective,1
33,"We provide frame-by-frame head pose labels obtained from a motion-capture system, as well as annotations about occlusions of the driver's face.",method,2
34,"To the best of our knowledge, DriveAHead is the largest publicly available driver head pose dataset, and also the only one that provides 2D and 3D data aligned at the pixel level using the Kinect v2.",result,3
35,Existing performance metrics are based on the mean error without any consideration of the bias towards one position or another.,result,3
36,"Here, we suggest a new performance metric, named Balanced Mean Angular Error, that addresses the bias towards the forward looking position existing in driving datasets.",method,2
37,"Finally, we present the Head Pose Network, a deep learning model that achieves better performance than current state-of-the-art algorithms, and we analyze its performance when using our dataset.",result,3
38,"In multi-label classification, the main focus has been to develop ways of learning the underlying dependencies between labels, and to take advantage of this at classification time.",background,0
39,"Developing better feature-space representations has been predominantly employed to reduce complexity, e.g., by eliminating non-helpful feature attributes from the input space prior to (or during) training.",background,0
40,"This is an important task, since many multilabel methods typically create many different copies or views of the same input data as they transform it, and considerable memory can be saved by taking advantage of redundancy.",method,2
41,"In this paper, we show that a proper development of the feature space can make labels less interdependent and easier to model and predict at inference time.",method,2
42,For this task we use a deep learning approach with restricted Boltzmann machines.,method,2
43,"We present a deep network that, in an empirical evaluation, outperforms a number of competitive methods from the literature.",method,2
44,The Collaborative Filtering is the most successful algorithm in the recommender systems' field.,background,0
45,A recommender system is an intelligent system can help users to come across interesting items.,background,0
46,It uses data mining and information filtering techniques.,background,0
47,The collaborative filtering creates suggestions for users based on their neighbors' preferences.,method,2
48,But it suffers from its poor accuracy and scalability.,method,2
49,This paper considers the users are m (m is the number of users) points in n dimensional space (n is the number of items) and represents an approach based on user clustering to produce a recommendation for active user by a new method.,method,2
50,It uses k-means clustering algorithm to categorize users based on their interests.,method,2
51,Then it uses a new method called voting algorithm to develop a recommendation.,method,2
52,We evaluate the traditional collaborative filtering and the new one to compare them.,result,3
53,"Our results show the proposed algorithm is more accurate than the traditional one, besides it is less time consuming than it.",result,3
54,"In this paper, we present a detailed tutorial on linear cryp tanalysis and differential cryptanalysis, the two most significant attacks a pplicable to symmetric-key block ciphers.",background,0
55,"The intent of the paper is to present a lucid explanat ion of the attacks, detailing the practical application of the attacks to a cipher i n a simple, conceptually revealing manner for the novice cryptanalyst.",objective,1
56,"The tutorial is base d on the analysis of a simple, yet realistically structured, basic Substitution-Permuta tion Network cipher.",method,2
57,"Understanding the attacks as they apply to this structure is use ful, as the Rijndael cipher, recently selected for the Advanced Encryption Standard (AES), has bee n derived from the basic SPN architecture.",method,2
58,"As well, experimental data from t he a tacks is presented as confirmation of the applicability of the concepts as outlined.",result,3
59,"In a knowledge and information society, e-learning has built on the extensive use of advanced information and communication technologies to deliver learning and instruction.",background,0
60,"In addition, employees who need the training do not have to gather in a place at the same time, and thus it is not necessary for them to travel far away for attending training courses.",background,0
61,"Furthermore, the flexibility allows employees who perform different jobs or tasks for training courses according to their own scheduling.",background,0
62,"Since many studies have discussed learning and training of employees and most of them are focused on the learning emotion, learning style, educational content, and technology, there is limited research exploring the relationship between the e-learning and employee’s satisfaction.",background,0
63,"Therefore, this study aims to explore how to enhance employee’s satisfaction by means of e-learning systems, and what kinds of training or teaching activities are effective to increase their learning satisfaction.",objective,1
64,We provide a model and framework for assessing the impact of e-learning on employee’s satisfaction which improve learning and teaching outcomes.,method,2
65,Findings from the study confirmed the validity of the proposed model for e-learning satisfaction assessment.,result,3
66,"In addition, the results showed that the four variables technology, educational content, motivation, and attitude significantly influenced employee’s learning satisfaction.",result,3
67,2015 Elsevier Ltd.,other,4
69,We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image).,objective,1
70,"We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type.",objective,1
71,"We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval.",method,2
72,"Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark.",background,0
73,"Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available.",background,0
74,"We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant.",objective,1
75,We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture.,method,2
76,Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.,result,3
77,A variety of circle detection methods which are based on variations of the Hough Transform are investigated.,objective,1
78,"The ,five methods considered are the standard Hough Trans,form, the Fast Hough Transform of Li et al.‘, a two stage Hough method, and two space saving approaches based on the method devised by Gerig and Klein2.",method,2
79,The performance of each of the methods has been compared on synthetic imagery and real images from a metallurgical application.,method,2
80,"Figures and comments are presented concerning the accuracy, reliability, computational efficiency and storage requirements of each of the methods.",result,3
81,We present a model that generates natural language descriptions of images and their regions.,method,2
82,Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data.,background,0
83,"Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks (RNN) over sentences, and a structured objective that aligns the two modalities through a multimodal embedding.",result,3
84,We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions.,result,3
85,"We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets.",result,3
86,We then show that the generated descriptions outperform retrieval baselines on both full images and on a new dataset of region-level annotations.,result,3
87,"Finally, we conduct large-scale analysis of our RNN language model on the Visual Genome dataset of 4.1 million captions and highlight the differences between image and region-level caption statistics.",result,3
88,"Literature reports the experiences with e-government initiatives as chaotic and unmanageable, despite recent numerous initiatives at different levels of government and academic and practitionersâ€TM conferences on e-government.",background,0
89,E-government presents a number of challenges for public administrators.,background,0
90,"To help public administrators think about e-government and their organizations, this article describes different stages of egovernment development and proposes a â€ ̃stages of growthâ€TM model for fully functional e-government.",background,0
91,Various government websites and related e-government initiatives help to ground and explain this model.,objective,1
92,These stages outline the multiperspective transformation within government structures and functions as they make transitions to e-government through each stage.,method,2
93,Technological and organizational challenges for each stage accompany these descriptions.,result,3
94,"At the same time, this paper describes how the e-government becomes amalgamated with traditional public administrative structure.",result,3
95,a b Purchase Export,other,4
96,"This paper describes a simple, non-parametric and generic test of the equivalence of Receiver Operating Characteristic (ROC) curves based on a modified Kolmogorov-Smirnov (KS) test.",background,0
97,The test is described in relation to the commonly used techniques such as the Area Under the ROC curve (AUC) and the Neyman-Pearson method.,objective,1
98,We first review how the KS test is used to test the null hypotheses that the class labels predicted by a classifier are no better than random.,method,2
99,We then propose an interval mapping technique that allows us to use two KS tests to test the null hypothesis that two classifiers have ROC curves that are equivalent.,method,2
100,We demonstrate that this test discriminates different ROC curves both when one curve dominates another and when the curves cross and so are not discriminated by AUC.,method,2
101,"The interval mapping technique is then used to demonstrate that, although AUC has its limitations, it can be a model-independent and coherent measure of classifier performance.",result,3
102,Smartphone has become highly prevalent in recent years.,background,0
103,It demonstrates as a useful technology that brings productivity and convenience in our daily life.,background,0
104,"However, smartphone usage can also drive psychological and behavioral maladaptive dependency, which may result in negative problems.",background,0
105,"Given that research on smartphone addiction is still limited in the information systems literature, this paper aims to propose a framework of motives from the functionalist perspective and investigate why users will be addicted to smartphones.",objective,1
106,Four categories of motives for smartphone usage are proposed in this study.,objective,1
107,"They include enhancement motives (i.e., information seeking and perceived enjoyment), social motives (i.e., social relationship), coping motives (i.e., mood regulation and pastime), and conformity motives (i.e., conformity).",method,2
108,We empirically test our research model using online survey method.,method,2
109,"The findings illustrate that perceived enjoyment, mood regulation, pastime, and conformity positively affect smartphone addiction, whereas information seeking and social relationship have no significant effects.",result,3
110,Implications for both research and practice are provided.,result,3
111,"As the density of wireless networks continues to grow with more clients, more base stations, and more traffic, designing cost-effective wireless solutions with efficient resource usage and ease to manage is an increasing challenging task due to the overall system complexity.",background,0
112,"A number of vendors offer scalable and high-performance wireless networks but at a high cost and commonly as a single-vendor solution, limiting the ability to innovate after roll-out.",background,0
113,"Recent Software-Defined Networking (SDN) approaches propose new means for network virtualization and programmability advancing the way networks can be designed and operated, including user-defined features and customized behaviour even at run-time.",background,0
114,"However, means for rapid prototyping and experimental evaluation of SDN for wireless environments are not yet available.",result,3
115,This paper introduces Mininet-WiFi as a tool to emulate wireless OpenFlow/SDN scenarios allowing high-fidelity experiments that replicate real networking environments.,objective,1
116,Mininet-WiFi augments the well-known Mininet emulator with virtual wireless stations and access points while keeping the original SDN capabilities and the lightweight virtualization software architecture.,method,2
117,We elaborate on the potential applications of Mininet-Wifi and discuss the benefits and current limitations.,method,2
118,Two use cases based on IEEE 802.11 demonstrate available functionality in our open source developments.,result,3
119,Phishing attacks are one of the most common and least defended security threats today.,background,0
120,We present an approach which uses natural language processing techniques to analyze text and detect inappropriate statements which are indicative of phishing attacks.,background,0
121,"Our approach is novel compared to previous work because it focuses on the natural language text contained in the attack, performing semantic analysis of the text to detect malicious intent.",method,2
122,"To demonstrate the effectiveness of our approach, we have evaluated it using a large benchmark set of phishing emails.",method,2
123,"Imagining a scene described in natural language with realistic layout and appearance of entities is the ultimate test of spatial, visual, and semantic world knowledge.",background,0
124,"Towards this goal, we present the Composition, Retrieval and Fusion Network (Craft), a model capable of learning this knowledge from video-caption data and applying it while generating videos from novel captions.",objective,1
125,"Craft explicitly predicts a temporal-layout of mentioned entities (characters and objects), retrieves spatio-temporal entity segments from a video database and fuses them to generate scene videos.",objective,1
126,"Our contributions include sequential training of components of Craft while jointly modeling layout and appearances, and losses that encourage learning compositional representations for retrieval.",method,2
127,"We evaluate Craft on semantic fidelity to caption, composition consistency, and visual quality.",result,3
128,Craft outperforms direct pixel generation approaches and generalizes well to unseen captions and to unseen video databases with no text annotations.,objective,1
129,"We demonstrate Craft on Flintstones, a new richly annotated video-caption dataset with over 25000 videos.",result,3
130,"For a glimpse of videos generated by Craft, see https://youtu.be/688Vv86n0z8.",result,3
131,Fred wearing a red hat is walking in the living room Retrieve Compose Retrieve Compose Retrieve Pebbles is sitting at a table in a room watching the television Retrieve Compose Retrieve Compose Compose Retrieve Retrieve Fuse,other,4
132,We present an approach to efficiently detect the 2D pose of multiple people in an image.,objective,1
133,"The approach uses a nonparametric representation, which we refer to as Part Affinity Fields (PAFs), to learn to associate body parts with individuals in the image.",method,2
134,"The architecture encodes global context, allowing a greedy bottom-up parsing step that maintains high accuracy while achieving realtime performance, irrespective of the number of people in the image.",method,2
135,The architecture is designed to jointly learn part locations and their association via two branches of the same sequential prediction process.,method,2
136,"Our method placed first in the inaugural COCO 2016 keypoints challenge, and significantly exceeds the previous state-of-the-art result on the MPII Multi-Person benchmark, both in performance and efficiency.",method,2
137,"Many natural language questions require recognizing and reasoning with qualitative relationships (e.g., in science, economics, and medicine), but are challenging to answer with corpus-based methods.",background,0
138,"Qualitative modeling provides tools that support such reasoning, but the semantic parsing task of mapping questions into those models has formidable challenges.",background,0
139,"We present QUAREL, a dataset of diverse story questions involving qualitative relationships that characterize these challenges, and techniques that begin to address them.",background,0
140,The dataset has 2771 questions relating 19 different types of quantities.,method,2
141,"For example, “Jenny observes that the robot vacuum cleaner moves slower on the living room carpet than on the bedroom carpet.",method,2
142,Which carpet has more friction?,method,2
143,"” We contribute (1) a simple and flexible conceptual framework for representing these kinds of questions; (2) the QUAREL dataset, including logical forms, exemplifying the parsing challenges; and (3) two novel models for this task, built as extensions of type-constrained semantic parsing.",result,3
144,The first of these models (called QUASP+) significantly outperforms off-the-shelf tools on QUAREL.,result,3
145,"The second (QUASP+ZERO) demonstrates zero-shot capability, i.e., the ability to handle new qualitative relationships without requiring additional training data, something not possible with previous models.",result,3
146,"This work thus makes inroads into answering complex, qualitative questions that require reasoning, and scaling to new relationships at low cost.",result,3
147,Non-maximum suppression (NMS) is a key post-processing step in many computer vision applications.,background,0
148,"In the context of object detection, it is used to transform a smooth response map that triggers many imprecise object window hypotheses in, ideally, a single bounding-box for each detected object.",background,0
149,"The most common approach for NMS for object detection is a greedy, locally optimal strategy with several hand-designed components (e.g., thresholds).",background,0
150,"Such a strategy inherently suffers from several shortcomings, such as the inability to detect nearby objects.",background,0
151,"In this paper, we try to alleviate these problems and explore a novel formulation of NMS as a well-defined clustering problem.",method,2
152,"Our method builds on the recent Affinity Propagation Clustering algorithm, which passes messages between data points to identify cluster exemplars.",method,2
153,"Contrary to the greedy approach, our method is solved globally and its parameters can be automatically learned from training data.",result,3
154,"In experiments, we show in two contexts – object class and generic object detection – that it provides a promising solution to the shortcomings of the greedy NMS.",result,3
155,Every day a large number of Earth observation (EO) spaceborne and airborne sensors from many different countries provide a massive amount of remotely sensed data.,background,0
156,"Those data are used for different applications, such as natural hazard monitoring, global climate change, urban planning, etc.",background,0
157,The applications are data driven and mostly interdisciplinary.,method,2
158,Based on this it can truly be stated that we are now living in the age of big remote sensing data.,objective,1
159,"Furthermore, these data are becoming an economic asset and a new important resource in many applications.",method,2
160,"In this paper, we specifically analyze the challenges and opportunities that big data bring in the context of remote sensing applications.",method,2
161,Our focus is to analyze what exactly does big data mean in remote sensing applications and how can big data provide added value in this context.,method,2
162,"Furthermore, this paper describes the most challenging issues in managing, processing, and efficient exploitation of big data for remote sensing problems.",method,2
163,"In order to illustrate the aforementioned aspects, two case studies discussing the use of big data in remote sensing are demonstrated.",result,3
164,"In the first test case, big data are used to automatically detect marine oil spills using a large archive of remote sensing data.",other,4
165,Cyber-Physical Systems (CPS) are integrations of computation and physical processes.,background,0
166,"Embedded computers and networks monitor and control the physical processes, usually with feedback loops where physical processes affect computations and vice versa.",background,0
167,"The economic and societal potential of such systems is vastly greater than what has been realized, and major investments are being made worldwide to develop the technology.",background,0
168,"There are considerable challenges, particularly because the physical components of such systems introduce safety and reliability requirements qualitatively different from those in general- purpose computing.",background,0
169,"Moreover, physical components are qualitatively different from object-oriented software components.",background,0
170,Standard abstractions based on method calls and threads do not work.,background,0
171,"This paper examines the challenges in designing such systems, and in particular raises the question of whether today's computing and networking technologies provide an adequate foundation for CPS.",objective,1
172,"It concludes that it will not be sufficient to improve design processes, raise the level of abstraction, or verify (formally or otherwise) designs that are built on today's abstractions.",method,2
173,"To realize the full potential of CPS, we will have to rebuild computing and networking abstractions.",method,2
174,These abstractions will have to embrace physical dynamics and computation in a unified way.,result,3
175,Log messages are generated by operating systems and applications.,background,0
176,These messages contain important information about the health and operation of the system.,background,0
177,"The messages are also of great significance for security management, audit-checks, and forensics in an intranet.",background,0
178,"So, a logging system that generates, relays, collects and archives log messages, must be monitored and managed just like all other components of the ICT infrastructure, to ensure that it is operating normally i.e., the logs are being collected and archived as desired.",method,2
179,"In the Internet, some progress has been made towards the standardization of the syslog protocol but, to date, the management aspect of syslog has been neglected, for all practical purposes.",method,2
180,"In this paper, we discuss the necessity and importance of monitoring and managing logging systems.",objective,1
181,We present the basic design of a Management Information Base module which will make it possible to monitor and manage a syslog system using standard management protocols.,method,2
182,Then we discuss a prototype implementation of the MIB and demonstrate a syslog management application for managing the syslog configuration of an enterprise.,result,3
183,A quasi-passive leg exoskeleton is presented for load-carrying augmentation during walking.,method,2
184,"The exoskeleton has no actuators, only ankle and hip springs and a knee variabledamper.",method,2
185,"Without a payload, the exoskeleton weighs 11.7kg and requires only 2 Watts of electrical power during loaded walking.",method,2
186,"For a 36 kg payload, we demonstrate that the quasi-passive exoskeleton transfers on average 80% of the load to the ground during the single support phase of walking.",method,2
187,"By measuring the rate of oxygen consumption on a study participant walking at a self-selected speed, we find that the exoskeleton slightly increases the walking metabolic cost of transport (COT) as compared to a standard loaded backpack (10% increase).",method,2
188,"However, a similar exoskeleton without joint springs or damping control (zero-impedance exoskeleton) is found to increase COT by 23% compared to the loaded backpack, highlighting the benefits of passive and quasi-passive joint mechanisms in the design of efficient, low-mass leg exoskeletons.",result,3
189,Otsu method is one of the most successful methods for image thresholding.,background,0
190,This paper proves that the objective function of Otsu method is equivalent to that of K-means method in multilevel thresholding .,objective,1
191,They are both based on a same criterion that minimizes the within-class variance.,method,2
192,"However, Otsu method is an exhaustive algorithm of searching the global optimal threshold, while K-means is a local optimal method.",method,2
193,"Moreover, K-means does not require computing a gray-level histogram before running, but Otsu method needs to compute a gray-level histogram firstly.",method,2
194,"Therefore, K-means can be more efficiently extended to multilevel thresholding method, two-dimensional thresholding method and three-dimensional method than Otsu method.",method,2
195,This paper proved that the clustering results of K-means keep the order of the initial centroids with respect to one-dimensional data set.,result,3
196,The experiments show that the k-means thresholding method performs well with less computing time than Otsu method does on three dimensional image thresholding.,result,3
197,"While dynamic malware analysis methods generally provide better precision than purely static methods, they have the key drawback that they can only detect malicious behavior if it is executed during analysis.",background,0
198,This requires inputs that trigger the malicious behavior to be applied during execution.,background,0
199,"All current methods, such as hard-coded tests, random fuzzing and concolic testing, can provide good coverage but are inefficient because they are unaware of the specific capabilities of the dynamic analysis tool.",method,2
200,"In this work, we introduce IntelliDroid, a generic Android input generator that can be configured to produce inputs specific to a dynamic analysis tool, for the analysis of any Android application.",objective,1
201,"Furthermore, IntelliDroid is capable of determining the precise order that the inputs must be injected, and injects them at what we call the device-framework interface such that system fidelity is preserved.",method,2
202,This enables it to be paired with full-system dynamic analysis tools such as TaintDroid.,method,2
203,Our experiments demonstrate that IntelliDroid requires an average of 72 inputs and only needs to execute an average of 5% of the application to detect malicious behavior.,result,3
204,"When evaluated on 75 instances of malicious behavior, IntelliDroid successfully identifies the behavior, extracts path constraints, and executes the malicious code in all but 5 cases.",result,3
205,"On average, IntelliDroid performs these tasks in 138.4 seconds per application.",result,3
206,Backtracting is a well-known technique for solving combinatorial problems.,background,0
207,It is of interest to programming methodologists because (1) correctness of backtracking programs may be difficult to ascertain experimentally and (2) efficiency is often of paramount importance.,background,0
208,"This paper applies a programming methodology, which we call control structure abstraction, to the backtracking technique.",background,0
209,The value of control structure abstraction in the context of correctness is that proofs of general properties of a class of programs with similar control structures are separated from proofs of specific properties of individual programs of the class.,method,2
210,"In the context of efficiency, it provides sufficient conditions for correctness of an initial program which may subsequently be improved for efficiency while preserving correctness.",method,2
211,"Global navigation satellite signals can be spoofed by false signals, but special receivers can provide defenses against such attacks.",background,0
212,The development of good spoofing defenses requires an understanding of the possible attack modes of a spoofer and the properties of those modes that can be exploited for defense purposes.,background,0
213,Sets of attack methods and defense methods are described in detail.,background,0
214,An attack/defense matrix is developed that documents which defense techniques are effective against the various attack techniques.,method,2
215,"Recommendations are generated to improve the offerings of commercial off-the-shelf receivers from the current situation, a complete lack of spoofing defenses, to a situation in which various levels of defense are present, some that add significant security for relatively little additional cost and others that add more security at costs that start to become appreciable.",method,2
216,This paper describes an approach to overcome a situation of monitoring and managing a parking area using a vision based automated parking system.,objective,1
217,"With the rapid increase of cars the need to find available parking space in the most efficient manner, to avoid traffic congestion in a parking area, is becoming a necessity in car park management.",objective,1
218,Current car park management is dependent on either human personnel keeping track of the available car park spaces or a sensor based system that monitors the availability of each car park space or the overall number of available car park spaces.,method,2
219,"In both situations, the information available was only the total number of car park spaces available and not the actual location available.",method,2
220,"In addition, the installation and maintenance cost of a sensor based system is dependent on the number of sensors used in a car park.",method,2
221,This paper shows a vision based system that is able to detect and indicate the available parking spaces in a car park.,method,2
222,The methods utilized to detect available car park spaces were based on coordinates to indicate the regions of interest and a car classifier.,method,2
223,This paper shows that the initial work done here has an accuracy that ranges from 90% to 100% for a 4 space car park.,result,3
224,The work done indicated that the application of a vision based car park management system would be able to detect and indicate the available car park spaces,result,3
225,"Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts.",background,0
226,"However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets.",background,0
227,"In this paper, we present LIAR: a new, publicly available dataset for fake news detection.",method,2
228,"We collected a decade-long, 12.8K manually labeled short statements in various contexts from POLITIFACT.COM, which provides detailed analysis report and links to source documents for each case.",result,3
229,This dataset can be used for fact-checking research as well.,result,3
230,"Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type.",result,3
231,"Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns.",result,3
232,"We have designed a novel, hybrid convolutional neural network to integrate metadata with text.",result,3
233,We show that this hybrid approach can improve a text-only deep learning model.,result,3
234,Traditional companies used to be authoritarian and built around hierarchical organizational charts.,background,0
235,"Facing more dynamic environments in recent history, many companies experimented with newer forms of organization, usually cutting down long decision paths and fostering lean structures able to react to rapid changes in the marketplace.",background,0
236,"We believe that the future of organizational structures lies in hybrid, dynamic models allowing enterprises to internally move from bureaucratic to adhocratic structures at will, according to changing contexts and focuses of attention.",objective,1
237,"This paper introduces a four-level model representing organizational structures such as social networks, enterprises, communities, and task forces in a decision process.",objective,1
238,It also discusses how context intervenes in this fourlevel model and the role of context at each level.,method,2
239,RÉSUMÉ.,other,4
240,Les entreprises ont longtemps été organisées autour d’organigrammes hiérarchiques et autoritaires.,background,0
241,"Confrontées à des environnements de plus en plus dynamiques, de nombreuses entreprises ont expérimenté de nouvelles formes organisationnelles caractérisées par des chemins de décision raccourcis et des structures allégées, capables de réagir aux changements rapides du marché.",result,3
242,L’avenir des structures organisationnelles dépend de modèles hybrides permettant aux entreprises de passer d’une structure bureaucratique à une structure adhocratique en fonction des changements de contextes et d’objectifs.,method,2
243,"Cet article présente un modèle à quatre niveaux positionnant des structures organisationnelles telles que les réseaux sociaux, les entreprises, les communautés et les task forces au sein d’un processus décisionnel.",background,0
244,Access control is a fundamental aspect of security.,background,0
245,There are many variations of the basic access control models and it is confusing for a software developer to select an appropriate model for her application.,background,0
246,The result in practice is that only basic models are used and the power of more advanced models is thus lost.,method,2
247,We try to clarify this panorama here through the use of patterns.,method,2
248,"In particular, we use pattern diagrams to navigate the pattern space.",method,2
249,A pattern diagram shows relationships between patterns and we can see how different models relate to each other.,method,2
250,A subproduct of our work is the analysis of which patterns are available for use and which need to be written.,objective,1
251,Pattern maps are also useful to perform semi-automatic model transformations as required for Model-Driven Development (MDD).,result,3
252,The idea is to provide the designer of a secure system with a navigation tool that she can use to select an appropriate pattern from a catalog of security patterns.,result,3
253,We also indicate how to compose new access control models by adding features to an existing pattern and how to define patterns by analogy.,objective,1
254,"In this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information.",objective,1
255,"Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the samplingbased method for generating linear sequences proposed by Perozzi et al. (2014).",method,2
256,The advantages of our approach will be illustrated from both theorical and empirical perspectives.,method,2
257,"We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skipgram model with negative sampling proposed by Mikolov et al. (2013).",method,2
258,"Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities.",method,2
259,"To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features.",result,3
260,Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks.,result,3
261,"Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability.",background,0
262,"The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge.",background,0
263,"We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior.",background,0
264,We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input.,objective,1
265,"Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators.",method,2
266,We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.,method,2
267,†,result,3
268,"In this paper, we introduce a Web-scale linguistics search engine, Linggle, that retrieves lexical bundles in response to a given query.",background,0
269,"The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and additional regular expression (RE) operators.",background,0
270,"In our approach, we incorporate inverted file indexing, PoS information from BNC, and semantic indexing based on Latent Dirichlet Allocation with Google Web 1T.",objective,1
271,The method involves parsing the query to transforming it into several keyword retrieval commands.,method,2
272,"Word chunks are retrieved with counts, further filtering the chunks with the query as a RE, and finally displaying the results according to the counts, similarities, and topics.",method,2
273,Clusters of synonyms or conceptually related words are also provided.,result,3
274,"In addition, Linggle provides example sentences from The New York Times on demand.",result,3
275,"The current implementation of Linggle is the most functionally comprehensive, and is in principle language and dataset independent.",result,3
276,We plan to extend Linggle to provide fast and convenient access to a wealth of linguistic information embodied in Web scale datasets including Google Web 1T and Google Books Ngram for many major languages in the world.,result,3
277,"Recently, a state-of-the-art algorithm, called deep deterministic policy gradient (DDPG), has achieved good performance in many continuous control tasks in the MuJoCo simulator.",background,0
278,"To further improve the efficiency of the experience replay mechanism in DDPG and thus speeding up the training process, in this paper, a prioritized experience replay method is proposed for the DDPG algorithm, where prioritized sampling is adopted instead of uniform sampling.",objective,1
279,The proposed DDPG with prioritized experience replay is tested with an inverted pendulum task via OpenAI Gym.,method,2
280,"The experimental results show that DDPG with prioritized experience replay can reduce the training time and improve the stability of the training process, and is less sensitive to the changes of some hyperparameters such as the size of replay buffer, minibatch and the updating rate of the target network.",result,3
281,"Deep learning has been shown successful in a number of domains, ranging from acoustics, images to natural language processing.",background,0
282,"However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs.",background,0
283,"Recently, a significant amount of research efforts have been devoted to this area, greatly advancing graph analyzing techniques.",background,0
284,"In this survey, we comprehensively review different kinds of deep learning methods applied to graphs.",method,2
285,"We divide existing methods into three main categories: semi-supervised methods including Graph Neural Networks and Graph Convolutional Networks, unsupervised methods including Graph Autoencoders, and recent advancements including Graph Recurrent Neural Networks and Graph Reinforcement Learning.",method,2
286,We then provide a comprehensive overview of these methods in a systematic manner following their history of developments.,method,2
287,We also analyze the differences of these methods and how to composite different architectures.,result,3
288,"Finally, we briefly outline their applications and discuss potential future directions.",result,3
289,The mobile data traffic is expected to grow beyond 1000 times by 2020 compared with it in 2010.,background,0
290,"In order to support 1000 times of capacity increase, improving spectrum efficiency is one of the important approaches.",background,0
291,"Meanwhile, in Long Term Evolution (LTE)-Advanced, small cell and hotspot are important scenarios for future network deployment to increase the capacity from the network density domain.",method,2
292,"Under such environment, the probability of high Signal to Interference plus Noise Ratio (SINR) region becomes larger which brings the possibility of introducing higher order modulation, i.e., 256 Quadrature Amplitude Modulation(QAM) to improve the spectrum efficiency.",method,2
293,Channel quality indicator (CQI) table design is a key issue to support 256 QAM.,method,2
294,"In this paper, we investigate the feasibility of 256 QAM by SINR geometry and propose two methods on CQI table design to support the 256 QAM transmission.",objective,1
295,Simulation results show proposed methods can improve average user equipment (UE) throughput and cell center UE throughput with almost no loss on cell edge UE throughput.,result,3
296,Detection of abusive language in user generated online content has become an issue of increasing importance in recent years.,background,0
297,"Most current commercial methods make use of blacklists and regular expressions, however these measures fall short when contending with more subtle, less ham-fisted examples of hate speech.",background,0
298,"In this work, we develop a machine learning based method to detect hate speech on online user comments from two domains which outperforms a state-ofthe-art deep learning approach.",method,2
299,"We also develop a corpus of user comments annotated for abusive language, the first of its kind.",result,3
300,"Finally, we use our detection tool to analyze abusive language over time and in different settings to further enhance our knowledge of this behavior.",result,3
301,Structured light sensors are popular due to their robustness to untextured scenes and multipath.,background,0
302,These systems triangulate depth by solving a correspondence problem between each camera and projector pixel.,background,0
303,"This is often framed as a local stereo matching task, correlating patches of pixels in the observed and reference image.",background,0
304,"However, this is computationally intensive, leading to reduced depth accuracy and framerate.",background,0
305,"We contribute an algorithm for solving this correspondence problem efficiently, without compromising depth accuracy.",method,2
306,"For the first time, this problem is cast as a classification-regression task, which we solve extremely efficiently using an ensemble of cascaded random forests.",method,2
307,"Our algorithm scales in number of disparities, and each pixel can be processed independently, and in parallel.",method,2
308,"No matching or even access to the corresponding reference pattern is required at runtime, and regressed labels are directly mapped to depth.",method,2
309,"Our GPU-based algorithm runs at a 1KHz for 1.3MP input/output images, with disparity error of 0.1 subpixels.",method,2
310,"We show a prototype high framerate depth camera running at 375Hz, useful for solving tracking-related problems.",result,3
311,In this paper we present a new approach for the assessment of noise pollution involving the general public.,background,0
312,The goal of this project is to turn GPS-equipped mobile phones into noise sensors that enable citizens to measure their personal exposure to noise in their everyday environment.,objective,1
313,Thus each user can contribute by sharing their geo-localised measurements and further personal annotation to produce a collective noise map.,method,2
314,AI software is often adeclarative model-based executable knowledgelevel nondeterministic complex adaptive system.,background,0
315,These article describes all these features as well as their implications for verification and validation.,background,0
316,"To appear, Foundations 02: A V&V Workshop; October 22-23, 2002Kossiakoff Conference & Education Center, Johns Hopkins U. Applied Physics Lab Laurel, Maryland USA.",other,4
317,Home page: http://www.sisostds.org/webletter/siso/iss_86/art_493.htm .,other,4
318,Download this paper at http://tim.menzies.com/pdf/02vvai.pdf .,other,4
319,WP ref: wp/02/aivv/aivvis-v2.,other,4
320,Conversational modeling is an important task in natural language understanding and machine intelligence.,background,0
321,"Although previous approaches exist, they are often restricted to specific domains (e.g., booking an airline ticket) and require handcrafted rules.",background,0
322,"In this paper, we present a simple approach for this task which uses the recently proposed sequence to sequence framework.",objective,1
323,Our model converses by predicting the next sentence given the previous sentence or sentences in a conversation.,method,2
324,The strength of our model is that it can be trained end-to-end and thus requires much fewer hand-crafted rules.,method,2
325,We find that this straightforward model can generate simple conversations given a large conversational training dataset.,method,2
326,"Our preliminary results suggest that, despite optimizing the wrong objective function, the model is able to converse well.",result,3
327,"It is able extract knowledge from both a domain specific dataset, and from a large, noisy, and general domain dataset of movie subtitles.",result,3
328,"On a domainspecific IT helpdesk dataset, the model can find a solution to a technical problem via conversations.",result,3
329,"On a noisy open-domain movie transcript dataset, the model can perform simple forms of common sense reasoning.",result,3
330,"Nowadays, smartphones become very popular in our daily activities.",background,0
331,Current phone models have been integrated with high-accuracy built-in sensors.,background,0
332,Many developers have been taking advantage of those sensors to build useful applications.,background,0
333,Tracking user's activities via smartphones is one of the hot topics in research community.,background,0
334,Step detection or step counting is one of the key problems in the field of understanding user's activities.,objective,1
335,There are a few research work and many commercial smartphone applications to detect or count the user's steps.,objective,1
336,"In other work, researchers have tried to detect or count the steps by attaching the phone into a specific position.",method,2
337,"In this paper, we propose a new method based on Kalman Filter to detect and count the user's step with higher accuracy using built-in accelerometer in iOS.",method,2
338,"In our experiments, we allow users to hold the phone in hand or keep it in the pocket.",method,2
339,The experimental results show that our approach gives better results than other commercial applications in the market.,result,3
340,"In this work, we compare three datasets which build on the paradigm defined in SQuAD for question answering: SQuAD 2.0, QuAC, and CoQA.",method,2
341,"We compare these three datasets along several of their new features: (1) unanswerable questions, (2) multi-turn interactions, and (3) abstractive answers.",method,2
342,"We show that the datasets provide complementary coverage of the first two aspects, but weak coverage of the third.",result,3
343,"Because of the datasets’ structural similarity, a single extractive model can be easily adapted to any of the datasets.",result,3
344,We show that this model can improve baseline results on both SQuAD 2.0 and CoQA.,method,2
345,"Despite the core similarity between the datasets, models trained on one dataset are ineffective on another dataset, but we do find moderate performance improvement through pretraining.",result,3
346,"To encourage evaluation of methods on all of these datasets, we release code for conversion between them.",result,3
347,An experiment was conducted where neural networks compete for survival in an evolving population based on their ability to play checkers.,background,0
348,"More specifically, multilayer feedforward neural networks were used to evaluate alternative board positions and games were played using a minimax search strategy.",method,2
349,"At each generation, the extant neural networks were paired in competitions and selection was used to eliminate those that performed poorly relative to other networks.",method,2
350,Offspring neural networks were created from the survivors using random variation of all weights and bias terms.,method,2
351,"After a series of 250 generations, the best-evolved neural network was played against human opponents in a series of 90 games on an internet website.",method,2
352,The neural network was able to defeat two expert-level players and played to a draw against a master.,method,2
353,"The final rating of the neural network placed it in the ""Class A"" category using a standard rating system.",method,2
354,Of particular importance in the design of the experiment was the fact that no features beyond the piece differential were given to the neural networks as a priori knowledge.,result,3
355,The process of evolution was able to extract all of the additional information required to play at this level of competency.,result,3
356,"It accomplished this based almost solely on the feedback offered in the final aggregated outcome of each game played (i.e., win, lose, or draw).",result,3
357,Business analytics has the potential to deliver performance gains and competitive advantage.,background,0
358,"However, a theoretically grounded model identifying the factors and processes involved in realizing those performance gains has not been clearly articulated in the literature.",background,0
359,This paper draws on the literature on dynamic capabilities to develop such a theoretical framework.,objective,1
360,"It identifies the critical roles of organizational routines and organization-wide capabilities for identifying, resourcing and implementing business analytics-based competitive actions in delivering performance gains and competitive advantage.",objective,1
361,A theoretical framework and propositions for future research are developed.,method,2
362,The present study examine s the relation ship betwe en technology self-efficacy among university students and gender roles.,background,0
363,Previous research has based differences in technology self-efficacy on biological sex and found significant differences.,background,0
364,University students were asked to complete a survey dealing with gender roles and technology self-efficacy.,method,2
365,"The current study shows that gender roles, specifically masculinity, is the source of this difference in technology self-efficacy, and not biological sex alone.",result,3
366,"Further, masculinity predicts technology self-efficacy above and beyond what can be explained by other contributing factors such as previous computer hassles and perceived structural technology support.",result,3
367,2013 Elsevier Ltd. All rights reserved.,other,4
368,"We are given a large database of customer transactions, where each transaction consists of customer-id, transaction time, and the items bought in the transaction.",background,0
369,We introduce the problem of mining sequential patterns over such databases.,method,2
370,"We present three algorithms to solve this problem, and empirically evaluate their performance using synthetic data.",method,2
371,"Two of the proposed algorithms, AprioriSome and AprioriAll, have comparable performance, albeit AprioriSome performs a little better when the minimum number of customers that must support a sequential pattern is low.",method,2
372,Scale-up experiments show that both AprioriSome and AprioriAll scale linearly with the number of customer transactions.,result,3
373,They also have excellent scale-up properties with respect to the number of transactions per customer and the number of items in a transaction.,result,3
374,Current High-Frequency Trading (HFT) platforms are typically implemented in software on computers with high-performance network adapters.,background,0
375,"The high and unpredictable latency of these systems has led the trading world to explore alternative ""hybrid"" architectures with hardware acceleration.",background,0
376,"In this paper, we survey existing solutions and describe how FPGAs are being used in electronic trading to approach the goal of zero latency.",method,2
377,"We present an FPGA IP library which implements networking, I/O, memory interfaces and financial protocol parsers.",method,2
378,The library provides pre-built infrastructure which accelerates the development and verification of new financial applications.,method,2
379,We have developed an example financial application using the IP library on a custom 1U FPGA appliance.,result,3
380,The application sustains 10Gb/s Ethernet line rate with a fixed end-to-end latency of 1μs - up to two orders of magnitude lower than comparable software implementations.,result,3
381,SIDEKIT is a new open-source Python toolkit that includes a large panel of state-of-the-art components and allow a rapid prototyping of an end-to-end speaker recognition system.,result,3
382,"For each step from front-end feature extraction, normalization, speech activity detection, modelling, scoring and visualization, SIDEKIT offers a wide range of standard algorithms and flexible interfaces.",background,0
383,"The use of a single efficient programming and scripting language (Python in this case), and the limited dependencies, facilitate the deployment for industrial applications and extension to include new algorithms as part of the whole tool-chain provided by SIDEKIT.",background,0
384,"Performance of SIDEKIT is demonstrated on two standard evaluation tasks, namely the RSR2015 and NIST-SRE 2010.",method,2
385,"INTRODUCTION Policy implementation for electronic commerce is a complex process since policy makers, national governments in their majority, have to act in a fast changing environment.",background,0
386,"They need to balance special national demands with international cooperation (Papazafeiropoulou & Pouloudi, 2000).",background,0
387,One of the areas that policy makers have to tackle is dealing with barriers that have been reported in the adoption of electric commerce today.,background,0
388,These barriers are mostly derived from factors such as lack of awareness about the opportunities offered by electronic commerce as well as lack of trust to ward network security.,background,0
389,"Additionally the current legislative framework, drawn before the advent of electronic commerce, is perceived as outdated, thus impeding the expansion of online transactions.",background,0
390,"Policy makers, therefore, find it increasingly critical to update commerce legislation (Owens, 1999; Shim et al., 2000; the White House, 1999) and take other measures to facilitate the uptake of electronic commerce.",background,0
391,"As the need for appropriate policy measures that support the information society is increasing, it is important to prevent a predominantly technical, commercial or legal approach that neglects the broader social issues related to policy making.",objective,1
392,"To this end, this chapter examines social issues related to electronic commerce policy-making and is structured as follows.",background,0
393,In the next section we present two fundamental social concerns that are related to policy making in,result,3
394,"Agricultural monitoring, especially in developing countries, can help prevent famine and support humanitarian efforts.",objective,1
395,"A central challenge is yield estimation, i.e., predicting crop yields before harvest.",objective,1
396,"We introduce a scalable, accurate, and inexpensive method to predict crop yields using publicly available remote sensing data.",method,2
397,Our approach improves existing techniques in three ways.,method,2
398,"First, we forego hand-crafted features traditionally used in the remote sensing community and propose an approach based on modern representation learning ideas.",method,2
399,We also introduce a novel dimensionality reduction technique that allows us to train a Convolutional Neural Network or Long-short Term Memory network and automatically learn useful features even when labeled training data are scarce.,method,2
400,"Finally, we incorporate a Gaussian Process component to explicitly model the spatio-temporal structure of the data and further improve accuracy.",method,2
401,We evaluate our approach on county-level soybean yield prediction in the U.S. and show that it outperforms competing techniques.,result,3
402,We present a 3-D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion.,background,0
403,Recognition is based on matching surfaces by matching points using the spin-image representation.,background,0
404,The spin-image is a data level shape descriptor that is used to match surfaces represented as surface meshes.,background,0
405,We present a compression scheme for spin-images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models.,background,0
406,"Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes.",method,2
407,This research was performed at Carnegie Mellon University and was supported by the US Department of Energy under contract DE-AC21-92MC29104.,objective,1
408,1,other,4
409,Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text).,background,0
410,"However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves.",background,0
411,In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways.,objective,1
412,"First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator.",method,2
413,"Second, we use coverage to keep track of what has been summarized, which discourages repetition.",method,2
414,"We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.",method,2
415,The visual analysis of peripheral blood samples is an important test in the procedures for the diagnosis of leukemia.,background,0
416,Automated systems based on artificial vision methods can speed up this operation and increase the accuracy and homogeneity of the response also in telemedicine applications.,background,0
417,"Unfortunately, there are not available public image datasets to test and compare such algorithms.",background,0
418,"In this paper, we propose a new public dataset of blood samples, specifically designed for the evaluation and the comparison of algorithms for segmentation and classification.",objective,1
419,"For each image in the dataset, the classification of the cells is given, as well as a specific set of figures of merits to fairly compare the performances of different algorithms.",method,2
420,"This initiative aims to offer a new test tool to the image processing and pattern matching communities, direct to stimulating new studies in this important field of research.",result,3
421,"As one of the powerful tools of machine learning, Convolutional Neural Network (CNN) architectures are used tosolve complex problems like image recognition, video analysisand natural language processing.",objective,1
422,"In this paper, three differentCNN architectures for age classification using face images arecompared.",objective,1
423,The Morph dataset containing over 55k images isused in experiments and success of a 6-layer CNN and 2 variantsof ResNet with different depths are compared.,method,2
424,The images in thedataset are divided into 6 different age classes.,method,2
425,"While 80% of theimages are used in training of the networks, the rest of the 20% isused for testing.",result,3
426,"The performance of the networks are comparedaccording to two different criteria namely, the ability to makethe estimation pointing the exact age classes of test images andthe ability to make the estimation pointing the exact age classesor at most neighboring classes of the images.",result,3
427,"According to theperformance results obtained, with 6-layer network, it is possibleto estimate the exact or neighboring classes of the images withless than 5% error.",result,3
428,It is shown that for a 6 class age classificationproblem 6-layer network is more successful than the deeperResNet counterparts since 6-layer network is less susceptible tooverfitting for this problem.,result,3
429,Social media systems allow Internet users a congenial platform to freely express their thoughts and opinions.,background,0
430,"Although this property represents incredible and unique communication opportunities, it also brings along important challenges.",background,0
431,Online hate speech is an archetypal example of such challenges.,background,0
432,"Despite its magnitude and scale, there is a significant gap in understanding the nature of hate speech on social media.",background,0
433,"In this paper, we provide the first of a kind systematic large scale measurement study of the main targets of hate speech in online social media.",method,2
434,"To do that, we gather traces from two social media systems: Whisper and Twitter.",method,2
435,We then develop and validate a methodology to identify hate speech on both these systems.,result,3
436,"Our results identify online hate speech forms and offer a broader understanding of the phenomenon, providing directions for prevention and detection approaches.",result,3
437,0360-1315/$ see front matter 2009 Elsevier Ltd. A doi:10.1016/j.compedu.2008.12.020 * Corresponding author.,background,0
439,: +1 919 513 1286; fax E-mail address: len_annetta@ncsu.edu (L.A. Annet The popularity of video games has transcended entertainment crossing into the world of education.,background,0
440,"While the literature base on educational gaming is growing, there is still a lack of systematic study of this emerging technology’s efficacy.",method,2
441,This quasi-experimental study evaluated a teacher created video game on genetics in terms of its affective and cognitive impact on student users.,method,2
442,"While statistical results indicated no differences (p > .05) in student learning as measured by our instrument, there were significant differences (p < .05) found in the participants’ level of engagement while interfacing with the video game.",result,3
443,Implications on this emerging line of inquiry are discussed.,result,3
444,2009 Elsevier Ltd.,other,4
446,Scholarly publishing increasingly requires automated systems that semantically enrich documents in order to support management and quality assessment of scientific output.,background,0
447,"However, contextual information, such as the authors’ affiliations, references, and funding agencies, is typically hidden within PDF files.",background,0
448,To access this information we have developed a processing pipeline that analyses the structure of a PDF document incorporating a diverse set of machine learning techniques.,objective,1
449,"First, unsupervised learning is used to extract contiguous text blocks from the raw character stream as the basic logical units of the article.",method,2
450,"Next, supervised learning is employed to classify blocks into different meta-data categories, including authors and affiliations.",method,2
451,"Then, a set of heuristics are applied to detect the reference section at the end of the paper and segment it into individual reference strings.",method,2
452,Sequence classification is then utilised to categorise the tokens of individual references to obtain information such as the journal and the year of the reference.,method,2
453,"Finally, we make use of named entity recognition techniques to extract references to research grants, funding agencies, and EU projects.",method,2
454,Our system is modular in nature.,result,3
455,"Some parts rely on models learnt on training data, and the overall performance scales with the quality of these data sets.",result,3
456,"Using tweets extracted from Twitter during the Australian 2010-2011 floods, social network analysis techniques were used to generate and analyse the online networks that emerged at that time.",background,0
457,"The aim was to develop an understanding of the online communities for the Queensland, New South Wales and Victorian floods in order to identify active players and their effectiveness in disseminating critical information.",objective,1
458,A secondary goal was to identify important online resources disseminated by these communities.,objective,1
459,"Important and effective players during the Queensland floods were found to be: local authorities (mainly the Queensland Police Services), political personalities (Queensland Premier, Prime Minister, Opposition Leader, Member of Parliament), social media volunteers, traditional media reporters, and people from not-for-profit, humanitarian, and community associations.",method,2
460,"A range of important resources were identified during the Queensland flood; however, they appeared to be of a more general information nature rather than vital information and updates on the disaster.",method,2
461,"Unlike Queensland, there was no evidence of Twitter activity from the part of local authorities and the government in the New South Wales and Victorian floods.",result,3
462,"Furthermore, the level of Twitter activity during the NSW floods was almost nil.",method,2
463,Most of the active players during the NSW and Victorian floods were volunteers who were active during the Queensland floods.,method,2
464,"Given the positive results obtained by the active involvement of the local authorities and government officials in Queensland, and the increasing adoption of Twitter in other parts of the world for emergency situations, it seems reasonable to push for greater adoption of Twitter from local and federal authorities Australia-wide during periods of mass emergencies.",result,3
465,This paper presents a novel adaptive synthetic (ADASYN) sampling approach for learning from imbalanced data sets.,background,0
466,"The essential idea of ADASYN is to use a weighted distribution for different minority class examples according to their level of difficulty in learning, where more synthetic data is generated for minority class examples that are harder to learn compared to those minority examples that are easier to learn.",method,2
467,"As a result, the ADASYN approach improves learning with respect to the data distributions in two ways: (1) reducing the bias introduced by the class imbalance, and (2) adaptively shifting the classification decision boundary toward the difficult examples.",result,3
468,Simulation analyses on several machine learning data sets show the effectiveness of this method across five evaluation metrics.,result,3
469,"We apply the two-pluyer game assumprio~ls of 1i111ited search horizon and cornn~itnrent to nroves i constant time, to .single-agent heuristic search problems.",background,0
470,"We present a varicrtion of nrinimcr lookuhead search, and an analog to ulphu-betu pruning rlrot signijicantly improves the efficiency c. the algorithm.",method,2
471,Paradoxically. the search horizon reachuble with this algorithm increases wir.,method,2
472,increusing branching facior.,method,2
473,hl addition.,other,4
474,"we present a new algorithm, called Real-Time-A ', fo interleaving planning and execution.",method,2
475,We prove that the ulgorithm makes locally optimal decision and is guaranteed to find a solution.,result,3
476,"We also present a learning version of this algorithm thrr improves its performance over successive problen~ solving trials by learning more accurate heuristi values, and prove that the learned values converge to their exact values along every optimal path These algorithms ef/ectively solve significanrly larger problems rhan have previously beerr solvabk using heuristic evaluation functions.",result,3
477,"This paper introduces ANYmal, a quadrupedal robot that features outstanding mobility and dynamic motion capability.",background,0
478,"Thanks to novel, compliant joint modules with integrated electronics, the 30 kg, 0.5 m tall robotic dog is torque controllable and very robust against impulsive loads during running or jumping.",background,0
479,"The presented machine was designed with a focus on outdoor suitability, simple maintenance, and user-friendly handling to enable future operation in real world scenarios.",method,2
480,"Performance tests with the joint actuators indicated a torque control bandwidth of more than 70 Hz, high disturbance rejection capability, as well as impact robustness when moving with maximal velocity.",result,3
481,"It is demonstrated in a series of experiments that ANYmal can execute walking gaits, dynamically trot at moderate speed, and is able to perform special maneuvers to stand up or crawl very steep stairs.",method,2
482,"Detailed measurements unveil that even full-speed running requires less than 280 W, resulting in an autonomy of more than 2 h.",result,3
483,Conventional unsupervised image segmentation methods use color and geometric information and apply clustering algorithms over pixels.,background,0
484,They preserve object boundaries well but often suffer from over-segmentation due to noise and artifacts in the images.,background,0
485,"In this paper, we contribute on a preprocessing step for image smoothing, which alleviates the burden of conventional unsupervised image segmentation and enhance their performance.",objective,1
486,Our approach relies on a convolutional autoencoder (CAE) with the total variation loss (TVL) for unsupervised learning.,method,2
487,"We show that, after our CAE-TVL preprocessing step, the over-segmentation effect is significantly reduced using the same unsupervised image segmentation methods.",method,2
488,We evaluate our approach using the BSDS500 image segmentation benchmark dataset and show the performance enhancement introduced by our approach in terms of both increased segmentation accuracy and reduced computation time.,result,3
489,We examine the robustness of the trained CAE and show that it is directly applicable to other natural scene images.,result,3
490,"The purpose of this study is to examine whether supportive interactions on social networking sites mediate the influence of SNS use and the number of SNS friends on perceived social support, affect, sense of community, and life satisfaction.",objective,1
491,"Employing momentary sampling, the current study also looked at the relationship between supportive interaction and immediate affect after the interaction over a period of 5 days.",method,2
492,An analysis of 339 adult participants revealed a positive relationship between supportive interaction and positive affect after the interaction.,result,3
493,"A path model revealed positive associations among the number of SNS friends, supportive interactions, affect, perceived social support, sense of community, and life satisfaction.",result,3
494,Implications for the research of online social networking and social support are discussed.,result,3
495,2013 Elsevier Ltd. All rights reserved.,other,4
496,"In this paper, we extend the guidelines of Venkatesh et al. (2013) for mixed-methods research by identifying and integrating variations in mixed-methods research.",objective,1
497,"By considering 14 properties of mixed-methods research (e.g., purposes, research questions, epistemological assumptions), our guidelines demonstrate how researchers can flexibly identify the existing variations in mixed-methods research and proceed accordingly with a study design that suits their needs.",method,2
498,"To make the guidelines actionable for various situations and issues that researchers could encounter, we develop a decision tree to map the flow and relationship among the design strategies.",method,2
499,We also illustrate one possible type of mixed-methods research in information systems in depth and discuss how to develop and validate metainferences as the outcomes of such a study.,result,3
500,"In recent years, the convolutional neural network (CNN) has achieved great success in many computer vision tasks.",background,0
501,"Partially inspired by neuroscience, CNN shares many properties with the visual system of the brain.",background,0
502,A prominent difference is that CNN is typically a feed-forward architecture while in the visual system recurrent connections are abundant.,background,0
503,"Inspired by this fact, we propose a recurrent CNN (RCNN) for object recognition by incorporating recurrent connections into each convolutional layer.",objective,1
504,"Though the input is static, the activities of RCNN units evolve over time so that the activity of each unit is modulated by the activities of its neighboring units.",method,2
505,"This property enhances the ability of the model to integrate the context information, which is important for object recognition.",method,2
506,"Like other recurrent neural networks, unfolding the RCNN through time can result in an arbitrarily deep network with a fixed number of parameters.",method,2
507,"Furthermore, the unfolded network has multiple paths, which can facilitate the learning process.",method,2
508,"The model is tested on four benchmark object recognition datasets: CIFAR-10, CIFAR-100, MNIST and SVHN.",method,2
509,"With fewer trainable parameters, RCNN outperforms the state-of-the-art models on all of these datasets.",result,3
510,"In this chapter, we give an overview of the main Data Mining techniques used in the context of Recommender Systems.",background,0
511,We first describe common preprocessing methods such as sampling or dimensionality reduction.,background,0
512,"Next, we review the most important classification techniques, including Bayesian Networks and Support Vector Machines.",method,2
513,We describe the k-means clustering algorithm and discuss several alternatives.,method,2
514,We also present association rules and related algorithms for an efficient training process.,method,2
515,"In addition to introducing these techniques, we survey their uses in Recommender Systems and present cases where they have been successfully applied.",method,2
516,"Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs.",background,0
517,"In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains.",objective,1
518,"This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space.",method,2
519,A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model.,method,2
520,The computational cost of the proposed algorithm is also considered.,background,0
521,"Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.",result,3
522,Full end-to-end text recognition in natural images is a challenging problem that has received much attention recently.,background,0
523,Traditional systems in this area have relied on elaborate models incorporating carefully hand-engineered features or large amounts of prior knowledge.,background,0
524,"In this paper, we take a different route and combine the representational power of large, multilayer neural networks together with recent developments in unsupervised feature learning, which allows us to use a common framework to train highly-accurate text detector and character recognizer modules.",objective,1
525,"Then, using only simple off-the-shelf methods, we integrate these two modules into a full end-to-end, lexicon-driven, scene text recognition system that achieves state-of-the-art performance on standard benchmarks, namely Street View Text and ICDAR 2003.",method,2
526,A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language.,background,0
527,Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories.,background,0
528,We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords.,background,0
529,"We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither.",background,0
530,We train a multi-class classifier to distinguish between these different categories.,background,0
531,Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult.,method,2
532,We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive.,result,3
533,Tweets without explicit hate keywords are also more difficult to classify.,result,3
534,"A novel efficient trilateration algorithm is presented to estimate the position of a target object, such as a mobile robot, in a 2D or 3D space.",background,0
535,"The proposed algorithm is derived from a nonlinear least-squares formulation, and provides an optimal position estimate from a number (greater than or equal to the dimension of the environment) of reference points and corresponding distance measurements.",background,0
536,"Using standard linear algebra techniques, the proposed algorithm has low computational complexity and high operational robustness.",method,2
537,Error analysis has been conducted through simulations on representative examples.,method,2
538,"The results show that the proposed algorithm has lower systematic error and uncertainty in position estimation when dealing with erroneous inputs, compared with representative closed-form methods.",result,3
539,"Model distillation was originally designed to distill knowledge from a large, complex teacher model to a faster, simpler student model without significant loss in prediction accuracy.",background,0
540,We investigate model distillation for another goal – transparency – investigating if fully-connected neural networks can be distilled into models that are transparent or interpretable in some sense.,method,2
541,"Our teacher models are multilayer perceptrons, and we try two types of student models: (1) treebased generalized additive models (GA2Ms), a type of boosted, short tree (2) gradient boosted trees (GBTs).",method,2
542,More transparent student models are forthcoming.,method,2
543,Our results are not yet conclusive.,result,3
544,"GA2Ms show some promise for distilling binary classification teachers, but not yet regression.",result,3
545,GBTs are not “directly” interpretable but may be promising for regression teachers.,result,3
546,GA2M models may provide a computationally viable alternative to additive decomposition methods for global function approximation.,result,3
547,The goal of this research is to build a model to predict stock price movement using the sentiment from social media.,objective,1
548,"Unlike previous approaches where the overall moods or sentiments are considered, the sentiments of the specific topics of the company are incorporated into the stock prediction model.",objective,1
549,Topics and related sentiments are automatically extracted from the texts in a message board by using our proposed method as well as existing topic models.,method,2
550,"In addition, this paper shows an evaluation of the effectiveness of the sentiment analysis in the stock prediction task via a large scale experiment.",result,3
551,"Comparing the accuracy average over 18 stocks in one year transaction, our method achieved 2.07% better performance than the model using historical prices only.",method,2
552,"Furthermore, when comparing the methods only for the stocks that are difficult to predict, our method achieved 9.83% better accuracy than historical price method, and 3.03% better than human sentiment method.",method,2
553,© 2015 Elsevier Ltd.,other,4
555,Automated affective computing in the wild setting is a challenging problem in computer vision.,background,0
556,Existing annotated databases of facial expressions in the wild are small and mostly cover discrete emotions (aka the categorical model).,background,0
557,"There are very limited annotated facial databases for affective computing in the continuous dimensional model (e.g., valence and arousal).",background,0
558,"To meet this need, we collected, annotated, and prepared for public distribution a new database of facial emotions in the wild (called AffectNet).",objective,1
559,"AffectNet contains more than 1,000,000 facial images from the Internet by querying three major search engines using 1250 emotion related keywords in six different languages.",result,3
560,About half of the retrieved images were manually annotated for the presence of seven discrete facial expressions and the intensity of valence and arousal.,method,2
561,"AffectNet is by far the largest database of facial expression, valence, and arousal in the wild enabling research in automated facial expression recognition in two different emotion models.",result,3
562,Two baseline deep neural networks are used to classify images in the categorical model and predict the intensity of valence and arousal.,result,3
563,Various evaluation metrics show that our deep neural network baselines can perform better than conventional machine learning methods and off-the-shelf facial expression recognition systems.,result,3
564,The Traveling Salesman Problem (TSP) is one of the standard test problems used in performance analysis of discrete optimization algorithms.,background,0
565,The Ant Colony Optimization (ACO) algorithm appears among heuristic algorithms used for solving discrete optimization problems.,background,0
566,"In this study, a new hybrid method is proposed to optimize parameters that affect performance of the ACO algorithm using Particle Swarm Optimization (PSO).",method,2
567,"In addition, 3-Opt heuristic method is added to proposed method in order to improve local solutions.",method,2
568,The PSO algorithm is used for detecting optimum values of parameters ̨ and ˇ which are used for city selection operations in the ACO algorithm and determines significance of inter-city pheromone and distances.,method,2
569,"The 3-Opt algorithm is used for the purpose of improving city selection operations, which could not be improved due to falling in local minimums by the ACO algorithm.",method,2
570,The performance of proposed hybrid method is investigated on ten different benchmark problems taken from literature and it is compared to the performance of some well-known algorithms.,method,2
571,Experimental results show that the performance of proposed method by using fewer ants than the number of cities for the TSPs is better than the performance of compared methods in most cases in terms of solution quality and robustness.,result,3
574,"With the advent of Web 2.0, we see a new and differentiated scenario: there is more data than that can be effectively analyzed.",background,0
575,Organizing this data has become one of the biggest problems in Computer Science.,background,0
576,"Many algorithms have been proposed for this purpose, highlighting those related to the Data Mining area, specifically the clustering algorithms.",method,2
577,"However, these algorithms are still a computational challenge because of the volume of data that needs to be processed.",method,2
578,"We found in the literature some proposals to make these algorithms feasible, and, recently, those related to parallelization on graphics processing units (GPUs) have presented good results.",method,2
579,"In this work we present the G-DBSCAN, a GPU parallel version of one of the most widely used clustering algorithms, the DBSCAN.",method,2
580,"Although there are other parallel versions of this algorithm, our technique distinguishes itself by the simplicity with which the data are indexed, using graphs, allowing various parallelization opportunities to be explored.",result,3
581,"In our evaluation we show that the G-DBSCAN using GPU, can be over 100x faster than its sequential version using CPU.",result,3
582,"Since the 1990s, the scope of research evaluations becomes broader as the societal products (outputs), societal use (societal references), and societal benefits (changes in society) of research come into scope.",background,0
583,"Society can reap the benefits of successful research studies only if the results are converted into marketable and consumable products (e.g., medicaments, diagnostic tools, machines, and devices) or services.",background,0
584,"A series of different names have been introduced which refer to the societal impact of research: third stream activities, societal benefits, societal quality, usefulness, public values, knowledge transfer, and societal relevance.",background,0
585,"What most of these names are concerned with is the assessment of social, cultural, environmental, and economic returns (impact and effects) from results (research output) or products (research outcome) of publicly funded research.",background,0
586,This review intends to present existing research on and practices employed in the assessment of societal impact in the form of a literature survey.,result,3
587,The objective is for this review to serve as a basis for the development of robust and reliable methods of societal impact measurement.,method,2
588,"Java programmers cannot but be aware of the advent of C#, the .NET network environment, and a host of new supporting technologies, such as web services.",background,0
589,"Before taking the big step of moving all development to a new environment, programmers will want to know what are the advantages of C# as a language over Java, and whether the new and interesting features of C# and .NET can be incorporated into existing Java software.",background,0
590,This paper surveys the advantages of C# and then presents and evaluates experience with connecting it to Java in a variety of ways.,result,3
591,"The first way provides evidence that Java can be linked to C# at the native code level, albeit through C++ wrappers.",method,2
592,"The second is a means for retaining the useful applet feature of Java in the serverside architecture of web services written in C#. The third is by providing a common XML-based class for the development of GUIs, which can be incorporated into Java or C#. An added advantage of this system, called Views, is that it can run independently of the resource-intensive development environment that would otherwise be needed for using C#. A major advantage of the methods described in this paper is that in all cases the Java program is not affected by the fact that it is interfacing with C#. The paper concludes that there are many common shared technologies that bring Java and C# close together, and that innovative ways of using others can open up opportunities not hitherto imagined.",result,3
593,The Technology Acceptance model (TAM) is one of the most influential theories in Information Systems.,background,0
594,"However, despite the model's significant contributions, the intense focus on TAM has diverted researchers’ attention away from other important research issues and has created an illusion of progress in knowledge accumulation.",background,0
595,"Furthermore, the independent attempts by several researchers to expand TAM in order to adapt it to the constantly changing IT environments has lead to a state of theoretical chaos and confusion in which it is not clear which version of the many iterations of TAM is the commonly accepted one.",method,2
596,"The present commentary discusses these concerns, speculates on the possible contributions to the current state of affairs, and makes several suggestions to alleviate the problems associated with TAM and to advance IT adoption research to the next stage.",objective,1
597,Image based vehicle insurance processing is an important area with large scope for automation.,background,0
598,"In this paper we consider the problem of car damage classification, where some of the categories can be fine-granular.",objective,1
599,We explore deep learning based techniques for this purpose.,method,2
600,"Initially, we try directly training a CNN.",objective,1
601,"However, due to small set of labeled data, it does not work well.",result,3
602,"Then, we explore the effect of domain-specific pre-training followed by fine-tuning.",result,3
603,"Finally, we experiment with transfer learning and ensemble learning.",result,3
604,Experimental results show that transfer learning works better than domain specific fine-tuning.,result,3
605,We achieve accuracy of 89.5% with combination of transfer and ensemble learning.,result,3
606,"In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels.",background,0
607,"While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image.",background,0
608,"Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation.",result,3
609,We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.,result,3
610,Numerous approaches for identifying important content for automatic text summarization have been developed to date.,background,0
611,Topic representation approaches first derive an intermediate representation of the text that captures the topics discussed in the input.,background,0
612,"Based on these representations of topics, sentences in the input document are scored for importance.",background,0
613,"In contrast, in indicator representation approaches, the text is represented by a diverse set of possible indicators of importance which do not aim at discovering topicality.",objective,1
614,"These indicators are combined, very often using machine learning techniques, to score the importance of each sentence.",method,2
615,"Finally, a summary is produced by selecting sentences in a greedy approach, choosing the sentences that will go in the summary one by one, or globally optimizing the selection, choosing the best set of sentences to form a summary.",method,2
616,"In this chapter we give a broad overview of existing approaches based on these distinctions, with particular attention on how representation, sentence scoring or summary selection strategies alter the overall performance of the summarizer.",objective,1
617,"We also point out some of the peculiarities of the task of summarization which have posed challenges to machine learning approaches for the problem, and some of the suggested solutions.",objective,1
618,1Portions of this chapter have already appeared in our more detailed overview of summarization research [67].,background,0
619,"The larger manuscript includes sections on generation techniques for © Springer Science+Business Media, LLC 2012 43 C.C. Aggarwal and C.X. Zhai (eds.), Mining Text Data, DOI 10.1007/978-1-4614-3223-4_3,",result,3
620,"The design of video game environments, or levels, aims to control gameplay by steering the player through a sequence of designer-controlled steps, while simultaneously providing a visually engaging experience.",background,0
621,"Traditionally these levels are painstakingly designed by hand, often from pre-existing building blocks, or space templates.",background,0
622,"In this paper, we propose an algorithmic approach for automatically laying out game levels from user-specified blocks.",objective,1
623,"Our method allows designers to retain control of the gameplay flow via user-specified level connectivity graphs, while relieving them from the tedious task of manually assembling the building blocks into a valid, plausible layout.",method,2
624,"Our method produces sequences of diverse layouts for the same input connectivity, allowing for repeated replay of a given level within a visually different, new environment.",method,2
625,"We support complex graph connectivities and various building block shapes, and are able to compute complex layouts in seconds.",method,2
626,The two key components of our algorithm are the use of configuration spaces defining feasible relative positions of building blocks within a layout and a graph-decomposition based layout strategy that leverages graph connectivity to speed up convergence and avoid local minima.,result,3
627,Together these two tools quickly steer the solution toward feasible layouts.,result,3
628,"We demonstrate our method on a variety of real-life inputs, and generate appealing layouts conforming to user specifications.",result,3
629,Firms today use information about customers to improve service and design personalized offerings.,background,0
630,"To do this successfully, however, firms must collect consumer information.",background,0
631,"This study enhances awareness about a central paradox for firms investing in personalization; namely, that consumers who value information transparency are also less likely to participate in personalization.",objective,1
632,"We examine the relationship between information technology features, specifically information transparency features, and consumer willingness to share information for online personalization.",method,2
633,Based on a survey V. Sambamurthy was the accepting senior editor for this paper.,method,2
634,Prabhudev Konana was the associate editor.,other,4
635,Sridhar Balasubramanian and Nirup Menon served as reviewers.,other,4
636,"of over 400 online consumers, we examine the question of whether customer perceived information transparency is associated with consumer willingness to be profiled online.",method,2
637,Our results indicate that customers who desire greater information transparency are less willing to be profiled.,result,3
638,"This result poses a dilemma for firms, as the consumers that value information transparency features most are also the consumers who are less willing to be profiled online.",result,3
639,Structure from Motion (SfM) algorithms take as input multiview stereo images (along with internal calibration information) and yield a 3D point cloud and camera orientations/poses in a common 3D coordinate system.,background,0
640,"In the case of an incremental SfM pipeline, the process requires repeated model estimations based on detected feature points: homography, fundamental and essential matrices, as well as camera poses.",background,0
641,These estimations have a crucial impact on the quality of 3D reconstruction.,background,0
642,We propose to improve these estimations using the a contrario methodology.,method,2
643,"While SfM pipelines usually have globallyxed thresholds for model estimation, the a contrario principle adapts thresholds to the input data and for each model estimation.",method,2
644,Our experiments show that adaptive thresholds reach a signi cantly better precision.,method,2
645,"Additionally, the user is free from having to guess thresholds or to optimistically rely on default values.",method,2
646,"There are also cases where a globallyxed threshold policy, whatever the threshold value is, cannot provide the best accuracy, contrary to an adaptive threshold policy.",method,2
647,Perceptual image quality assessment (IQA) aims to use computational models to measure the image quality in consistent with subjective evaluations.,objective,1
648,"Visual saliency (VS) has been widely studied by psychologists, neurobiologists, and computer scientists during the last decade to investigate, which areas of an image will attract the most attention of the human visual system.",background,0
649,"Intuitively, VS is closely related to IQA in that suprathreshold distortions can largely affect VS maps of images.",background,0
650,"With this consideration, we propose a simple but very effective full reference IQA method using VS.",method,2
651,"In our proposed IQA model, the role of VS is twofold.",method,2
652,"First, VS is used as a feature when computing the local quality map of the distorted image.",method,2
653,"Second, when pooling the quality score, VS is employed as a weighting function to reflect the importance of a local region.",method,2
654,The proposed IQA index is called visual saliency-based index (VSI).,method,2
655,Several prominent computational VS models have been investigated in the context of IQA and the best one is chosen for VSI.,result,3
656,Extensive experiments performed on four largescale benchmark databases demonstrate that the proposed IQA index VSI works better in terms of the prediction accuracy than all state-of-the-art IQA indices we can find while maintaining a moderate computational complexity.,result,3
657,"Motivated by the recent explosion of interest around blockchains, we examine whether they make a good fit for the Internet of Things (IoT) sector.",background,0
658,"Blockchains allow us to have a distributed peer-to-peer network where non-trusting members can interact with each other without a trusted intermediary, in a verifiable manner.",background,0
659,We review how this mechanism works and also look into smart contracts-scripts that reside on the blockchain that allow for the automation of multi-step processes.,method,2
660,"We then move into the IoT domain, and describe how a blockchain-IoT combination: 1) facilitates the sharing of services and resources leading to the creation of a marketplace of services between devices and 2) allows us to automate in a cryptographically verifiable manner several existing, time-consuming workflows.",method,2
661,We also point out certain issues that should be considered before the deployment of a blockchain network in an IoT setting: from transactional privacy to the expected value of the digitized assets traded on the network.,method,2
662,"Wherever applicable, we identify solutions and workarounds.",result,3
663,"Our conclusion is that the blockchain-IoT combination is powerful and can cause significant transformations across several industries, paving the way for new business models and novel, distributed applications.",result,3
664,"The Impact of computer self-efficacy and technology dependence on computer-related technostress: A Social cognitive theory perspective"" (2011).",background,0
665,"This article may be used for research, teaching, and private study purposes.",background,0
666,"Any substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing, systematic supply, or distribution in any form to anyone is expressly forbidden.",background,0
667,The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date.,background,0
668,"The accuracy of any instructions, formulae, and drug doses should be independently verified with primary sources.",background,0
669,"The publisher shall not be liable for any loss, actions, claims, proceedings, demand, or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material.",background,0
670,Professionals and end users of computers often experience being constantly surrounded by modern technology.,background,0
671,"One side effect of modern technology is termed technostress, which refers to the "" negative impact on attitudes, thoughts, behaviors, or body physiology that is caused either directly or indirectly by technology "" (Well and Rosen, 1997).",result,3
672,"Based on social cognitive theory, this study developed a conceptual model in which computer-related technostress was studied as consequences of computer self-efficacy and technology dependence.",method,2
673,"Results show that (a) employees with higher level of computer self-efficacy have lower level of computer-related technos-tress, (b) employees with higher level of technology dependence have higher level of computer-related technostress, and (c) employees under different individual situations may perceive different levels of technostress.",result,3
674,Modern neural image captioning systems typically adopt the encoder-decoder framework consisting of two principal components: a convolutional neural network (CNN) for image feature extraction and a recurrent neural network (RNN) for caption generation.,background,0
675,"Inspired by the robustness analysis of CNN-based image classifiers to adversarial perturbations, we propose Show-and-Fool, a novel algorithm for crafting adversarial examples in neural image captioning.",background,0
676,"Unlike image classification tasks with a finite set of class labels, finding visually-similar adversarial examples in an image captioning system is much more challenging since the space of possible captions in a captioning system is almost infinite.",background,0
677,"In this paper, we design three approaches for crafting adversarial examples in image captioning: (i) targeted caption method; (ii) targeted keyword method; and (iii) untargeted method.",method,2
678,We formulate the process of finding adversarial perturbations as optimization problems and design novel loss functions for efficient search.,method,2
679,"Experimental results on the Show-and-Tell model and MSCOCO data set show that Show-and-Fool can successfully craft visuallysimilar adversarial examples with randomly targeted captions, and the adversarial examples can be made highly transferable to the Show-Attend-and-Tell model.",result,3
680,"Consequently, the presence of adversarial examples leads to new robustness implications of neural image captioning.",result,3
681,"To the best of our knowledge, this is the first work on crafting effective adversarial examples for image captioning tasks.",result,3
682,"With the ever-increasing development of technology and its integration into users’ private and professional life, a decision regarding its acceptance or rejection still remains an open question.",background,0
683,"A respectable amount of work dealing with the technology acceptance model (TAM), from its first appearance more than a quarter of a century ago, clearly indicates a popularity of the model in the field of technology acceptance.",background,0
684,"Originated in the psychological theory of reasoned action and theory of planned behavior, TAM has evolved to become a key model in understanding predictors of human behavior toward potential acceptance or rejection of the technology.",background,0
685,"The main aim of the paper is to provide an up-to-date, well-researched resource of past and current references to TAM-related literature and to identify possible directions for future TAM research.",objective,1
686,"The paper presents a comprehensive concept-centric literature review of the TAM, from 1986 onwards.",objective,1
687,"According to a designed methodology, 85 scientific publications have been selected and classified according to their aim and content into three categories such as (i) TAM literature reviews, (ii) development and extension of TAM, and (iii) modification and application of TAM.",method,2
688,"Despite a continuous progress in revealing new factors with significant influence on TAM’s core variables, there are still many unexplored areas of model potential application that could contribute to its predictive validity.",method,2
689,"Consequently, four possible future directions for TAM research based on the conducted literature review and analysis are identified and presented.",result,3
690,"Rail inspection is a very important task in railway maintenance, and it is periodically needed for preventing dangerous situations.",background,0
691,Inspection is operated manually by trained human operator walking along the track searching for visual anomalies.,background,0
692,"This monitoring is unacceptable for slowness and lack of objectivity, as the results are related to the ability of the observer to recognize critical situations.",method,2
693,"The correspondence presents a patent-pending real-time Visual Inspection System for Railway (VISyR) maintenance, and describes how presence/absence of the fastening bolts that fix the rails to the sleepers is automatically detected.",method,2
694,VISyR acquires images from a digital line-scan camera.,method,2
695,"Data are simultaneously preprocessed according to two discrete wavelet transforms, and then provided to two multilayer perceptron neural classifiers (MLPNCs).",method,2
696,"The ""cross validation"" of these MLPNCs avoids (practically-at-all) false positives, and reveals the presence/absence of the fastening bolts with an accuracy of 99.6% in detecting visible bolts and of 95% in detecting missing bolts.",result,3
697,"A field-programmable gate array-based architecture performs these tasks in 8.09 mus, allowing an on-the-fly analysis of a video sequence acquired at 200 km/h",result,3
698,"Within the framework of evidence theory, data fusion consists in obtaining a single belief function by the combination of several belief functions resulting from distinct information sources.",background,0
699,"The most popular rule of combination, called Dempster’s rule of combination (or the orthogonal sum), has several interesting mathematical properties such as commutativity or associativity.",background,0
700,"However, combining belief functions with this operator implies normalizing the results by scaling them proportionally to the conflicting mass in order to keep some basic properties.",background,0
701,"Although this normalization seems logical, several authors have criticized it and some have proposed other solutions.",background,0
702,"In particular, Dempster’s combination operator is a poor solution for the management of the conflict between the various information sources at the normalization step.",method,2
703,Conflict management is a major problem especially during the fusion of many information sources.,method,2
704,"Indeed, the conflict increases with the number of information sources.",result,3
705,That is why a strategy for re-assigning the conflicting mass is essential.,result,3
706,"In this paper, we define a formalism to describe a family of combination operators.",method,2
707,"So, we propose to develop a generic framework in order to unify several classical rules of combination.",method,2
708,The objective of this paper is to investigate the experiences of implementing a pharmacy automation drug dispensing system in Saudi Arabia.,objective,1
709,"Key informant interviews, meeting documents, and experience of the researcher were the data collection sources used in the study.",method,2
710,A thematic analysis of the data was conducted.,method,2
711,Study results discuss the organizational challenges prior to implementation as well as details of the implementation process.,method,2
712,Preliminary results show improvements in the services provided by the pharmaceutical department.,result,3
713,Lessons learned are also discussed.,result,3
714,The work presented in this paper is preliminary and more research is needed to evaluate the overall impact of the new pharmacy automation system on services provided by the pharmaceutical department.,result,3
715,Methods that learn representations of graph nodes play a critical role in network analysis since they enable many downstream learning tasks.,background,0
716,We propose Graph2Gauss – an approach that can efficiently learn versatile node embeddings on large scale (attributed) graphs that show strong performance on tasks such as link prediction and node classification.,objective,1
717,"Unlike most approaches that represent nodes as (point) vectors in a lower-dimensional continuous space, we embed each node as a Gaussian distribution, allowing us to capture uncertainty about the representation.",method,2
718,"Furthermore, in contrast to previous approaches we propose a completely unsupervised method that is also able to handle inductive learning scenarios and is applicable to different types of graphs (plain, attributed, directed, undirected).",method,2
719,"By leveraging both the topological network structure and the associated node attributes, we are able to generalize to unseen nodes without additional training.",method,2
720,To learn the embeddings we adopt a personalized ranking formulation w.r.t.,method,2
721,the node distances that exploits the natural ordering between the nodes imposed by the network structure.,result,3
722,"Experiments on real world networks demonstrate the high performance of our approach, outperforming state-of-the-art network embedding methods on several different tasks.",result,3
723,Most research in text classification to date has used a “bag of words” representation in which each feature corresponds to a single word.,background,0
724,"This paper examines some alternative ways to represent text based on syntactic and semantic relationships between words (phrases, synonyms and hypernyms).",background,0
725,We describe the new representations and try to justify our hypothesis that they could improve the performance of a rule-based learner.,method,2
726,The representations are evaluated using the RIPPER learning algorithm on the Reuters-21578 and DigiTrad test corpora.,method,2
727,On their own the new representations are not found to produce significant performance improvements.,method,2
728,"We also try combining classifiers based on different representations using a majority voting technique, and this improves performance on both test collections.",method,2
729,"In our opinion, more sophisticated Natural Language Processing techniques need to be developed before better text representations can be produced for classification.",result,3
730,Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or assembly contigs against a large reference genome such as human.,background,0
731,"It automatically chooses between local and end-to-end alignments, supports paired-end reads and performs chimeric alignment.",background,0
732,The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases.,background,0
733,"For mapping 100bp sequences, BWA-MEM shows better performance than several state-of-art read aligners to date.",result,3
734,"Availability and implementation: BWA-MEM is implemented as a component of BWA, which is available at http://github.com/lh3/bwa.",other,4
735,Contact: hengli@broadinstitute.org,other,4
736,This paper presents Smart Home concepts for Internet of Things (IoT) technologies that will make life at home more convenient.,objective,1
737,"In this paper, we first describe the overall design of a low-cost Smart Refrigerator built with Raspberry Pi.",objective,1
738,"Next, we explain two sensors controlling each camera, which are hooked up to our Rasberry Pi board.",method,2
739,We further show how the user can use the Graphical User Interface (GUI) to interact with our system.,method,2
740,"With this Smart Home and Internet of Things technology, a user-friendly graphical user interface, prompt data synchronization among multiple devices, and real-time actual images captured from the refrigerator, our system can easily assist a family to reduce food waste.",result,3
741,"Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features.",background,0
742,"Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful.",background,0
743,Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted.,background,0
744,"In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors (Kiros et al., 2015) on a wide range of transfer tasks.",method,2
745,"Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks.",result,3
746,Our encoder is publicly available1.,other,4
747,"As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years.",background,0
748,"At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research.",background,0
749,"Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications.",background,0
750,"For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem.",background,0
751,"In other words, current systems are still far away from the capability of the human perception system.",background,0
752,This paper provides an up-to-date critical survey of still- and video-based face recognition research.,objective,1
753,"There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces.",method,2
754,"To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category.",method,2
755,"In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered.",result,3
756,In this paper we propose a design of the main modulation and demodulation units of a modem compliant with the new DVB-S2 standard (Int.,objective,1
757,J. Satellite Commun.,other,4
758,2004; 22:249–268).,other,4
759,A typical satellite channel model consistent with the targeted applications of the aforementioned standard is assumed.,method,2
760,"In particular, non-linear pre-compensation as well as synchronization techniques are described in detail and their performance assessed by means of analysis and computer simulations.",method,2
761,"The proposed algorithms are shown to provide a good trade-off between complexity and performance and they apply to both the broadcast and the unicast profiles, the latter allowing the exploitation of adaptive coding and modulation (ACM) (Proceedings of the 20th AIAA Satellite Communication Systems Conference, Montreal, AIAA-paper 2002-1863, May 2002).",method,2
762,"Finally, end-to-end system performances in term of BER versus the signal-to-noise ratio are shown as a result of extensive computer simulations.",result,3
763,"The whole communication chain is modelled in these simulations, including the BCH and LDPC coder, the modulator with the pre-distortion techniques, the satellite transponder model with its typical impairments, the downlink chain inclusive of the RF-front-end phase noise, the demodulator with the synchronization sub-system units and finally the LDPC and BCH decoders.",result,3
764,"Copyright # 2004 John Wiley & Sons, Ltd.",other,4
765,"This paper proposes a novel control scheme of single-phase-to-three-phase pulsewidth-modulation (PWM) converters for low-power three-phase induction motor drives, where a single-phase half-bridge PWM rectifier and a two-leg inverter are used.",objective,1
766,"With this converter topology, the number of switching devices is reduced to six from ten in the case of full-bridge rectifier and three-leg inverter systems.",method,2
767,"In addition, the source voltage sensor is eliminated with a state observer, which controls the deviation between the model current and the system current to be zero.",method,2
768,"A simple scalar voltage modulation method is used for a two-leg inverter, and a new technique to eliminate the effect of the dc-link voltage ripple on the inverter output current is proposed.",method,2
769,"Although the converter topology itself is of lower cost than the conventional one, it retains the same functions such as sinusoidal input current, unity power factor, dc-link voltage control, bidirectional power flow, and variable-voltage and variable-frequency output voltage.",method,2
770,The experimental results for the V/f control of 3-hp induction motor drives controlled by a digital signal processor TMS320C31 chip have verified the effectiveness of the proposed scheme,result,3
771,"Very little is known about the neural circuitry guiding anger, angry rumination, and aggressive personality.",background,0
772,"In the present fMRI experiment, participants were insulted and induced to ruminate.",background,0
773,Activity in the dorsal anterior cingulate cortex was positively related to self-reported feelings of anger and individual differences in general aggression.,background,0
774,Activity in the medial prefrontal cortex was related to self-reported rumination and individual differences in displaced aggression.,method,2
775,"Increased activation in the hippocampus, insula, and cingulate cortex following the provocation predicted subsequent self-reported rumination.",result,3
776,These findings increase our understanding of the neural processes associated with the risk for aggressive behavior by specifying neural regions that mediate the subjective experience of anger and angry rumination as well as the neural pathways linked to different types of aggressive behavior.,result,3
777,Head movement prediction is the key enabler for the emerging 360-degree videos since it can enhance both streaming and rendering efficiency.,background,0
778,"To achieve accurate head movement prediction, it becomes imperative to understand user's visual attention on 360-degree videos under head-mounted display (HMD).",background,0
779,"Despite the rich history of saliency detection research, we observe that traditional models are designed for regular images/videos fixed at a single viewport and would introduce problems such as central bias and multi-object confusion when applied to the multi-viewport 360-degree videos switched by user interaction.",result,3
780,"To fill in this gap, this paper shifts the traditional single-viewport saliency models that have been extensively studied for decades to a fresh panoramic saliency detection specifically tailored for 360-degree videos, and thus maximally enhances the head movement prediction performance.",method,2
781,"The proposed head movement prediction framework is empowered by a newly created dataset for 360-degree video saliency, a panoramic saliency detection model and an integration of saliency and head tracking history for the ultimate head movement prediction.",method,2
782,Experimental results demonstrate the measurable gain of both the proposed panoramic saliency detection and head movement prediction over traditional models for regular images/videos.,result,3
783,"Since its inception, the blockchain technology has shown promising application prospects.",background,0
784,"From the initial cryptocurrency to the current smart contract, blockchain has been applied to many fields.",background,0
785,"Although there are some studies on the security and privacy issues of blockchain, there lacks a systematic examination on the security of blockchain systems.",background,0
786,"In this paper, we conduct a systematic study on the security threats to blockchain and survey the corresponding real attacks by examining popular blockchain systems.",result,3
787,"We also review the security enhancement solutions for blockchain, which could be used in the development of various blockchain systems, and suggest some future directions to stir research efforts into this area.",result,3
788,"We have long envisioned that one day computers will understand natural language and anticipate what we need, when and where we need it, and proactively complete tasks on our behalf.",background,0
789,"As computers get smaller and more pervasive, how humans interact with them is becoming a crucial issue.",background,0
790,"Despite numerous attempts over the past 30 years to make language understanding (LU) an effective and robust natural user interface for computer interaction, success has been limited and scoped to applications that were not particularly central to everyday use.",background,0
791,"However, speech recognition and machine learning have continued to be refined, and structured data served by applications and content providers has emerged.",background,0
792,"These advances, along with increased computational power, have broadened the application of natural LU to a wide spectrum of everyday tasks that are central to a user's productivity.",method,2
793,"We believe that as computers become smaller and more ubiquitous [e.g., wearables and Internet of Things (IoT)], and the number of applications increases, both system-initiated and user-initiated task completion across various applications and web services will become indispensable for personal life management and work productivity.",result,3
794,"In this article, we give an overview of personal digital assistants (PDAs); describe the system architecture, key components, and technology behind them; and discuss their future potential to fully redefine human?computer interaction.",result,3
795,"Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers.",background,0
796,Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior.,background,0
797,"Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data.",background,0
798,We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge.,method,2
799,"Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs.",method,2
800,"Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN.",method,2
801,"We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN.",method,2
802,"To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API.",method,2
803,We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute.,result,3
804,"We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes.",result,3
805,Datasets originating from social networks are very valuable to many fields such as sociology and psychology.,background,0
806,"However, the supports from technical perspective are far from enough, and specific approaches are urgently in need.",background,0
807,This paper applies data mining to psychology area for detecting depressed users in social network services.,objective,1
808,"Firstly, a sentiment analysis method is proposed utilizing vocabulary and man-made rules to calculate the depression inclination of each micro-blog.",method,2
809,"Secondly, a depression detection model is constructed based on the proposed method and 10 features of depressed users derived from psychological research.",method,2
810,"Then 180 users and 3 kinds of classifiers are used to verify the model, whose precisions are all around 80%.",method,2
811,"Also, the significance of each feature is analyzed.",result,3
812,"Lastly, an application is developed within the proposed model for mental health monitoring online.",result,3
813,"This study is supported by some psychologists, and facilitates them in data-centric aspect in turn.",result,3
814,"Next-generation wireless networks must support ultra-reliable, low-latency communication and intelligently manage a massive number of Internet of Things (IoT) devices in real-time, within a highly dynamic environment.",background,0
815,This need for stringent communication quality-of-service (QoS) requirements as well as mobile edge and core intelligence can only be realized by integrating fundamental notions of artificial intelligence (AI) and machine learning across the wireless infrastructure and end-user devices.,background,0
816,"In this context, this paper provides a comprehensive tutorial that introduces the main concepts of machine learning, in general, and artificial neural networks (ANNs), in particular, and their potential applications in wireless communications.",objective,1
817,"For this purpose, we present a comprehensive overview on a number of key types of neural networks that include feed-forward, recurrent, spiking, and deep neural networks.",method,2
818,"For each type of neural network, we present the basic architecture and training procedure, as well as the associated challenges and opportunities.",method,2
819,"Then, we provide an in-depth overview on the variety of wireless communication problems that can be addressed using ANNs, ranging from communication using unmanned aerial vehicles to virtual reality and edge caching.",method,2
820,"For each individual application, we present the main motivation for using ANNs along with the associated challenges while also providing a detailed example for a use case scenario and outlining future works that can be addressed using ANNs.",method,2
821,"In a nutshell, this article constitutes one of the first holistic tutorials on the development of machine learning techniques tailored to the needs of future wireless networks.",method,2
822,This research was supported by the U.S. National Science Foundation under Grants CNS-1460316 and IIS-1633363.,other,4
823,ar X iv :1 71 0.,other,4
824,We investigate architectures of discriminatively trained deep Convolutional Networks (ConvNets) for action recognition in video.,background,0
825,The challenge is to capture the complementary information on appearance from still frames and motion between frames.,objective,1
826,We also aim to incorporate into the network design aspects of the best performing hand-crafted features.,method,2
827,Our contribution is three-fold.,method,2
828,"First, we propose a two-stream ConvNet architecture which incorporates spatial and temporal networks.",method,2
829,"Second, we demonstrate that a ConvNet trained on multi-frame dense optical flow is able to achieve very good performance in spite of limited training data.",method,2
830,"Finally, we show that multitask learning, applied to two different action classification datasets, can be used to increase the amount of training data and improve the performance on both.",method,2
831,"Our architecture is trained and evaluated on the standard video actions benchmarks of UCF-101 and HMDB-51, where it matches the state of the art.",result,3
832,It also exceeds by a large margin previous attempts to use deep nets for video classification.,result,3
833,"Despite the relatively recent emergence of the Unified Theory of Acceptance and Use of Technology (UTAUT), the originating article has already been cited by a large number of studies, and hence it appears to have become a popular theoretical choice within the field of information system (IS)/information technology (IT) adoption and diffusion.",background,0
834,"However, as yet there have been no attempts to analyse the reasons for citing the originating article.",background,0
835,Such a systematic review of citations may inform researchers and guide appropriate future use of the theory.,background,0
836,"This paper therefore presents the results of a systematic review of 450 citations of the originating article in an attempt to better understand the reasons for citation, use and adaptations of the theory.",background,0
837,"Findings revealed that although a large number of studies have cited the originating article since its appearance, only 43 actually utilised the theory or its constructs in their empirical research for examining IS/IT related issues.",result,3
838,This chapter also classifies and discusses these citations and explores the limitations of UTAUT use in existing research.,result,3
839,"Monitoring, predicting and understanding tra c conditions in a city is an important problem for city planning and environmental monitoring.",background,0
840,GPS-equipped taxis can be viewed as pervasive sensors and the large-scale digital traces produced allow us to have a unique view of the underlying dynamics of a city’s road network.,background,0
841,"In this paper, we propose a method to construct a model of tra c density based on large scale taxi traces.",objective,1
842,This model can be used to predict future tra c conditions and estimate the e↵ect of emissions on the city’s air quality.,method,2
843,"We argue that considering tra c density on its own is insu cient for a deep understanding of the underlying tra c dynamics, and hence propose a novel method for automatically determining the capacity of each road segment.",method,2
844,We evaluate our methods on a large scale database of taxi GPS logs and demonstrate their outstanding performance.,result,3
845,We use single-agent and multi-agent Reinforcement Learning (RL) for learning dialogue policies in a resource allocation negotiation scenario.,background,0
846,Two agents learn concurrently by interacting with each other without any need for simulated users (SUs) to train against or corpora to learn from.,background,0
847,"In particular, we compare the Qlearning, Policy Hill-Climbing (PHC) and Win or Learn Fast Policy Hill-Climbing (PHC-WoLF) algorithms, varying the scenario complexity (state space size), the number of training episodes, the learning rate, and the exploration rate.",objective,1
848,Our results show that generally Q-learning fails to converge whereas PHC and PHC-WoLF always converge and perform similarly.,objective,1
849,We also show that very high gradually decreasing exploration rates are required for convergence.,result,3
850,We conclude that multiagent RL of dialogue policies is a promising alternative to using single-agent RL and SUs or learning directly from corpora.,result,3
851,"Neural networks, as powerful tools for data mining and knowledge engineering, can learn from data to build feature-based classifiers and nonlinear predictive models.",background,0
852,"Training neural networks involves the optimization of nonconvex objective functions, and usually, the learning process is costly and infeasible for applications associated with data streams.",background,0
853,"A possible, albeit counterintuitive, alternative is to randomly assign a subset of the networks’ weights so that the resulting optimization task can be formulated as a linear least-squares problem.",background,0
854,"This methodology can be applied to both feedforward and recurrent networks, and similar techniques can be used to approximate kernel functions.",method,2
855,"Many experimental results indicate that such randomized models can reach sound performance compared to fully adaptable ones, with a number of favorable benefits, including (1) simplicity of implementation, (2) faster learning with less intervention from human beings, and (3) possibility of leveraging overall linear regression and classification algorithms (e.g., l1 norm minimization for obtaining sparse formulations).",result,3
856,"This class of neural networks attractive and valuable to the data mining community, particularly for handling large scale data mining in real-time.",result,3
857,"However, the literature in the field is extremely vast and fragmented, with many results being reintroduced multiple times under different names.",method,2
858,"This overview aims to provide a self-contained, uniform introduction to the different ways in which randomization can be applied to the design of neural networks and kernel functions.",method,2
859,"A clear exposition of the basic framework underlying all these approaches helps to clarify innovative lines of research, open problems, and most importantly, foster the exchanges of well-known results throughout different communities.",method,2
860,"© 2017 John Wiley & Sons, Ltd",result,3
861,"Currently, online social networks such as Facebook, Twitter, Google+, LinkedIn, and Foursquare have become extremely popular all over the world and play a significant role in people¿s daily lives.",background,0
862,People access OSNs using both traditional desktop PCs and new emerging mobile devices.,background,0
863,"With more than one billion users worldwide, OSNs are a new venue of innovation with many challenging research problems.",background,0
864,"In this survey, we aim to give a comprehensive review of state-of-the-art research related to user behavior in OSNs from several perspectives.",objective,1
865,"First, we discuss social connectivity and interaction among users.",method,2
866,"Also, we investigate traffic activity from a network perspective.",method,2
867,"Moreover, as mobile devices become a commodity, we pay attention to the characteristics of social behaviors in mobile environments.",method,2
868,"Last but not least, we review malicious behaviors of OSN users, and discuss several solutions to detect misbehaving users.",method,2
869,Our survey serves the important roles of both providing a systematic exploration of existing research highlights and triggering various potentially significant research in these topics.,result,3
870,This article provides a comprehensive review of research articles related to the application of decision support and intelligent systems in the textile and apparel supply chains.,objective,1
871,Data were obtained from 77 articles published from 1994 to 2009 in 35 journals.,result,3
872,"The articles were categorized according to their applicability into three basic sectors – textile production, apparel manufacture, and distribution/sales.",method,2
873,They were further categorized into 16 subsectors based on their operational and management/control processes.,method,2
874,A comprehensive list of categorized journal articles identified in this study provides insights and relevant references for both researchers and practitioners on the application of decision support and intelligent systems to various stages of a textile and apparel supply chain.,method,2
875,"In light of the developed classification framework, we identify gaps in extending the use of the decision support and artificial intelligent systems in the industry and suggest potential and applicable research areas for further consideration in this subject area.",result,3
876,2013 Elsevier Ltd. All rights reserved.,other,4
877,"If you find yourself in need of a resource book for numerical computing that contains advice and solutions for many of your everyday numerical computing problems, then this may just be the book for you.",background,0
878,"The lineage of the the Numerical Recipes books goes back to the mid 1980's, when I can recall using recipes in both FORTRAN and C. This was at the advent of the internet and before the open source software movement, so having a resource such as this was valuable.",background,0
879,"Not only did the book give advice for solving numerical problems, but it was also possible to avoid a lot of typing by purchasing the companion code CD.",background,0
880,The software alternatives were expensive and did not come with the discourse given in the Numerical Recipe book.,result,3
881,"Today, this third edition of Numerical Recipes remains a broad one volume tome for numerically solving a wide range of mathematical , statistical, and computational problems.",method,2
882,The code for this book is done with C++.,method,2
883,In the preface it is pointed out that several hundred pages of new material have been added.,method,2
884,This new materi,other,4
885,The organizations today need to apply proper IT governance for beneficial IT investments.,background,0
886,This research focuses on how the organization structure should be done through the IT governance mechanisms application.,objective,1
887,A case study is done in a large Swedish constructing company using the ISO/IEC 38500:2008 IT governance standard.,method,2
888,"Several IT governance practices related to the ISO/IEC 38500:2008 standard were identified which were mostly related to “Responsibility”, “Strategy” and “Performance” compared to “Conformance” and “Acquisition” principals.",method,2
889,The results reveal the importance of the way that the company has chosen to structure its organization around an IT project in their IT Governance mechanisms.,result,3
890,This is closely linked to the principle of “Responsibility”.,result,3
891,Practically the standard can be used in future IT projects and the practices found in this study can be beneficial for analyzing and achieving an effective IT Governance implementation.,result,3
892,The goal of dataset editing in instance-based learning is to remove objects from a training set in order to increase the accuracy of a classifier.,objective,1
893,"For example, Wilson editing removes training examples that are misclassified by a nearest neighbor classifier so as to smooth the shape of the resulting decision boundaries.",objective,1
894,This paper revolves around the use of representative-based clustering algorithms for nearest neighbor dataset editing.,method,2
895,We term this approach supervised clustering editing.,result,3
896,The main idea is to replace a dataset by a set of cluster prototypes.,objective,1
897,A clustering approach called supervised clustering is introduced for this purpose.,method,2
898,Our empirical evaluation using eight UCI datasets shows that both Wilson and supervised clustering editing improve accuracy on more than 50% of the datasets tested.,result,3
899,"However, supervised clustering editing achieves four times higher compression rates than Wilson editing.",result,3
900,This paper presents a novel technique for camera tampering detection.,objective,1
901,It is implemented in real-time and was developed for use in surveillance and security applications.,background,0
902,This method identifies camera tampering by detecting large differences between older frames of video and more recent frames.,method,2
903,A buffer of incoming video frames is kept and three different measures of image dissimilarity are used to compare the frames.,method,2
904,"After normalization, a set of conditions is tested to decide if camera tampering has occurred.",method,2
905,The effects of adjusting the internal parameters of the algorithm are examined.,method,2
906,The performance of this method is shown to be extremely favorable in real-world settings.,result,3
907,Research in socio-technical factors in computer security has traditionally focused on employees and their work practice within the premises of the organization.,background,0
908,"However, with universal access to computing and the diverse means of connecting such devices to each another and to the global Internet, work carried out has shifted outside one central physical location to encompass a variety of possible points-of-access that include homes, modern cafés, and public libraries.",background,0
909,"Given the ubiquity of wireless devices used for last-hop access to the Internet from home, we look at the security of home wireless networks.",background,0
910,"In this work, we identify the variables that affect the decision of home wireless network users to implement security features on their networks.",objective,1
911,Our study is based on the protection motivation theory.,method,2
912,A survey was conducted on 189 home users to identify and characterize predictors that differentiate between users who secure their home wireless networks and those who don’t.,method,2
913,"Results of the analysis identified the following variables as significant: perceived severity, response efficacy, self efficacy, and response cost.",result,3
914,Cloud computing is a powerful technology to perform massive-scale and complex computing.,background,0
915,"It eliminates the need to maintain expensive computing hardware, dedicated space, and software.",objective,1
916,Massive growth in the scale of data or big data generated through cloud computing has been observed.,result,3
917,Addressing big data is a challenging and timedata processing and analysis.,method,2
918,The rise of big data in cloud computing is reviewed in this study.,method,2
919,"The definition, characteristics, and classification of big data along with some discussions on cloud computing are introduced.",objective,1
920,"The relationship between big data and cloud computing, big data storage systems, and Hadoop technology are also discussed.",objective,1
921,"Furthermore, research challenges are investigated, with focus on scalability, availability, data integrity, data transformation, data quality, data heterogeneity, privacy, legal and regulatory issues, and governance.",objective,1
922,"Lastly, open research issues that require substantial research efforts are summarized.",result,3
923,& 2014 Elsevier Ltd. All rights reserved.,other,4
924,The widely popular browser extensions now become one of the most commonly used malware attack vectors.,background,0
925,"The Google Chrome browser, which implements the principles of least privileges and privilege separation by design, offers a strong security mechanism to protect malicious websites from damaging the whole browser system via extensions.",background,0
926,"In this study, we however reveal that Chrome’s extension security model is not a panacea for all possible attacks with browser extensions.",objective,1
927,"Through a series of practical bot-based attacks that can be performed even under typical settings, we demonstrate that malicious Chrome extensions pose serious threats, including both information dispersion and harvesting, to browsers.",method,2
928,"We further conduct an in-depth analysis of Chrome’s extension security model, and conclude that its vulnerabilities are rooted fro m the violation of the principles of least privileges and priv ilege separation.",method,2
929,"Following these principles, we propose a set of countermeasures that enforce the policies of microprivilege management and differentiating DOM elements.",method,2
930,"Using a prototype developed on the latest Chrome browser, we show that they can effectively mitigate the threats posed by malicious Chrome extensions with little effect on normal browsing experience.",result,3
931,"ial gital ce, on.",other,4
932,al 003 Abstract.,other,4
933,Many different descriptions of Retinex methods of lightness computation exist.,background,0
934,We provide concise MATLABTM implementations of two of the spatial techniques of making pixel comparisons.,method,2
935,"The code is presented, along with test results on several images and a discussion of the results.",method,2
936,We also discuss the calibration of input images and the postRetinex processing required to display the output images.,method,2
937,© 2004 SPIE and IS&T. [DOI: 10.1117/1.1636761],other,4
938,Rectified activation units (rectifiers) are essential for state-of-the-art neural networks.,background,0
939,"In this work, we study rectifier neural networks for image classification from two aspects.",objective,1
940,"First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit.",method,2
941,PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk.,result,3
942,"Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities.",method,2
943,This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures.,method,2
944,"Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset.",result,3
945,"This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]).",result,3
946,"To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.",result,3
947,"Baeza-Yates, R. and IM.",background,0
948,"Rignier, Fast two-dimensional pattern matching, Information Processing Letters 45 (1993) 51-57.",background,0
949,An algorithm for searching for a two-dimensional m X m pattern in a two-dimensional n x II text is presented.,method,2
950,It performs on the average less comparisons than the size of the text: n’/m using ma e.xtra space.,method,2
951,"Basically, it uses multiple string matching on only n/m rows of the text.",method,2
952,It runs in at most 2nz time and is close to the optimal n’ time for many patterns.,method,2
953,It steadily extends to an alphabet-independent algorithm with a similar worst case.,method,2
954,Experimental results are included for a practical version.,method,2
955,The problem of finding the minimal spanning tree on an undirected weighted graph has been investigated by many people and O(nZ) algorithms are well known.,background,0
956,"P. M. Spira and A. Pan (Siam J. Computing 4 (1975), 375-380) present an O(n) algorithm for updating the minimal spanning tree if a new vertex is inserted into the graph.",background,0
957,"In this paper, we present another O(n) algorithm simpler than that presented by Spira and Pan for the insertion of a vertex.",method,2
958,Spira and Pan further show that the deletion of a vertex requires O(3) steps.,method,2
959,"If all the vertices are considered, O(ns) steps may be used.",method,2
960,The algorithm which we present here takes only O(n2) steps and labels the vertices of the graph in such a way that any vertex may be deleted from the graph and the minimal spanning tree can be updated in constant time.,method,2
961,Similar results are obtained for the insertion and the deletion of an edge.,result,3
962,"In this paper we present the UMUX-LITE, a two-item questionnaire based on the Usability Metric for User Experience (UMUX) [6].",background,0
963,The UMUX-LITE items are This system's capabilities meet my requirements and This system is easy to use.,background,0
964,""" Data from two independent surveys demonstrated adequate psychometric quality of the questionnaire.",result,3
965,Estimates of reliability were .82 and .83 -- excellent for a two-item instrument.,result,3
966,"Concurrent validity was also high, with significant correlation with the SUS (.81, .81) and with likelihood-to-recommend (LTR) scores (.74, .73).",result,3
967,The scores were sensitive to respondents' frequency-of-use.,result,3
968,"UMUX-LITE score means were slightly lower than those for the SUS, but easily adjusted using linear regression to match the SUS scores.",result,3
969,"Due to its parsimony (two items), reliability, validity, structural basis (usefulness and usability) and, after applying the corrective regression formula, its correspondence to SUS scores, the UMUX-LITE appears to be a promising alternative to the SUS when it is not desirable to use a 10-item instrument.",result,3
970,The diverse ways in which technologies are modified and appropriated into local contexts are an important theme in CSCW research.,background,0
971,"Today, translocal processes such as the formation of international corporations and the movement of people and ideas across nation states increasingly shape these local contexts of technology use and design.",background,0
972,We draw from prior work on appropriation in CSCW and meld it with work from transnational studies to illustrate appropriation as a cultural phenomenon and as it unfolds in relation to emerging translocal processes.,background,0
973,We ground our explorations in findings from ethnographic research on collaborations and exchange among IT professionals in urban China.,background,0
974,This work makes two main contributions.,objective,1
975,"First, it expands CSCW's focus on socio-technical systems by taking seriously socio-political and socio-economic processes.",objective,1
976,"Second, it contributes to debates on cross-cultural and global technological development by employing transnational imagination as an analytical tool.",objective,1
977,"A variety of real-life mobile sensing applications are becoming available, especially in the life-logging, fitness tracking and health monitoring domains.",background,0
978,These applications use mobile sensors embedded in smart phones to recognize human activities in order to get a better understanding of human behavior.,background,0
979,"While progress has been made, human activity recognition remains a challenging task.",background,0
980,This is partly due to the broad range of human activities as well as the rich variation in how a given activity can be performed.,background,0
981,Using features that clearly separate between activities is crucial.,background,0
982,"In this paper, we propose an approach to automatically extract discriminative features for activity recognition.",method,2
983,"Specifically, we develop a method based on Convolutional Neural Networks (CNN), which can capture local dependency and scale invariance of a signal as it has been shown in speech recognition and image recognition domains.",method,2
984,"In addition, a modified weight sharing technique, called partial weight sharing, is proposed and applied to accelerometer signals to get further improvements.",method,2
985,"The experimental results on three public datasets, Skoda (assembly line activities), Opportunity (activities in kitchen), Actitracker (jogging, walking, etc.), indicate that our novel CNN-based approach is practical and achieves higher accuracy than existing state-of-the-art methods.",result,3
986,Abstract-Sign language is a lingua among the speech and the hearing impaired community.,background,0
987,It is hard for most people who are not familiar with sign language to communicate without an interpreter.,background,0
988,"Sign language recognition appertains to track and recognize the meaningful emotion of human made with fingers, hands, head, arms, face etc.",background,0
989,"The technique that has been proposed in this work, transcribes the gestures from a sign language to a spoken language which is easily understood by the hearing.",objective,1
990,"The gestures that have been translated include alphabets, words from static images.",objective,1
991,This becomes more important for the people who completely rely on the gestural sign language for communication tries to communicate with a person who does not understand the sign language.,objective,1
992,"We aim at representing features which will be learned by a technique known as convolutional neural networks (CNN), contains four types of layers: convolution layers, pooling/subsampling layers, nonlinear layers, and fully connected layers.",objective,1
993,The new representation is expected to capture various image features and complex non-linear feature interactions.,method,2
994,A softmax layer will be used to recognize signs.,result,3
995,"Keywords-Convolutional Neural Networks, Softmax (key words) __________________________________________________*****_________________________________________________",result,3
996,"The rapid advance of mobile computing technology and wireless networking, there is a significant increase of mobile subscriptions.",background,0
997,This drives a strong demand for mobile cloud applications and services for mobile device users.,background,0
998,This brings out a great business and research opportunity in mobile cloud computing (MCC).,objective,1
999,This paper first discusses the market trend and related business driving forces and opportunities.,method,2
1000,"Then it presents an overview of MCC in terms of its concepts, distinct features, research scope and motivations, as well as advantages and benefits.",method,2
1001,"Moreover, it discusses its opportunities, issues and challenges.",method,2
1002,"Furthermore, the paper highlights a research roadmap for MCC.",method,2
1003,"In the Internet of Things (IoT) scenario, the block-chain and, in general, Peer-to-Peer approaches could play an important role in the development of decentralized and dataintensive applications running on billion of devices, preserving the privacy of the users.",background,0
1004,"Our research goal is to understand whether the blockchain and Peer-to-Peer approaches can be employed to foster a decentralized and private-by-design IoT. As a first step in our research process, we conducted a Systematic Literature Review on the blockchain to gather knowledge on the current uses of this technology and to document its current degree of integrity, anonymity and adaptability.",objective,1
1005,We found 18 use cases of blockchain in the literature.,background,0
1006,Four of these use cases are explicitly designed for IoT. We also found some use cases that are designed for a private-by-design data management.,background,0
1007,"We also found several issues in the integrity, anonymity and adaptability.",background,0
1008,"Regarding anonymity, we found that in the blockchain only pseudonymity is guaranteed.",result,3
1009,"Regarding adaptability and integrity, we discovered that the integrity of the blockchain largely depends on the high difficulty of the Proof-of-Work and on the large number of honest miners, but at the same time a difficult Proof-of-Work limits the adaptability.",result,3
1010,"We documented and categorized the current uses of the blockchain, and provided a few recommendations for future work to address the above-mentioned issues.",result,3
1011,"Although Generative Adversarial Networks (GANs) have shown remarkable success in various tasks, they still face challenges in generating high quality images.",background,0
1012,"In this paper, we propose Stacked Generative Adversarial Networks (StackGANs) aimed at generating high-resolution photo-realistic images.",objective,1
1013,"First, we propose a two-stage generative adversarial network architecture, StackGAN-v1, for text-to-image synthesis.",method,2
1014,"The Stage-I GAN sketches the primitive shape and colors of a scene based on a given text description, yielding low-resolution images.",method,2
1015,"The Stage-II GAN takes Stage-I results and the text description as inputs, and generates high-resolution images with photo-realistic details.",method,2
1016,"Second, an advanced multi-stage generative adversarial network architecture, StackGAN-v2, is proposed for both conditional and unconditional generative tasks.",method,2
1017,Our StackGAN-v2 consists of multiple generators and multiple discriminators arranged in a tree-like structure; images at multiple scales corresponding to the same scene are generated from different branches of the tree.,method,2
1018,StackGAN-v2 shows more stable training behavior than StackGAN-v1 by jointly approximating multiple distributions.,result,3
1019,Extensive experiments demonstrate that the proposed stacked generative adversarial networks significantly outperform other state-of-the-art methods in generating photo-realistic images.,result,3
1020,Empathy allows emotional psychological inference about other person's mental states and feelings in social contexts.,background,0
1021,We aimed at specifying the common and differential neural mechanisms of self- and other-related attribution of emotional states using event-related functional magnetic resonance imaging.,background,0
1022,Subjects viewed faces expressing emotions with direct or averted gaze and either focused on their own emotional response to each face (self-task) or evaluated the emotional state expressed by the face (other-task).,objective,1
1023,"The common network activated by both tasks included the left lateral orbito-frontal and medial prefrontal cortices (MPFC), bilateral inferior frontal cortices, superior temporal sulci and temporal poles, as well as the right cerebellum.",background,0
1024,"In a subset of these regions, neural activity was significantly correlated with empathic abilities.",method,2
1025,"The self- (relative to the other-) task differentially activated the MPFC, the posterior cingulate cortex (PCC)/precuneus, and the temporo-parietal junction bilaterally.",background,0
1026,Empathy-related processing of emotional facial expressions recruited brain areas involved in mirror neuron and theory-of-mind (ToM) mechanisms.,objective,1
1027,"The differential engagement of the MPFC, the PCC/precuneus, and temporo-parietal regions in the self-task indicates that these structures act as key players in the evaluation of one's own emotional state during empathic face-to-face interaction.",method,2
1028,Activation of mirror neurons in a task relying on empathic abilities without explicit task-related motor components supports the view that mirror neurons are not only involved in motor cognition but also in emotional interpersonal cognition.,result,3
1029,An interplay between ToM and mirror neuron mechanisms may hold for the maintenance of a self-other distinction during empathic interpersonal face-to-face interactions.,result,3
1030,Digital Analog Simulation (DAS) is a programming technique which makes a digital computer operate much like an analog computer.,background,0
1031,The application of the technique to programming an IBM 7090 computer is described.,background,0
1032,"Although it is not intended primarily as an analog computer simulator, the similarity of DAS programming to analog programming is readily apparent.",objective,1
1033,DAS combines remarkable ease and speed of programming with reasonably high computing speed.,objective,1
1034,The DAS input language is designed to permit a simple and concise description of an analog-style block diagram of the problem to be solved.,objective,1
1035,"The blocks in the diagram are restricted to summers, integrators, multipliers, limiters, relays and other ""components"" for which macro-instructions appear in the DAS compiler.",method,2
1036,"The construction of a DAS block diagram is more straight-forward than an analog computer block diagram because there is virtually no restriction on the number of available components, and because no amplitude scaling is required.",method,2
1037,The standard output format provides a complete record of the problem by printing the entire input program and all input data.,method,2
1038,This is followed by a multiple column table of sequential values of the desired output quantities.,method,2
1039,These columns of data serve the same purpose as the recording channels of a conventional analog computer output device in that each column provides a complete history of one variable.,method,2
1040,Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms.,background,0
1041,Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves.,background,0
1042,"However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks.",background,0
1043,"Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks.",method,2
1044,"In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes.",method,2
1045,"We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods.",method,2
1046,"Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations.",method,2
1047,We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains.,result,3
1048,"Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.",result,3
1049,A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user's interest.,background,0
1050,"A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model.",background,0
1051,Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive.,background,0
1052,The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications.,method,2
1053,This paper proposes a new fast learning technique to learn a large number of individual user profiles.,method,2
1054,The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens.,result,3
1055,This research aims to prototype a small smart off-grid solar cell system.,objective,1
1056,o provide an alternative electrical supply for a smart Lingzhi mushroom farm.,objective,1
1057,"This research applied the use of IOT with voltage and current sensors to measure and monitor the voltage of solar cell charging, amp (ampere) of current charging from the solar panel into a battery and (ampere) of current loading from a battery to the irrigation systems (fog and sprinkler pumps).",method,2
1058,Voltage and current data processed through Blynk was developed as an IOT cloud service.,method,2
1059,Data was stored into the Blynk and displayed on mobile devices in real time.,method,2
1060,"The functional status (switching on and off for periods of time, current consumption) pushes notifications through Blynk IOT cloud service on the Blynk application.",method,2
1061,"The equipment and tools used in this research were NodeMCU, voltage and current sensors, relay modules, DC sprinkler, and fog pumps.",method,2
1062,A small off-grid solar cell was applied.,method,2
1063,"The solar cell system consists of a charger, battery, and solar panels.",result,3
1064,The IOT cloud used is Blynk.,background,0
1065,Power-efficient design requires reducing power dissipation in all parts of the design and during all stages of the design process subject to constraints on the system performance and quality of service (QoS).,background,0
1066,"Power-aware high-level language compilers, dynamic power management policies, memory management schemes, bus encoding techniques, and hardware design tools are needed to meet these often-conflicting design requirements.",background,0
1067,"This paper reviews techniques and tools for power-efficient embedded system design, considering the hardware platform, the application software, and the system software.",method,2
1068,Design examples from an Intel StrongARM based system are provided to illustrate the concepts and the techniques.,method,2
1069,"This paper is not intended as a comprehensive review, rather as a starting point for understanding power-aware design methodologies and techniques targeted toward embedded systems.",objective,1
1070,Current end-to-end machine reading and question answering (Q&A) models are primarily based on recurrent neural networks (RNNs) with attention.,background,0
1071,"Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs.",background,0
1072,"We propose a new Q&A architecture called QANet, which does not require recurrent networks: Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions.",background,0
1073,"On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference, while achieving equivalent accuracy to recurrent models.",method,2
1074,The speed-up gain allows us to train the model with much more data.,result,3
1075,We hence combine our model with data generated by backtranslation from a neural machine translation model.,result,3
1076,"On the SQuAD dataset, our single model, trained with augmented data, achieves 84.6 F1 score1 on the test set, which is significantly better than the best published F1 score of 81.8.",result,3
1077,This paper examines the effect of technology scaling and microarchitectural trends on the rate of soft errors in CMOS memory and logic circuits.,background,0
1078,We describe and validate an end-to-end model that enables us to compute the soft error rates (SER) for existing and future microprocessor-style designs.,background,0
1079,"The model captures the effects of two important masking phenomena, electrical masking and latchingwindow masking, which inhibit soft errors in combinational logic.",objective,1
1080,We quantify the SER in combinational logic and latches for feature sizes from 600nm to 50nm and clock rates from 16 to 6 fan-out-of-4 delays.,method,2
1081,Our model predicts that the SER per chip of logic circuits will increase eight orders of magnitude by the year 2011 and at that point will be comparable to the SER per chip of unprotected memory elements.,method,2
1082,Our result emphasizes the need for computer system designers to address the risks of SER in logic circuits in future designs.,result,3
1083,Credit card fraud events take place frequently and then result in huge financial losses.,background,0
1084,Criminals can use some technologies such as Trojan or Phishing to steal the information of other people's credit cards.,background,0
1085,"Therefore, an effictive fraud detection method is important since it can identify a fraud in time when a criminal uses a stolen card to consume.",objective,1
1086,"One method is to make full use of the historical transaction data including normal transactions and fraud ones to obtain normal/fraud behavior features based on machine learning techniques, and then utilize these features to check if a transaction is fraud or not.",method,2
1087,"In this paper, two kinds of random forests are used to train the behavior features of normal and abnormal transactions.",method,2
1088,"We make a comparison of the two random forests which are different in their base classifiers, and analyze their performance on credit fraud detection.",method,2
1089,The data used in our experiments come from an e-commerce company in China.,result,3
1090,The recent explosive growth in convolutional neural network (CNN) research has produced a variety of new architectures for deep learning.,background,0
1091,"One intriguing new architecture is the bilinear CNN (B-CNN), which has shown dramatic performance gains on certain fine-grained recognition problems [15].",background,0
1092,"We apply this new CNN to the challenging new face recognition benchmark, the IARPA Janus Benchmark A (IJB-A) [12].",objective,1
1093,It features faces from a large number of identities in challenging real-world conditions.,background,0
1094,"Because the face images were not identified automatically using a computerized face detection system, it does not have the bias inherent in such a database.",method,2
1095,We demonstrate the performance of the B-CNN model beginning from an AlexNet-style network pre-trained on ImageNet.,method,2
1096,"We then show results for fine-tuning using a moderate-sized and public external database, FaceScrub [17].",result,3
1097,We also present results with additional fine-tuning on the limited training data provided by the protocol.,result,3
1098,"In each case, the fine-tuned bilinear model shows substantial improvements over the standard CNN.",result,3
1099,"Finally, we demonstrate how a standard CNN pre-trained on a large face database, the recently released VGG-Face model [20], can be converted into a B-CNN without any additional feature training.",result,3
1100,The estimation of the eye centres is used in several computer vision applications such as face recognition or eye tracking.,background,0
1101,"Especially for the latter, systems that are remote and rely on available light have become very popular and several methods for accurate eye centre localisation have been proposed.",background,0
1102,"Nevertheless, these methods often fail to accurately estimate the eye centres in difficult scenarios, e.g. low resolution, low contrast, or occlusions.",method,2
1103,We therefore propose an approach for accurate and robust eye centre localisation by using image gradients.,objective,1
1104,"We derive a simple objective function, which only consists of dot products.",objective,1
1105,The maximum of this function corresponds to the location where most gradient vectors intersect and thus to the eye’s centre.,method,2
1106,"Although simple, our method is invariant to changes in scale, pose, contrast and variations in illumination.",method,2
1107,We extensively evaluate our method on the very challenging BioID database for eye centre and iris localisation.,result,3
1108,"Moreover, we compare our method with a wide range of state of the art methods and demonstrate that our method yields a significant improvement regarding both accuracy and robustness.",result,3
1109,Pairwise key establishment is a fundamental service provided in secure sensor networks.,background,0
1110,"However, due to resource constraints, establishing pairwise keys is not a trivial task.",background,0
1111,"Recently, a random key pre-distribution scheme and its improvements have been proposed.",background,0
1112,The scheme proposed by Du et al. uses deployment knowledge to improve the performance and security of sensor networks.,method,2
1113,"However, this scheme assumes group-based deployment in which groups of nodes are deployed from horizontal grid points.",method,2
1114,This assumption limits applications of the scheme.,method,2
1115,"Therefore, in this paper, we propose an advanced key pre-distribution scheme in which different keys are logically mapped to two-dimensional positions, and the keys that are distributed to a node are determined by positions estimated using a node probability density function.",method,2
1116,The scheme can be applied to any deployment model provided the node probability density function has already been determined.,method,2
1117,"Furthermore, simulation results show that our scheme achieves higher connectivity than Du et al.'s scheme.",result,3
1118,"The K-nearest neighbor (KNN) classifier is one of the simplest and most common classifiers, yet its performance competes with the most complex classifiers in the literature.",background,0
1119,The core of this classifier depends mainly on measuring the distance or similarity between the tested example and the training examples.,background,0
1120,This raises a major question about which distance measures to be used for the KNN classifier among a large number of distance and similarity measures?,background,0
1121,"This review attempts to answer the previous question through evaluating the performance (measured by accuracy, precision and recall) of the KNN using a large number of distance measures, tested on a number of real world datasets, with and without adding different levels of noise.",objective,1
1122,"The experimental results show that the performance of KNN classifier depends significantly on the distance used, the results showed large gaps between the performances of different distances.",result,3
1123,We found that a recently proposed non-convex distance performed the best when applied on most datasets comparing to the other tested distances.,result,3
1124,"In addition, the performance of the KNN degraded only about 20% while the noise level reaches 90%, this is true for all the distances used.",result,3
1125,This means that the KNN classifier using any of the top 10 distances tolerate noise to a certain degree.,result,3
1126,"Moreover, the results show that some distances are less affected by the added noise comparing to other distances.",result,3
1127,Internet of Things (IoT) brings more than an explosive proliferation of endpoints.,background,0
1128,It is disruptive in several ways.,background,0
1129,"In this chapter we examine those disruptions, and propose a hierarchical distributed architecture that extends from the edge of the network to the core nicknamed Fog Computing.",method,2
1130,"In particular, we pay attention to a new dimension that IoT adds to Big Data and Analytics: a massively distributed number of sources at the edge.",result,3
1131,"Based on the real data of a Chinese commercial bank’s credit card, in this paper, we classify the credit card customers into four classifications by K-means.",background,0
1132,"Then we built forecasting models separately based on four data mining methods such as C5.0, neural network, chi-squared automatic interaction detector, and classification and regression tree according to the background information of the credit cards holders.",method,2
1133,"Conclusively, we obtain some useful information of decision tree regulation by the best model among the four.",method,2
1134,"The information is not only helpful for the bank to understand related characteristics of different customers, but also marketing representatives to find potential customers and to implement target marketing.",result,3
1135,Speaker diarization via unsupervised i-vector clustering has gained popularity in recent years.,background,0
1136,"In this approach, i-vectors are extracted from short clips of speech segmented from a larger multi-speaker conversation and organized into speaker clusters, typically according to their cosine score.",background,0
1137,"In this paper, we propose a system that incorporates probabilistic linear discriminant analysis (PLDA) for i-vector scoring, a method already frequently utilized in speaker recognition tasks, and uses unsupervised calibration of the PLDA scores to determine the clustering stopping criterion.",method,2
1138,We also demonstrate that denser sampling in the i-vector space with overlapping temporal segments provides a gain in the diarization task.,method,2
1139,"We test our system on the CALLHOME conversational telephone speech corpus, which includes multiple languages and a varying number of speakers, and we show that PLDA scoring outperforms the same system with cosine scoring, and that overlapping segments reduce diarization error rate (DER) as well.",result,3
1140,1570-8705/$ see front matter 2012 Elsevier B.V http://dx.doi.org/10.1016/j.adhoc.2012.02.016 ⇑ Corresponding author.,other,4
1142,: +39 0461 40 84 00; fa E-mail addresses:,other,4
1143,"daniele.miorandi@create-ne sabrina.sicari@uninsubria.it (S. Sicari), francesco.dep org (F. De Pellegrini), imrich.chlamtac@create-net.or The term ‘‘",other,4
1144,"Internet-of-Things’’ is used as an umbrella keyword for covering various aspects related to the extension of the Internet and the Web into the physical realm, by means of the widespread deployment of spatially distributed devices with embedded identification, sensing and/or actuation capabilities.",other,4
1145,"Internet-of-Things envisions a future in which digital and physical entities can be linked, by means of appropriate information and communication technologies, to enable a whole new class of applications and services.",background,0
1146,"In this article, we present a survey of technologies, applications and research challenges for Internetof-Things.",result,3
1147,2012 Elsevier B.V. All rights reserved.,other,4
1148,"Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available at .",background,0
1149,http://www.jstor.org/page/info/about/policies/terms.jsp.,background,0
1150,"JSTOR's Terms and Conditions of Use provides, in part, that unless you have obtained prior permission, you may not download an entire issue of a journal or multiple copies of articles, and you may use content in the JSTOR archive only for your personal, non-commercial use.",background,0
1151,Clustering is one of the most important data mining techniques that partitions data according to some similarity criterion.,background,0
1152,The problems of clustering categorical data have attracted much attention from the data mining research community recently.,background,0
1153,"As the extension of the k-Means algorithm, the k-Modes algorithm has been widely applied to categorical data clustering by replacing means with modes.",method,2
1154,"In this paper, the limitations of the simple matching dissimilarity measure and Ng’s dissimilarity measure are analyzed using some illustrative examples.",method,2
1155,"Based on the idea of biological and genetic taxonomy and rough membership function, a new dissimilarity measure for the k-Modes algorithm is defined.",method,2
1156,A distinct characteristic of the new dissimilarity measure is to take account of the distribution of attribute values on the whole universe.,method,2
1157,A convergence study and time complexity of the k-Modes algorithm based on new dissimilarity measure indicates that it can be effectively used for large data sets.,method,2
1158,"The results of comparative experiments on synthetic data sets and five real data sets from UCI show the effectiveness of the new dissimilarity measure, especially on data sets with biological and genetic taxonomy information.",result,3
1159,2011 Elsevier B.V. All rights reserved.,other,4
1160,"Despite the increasing use of social media platforms for information and news gathering, its unmoderated nature often leads to the emergence and spread of rumours, i.e., items of information that are unverified at the time of posting.",background,0
1161,"At the same time, the openness of social media platforms provides opportunities to study how users share and discuss rumours, and to explore how to automatically assess their veracity, using natural language processing and data mining techniques.",background,0
1162,"In this article, we introduce and discuss two types of rumours that circulate on social media: long-standing rumours that circulate for long periods of time, and newly emerging rumours spawned during fast-paced events such as breaking news, where reports are released piecemeal and often with an unverified status in their early stages.",objective,1
1163,"We provide an overview of research into social media rumours with the ultimate goal of developing a rumour classification system that consists of four components: rumour detection, rumour tracking, rumour stance classification, and rumour veracity classification.",objective,1
1164,We delve into the approaches presented in the scientific literature for the development of each of these four components.,method,2
1165,We summarise the efforts and achievements so far toward the development of rumour classification systems and conclude with suggestions for avenues for future research in social media mining for the detection and resolution of rumours.,result,3
1166,"In modern manufacturing environments, vast amounts of data are collected in database management systems and data warehouses from all involved areas, such as product and process design, assembly, materials planning, quality control, scheduling, maintenance, fault detection and so on.",background,0
1167,Data mining has emerged as an important tool for knowledge acquisition in manufacturing databases.,background,0
1168,This paper reviews the literature dealing with knowledge discovery and data mining applications in the broad domain of manufacturing with an special emphasis on the type of functions to be performed on data.,objective,1
1169,"The major data mining functions to be performed include characterization and description, association, classification, prediction, clustering and evolution analysis.",method,2
1170,The papers reviewed have therefore been categorized in these five categories.,method,2
1171,It has been shown that there is a rapid growth in the application of data mining in the context of manufacturing processes and enterprises in the last 3 years.,result,3
1172,This review reveals the progressive applications and existing gaps identified in the context of data mining in manufacturing.,result,3
1173,"A novel text mining approach has also been applied to the abstracts and keywords of 150 identified literatures to identify the research gaps and find the linkages between knowledge area, knowledge type and data mining tools and techniques applied.",result,3
1174,"1 Wolfson School of Mechanical and Manufacturing Engineering, Loughborough University, Loughborough, Leicestershire, UK, LE113TU",other,4
1175,Crowdfunding platforms offer promising opportunities for project founders to publish their project ideas and to collect money in order to be able to realize them.,background,0
1176,"Consequently, the question of what influences the successful funding of projects, i.e., reaching the target amount of money, is very important.",objective,1
1177,"Building upon media richness theory and the concept of reciprocity, we extend previous research in the field of crowdfunding success factors.",method,2
1178,We provide a comprehensive view on factors influencing crowdfunding success by both focusing on project-specific as well as founder-specific aspects.,method,2
1179,"Analyzing a sample of projects of the crowdfunding platform kickstarter.com, we find that the project description, related images and videos as well as the question of whether the founder has previously backed other projects influence funding success.",method,2
1180,"Interestingly, the question of whether the founder has previously created other projects has no significant influence.",background,0
1181,Our results are of high interest for the stakeholders on crowdfunding platforms.,result,3
1182,Emerging smart contract systems over decentralized cryptocurrencies allow mutually distrustful parties to transact safely without trusted third parties.,background,0
1183,"In the event of contractual breaches or aborts, the decentralized blockchain ensures that honest parties obtain commensurate compensation.",background,0
1184,"Existing systems, however, lack transactional privacy.",background,0
1185,"All transactions, including flow of money between pseudonyms and amount transacted, are exposed on the blockchain.",background,0
1186,"We present Hawk, a decentralized smart contract system that does not store financial transactions in the clear on the blockchain, thus retaining transactional privacy from the public's view.",method,2
1187,"A Hawk programmer can write a private smart contract in an intuitive manner without having to implement cryptography, and our compiler automatically generates an efficient cryptographic protocol where contractual parties interact with the blockchain, using cryptographic primitives such as zero-knowledge proofs.",method,2
1188,"To formally define and reason about the security of our protocols, we are the first to formalize the blockchain model of cryptography.",method,2
1189,The formal modeling is of independent interest.,result,3
1190,We advocate the community to adopt such a formal model when designing applications atop decentralized blockchains.,result,3
1191,The purpose of STIL is to provide a common language for the representation of test patterns and waveforms that are created from the simulation of a digital integrated circuit.,objective,1
1192,"The language represents the data in terms of intent (i.e., the waveform that is to be created at the device under test), rather than in terms of a specific piece of ATE hardware.",background,0
1193,"The language is flexible enough to represent patterns from simple to the most complex devices, and has built in optimizing features to minimize the volume of data that is generated by today’s designs.",result,3
1194,The wireless research community aspires to conceive full duplex operation by supporting concurrent transmission and reception in a single time/frequency channel for the sake of improving the attainable spectral efficiency by a factor of two as compared to the family of conventional half duplex wireless systems.,background,0
1195,The main challenge encountered in implementing FD wireless devices is that of finding techniques for mitigating the performance degradation imposed by self-interference.,background,0
1196,"In this article, we investigate the potential FD techniques, including passive suppression, active analog cancellation, and active digital cancellation, and highlight their pros and cons.",method,2
1197,"Furthermore, the troubles of FD medium access control protocol design are discussed for addressing the problems such as the resultant end-to-end delay and network congestion.",method,2
1198,"Additionally, an opportunistic decode-and-forward- based relay selection scheme is analyzed in underlay cognitive networks communicating over independent and identically distributed Rayleigh and Nakagami-m fading channels in the context of FD relaying.",method,2
1199,We demonstrate that the outage probability of multi-relay cooperative communication links can be substantially reduced.,method,2
1200,"Finally, we discuss the challenges imposed by the aforementioned techniques and a range of critical issues associated with practical FD implementations.",method,2
1201,"It is shown that numerous open challenges, such as efficient SI suppression, high-performance FD MAC-layer protocol design, low power consumption, and hybrid FD/HD designs, have to be tackled before successfully implementing FD-based systems.",result,3
1202,"This study investigates self-presentation strategies among online dating participants, exploring how participants manage their online presentation of self in order to accomplish the goal of finding a romantic partner.",objective,1
1203,Thirty-four individuals active on a large online dating site participated in telephone interviews about their online dating experiences and perceptions.,background,0
1204,"Qualitative data analysis suggests that participants attended to small cues online, mediated the tension between impression management pressures and the desire to present an authentic sense of self through tactics such as creating a profile that reflected their ""ideal self,"" and attempted to establish the veracity of their identity claims.",method,2
1205,"This study provides empirical support for Social Information Processing theory in a naturalistic context while offering insight into the complicated way in which ""honesty"" is enacted online.",result,3
1206,Properties of simple strategies for swinging up an inverted pendulum are discussed.,background,0
1207,It is shown that the behavior critically depends on the ratio of the maximum acceleration of the pivot to the acceleration of gravity.,background,0
1208,A comparison of energy based strategies with minimum time strategy gives interesting insights into the robustness of minimum time solutions.,method,2
1209,Purpose –,other,4
1210,"In the last two decades, a proliferation of business process management (BPM) modeling languages, standards and software systems has given rise to much confusion and obstacles to adoption.",background,0
1211,"Since new BPM languages and notation terminologies were not well defined, duplicate features are common.",background,0
1212,"This paper seeks to make sense of the myriad BPM standards, organising them in a classification framework, and to identify key industry trends.",objective,1
1213,"Design/methodology/approach – An extensive literature review is conducted and relevant BPM notations, languages and standards are referenced against the proposed BPM Standards Classification Framework, which lists each standard’s distinct features, strengths and weaknesses.",method,2
1214,Findings – The paper is unaware of any classification of BPM languages.,result,3
1215,"An attempt is made to classify BPM languages, standards and notations into four main groups: execution, interchange, graphical, and diagnosis standards.",result,3
1216,"At the present time, there is a lack of established diagnosis standards.",background,0
1217,"It is hoped that such a classification facilitates the meaningful adoption of BPM languages, standards and notations.",objective,1
1218,"Practical implications – The paper differentiates BPM standards, thereby resolving common misconceptions; establishes the need for diagnosis standards; identifies the strengths and limitations of current standards; and highlights current knowledge gaps and future trends.",method,2
1219,"Prior to 1994, student registration at Newcastle University involved students being registered in a single place, where they would present a form which had previously been filled in by the student and their department.",background,0
1220,After registration this information was then transferred to a computerised format.,background,0
1221,"The University decided that the entire registration process was to be computerised for the Autumn of 1994, with the admission and registration being carried out at the departments of the students.",background,0
1222,Such a system has a very high availability requirement: admissions tutors and secretaries must be able to access and create student records (particularly at the start of a new academic year when new students arrive).,background,0
1223,The Arjuna distributed system has been under development in the Department of Computing Science for many years.,background,0
1224,"Arjuna’s design aims are to provide tools to assist in the construction of fault-tolerant, highly available distributed applications using atomic actions (atomic transactions) and replication.",objective,1
1225,"Arjuna offers the right set of facilities for this application, and its deployment would enable the University to exploit the existing campus network and workstation clusters, thereby obviating the need for any specialised fault tolerant hardware.",objective,1
1226,Minutiae-based method is the most popular approach in fingerprint matching.,background,0
1227,"However, most existing methods need to search for the best correspondence of minutiae pairs or use reference points (core and delta points) to estimate the alignment parameters.",background,0
1228,The problem of lost minutiae or spurious minutiae always occurs during the minutiae detection process.,background,0
1229,"Hence, the corresponding pairs or reference points may not be found under this condition.",background,0
1230,This paper proposes a new minutiae-based fingerprint matching algorithm using phase correlation.,objective,1
1231,We define a new representation called Minutiae Direction Map (MDM).,method,2
1232,"First, we convert minutiae sets into 2D image spaces.",method,2
1233,Then the transformation parameters are calculated using phase correlation between two MDMs to align two fingerprints to be matched.,method,2
1234,The similarity of two fingerprints is determined by the distance between two minutiae sets.,method,2
1235,Our approach does not need to search for the corresponding minutiae pairs.,result,3
1236,"Brain damage may doubly dissociate cognitive modules, but the practice of revealing dissociations is predicated on modularity being true (T. Shallice, 1988).",background,0
1237,"This article questions the utility of assuming modularity, as it examines a paradigmatic double dissociation of reading modules.",background,0
1238,Reading modules illustrate two general problems.,objective,1
1239,"First, modularity fails to converge on a fixed set of exclusionary criteria that define pure cases.",background,0
1240,"As a consequence, competing modular theories force perennial quests for purer cases, which simply perpetuates growth in the list of exclusionary criteria.",background,0
1241,"The first problem leads, in part, to the second problem.",background,0
1242,Modularity fails to converge on a fixed set of pure cases.,background,0
1243,The second failure perpetuates unending fractionation into more modules.,background,0
1244,"© 2001 Cognitive Science Society, Inc.",other,4
1246,This study looked at young adult cell phone usage patterns.,background,0
1247,Results of a survey of 182 students at a large southern university revealed that respondents typically used their phones an average of 10.5 hours per week – the overwhelming majority of that with traditional calling.,background,0
1248,Features and services that were regularly utilised related to interpersonal communication.,result,3
1249,Limited support was found for the hypothesis that cell phone use may be utilised to avoid communication apprehension events.,result,3
1250,Stronger support was found for the hypothesis that interpersonal communication motives are positively correlated with cell phone usage gratifications.,result,3
1251,"Creating a mesh is the first step in a wide range of applications, including scientific computing and computer graphics.",objective,1
1252,An unstructured simplex mesh requires a choice of meshpoints (vertex nodes) and a triangulation.,method,2
1253,"We want to offer a short and simple MATLAB code, described in more detail than usual, so the reader can experiment (and add to the code) knowing the underlying principles.",objective,1
1254,We find the node locations by solving for equilibrium in a truss structure (using piecewise linear force-displacement relations) and we reset the topology by the Delaunay algorithm.,method,2
1255,The geometry is described implicitly by its distance function.,background,0
1256,"In addition to being much shorter and simpler than other meshing techniques, our algorithm typically produces meshes of very high quality.",result,3
1257,"We discuss ways to improve the robustness and the performance, but our aim here is simplicity.",objective,1
1258,Readers can download (and edit) the codes from http://math.mit.edu/~persson/mesh.,other,4
1259,"We present a new question set, text corpus, and baselines assembled to encourage AI research in advanced question answering.",objective,1
1260,"Together, these constitute the AI2 Reasoning Challenge (ARC), which requires far more powerful knowledge and reasoning than previous challenges such as SQuAD or SNLI.",objective,1
1261,"The ARC question set is partitioned into a Challenge Set and an Easy Set, where the Challenge Set contains only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurence algorithm.",method,2
1262,"The dataset contains only natural, grade-school science questions (authored for human tests), and is the largest public-domain set of this kind (7,787 questions).",method,2
1263,"We test several baselines on the Challenge Set, including leading neural models from the SQuAD and SNLI tasks, and find that none are able to significantly outperform a random baseline, reflecting the difficult nature of this task.",result,3
1264,"We are also releasing the ARC Corpus, a corpus of 14M science sentences relevant to the task, and implementations of the three neural baseline models tested.",method,2
1265,Can your model perform better?,other,4
1266,We pose ARC as a challenge to the community.,other,4
1267,"Finally, here is a modern, self-contained text on quantum information theory suitable for graduate-level courses.",background,0
1268,"Developing the subject “from the ground up,” it covers classical results as well as major advances of the past decade.",background,0
1269,"Beginning with an extensive overview of classical information theory suitable for the non-expert, the author then turns his attention to quantum mechanics for quantum information theory, and the important protocols of teleportation, super-dense coding, and entanglement distribution.",objective,1
1270,"He develops all of the tools necessary for understanding important results in quantum information theory, including capacity theorems for classical, entanglement-assisted, private, and quantum communication.",background,0
1271,"The book also covers important recent developments such as superadditivity of private, coherent, and Holevo information, and the superactivation of quantum capacity.",method,2
1272,This book will be warmly welcomed by the upcoming generation of quantum information theorists and by the already established community of classical information theorists.,other,4
1273,"G in the innovation diffusion literature and the resource-based theory, this paper develops an integrative research model for assessing the diffusion and consequence of e-business at the firm level.",background,0
1274,"Unlike the typical focus on adoption as found in the literature, we focus on postadoption stages, that is, actual usage and value creation.",background,0
1275,The model thus moves beyond dichotomous “adoption versus nonadoption” and accounts for the “missing link”—actual usage—as a critical stage of value creation.,method,2
1276,"The model links technological, organizational, and environmental factors to e-business use and value, based on which a series of hypotheses are developed.",method,2
1277,The theoretical model is tested by using structural equation modeling on a dataset of 624 firms across 10 countries in the retail industry.,method,2
1278,"To probe deeper into whether e-business use and value are influenced by economic environments, two subsamples from developed and developing countries are compared.",background,0
1279,"The study finds that technology competence, firm size, financial commitment, competitive pressure, and regulatory support are important antecedents of e-business use.",result,3
1280,"In addition, the study finds that, while both front-end and back-end capabilities contribute to e-business value, back-end integration has a much stronger impact.",result,3
1281,"While front-end functionalities are becoming commodities, e-businesses are more differentiated by back-end integration.",result,3
1282,"This is consistent with the resource-based theory because back-end integration possesses the value-creating characteristics of resources (e.g., firm specific, difficult to imitate), which are strengthened by the Internet-enabled connectivity.",result,3
1283,"A language model based in continuous representations of words is presented, which has been applied to a statistical machine translation task.",background,0
1284,"This model is implemented by means of a bidirectional recurrent neural network, which is able to take into account both the past and the future context of a word in order to perform predictions.",background,0
1285,"Due to its high temporal cost at training time, for obtaining relevant training data an instance selection algorithm is used, which aims to capture useful information for translating a test set.",method,2
1286,Obtained results show that the neural model trained with the selected data outperforms the results obtained by an n-gram language model.,result,3
1287,Automatic speech recognition systems typically model the relationship between the acoustic speech signal and the phones in two separate steps: feature extraction and classifier training.,background,0
1288,"In our recent works, we have shown that, in the framework of convolutional neural networks (CNN), the relationship between the raw speech signal and the phones can be directly modeled and ASR systems competitive to standard approach can be built.",method,2
1289,"In this paper, we first analyze and show that, between the first two convolutional layers, the CNN learns (in parts) and models the phone-specific spectral envelope information of 2-4 ms speech.",method,2
1290,"Given that we show that the CNN-based approach yields ASR trends similar to standard short-term spectral based ASR system under mismatched (noisy) conditions, with the CNN-based approach being more robust.",result,3
1291,Software-as-a-Service (SaaS) is emerging as a viable outsourcing option for clients interested in paying for the right to access through the network a standardized set of business software functions.,background,0
1292,"SaaS model largely replaced the Application Service Providers (ASPs)-based model, by creating an architecture that that provides no mechanisms for customizing the software on the vendor side; all customization is done on the client side through standardized interfaces.",background,0
1293,The fact that vendors are not making any client-specific investments makes this outsourcing model quite intriguing.,background,0
1294,In this paper we investigate client’s side determinants of adopting the SaaS model.,method,2
1295,"We draw on economic, strategic management, and IS theories to develop a theoretical framework.",method,2
1296,"In it, we develop a more elaborate view of uncertainty as some types uncertainty increase the propensity to adopt SaaS, while other types do the opposite.",result,3
1297,"Finally, we integrate the role of the internal enterprise IT architecture into our model.",result,3
1298,We summarize the potential impact that the European Union’s new General Data Protection Regulation will have on the routine use of machine learning algorithms.,background,0
1299,"Slated to take effect as law across the EU in 2018, it will restrict automated individual decision-making (that is, algorithms that make decisions based on user-level predictors) which “significantly affect” users.",background,0
1300,"The law will also create a “right to explanation,” whereby a user can ask for an explanation of an algorithmic decision that was made about them.",method,2
1301,"We argue that while this law will pose large challenges for industry, it highlights opportunities for machine learning researchers to take the lead in designing algorithms and evaluation frameworks which avoid discrimination.",method,2
1302,Microwave power transmission (MPT) has had a long history before the more recent movement toward wireless power transmission (WPT).,background,0
1303,MPT can be applied not only to beam-type point-to-point WPT but also to an energy harvesting system fed from distributed or broadcasting radio waves.,objective,1
1304,"The key technology is the use of a rectenna, or rectifying antenna, to convert a microwave signal to a DC signal with high efficiency.",method,2
1305,"In this paper, various rectennas suitable for MPT are discussed, including various rectifying circuits, frequency rectennas, and power rectennas.",method,2
1306,Online social networking sites have revealed an entirely new method of self-presentation.,background,0
1307,This cyber social tool provides a new site of analysis to examine personality and identity.,objective,1
1308,The current study examines how narcissism and self-esteem are manifested on the social networking Web site Facebook.com .,method,2
1309,Self-esteem and narcissistic personality self-reports were collected from 100 Facebook users at York University.,method,2
1310,Participant Web pages were also coded based on self-promotional content features.,method,2
1311,Correlation analyses revealed that individuals higher in narcissism and lower in self-esteem were related to greater online activity as well as some self-promotional content.,result,3
1312,Gender differences were found to influence the type of self-promotional content presented by individual Facebook users.,result,3
1313,Implications and future research directions of narcissism and self-esteem on social networking Web sites are discussed.,result,3
1314,Segmentation of anatomical structures in medical images is often based on a voxel/pixel classification approach.,background,0
1315,"Deep learning systems, such as convolutional neural networks (CNNs), can infer a hierarchical representation of images that fosters categorization.",background,0
1316,"We propose a novel system for voxel classification integrating three 2D CNNs, which have a one-to-one association with the xy, yz and zx planes of 3D image, respectively.",method,2
1317,We applied our method to the segmentation of tibial cartilage in low field knee MRI scans and tested it on 114 unseen scans.,method,2
1318,"Although our method uses only 2D features at a single scale, it performs better than a state-of-the-art method using 3D multi-scale features.",method,2
1319,"In the latter approach, the features and the classifier have been carefully adapted to the problem at hand.",result,3
1320,That we were able to get better results by a deep learning architecture that autonomously learns the features from the images is the main insight of this study.,result,3
1321,"While most Reinforcement Learning work utilizes temporal discounting to evaluate performance, the reasons for this are unclear.",background,0
1322,Is it out of desire or necessity?,background,0
1323,"We argue that it is not out of desire, and seek to dispel the notion that temporal discounting is necessary by proposing a framework for undiscounted optimization.",background,0
1324,We present a metric of undiscounted performance and an algorithm for finding action policies that maximize that measure.,method,2
1325,"The technique, which we call Rlearning, is modelled after the popular Q-learning algorithm [17].",method,2
1326,Initial experimental results are presented which attest to a great improvement over Q-learning in some simple cases.,result,3
1327,The Internet of Things (IoT) is a new paradigm that combines aspects and technologies coming from different approaches.,background,0
1328,"Ubiquitous computing, pervasive computing, Internet Protocol, sensing technologies, communication technologies, and embedded devices are merged together in order to form a system where the real and digital worlds meet and are continuously in symbiotic interaction.",objective,1
1329,The smart object is the building block of the IoT vision.,objective,1
1330,"By putting intelligence into everyday objects, they are turned into smart objects able not only to collect information from the environment and interact/control the physical world, but also to be interconnected, to each other, through Internet to exchange data and information.",objective,1
1331,"The expected huge number of interconnected devices and the significant amount of available data open new opportunities to create services that will bring tangible benefits to the society, environment, economy and individual citizens.",objective,1
1332,"In this paper we present the key features and the driver technologies of IoT. In addition to identifying the application scenarios and the correspondent potential applications, we focus on research challenges and open issues to be faced for the IoT realization in the real world.",result,3
1333,Pixel-wise image segmentation is demanding task in computer vision.,background,0
1334,"Classical U-Net architectures composed of encoders and decoders are very popular for segmentation of medical images, satellite images etc.",background,0
1335,"Typically, neural network initialized with weights from a network pre-trained on a large data set like ImageNet shows better performance than those trained from scratch on a small dataset.",background,0
1336,"In some practical applications, particularly in medicine and traffic safety, the accuracy of the models is of utmost importance.",background,0
1337,"In this paper, we demonstrate how the U-Net type architecture can be improved by the use of the pretrained encoder.",method,2
1338,Our code and corresponding pre-trained weights are publicly available at https://github.com/ternaus/TernausNet.,background,0
1339,"We compare three weight initialization schemes: LeCun uniform, the encoder with weights from VGG11 and full network trained on the Carvana dataset.",method,2
1340,This network architecture was a part of the winning solution (1st out of 735) in the Kaggle: Carvana Image Masking Challenge.,result,3
1341,"Keywords—Computer Vision, Image Segmentation, Image Recognition, Deep learning, Medical Image Processing, Satellite Imagery.",other,4
1342,A new method for decision-tree-based recommender systems is proposed.,method,2
1343,The proposed method includes two new major innovations.,method,2
1344,"First, the decision tree produces lists of recommended items at its leaf nodes, instead of single items.",background,0
1345,"This leads to reduced amount of search, when using the tree to compile a recommendation list for a user and consequently enables a scaling of the recommendation system.",objective,1
1346,The second major contribution of the paper is the splitting method for constructing the decision tree.,method,2
1347,Splitting is based on a new criterion the least probable intersection size.,result,3
1348,The new criterion computes the probability for getting the intersection for each potential split in a random split and selects the split that generates the least probable size of intersection.,method,2
1349,The proposed decision tree based recommendation system was evaluated on a large sample of the MovieLens dataset and is shown to outperform the quality of recommendations produced by the well known information gain splitting criterion.,result,3
1350,"In this paper, we propose a monocular SLAM system for robotic urban search and rescue (USAR), based on which most USAR tasks (e.g. localization, mapping, exploration and object recognition) can be fulfilled by rescue robots with only a single camera.",background,0
1351,The proposed system can be a promising basis to implement fully autonomous rescue robots.,objective,1
1352,"However, the feature-based map built by the monocular SLAM is difficult for the operator to understand and use.",background,0
1353,"We therefore combine the monocular SLAM with a 2D LIDAR SLAM to realize a 2D mapping and 6D localization SLAM system which can not only obtain a real scale of the environment and make the map more friendly to users, but also solve the problem that the robot pose cannot be tracked by the 2D LIDAR SLAM when the robot climbing stairs and ramps.",objective,1
1354,We test our system using a real rescue robot in simulated disaster environments.,result,3
1355,The experimental results show that good performance can be achieved using the proposed system in the USAR.,result,3
1356,"The system has also been successfully applied and tested in the RoboCup Rescue Robot League (RRL) competitions, where our rescue robot team entered the top 5 and won the Best in Class small robot mobility in 2016 RoboCup RRL Leipzig Germany, and the champions of 2016 and 2017 RoboCup China Open RRL competitions.",result,3
1357,"Concept representation is still an open problem in the field of ontology engineering and, more in general, of knowledge representation.",background,0
1358,"In particular, it still remains unsolved the problem of representing ""non classical"" concepts, i.e. concepts that cannot be defined in terms of necessary and sufficient conditions.",background,0
1359,"In this paper we review empirical evidence from cognitive psychology, which suggests that concept representation is not an unitary phenomenon.",objective,1
1360,"In particular, it seems that human beings employ both prototype and exemplar based representations in order to represent non classical concepts.",objective,1
1361,"We suggest that a similar, hybrid prototype-exemplar based approach could be useful also in the field of formal ontology technology.",result,3
1362,WiFi positioning system has been studying in many fields since the past.,background,0
1363,"Recently, a lot of mobile companies are competing for smartphones.",background,0
1364,"Accordingly, this paper proposes an indoor WiFi positioning system using Android-based smartphones.",background,0
1365,"In recent years, deep learning has garnered tremendous success in a variety of application domains.",background,0
1366,"This new field of machine learning has been growing rapidly, and has been applied to most traditional application domains, as well as some new areas that present more opportunities.",background,0
1367,"Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning.",background,0
1368,"Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bio-informatics, natural language processing (NLP), cybersecurity, and many others.",background,0
1369,"This report presents a brief survey on the advances that have occurred in the area of DL, starting with the Deep Neural Network (DNN).",objective,1
1370,"The survey goes on to cover the Convolutional Neural Network (CNN), the Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), the Auto-Encoder (AE), the Deep Belief Network (DBN), the Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL).",method,2
1371,"Additionally, we have included recent developments such as advanced variant DL techniques based on these DL approaches.",method,2
1372,This work considers most of the papers published after 2012 from when the history of deep learning began.,method,2
1373,"Furthermore, DL approaches that have been explored and evaluated in different application domains are also included in this survey.",method,2
1374,"We also included recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches.",method,2
1375,We present a siamese adaptation of the Long Short-Term Memory (LSTM) network for labeled data comprised of pairs of variable-length sequences.,background,0
1376,"Our model is applied to assess semantic similarity between sentences, where we exceed state of the art, outperforming carefully handcrafted features and recently proposed neural network systems of greater complexity.",objective,1
1377,"For these applications, we provide wordembedding vectors supplemented with synonymic information to the LSTMs, which use a fixed size vector to encode the underlying meaning expressed in a sentence (irrespective of the particular wording/syntax).",method,2
1378,"By restricting subsequent operations to rely on a simple Manhattan metric, we compel the sentence representations learned by our model to form a highly structured space whose geometry reflects complex semantic relationships.",method,2
1379,Our results are the latest in a line of findings that showcase LSTMs as powerful language models capable of tasks requiring intricate understanding.,result,3
1380,Blockchain refers to a range of general purpose technologies to exchange information and transact digital assets in distributed networks.,background,0
1381,The core question addressed in this paper is whether blockchain technology will lead to innovation and transformation of governmental processes.,background,0
1382,To address this question we present a critical assessment of the often exaggerated benefits of blockchain technology found in the literature and discuss their implications for governmental organizations and processes.,method,2
1383,We plea for a shift from a technology-driven to needdriven approach in which blockchain applications are customized to ensure a fit with requirements of administrative processes and in which the administrative processes are changed to benefit from the technology.,method,2
1384,Having sound governance models are found to be a condition for realizing benefits.,method,2
1385,Based on a critical assessment we offer directions for further research into the potential benefits of BC applications in e-government and the role of governance of BC architectures and applications to comply with societal needs and public values.,result,3
1386,"We present a system for accurate real-time mapping of complex and arbitrary indoor scenes in variable lighting conditions, using only a moving low-cost depth camera and commodity graphics hardware.",background,0
1387,We fuse all of the depth data streamed from a Kinect sensor into a single global implicit surface model of the observed scene in real-time.,method,2
1388,"The current sensor pose is simultaneously obtained by tracking the live depth frame relative to the global model using a coarse-to-fine iterative closest point (ICP) algorithm, which uses all of the observed depth data available.",method,2
1389,"We demonstrate the advantages of tracking against the growing full surface model compared with frame-to-frame tracking, obtaining tracking and mapping results in constant time within room sized scenes with limited drift and high accuracy.",result,3
1390,We also show both qualitative and quantitative results relating to various aspects of our tracking and mapping system.,result,3
1391,"Modelling of natural scenes, in real-time with only commodity sensor and GPU hardware, promises an exciting step forward in augmented reality (AR), in particular, it allows dense surfaces to be reconstructed in real-time, with a level of detail and robustness beyond any solution yet presented using passive computer vision.",background,0
1392,Multimedia services and especially digital video is expected to be the major traffic component transmitted over communication networks [such as internet protocol (IP)-based networks].,objective,1
1393,"For this reason, traffic characterization and modeling of such services are required for an efficient network operation.",method,2
1394,"The generated models can be used as traffic rate predictors, during the network operation phase (online traffic modeling), or as video generators for estimating the network resources, during the network design phase (offline traffic modeling).",background,0
1395,"In this paper, an adaptable neural-network architecture is proposed covering both cases.",method,2
1396,"The scheme is based on an efficient recursive weight estimation algorithm, which adapts the network response to current conditions.",method,2
1397,"In particular, the algorithm updates the network weights so that 1) the network output, after the adaptation, is approximately equal to current bit rates (current traffic statistics) and 2) a minimal degradation over the obtained network knowledge is provided.",method,2
1398,It can be shown that the proposed adaptable neural-network architecture simulates a recursive nonlinear autoregressive model (RNAR) similar to the notation used in the linear case.,result,3
1399,The algorithm presents low computational complexity and high efficiency in tracking traffic rates in contrast to conventional retraining schemes.,result,3
1400,"Furthermore, for the problem of offline traffic modeling, a novel correlation mechanism is proposed for capturing the burstness of the actual MPEG video traffic.",result,3
1401,The performance of the model is evaluated using several real-life MPEG coded video sources of long duration and compared with other linear/nonlinear techniques used for both cases.,result,3
1402,"The combination of the Internet and emerging technologies such as nearfield communications, real-time localization, and embedded sensors lets us transform everyday objects into smart objects that can understand and react to their environment.",background,0
1403,Such objects are building blocks for the Internet of Things and enable novel computing applications.,background,0
1404,"As a step toward design and architectural principles for smart objects, the authors introduce a hierarchy of architectures with increasing levels of real-world awareness and interactivity.",method,2
1405,"In particular, they describe activity-, policy-, and process-aware smart objects and demonstrate how the respective architectural abstractions support increasingly complex application.",result,3
1406,Computer vision is the science and technology of making machines that see.,background,0
1407,"It is concerned with the theory, design and implementation of algorithms that can automatically process visual data to recognize objects, track and recover their shape and spatial layout.",background,0
1408,The International Computer Vision Summer School ICVSS was established in 2007 to provide both an objective and clear overview and an in-depth analysis of the state-of-the-art research in Computer Vision.,background,0
1409,"The courses are delivered by world renowned experts in the field, from both academia and industry, and cover both theoretical and practical aspects of real Computer Vision problems.",background,0
1410,The school is organized every year by University of Cambridge (Computer Vision and Robotics Group) and University of Catania (Image Processing Lab).,method,2
1411,Different topics are covered each year.,background,0
1412,A summary of the past Computer Vision Summer Schools can be found at: http:// www.dmi.unict.it/icvss This edited volume contains a selection of articles covering some of the talks and tutorials held during the last editions of the school.,result,3
1413,The chapters provide an in-depth overview of challenging areas with key references to the existing literature.,result,3
1414,Microsoft Windows Azure Cloud offers scalable resources to its customers.,background,0
1415,"The price for renting the resources is linear, i.e. the customer pays exactly double price for double resources.",background,0
1416,"However, not always all offered resources of virtual machine instances are most suitable for the customers.",background,0
1417,"Some problems are memory demanding, others are compute intensive or even cache intensive.",background,0
1418,The same amount of resources offered by the cloud can be rented and utilized differently to speedup the computation.,background,0
1419,One way is to use techniques for parallelization on instances with more resources.,method,2
1420,Other way is to spread the job among several instances of virtual machine with less resources.,method,2
1421,In this paper we analyze which is the best way to scale the resources to speedup the calculations and obtain best performance for the same amount of money needed to rent those resources in the cloud.,result,3
1422,The paper proposes a description of information decision support system in the tourism domain and a set of methods and algorithms for generating recommendations for a user that allow significant increase of the system usability.,background,0
1423,The system generates for the user recommendations which attractions at the moment are better to attend based on the user preferences and the current situation in the location area.,background,0
1424,"The system also allows showing the user information about interesting attraction in more detail, which is based on analyzing information evaluations made by other users.",method,2
1425,Recent studies show that stock patterns might implicate useful information for stock price forecasting.,background,0
1426,"The patterns underlying the price time series can not be discovered exhaustively by the pure man power in a limited time, thus the computer algorithm for stock price pattern recognition becomes more and more popular.",background,0
1427,"Currently, there are mainly two kinds of stock price pattern recognition algorithms: the algorithm based on rule-matching and the algorithm based on template-matching.",background,0
1428,"However, both of the two algorithms highly require the participation of domain experts, as well as their lacks of the learning ability.",background,0
1429,"To solve these problems, the paper proposes a stock price pattern recognition approach based upon the artificial neural network.",objective,1
1430,"The experiment shows that the neural network can effectively learn the characteristics of the patterns, and accurately recognize the patterns.",result,3
1431,"To verify the validity of our previously reported autonomous indoor localization system in an actual environment, we implemented it in a wireless sensor network based on the ZigBee standard.",background,0
1432,The system automatically estimates the distance between sensor nodes by measuring the RSSI (received signal strength indicator) at an appropriate number of sensor nodes.,method,2
1433,"Through experiments, we clarified the validity of our data collection and position estimation techniques.",method,2
1434,"The results show that when the deployment density of sensor nodes was set to 0.27 nodes/ , the position estimation error was reduced to 1.5-2 m.",result,3
1435,Social media usage among organizations is growing tremendously.,background,0
1436,"Organizations are now building and maintaining social media public pages to improve their social network salience, enhance interest in their organizations, and build relationships with the online public.",background,0
1437,The majority of the studies on social media usage are based on the individual perspective while some are from the organizational perspective.,background,0
1438,"However, not many studies have investigated the actual impact of social media usage on organizational performance.",objective,1
1439,"Therefore, using the qualitative approach, this study investigates the various purposes of social media usage and its impact on organizational performance.",method,2
1440,"This study however, focuses only on the social media managers’ views.",method,2
1441,"The senior managers of six organizations that are using social media are interviewed from which we find that social media is used for various purposes in organizations, such as advertising and promotion, branding, information search, building customer relations and many more.",method,2
1442,"The results also show that social media has a greater impact on the performance of organizations in terms of enhancement in customer relations and customer service activities, improvement in information accessibility and cost reduction in terms of marketing and customer service.",result,3
1444,Object detection is a crucial task for autonomous driving.,background,0
1445,"In addition to requiring high accuracy to ensure safety, object detection for autonomous driving also requires realtime inference speed to guarantee prompt vehicle control, as well as small model size and energy efficiency to enable embedded system deployment.",background,0
1446,",,,,,, In this work, we propose SqueezeDet, a fully convolutional neural network for object detection that aims to simultaneously satisfy all of the above constraints.",objective,1
1447,"In our network we use convolutional layers not only to extract feature maps, but also as the output layer to compute bounding boxes and class probabilities.",method,2
1448,"The detection pipeline of our model only contains a single forward pass of a neural network, thus it is extremely fast.",method,2
1449,"Our model is fullyconvolutional, which leads to small model size and better energy efficiency.",method,2
1450,"Finally, our experiments show that our model is very accurate, achieving state-of-the-art accuracy on the KITTI [10] benchmark.",method,2
1451,The source code of SqueezeDet is open-source released.,result,3
1452,The e-commerce literature has rarely addressed the measurement of customer perceptions of website service quality in digital marketing environments.,background,0
1453,"It is argued that the current SERVQUAL and IS-SERVQUAL instruments need to be refined and validated to fit the digital marketing environment, as they are targeted primarily towards either traditional retailing or information systems contexts.",background,0
1454,This article validates and refines a comprehensive model and instrument for measuring customer-perceived service quality of websites that market digital products and services.,objective,1
1455,"After a discussion of the conceptualization and operationalization of the service quality construct, the procedure used in modifying items, collecting data, and validating a multiple-item scale is described.",method,2
1456,"Subsequently, evidence of reliability and validity on the basis of analyzing data from a quota sample of 260 adult respondents is presented.",method,2
1457,Implications for practice and research are then explored.,method,2
1458,"Finally, this paper concludes by discussing limitations that could be addressed in future studies.",result,3
1459,"The final EC-SERVQUAL instrument with good reliability and validity will be essential to the development and testing of e-business theories, and provide researchers with a common framework for explaining, justifying, and comparing differences across results.",result,3
1460,"Image classification datasets are often imbalanced, characteristic that negatively affects the accuracy of deeplearning classifiers.",background,0
1461,In this work we propose balancing GAN (BAGAN) as an augmentation tool to restore balance in imbalanced datasets.,objective,1
1462,This is challenging because the few minority-class images may not be enough to train a GAN.,objective,1
1463,We overcome this issue by including during the adversarial training all available images of majority and minority classes.,method,2
1464,The generative model learns useful features from majority classes and uses these to generate images for minority classes.,method,2
1465,We apply class conditioning in the latent space to drive the generation process towards a target class.,method,2
1466,The generator in the GAN is initialized with the encoder module of an autoencoder that enables us to learn an accurate class-conditioning in the latent space.,method,2
1467,We compare the proposed methodology with state-of-the-art GANs and demonstrate that BAGAN generates images of superior quality when trained with an imbalanced dataset.,result,3
1468,This paper focuses on the cultural effect of gender on the relationship of online word of mouth and trust in e-commerce.,objective,1
1469,"To encourage online commerce, many online retailers use online word-of-mouth systems, where consumers can rate products offered for sale.",background,0
1470,"To date, how such ratings affect trust and adoption of e-commerce across genders has been relatively unexplored.",background,0
1471,We assess whether the effect of online trust on intention to shop online is moderated by gender.,method,2
1472,Our results show that the effect of trust on intention to shop online is stronger for women than for men.,result,3
1473,"In addition, we find that men value their ability to post content online, whereas women value the responsive participation of other consumers to the content they have posted.",result,3
1474,"Finally, we find that online word-of-mouth quality affects online trust differently across genders.",result,3
1475,Witten and Frank 's textbook was one of two books that 1 used for a data mining class in the Fall o f 2001.,background,0
1476,T h e book covers all major methods o f data mining that p roduce a knowledge representa t ion as output .,background,0
1477,"Knowledge representa t ion is hereby unders tood as a representat ion that can be studied, unders tood, and interpreted by human beings, at least in principle.",background,0
1478,"Thus , neural networks and genetic a lgor i thms are excluded f rom the topics of this textbook.",background,0
1479,"We need to say ""can be unders tood in pr inciple"" because a large decision tree or a large rule set may be as hard to interpret as a neural network.",background,0
1480,The explosion of social media services presents a great opportunity to understand the sentiment of the public via analyzing its large-scale and opinion-rich data.,background,0
1481,"In social media, it is easy to amass vast quantities of unlabeled data, but very costly to obtain sentiment labels, which makes unsupervised sentiment analysis essential for various applications.",background,0
1482,"It is challenging for traditional lexicon-based unsupervised methods due to the fact that expressions in social media are unstructured, informal, and fast-evolving.",background,0
1483,Emoticons and product ratings are examples of emotional signals that are associated with sentiments expressed in posts or words.,background,0
1484,"Inspired by the wide availability of emotional signals in social media, we propose to study the problem of unsupervised sentiment analysis with emotional signals.",objective,1
1485,"In particular, we investigate whether the signals can potentially help sentiment analysis by providing a unified way to model two main categories of emotional signals, i.e., emotion indication and emotion correlation.",result,3
1486,We further incorporate the signals into an unsupervised learning framework for sentiment analysis.,result,3
1487,"In the experiment, we compare the proposed framework with the state-of-the-art methods on two Twitter datasets and empirically evaluate our proposed framework to gain a deep understanding of the effects of emotional signals.",result,3
1488,"The healthcare industry collects huge amounts of healthcare data which, unfortunately, are not "";mined""; to discover hidden information for effective decision making.",background,0
1489,Discovery of hidden patterns and relationships often goes unexploited.,background,0
1490,Advanced data mining techniques can help remedy this situation.,result,3
1491,"This research has developed a prototype Intelligent Heart Disease Prediction System (IHDPS) using data mining techniques, namely, Decision Trees, Naive Bayes and Neural Network.",method,2
1492,Results show that each technique has its unique strength in realizing the objectives of the defined mining goals.,method,2
1493,"IHDPS can answer complex "";what if""; queries which traditional decision support systems cannot.",method,2
1494,"Using medical profiles such as age, sex, blood pressure and blood sugar it can predict the likelihood of patients getting a heart disease.",result,3
1495,"It enables significant knowledge, e.g. patterns, relationships between medical factors related to heart disease, to be established.",result,3
1496,"IHDPS is Web-based, user-friendly, scalable, reliable and expandable.",method,2
1497,It is implemented on the .NET platform.,result,3
1498,"The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations.",background,0
1499,"In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far.",background,0
1501,We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause.,result,3
1502,We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples.,objective,1
1505,"Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors.",result,3
1506,This paper presents some convex stochastic programming models for single and multiperiod inventory control problems where the market demand is random and order quantities need to be decided before demand is realized.,background,0
1507,Both models minimize the expected losses subject to risk aversion constraints expressed through Value at Risk (VaR) and Conditional Value at Risk (CVaR) as risk measures.,objective,1
1508,A sample average approximation method is proposed for solving the models and convergence analysis of optimal solutions of the sample average approximation problem is presented.,method,2
1509,"Finally, some numerical examples are given to illustrate the convergence of the algorithm.",result,3
1510,This paper presents a novel approach to visualizing the time structure of music and audio.,background,0
1511,"The acoustic similarity between any two instants of an audio recording is displayed in a 2D representation, allowing identification of structural and rhythmic characteristics.",method,2
1512,Examples are presented for classical and popular music.,method,2
1513,"Applications include content-based analysis and segmentation, as well as tempo and structure extraction.",result,3
1514,"The word2vec software of Tomas Mikolov and colleagues 1 has gained a lot of traction lately, and provides state-of-the-art word embeddings.",background,0
1515,"The learning models behind the software are described in two research papers [1, 2].",background,0
1516,We found the description of the models in these papers to be somewhat cryptic and hard to follow.,background,0
1517,"While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations.",method,2
1518,"This note is an attempt to explain equation (4) (negative sampling) in "" Distributed Representations of Words and Phrases and their Compositionality "" by 1 The skip-gram model The departure point of the paper is the skip-gram model.",objective,1
1519,"In this model we are given a corpus of words w and their contexts c. We consider the conditional probabilities p(c|w), and given a corpus T ext, the goal is to set the parameters θ of p(c|w; θ) so as to maximize the corpus probability: arg max θ w∈T ext   c∈C(w) p(c|w; θ)   (1) in this equation, C(w) is the set of contexts of word w.",method,2
1520,"Alternatively: arg max θ (w,c)∈D p(c|w; θ) (2) here D is the set of all word and context pairs we extract from the text.",result,3
1521,"Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors.",background,0
1522,Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities.,background,0
1523,"In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together.",objective,1
1524,Multimodal machine learning aims to build models that can process and relate information from multiple modalities.,method,2
1525,It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential.,method,2
1526,"Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy.",method,2
1527,"We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning.",objective,1
1528,This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.,objective,1
1529,Bitcoin is a digital currency that unlike traditional currencies does not rely on a centralized authority.,background,0
1530,Instead Bitcoin relies on a network of volunteers that collectively implement a replicated ledger and verify transactions.,background,0
1531,In this paper we analyze how Bitcoin uses a multi-hop broadcast to propagate transactions and blocks through the network to update the ledger replicas.,objective,1
1532,We then use the gathered information to verify the conjecture that the propagation delay in the network is the primary cause for blockchain forks.,method,2
1533,Blockchain forks should be avoided as they are symptomatic for inconsistencies among the replicas in the network.,method,2
1534,We then show what can be achieved by pushing the current protocol to its limit with unilateral changes to the client's behavior.,result,3
1535,"Shoe-last, a 3D mould used for making footwear, influence the shape, size and fitting of footwear.",background,0
1536,Current shoe-last design software has focused mainly on reverse engineering of existing shoe-last and modification.,background,0
1537,Shoe-last designers have generally preferred to design the shoe-last manually due to limitations of design software.,background,0
1538,"In order to solve these problems, a new software based on CATIA platform was developed.",method,2
1539,The shoe-last model is based on foot shape measurement data and foot biomechanics.,method,2
1540,"Using the existing shoe-last design standards and the sections from existing shoe-lasts, design tables and relationship equations enables the design of shoe-last with different toe type, heel height and custom shoe-last.",method,2
1541,"The design includes comfort and fit aspects as well as design aspect, therefore enables design of aesthetical comfortable shoes.",result,3
1542,"Since the design can be modified instantaneously, the designers could visualize design changes leading to a reduction in shoe-last design cycle.",result,3
1543,2009 Elsevier B.V. All rights reserved.,other,4
1544,Several extensions to evolutionary algorithms (EAs) and particle swarm optimization (PSO) have been suggested during the last decades offering improved performance on selected benchmark problems.,background,0
1545,"Recently, another search heuristic termed differential evolution (DE) has shown superior performance in several real-world applications.",method,2
1546,"In this paper, we evaluate the performance of DE, PSO, and EAs regarding their general applicability as numerical optimization techniques.",objective,1
1547,The comparison is performed on a suite of 34 widely used benchmark problems.,method,2
1548,The results from our study show that DE generally outperforms the other algorithms.,result,3
1549,"However, on two noisy functions, both DE and PSO were outperformed by the EA.",result,3
1550,A long-standing question within the robotics community is about the degree of human-likeness robots ought to have when interacting with humans.,background,0
1551,We explore an unexamined aspect of this problem: how people empathize with robots along the anthropomorphic spectrum.,objective,1
1552,We conducted an experiment that measured how people empathized with robots shown to be experiencing mistreatment by humans.,method,2
1553,Our results indicate that people empathize more strongly with more human-looking robots and less with mechanical-looking robots.,result,3
1554,"In recent years, there has been an increasing interest in applying Augmented Reality (AR) to create unique educational settings.",background,0
1555,"So far, however, there is a lack of review studies with focus on investigating factors such as: the uses, advantages, limitations, effectiveness, challenges and features of augmented reality in educational settings.",background,0
1556,Personalization for promoting an inclusive learning using AR is also a growing area of interest.,method,2
1557,This paper reports a systematic review of literature on augmented reality in educational settings considering the factors mentioned before.,method,2
1558,"In total, 32 studies published between 2003 and 2013 in 6 indexed journals were analyzed.",result,3
1559,The main findings from this review provide the current state of the art on research in AR in education.,result,3
1560,"Furthermore, the paper discusses trends and the vision towards the future and opportunities for further research in augmented reality for educational settings.",result,3
1561,"How good are cheap depth cameras, namely the Microsoft Kinect, compared to state of the art Time-ofFlight depth cameras?",background,0
1562,In this paper several depth cameras of different types were put to the test on a variety of tasks in order to judge their respective performance and to find out their weaknesses.,background,0
1563,"We will concentrate on the common area of applications for which both types are specified, i.e. near field indoor scenes.",objective,1
1564,The characteristics and limitations of the different technologies as well as the concrete hardware implementations are discussed and evaluated with a set of experimental setups.,objective,1
1565,"Especially, the noise level and the axial and angular resolutions are compared.",result,3
1566,"Additionally, refined formulas to generate depth values based on the raw measurements of the Kinect are presented.",result,3
1567,Swarm intelligence is a relatively new approach to problem solving that takes inspiration from the social behaviors of insects and of other animals.,background,0
1568,"In particular, ants have inspired a number of methods and techniques among which the most studied and the most successful is the general purpose optimization technique known as ant colony optimization.",method,2
1569,Ant colony optimization (ACO) takes inspiration from the foraging behavior of some ant species.,objective,1
1570,These ants deposit pheromone on the ground in order to mark some favorable path that should be followed by other members of the colony.,method,2
1571,Ant colony optimization exploits a similar mechanism for solving optimization problems.,method,2
1572,"From the early nineties, when the first ant colony optimization algorithm was proposed, ACO attracted the attention of increasing numbers of researchers and many successful applications are now available.",result,3
1573,"Moreover, a substantial corpus of theoretical results is becoming available that provides useful guidelines to researchers and practitioners in further applications of ACO.",result,3
1574,The goal of this article is to introduce ant colony optimization and to survey its most notable applications,objective,1
1575,"In this paper, we propose a new method for indexing large amounts of point and spatial data in highdimensional space.",method,2
1576,An analysis shows that index structures such as the R*-tree are not adequate for indexing high-dimensional data sets.,background,0
1577,"The major problem of R-tree-based index structures is the overlap of the bounding boxes in the directory, which increases with growing dimension.",method,2
1578,"To avoid this problem, we introduce a new organization of the directory which uses a split algorithm minimizing overlap and additionally utilizes the concept of supernodes.",method,2
1579,"The basic idea of overlap-minimizing split and supernodes is to keep the directory as hierarchical as possible, and at the same time to avoid splits in the directory that would result in high overlap.",result,3
1580,"Our experiments show that for high-dimensional data, the X-tree outperforms the well-known R*-tree and the TV-tree by up to two orders of magnitude.",result,3
1581,"In this study 2,684 people evaluated the credibility of two live Web sites on a similar topic (such as health sites).",result,3
1582,We gathered the comments people wrote about each siteís credibility and analyzed the comments to find out what features of a Web site get noticed when people evaluate credibility.,method,2
1583,"We found that the ìdesign lookî of the site was mentioned most frequently, being present in 46.1% of the comments.",result,3
1584,Next most common were comments about information structure and information focus.,result,3
1585,In this paper we share sample participant comments in the top 18 areas that people noticed when evaluating Web site credibility.,result,3
1586,"We discuss reasons for the prominence of design look, point out how future studies can build on what we have learned in this new line of research, and outline six design implications for human-computer interaction professionals.",method,2
1587,Convolutional neural networks (CNNs) are inherently limited to model geometric transformations due to the fixed geometric structures in their building modules.,background,0
1588,"In this work, we introduce two new modules to enhance the transformation modeling capability of CNNs, namely, deformable convolution and deformable RoI pooling.",objective,1
1589,"Both are based on the idea of augmenting the spatial sampling locations in the modules with additional offsets and learning the offsets from the target tasks, without additional supervision.",method,2
1590,"The new modules can readily replace their plain counterparts in existing CNNs and can be easily trained end-to-end by standard back-propagation, giving rise to deformable convolutional networks.",method,2
1591,Extensive experiments validate the performance of our approach.,method,2
1592,"For the first time, we show that learning dense spatial transformation in deep CNNs is effective for sophisticated vision tasks such as object detection and semantic segmentation.",result,3
1593,The code is released at https://github.com/msracver/Deformable-ConvNets.,other,4
1594,"With the availability of low-cost and compact 2.5/3D visual sensing devices, computer vision community is experiencing a growing interest in visual scene understanding.",background,0
1595,This survey paper provides a comprehensive background to this research topic.,objective,1
1596,"We begin with a historical perspective, followed by popular 3D data representations and a comparative analysis of available datasets.",method,2
1597,"Before delving into the application specific details, this survey provides a succinct introduction to the core technologies that are the underlying methods extensively used in the literature.",method,2
1598,"Afterwards, we review the developed techniques according to a taxonomy based on the scene understanding tasks.",method,2
1599,"This covers holistic indoor scene understanding as well as subtasks such as scene classification, object detection, pose estimation, semantic segmentation, 3D reconstruction, saliency detection, physics-based reasoning and affordance prediction.",method,2
1600,"Later on, we summarize the performance metrics used for evaluation in different tasks and a quantitative comparison among the recent state-of-the-art techniques.",result,3
1601,We conclude this review with the current challenges and an outlook towards the open research problems requiring further investigation.,result,3
1602,"Among the growing number of Chinese companies that went public overseas, many have been detected and alleged as conducting financial fraud by market research firms or U.S. Securities and Exchange Commission (SEC).",background,0
1603,Then investors lost money and even confidence to all overseas-listed Chinese companies.,background,0
1604,"Likewise, these companies suffered serious stock sank or were even delisted from the stock exchange.",background,0
1605,Conventional auditing practices failed in these cases when misleading financial reports presented.,background,0
1606,"This is partly because existing auditing practices and academic researches primarily focus on statistical analysis of structured financial ratios and market activity data in auditing process, while ignoring large amount of textual information about those companies in financial statements.",background,0
1607,"In this paper, we build integrated language model, which combines statistical language model (SLM) and latent semantic analysis (LSA), to detect the strategic use of deceptive language in financial statements.",method,2
1608,"By integrating SLM with LSA framework, the integrated model not only overcomes SLM’s inability to capture long-span information, but also extracts the semantic patterns which distinguish fraudulent financial statements from non-fraudulent ones.",method,2
1609,Four different modes of the integrated model are also studied and compared.,method,2
1610,"With application to assess fraud risk in overseas-listed Chinese companies, the integrated model shows high accuracy to flag fraudulent financial statements.",result,3
1611,"Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent are effective for tasks involving sequences, visual and otherwise.",background,0
1612,"We describe a class of recurrent convolutional architectures which is end-to-end trainable and suitable for large-scale visual understanding tasks, and demonstrate the value of these models for activity recognition, image captioning, and video description.",method,2
1613,"In contrast to previous models which assume a fixed visual representation or perform simple temporal averaging for sequential processing, recurrent convolutional models are “doubly deep” in that they learn compositional representations in space and time.",objective,1
1614,Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates.,method,2
1615,"Differentiable recurrent models are appealing in that they can directly map variable-length inputs (e.g., videos) to variable-length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation.",result,3
1616,Our recurrent sequence models are directly connected to modern visual convolutional network models and can be jointly trained to learn temporal dynamics and convolutional perceptual representations.,method,2
1617,Our results show that such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined or optimized.,result,3
1618,"Smart world is envisioned as an era in which objects (e.g., watches, mobile phones, computers, cars, buses, and trains) can automatically and intelligently serve people in a collaborative manner.",background,0
1619,"Paving the way for smart world, Internet of Things (IoT) connects everything in the smart world.",background,0
1620,"Motivated by achieving a sustainable smart world, this paper discusses various technologies and issues regarding green IoT, which further reduces the energy consumption of IoT. Particularly, an overview regarding IoT and green IoT is performed first.",method,2
1621,"Then, the hot green information and communications technologies (ICTs) (e.g., green radio-frequency identification, green wireless sensor network, green cloud computing, green machine to machine, and green data center) enabling green IoT are studied, and general green ICT principles are summarized.",method,2
1622,"Furthermore, the latest developments and future vision about sensor cloud, which is a novel paradigm in green IoT, are reviewed and introduced, respectively.",method,2
1623,"Finally, future research directions and open problems about green IoT are presented.",result,3
1624,Our work targets to be an enlightening and latest guidance for research with respect to green IoT and smart world.,result,3
1625,The operating characteristic (OC) and average sample number (ASN) characterize the performance of the sequential probability ratio test (SPRT).,background,0
1626,"In this paper, the ASN and OC of the truncated SPRT (TSPRT) are examined in a general setting, in which the log-likelihood ratios are not necessarily identically distributed and the bounds for the test can be time varying.",background,0
1627,"Two inductive integral equations are derived for the OC and ASN respectively, which can be solved analytically by backward induction provided the convolution involved can be evaluated analytically.",method,2
1628,The initial value for backward induction can be readily determined by TSPRT's truncation strategy.,method,2
1629,"Due to the difficulty of analytically evaluating the convolution in the induction process, numerical methods may be necessary.",method,2
1630,Numerical algorithms based on the system of linear algebraic equation method and the finite element analysis are developed.,method,2
1631,Examples are provided to illustrate our algorithms.,other,4
1632,Sexism toward women in online video game environments has become a pervasive and divisive issue in the gaming community.,background,0
1633,"In this study, we sought to determine what personality traits, demographic variables, and levels of game play predicted sexist attitudes towards women who play video games.",objective,1
1634,Male and female participants (N = 301) who were players of networked video games were invited to participate in an anonymous online survey.,result,3
1635,"Social dominance orientation and conformity to some types of masculine norms (desire for power over women and the need for heterosexual self-presentation) predicted higher scores on the Video Game Sexism Scale (i.e., greater sexist beliefs about women and gaming).",result,3
1636,Implications for the social gaming environment and female gamers are discussed.,other,4
1637,2013 Elsevier Ltd. All rights reserved.,other,4
1638,We present a learned model of human body shape and pose-dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines.,background,0
1639,Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex-based model that accurately represents a wide variety of body shapes in natural human poses.,method,2
1640,"The parameters of the model are learned from data including the rest pose template, blend weights, pose-dependent blend shapes, identity-dependent blend shapes, and a regressor from vertices to joint locations.",method,2
1641,"Unlike previous models, the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices.",method,2
1642,This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses.,method,2
1643,We quantitatively evaluate variants of SMPL using linear or dual-quaternion blend skinning and show that both are more accurate than a Blend-SCAPE model trained on the same data.,result,3
1644,We also extend SMPL to realistically model dynamic soft-tissue deformations.,method,2
1645,"Because it is based on blend skinning, SMPL is compatible with existing rendering engines and we make it available for research purposes.",result,3
1646,Linear Discriminant Analysis (LDA) is a very common technique for dimensionality reduction problems as a preprocessing step for machine learning and pattern classification applications.,background,0
1647,"At the same time, it is usually used as a black box, but (sometimes) not well understood.",background,0
1648,"The aim of this paper is to build a solid intuition for what is LDA, and how LDA works, thus enabling readers of all levels be able to get a better understanding of the LDA and to know how to apply this technique in different applications.",objective,1
1649,The paper first gave the basic definitions and steps of how LDA technique works supported with visual explanations of these steps.,method,2
1650,"Moreover, the two methods of computing the LDA space, i.e. class-dependent and class-independent methods, were explained in details.",method,2
1651,"Then, in a step-by-step approach, two numerical examples are demonstrated to show how the LDA space can be calculated in case of the class-dependent and class-independent methods.",method,2
1652,"Furthermore, two of the most common LDA problems (i.e. Small Sample Size (SSS) and non-linearity problems) were highlighted and illustrated, and stateof-the-art solutions to these problems were investigated and explained.",result,3
1653,"Finally, a number of experiments was conducted with different datasets to (1) investigate the effect of the eigenvectors that used in the LDA space on the robustness of the extracted feature for the classification accuracy, and (2) to show when the SSS problem occurs and how it can be addressed.",result,3
1654,Multiuser Detection (MUD) based receivers theoretically require no power control (PC) as they have the ability to separate signals regardless of their relative power levels as long as these signals achieve a suitable SNR.,background,0
1655,"In practice, receiver designs have finite dynamic range.",background,0
1656,"In this paper, power aware scheduling (PAS) and power control (PC) algorithms are investigated to address the finite MUD dynamic range and performance results are shown.",objective,1
1657,The final PAS algorithm and motivating factors behind the design selections made on the DARPA Interference Multiple Access (DIMA) program are highlighted as well as different approaches involving both scheduling and PC.,method,2
1658,The techniques selected on the DIMA program are currently operating as part of the DEVIA mobile real-time experiments.,result,3
1659,"KDD 99 intrusion detection datasets, which are based on DARPA 98 dataset, provides labeled data for researchers working in the field of intrusion detection and is the only labeled dataset publicly available.",background,0
1660,Numerous researchers employed the datasets in KDD 99 intrusion detection competition to study the utilization of machine learning for intrusion detection and reported detection rates up to 91% with false positive rates less than 1%.,background,0
1661,To substantiate the performance of machine learning based detectors that are trained on KDD 99 training data; we investigate the relevance of each feature in KDD 99 intrusion detection datasets.,method,2
1662,"To this end, information gain is employed to determine the most discriminating features for each class.",result,3
1663,MT2DInvMatlab is an open-source MATLAB software package for two-dimensional (2D) inversion of magnetotelluric (MT) data; it is written in mixed languages of MATLAB and FORTRAN.,background,0
1664,"MT2DInvMatlab uses the finite element method (FEM) to compute 2D MT model responses, and smoothness-constrained least-squares inversion with a spatially variable regularization parameter algorithm to stabilize the inversion process and provide a high-resolution optimal earth model.",method,2
1665,It is also able to include terrain effects in inversion by incorporating topography into a forward model.,method,2
1666,"This program runs under the MATLAB environment so that users can utilize the existing general interface of MATLAB, while some specific functions are written in FORTRAN 90 to speed up computation and reuse pre-existing FORTRAN code in the MATLAB environment with minimal modification.",result,3
1667,"This program has been tested using synthetic models, including one with variable topography, and on field data.",result,3
1668,The results were assessed by comparing inverse models obtained with MT2DInvMatlab and with a non-linear conjugate gradient (NLCG) algorithm.,result,3
1669,In both tests the new inversion software reconstructs the subsurface resistivity structure very closely and provides an improvement in both resolution and stability.,result,3
1670,& 2009 Elsevier Ltd. All rights reserved.,other,4
1671,Newer models for interacting with wireless sensors such as Internet of Things and Sensor Cloud aim to overcome restricted resources and efficiency.,background,0
1672,"The Missouri S&T (science and technology) sensor cloud enables different networks, spread in a huge geographical area, to connect together and be employed simultaneously by multiple users on demand.",background,0
1673,"Virtual sensors, which are at the core of this sensor cloud architecture, assist in creating a multiuser environment on top of resource-constrained physical wireless sensors and can help in supporting multiple applications.",method,2
1674,The magnification factor for the steady-state response of a SDOF system under harmonic loading is described in many structural dynamics textbooks; the well known analytical solution is easily obtained from the solution to the damped equation of motion for harmonic loading.,background,0
1675,The complete and steady state solutions can differ significantly.,background,0
1676,"An analytical expression for the maximum response to the complete solution (steady state plus transient) remains elusive; however, a simple analytical expression is identified herein for the undamped case.",method,2
1677,Differences in the magnification factors obtained for both solutions are discussed.,result,3
1678,The arrival and proliferation of electronic resources and digital libraries have a number of significant impacts on the use of print resources and traditional libraries.,background,0
1679,This study explores the extent to which graduate students in a metropolitan university setting use print and electronic resources.,background,0
1680,Reading preferences and use of print and electronic resources vary among different disciplines.,background,0
1681,Graduate students seem to expect a hybrid of print and electronic resources.,background,0
1682,"They desire to meet their information needs through a mix of print and online resources, even though reasons for supplementing another type of resource differ.",method,2
1683,Circumstances that affect the selection of use between digital libraries and traditional libraries are also discussed.,method,2
1684,2005 Elsevier Ltd. All rights reserved.,other,4
1685,"We propose XSEED, a synopsis of path queries for cardinality estimation that is accurate, robust, efficient, and adaptive to memory budgets.",objective,1
1686,"XSEED starts from a very small kernel, and then incrementally updates information of the synopsis.",method,2
1687,"With such an incremental construction, a synopsis structure can be dynamically configured to accommodate different memory budgets.",method,2
1688,Cardinality estimation based on XSEED can be performed very efficiently and accurately.,result,3
1689,"Extensive experiments on both synthetic and real data sets show that even with less memory, XSEED could achieve accuracy that is an order of magnitude better than that of other synopsis structures.",result,3
1690,The cardinality estimation time is under 2% of the actual querying time for a wide range of queries in all test cases.,result,3
1691,Massively Multiplayer Online Games (MMOGs) routinely attract millions of players but little empirical data is available to assess their players' social experiences.,background,0
1692,"In this paper, we use longitudinal data collected directly from the game to examine play and grouping patterns in one of the largest MMOGs: World of Warcraft.",objective,1
1693,"Our observations show that the prevalence and extent of social activities in MMOGs might have been previously over-estimated, and that gaming communities face important challenges affecting their cohesion and eventual longevity.",background,0
1694,We discuss the implications of our findings for the design of future games and other online social spaces.,objective,1
1695,Research Article Gimun Kim Konyang University gmkim@konyang.ac.kr Bongsik Shin San Diego State University bshin@mail.sdsu.edu Kyung Kyu Kim Yonsei University kyu.kim@yonsei.ac.kr Ho Geun Lee Yonsei University h.lee@yonsei.ac.kr More and more publications are highlighting the value of IT in affecting business processes.,background,0
1696,"Recognizing firmlevel dynamic capabilities as key to improved firm performance, our work examines and empirically tests the influencing relationships among IT capabilities (IT personnel expertise, IT infrastructure flexibility, and IT management capabilities), process-oriented dynamic capabilities, and financial performance.",objective,1
1697,"Processoriented dynamic capabilities are defined as a firm’s ability to change (improve, adapt, or reconfigure) a business process better than the competition in terms of integrating activities, reducing cost, and capitalizing on business intelligence/learning.",objective,1
1698,"They encompass a broad category of changes in the firm’s processes, ranging from continual adjustments and improvements to radical one-time alterations.",method,2
1699,"Although the majority of changes may be incremental, a firm’s capacity for timely changes also implies its readiness to execute radical alterations when the need arises.",objective,1
1700,"Grounded on the theoretical position, we propose a research model and gather a survey data set through a rigorous process that retains research validity.",method,2
1701,"From the analysis of the survey data, we find an important route of causality, as follows: IT personnel expertise  IT management capabilities  IT infrastructure flexibility  process-oriented dynamic capabilities  financial performance.",method,2
1702,"Based on this finding, we discuss the main contributions of our study in terms of the strategic role of IT in enhancing firm performance.",result,3
1703,There has been a drastic growth of research in Generative Adversarial Nets (GANs) in the past few years.,background,0
1704,"Proposed in 2014, GAN has been applied to various applications such as computer vision and natural language processing, and achieves impressive performance.",objective,1
1705,"Among the many applications of GAN, image synthesis is the most well-studied one, and research in this area has already demonstrated the great potential of using GAN in image synthesis.",objective,1
1706,"In this paper, we provide a taxonomy of methods used in image synthesis, review different models for text-to-image synthesis and image-to-image translation, and discuss some evaluation metrics as well as possible future research directions in image synthesis with GAN.",method,2
1707,Recently there has been growing interest in applying object-oriented approach to large-scale programs with a view to treating the various complexities within these.,background,0
1708,Software designed using an object-oriented approach can be significantly more robust than traditional software.,background,0
1709,"More codes can be reused and it can be easier to refine, test, maintain and extend the software.",background,0
1710,Several benefits of this approach may also be observed in the area of finite element analysis.,background,0
1711,"This paper describes an implementation of objectoriented programming to the finite element method for engineering analysis using C++, and illustrates the advantages of this approach.",objective,1
1712,This paper presents a simple method to recognise multistroke sketches of geometric shapes.,method,2
1713,"It uses temporal adjacency and global geometric properties of gures to recognise a simple vocabulary of geometric shapes including solid and dashed line styles, selection and delete gestures.",background,0
1714,"The geometric features used (convex hull, smallest-area regular polygons, perimeter and area scalar ratios) are invariant with rotation and scale of gures.",background,0
1715,We have found the method very usable with acceptable recognition rates although the multi-stroke approach poses problems in choosing appropriate values for time-outs.,method,2
1716,"Although we have privileged simplicity over robustness, the method has proved suitable for interactive applications.",method,2
1717,One of the challenges in the study of generative adversarial networks is the instability of its training.,background,0
1718,"In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator.",objective,1
1719,Our new normalization technique is computationally light and easy to incorporate into existing implementations.,objective,1
1720,"We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques.",objective,1
1721,"The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.",result,3
1722,"The ambitious goals set for 5G wireless networks, which are expected to be introduced around 2020, require dramatic changes in the design of different layers for next generation communications systems.",background,0
1723,"Massive MIMO systems, filter bank multi-carrier modulation, relaying technologies, and millimeter-wave communications have been considered as some of the strong candidates for the physical layer design of 5G networks.",background,0
1724,"In this article, we shed light on the potential and implementation of IM techniques for MIMO and multi-carrier communications systems, which are expected to be two of the key technologies for 5G systems.",method,2
1725,"Specifically, we focus on two promising applications of IM: spatial modulation and orthogonal frequency-division multiplexing with IM, and discuss the recent advances and future research directions in IM technologies toward spectrum- and energy-efficient 5G wireless networks.",method,2
1726,LIBSVM is a library for Support Vector Machines (SVMs).,background,0
1727,We have been actively developing this package since the year 2000.,background,0
1728,The goal is to help users to easily apply SVM to their applications.,objective,1
1729,LIBSVM has gained wide popularity in machine learning and many other areas.,objective,1
1730,"In this article, we present all implementation details of LIBSVM.",method,2
1731,Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.,result,3
1732,"Active, constructive, and interactive are terms that are commonly used in the cognitive and learning sciences.",background,0
1733,They describe activities that can be undertaken by learners.,background,0
1734,"However, the literature is actually not explicit about how these terms can be defined; whether they are distinct; and whether they refer to overt manifestations, learning processes, or learning outcomes.",background,0
1735,"Thus, a framework is provided here that offers a way to differentiate active, constructive, and interactive in terms of observable overt activities and underlying learning processes.",method,2
1736,"The framework generates a testable hypothesis for learning: that interactive activities are most likely to be better than constructive activities, which in turn might be better than active activities, which are better than being passive.",method,2
1737,Studies from the literature are cited to provide evidence in support of this hypothesis.,method,2
1738,"Moreover, postulating underlying learning processes allows us to interpret evidence in the literature more accurately.",method,2
1739,"Specifying distinct overt activities for active, constructive, and interactive also offers suggestions for how learning activities can be coded and how each kind of activity might be elicited.",result,3
1740,The paper presents a new generation of torque-controlled li ghtweight robots (LWR) developed at the Institute of Robotics and Mechatronics of the German Aerospace Center .,background,0
1741,"I order to act in unstructured environments and interact with humans, the robots have design features an d co trol/software functionalities which distinguish them from classical robots, such as: load-to-weight ratio o f 1:1, torque sensing in the joints, active vibration damping, sensitive collision detection, as well as complia nt control on joint and Cartesian level.",objective,1
1742,"Due to the partially unknown properties of the environment, robustne s of planning and control with respect to environmental variations is crucial.",objective,1
1743,"After briefly describing the main har dware features, the paper focuses on showing how joint torque sensing (as a main feature of the robot) is conse quently used for achieving the above mentioned performance, safety, and robustness properties.",result,3
1744,"We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake.",background,0
1745,This framework corresponds to a minimax two-player game.,method,2
1746,"In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1 2 everywhere.",method,2
1747,"In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation.",method,2
1748,There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples.,method,2
1749,Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.,result,3
1750,Deep Bidirectional LSTM (DBLSTM) recurrent neural networks have recently been shown to give state-of-the-art performance on the TIMIT speech database.,background,0
1751,"However, the results in that work relied on recurrent-neural-network-specific objective functions, which are difficult to integrate with existing large vocabulary speech recognition systems.",background,0
1752,This paper investigates the use of DBLSTM as an acoustic model in a standard neural network-HMM hybrid system.,objective,1
1753,We find that a DBLSTM-HMM hybrid gives equally good results on TIMIT as the previous work.,result,3
1754,It also outperforms both GMM and deep network benchmarks on a subset of the Wall Street Journal corpus.,method,2
1755,"However the improvement in word error rate over the deep network is modest, despite a great increase in framelevel accuracy.",method,2
1756,We conclude that the hybrid approach with DBLSTM appears to be well suited for tasks where acoustic modelling predominates.,result,3
1757,Further investigation needs to be conducted to understand how to better leverage the improvements in frame-level accuracy towards better word error rates.,result,3
1758,"Since the early days of the Internet, gender gap has existed in using the Internet, and it is particularly evident for online shopping.",background,0
1759,"Females perceive higher level of risk for online shopping, and as a result, they tend to hesitate to make purchase online.",background,0
1760,Online consumer reviews can effectively mitigate such perceived risk by females and thereby attract them to buy online.,objective,1
1761,This study investigates the effect of online consumer reviews on consumer’s purchase intention.,objective,1
1762,"In particular, we examine whether there are gender differences in responding to online consumer reviews.",method,2
1763,The results show that the effect of online consumer reviews on purchase intention is stronger for females than males.,method,2
1764,"The negativity effect, that consumers are influenced by a negative review more than by a positive review, is also found to be more evident for females.",result,3
1765,These findings have practical implications for online sellers to guide them to effectively use online consumer reviews to engage females in online shopping.,result,3
1766,"Big-data server applications frequently encounter data misses, and hence, lose significant performance potential.",background,0
1767,One way to reduce the number of data misses or their effect is data prefetching.,background,0
1768,"As data accesses have high temporal correlations, temporal prefetching techniques are promising for them.",background,0
1769,"While state-of-the-art temporal prefetching techniques are effective at reducing the number of data misses, we observe that there is a significant gap between what they offer and the opportunity.",background,0
1770,This work aims to improve the effectiveness of temporal prefetching techniques.,objective,1
1771,We identify the lookup mechanism of existing temporal prefetchers responsible for the large gap between what they offer and the opportunity.,method,2
1772,"Existing lookup mechanisms either not choose the right stream in the history, or unnecessarily delay the stream selection, and hence, miss the opportunity at the beginning of every stream.",method,2
1773,"In this work, we introduce Domino prefetching to address the limitations of existing temporal prefetchers.",method,2
1774,Domino prefetcher is a temporal data prefetching technique that logically looks up the history with both one and two last miss addresses to find a match for prefetching.,method,2
1775,We propose a practical design for Domino prefetcher that employs an Enhanced Index Table that is indexed by just a single miss address.,method,2
1776,"In this paper we investigate whether Virtual Reality (VR) and Augmented Reality (AR) offer potential for the training of manual skills, such as for assembly tasks, in comparison to conventional media.",background,0
1777,We present results from experiments that compare assembly completion times for a number of different conditions.,result,3
1778,We firstly investigate completion times for a task where participants can study an engineering drawing and an assembly plan and then conduct the task.,result,3
1779,We then investigate the task under various VR conditions and,result,3
1780,The following paper presents results of combining two intensively developed technologies used to build database applications SQL’s recursive queries and object-relational mapping.,background,0
1781,Recursive queries are efficient tools for querying graph and hierarchical structures.,background,0
1782,They are very useful in solving problems such as searching for connections between two cities or calculating bill-of-material.,background,0
1783,Object-relational mapping allows for separation of business logic from database layer and more efficient implementation of computer software.,result,3
1784,"However, modern mapping systems still lack support for many advanced SQL techniques.",result,3
1785,In order to perform a recursive calculation a programmer has to either write a recursive function in a language supported by the target database or implement a native function in the main software code that recursively sends queries to the database.,result,3
1786,The authors propose an enhancement enabling the use of recursive queries in one of the most popular ORM systems Hibernate for Java language.,method,2
1787,With this enhancement a programmer will be able to take a full advantage of the support for the recursive queries offered by various object-relational database management systems and write a code fully compliant with Hibernate standard.,result,3
1788,"The proposed solution works with IBM DB2, Oracle and PostgreSQL DBMS and proved to be many times faster than the approaches currently used.",result,3
1789,The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by factorizing distributions.,background,0
1790,"This is for a good reason: the gaussian approximation is in general plagued by an number of variational parameters to be optimized, N being the number of random variables.",background,0
1791,"In this letter, we discuss the relationship between the Laplace and the variational approximation, and we show that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually .",method,2
1792,The approach is applied to gaussian process regression with nongaussian likelihoods.,result,3
1793,Auditors and process managers often face a huge amount of financial entries in accounting information systems.,background,0
1794,For many reasons like auditing the internal control system a process-oriented view would be more helpful to understand how a set of transactions produced financial entries.,background,0
1795,For this reason we present an algorithm capable to mine financial entries and open items to reconstruct the process instances which produced the financial entries.,objective,1
1796,"In this way, auditors can trace how balance sheet items have been produced in the system.",objective,1
1797,Traditional process mining techniques only reconstruct processes but pay no regard to the financial dimension.,method,2
1798,The paper wants to close this gap and integrate the process view with the accounting view.,method,2
1799,"In this paper, we present a possible application of neural networks as a component of an intrusion detection system.",background,0
1800,Neural network algorithms are emerging nowadays as a new arnficial intelligence techm”quethat can be applied to real-l~e problems.,background,0
1801,We present an approach of user behavior modeling that takes advantage of the properties of neural algorithms and display results obtained on preliminary testing of our approach.,method,2
1802,We consider the problem of embedding entities and relationships of multirelational data in low-dimensional vector spaces.,background,0
1803,"Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases.",objective,1
1804,"Hence, we propose TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities.",method,2
1805,"Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases.",other,4
1806,"Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.",result,3
1807,Visual speech enhancement is used on videos shot in noisy environments to enhance the voice of a visible speaker and to reduce background noise.,background,0
1808,"While most existing methods use audio-only inputs, we propose an audio-visual neural network model for this purpose.",method,2
1809,The visible mouth movements are used to separate the speaker’s voice from the background sounds.,method,2
1810,"Instead of training our speech enhancement model on a wide range of possible noise types, we train the model on videos where other speech samples of the target speaker are used as background noise.",method,2
1811,"A model trained using this paradigm generalizes well to various noise types, while also substantially reducing training time.",method,2
1812,The proposed model outperforms prior audio visual methods on two public lipreading datasets.,method,2
1813,It is also the first to be demonstrated on a general dataset not designed for lipreading.,result,3
1814,Our dataset was composed of weekly addresses of Barack Obama.,result,3
1815,Distributed real-time embedded (DRE) software systems such as are used to manage critical large-scale infrastructure are important systems to target for increased functionality and resiliency.,background,0
1816,DRE systems that can adapt to changes in the environment and/or changes in available resources are more robust to unexpected changes and extend both the systems' utility and lifespan.,background,0
1817,Artificial intelligence techniques are used for adaptation of software systems in general.,background,0
1818,"However, they must meet certain requirements to be appropriate for use with DRE systems.",background,0
1819,"Any artificial intelligence (AI) technique used in an adaptive DRE system should produce consistent results across a distributed system, operate in bounded time, make decisions autonomously, and gracefully handle and learn from previously unencountered environments.",background,0
1820,"This paper surveys a variety of AI techniques, providing a brief overview of each method, evaluating how each technique fits the requirements of an adaptive DRE system, and recognizing the gaps in each technique's ability to meet all of these requirements.",method,2
1821,"Our results show that there is not one single AI technique in our survey that is a perfect fit for adaptive DRE systems, although some techniques address more of these requirements than others.",result,3
1822,Digitization of paper-bound documents is one of the foremost commercial interests worldwide.,background,0
1823,"First step in all such applications is transforming a paper bound document into an electronic document by scanning, subsequently applying to the image OCR to generate textual information from the document image.",background,0
1824,In this paper we describe our work that acts as a pre-processing stage for OCR application.,background,0
1825,"Automatic document layout extraction and segmentation is done using spatial configuration of various text/image segments represented as bounded boxes; this segmented layout is than analyzed with certain heuristic tests and each segment is assigned labels (title, authors, abstract, body, header, footer etc).",objective,1
1826,"This information is than passed on to OCR module as an XML interface, accelerating it¿s performance by allowing it to label recognized text segments and identifying only those parts of the document which have text resulting saving in computation.",method,2
1827,"Although, the work has been motivated for application to an automated machine translation system preserving the overall document layout, it has a number of other applications such as in information retrieval, search etc.",method,2
1828,This information is also being used to classify technical documents into three categories which can be extended to any number of classes based on spatial configuration heuristics.,result,3
1829,In this paper we propose a new General Image DataBase (GIDB) model.,objective,1
1830,The model establishes taxonomy based on the systematisation of existing approaches.,objective,1
1831,The GIDB model is based on the General Image Data model [1] and General Image Retrieval model [2].,objective,1
1832,"The GIDB model uses the powerful features offered by objectoriented modelling, the elegance of the relational databases, the state of art of computer vision and the current methods for knowledge representation and management to achieve effective image retrieval.",method,2
1833,The developed language for the model is a hybrid between interactive and descriptive query languages.,method,2
1834,The ideas of the model can be used in the design of image retrieval libraries for an object-oriented database.,result,3
1835,As an illustration the results of applying the GIDB model to a plant database in the Sofia Image Database Management System are presented.,result,3
1836,"The increasing demand of mobile Internet and the Internet of Things poses challenging requirements for 5G wireless communications, such as high spectral efficiency and massive connectivity.",background,0
1837,"In this article, a promising technology, non-orthogonal multiple access (NOMA), is discussed, which can address some of these challenges for 5G.",background,0
1838,"Different from conventional orthogonal multiple access technologies, NOMA can accommodate much more users via nonorthogonal resource allocation.",background,0
1839,"We divide existing dominant NOMA schemes into two categories: power-domain multiplexing and code-domain multiplexing, and the corresponding schemes include power-domain NOMA, multiple access with low-density spreading, sparse code multiple access, multi-user shared access, pattern division multiple access, and so on.",method,2
1840,"We discuss their principles, key features, and pros/cons, and then provide a comprehensive comparison of these solutions from the perspective of spectral efficiency, system performance, receiver complexity, and so on.",background,0
1841,"In addition, challenges, opportunities, and future research trends for NOMA design are highlighted to provide some insight on the potential future work for researchers in this field.",result,3
1842,"Finally, to leverage different multiple access schemes including both conventional OMA and new NOMA, we propose the concept of software defined multiple access (SoDeMA), which enables adaptive configuration of available multiple access schemes to support diverse services and applications in future 5G networks.",method,2
1843,Many schemes have been recently advanced for storing data on multiple clouds.,background,0
1844,"Distributing data over different cloud storage providers (CSPs) automatically provides users with a certain degree of information leakage control, as no single point of attack can leak all user's information.",method,2
1845,"However, unplanned distribution of data chunks can lead to high information disclosure even while using multiple clouds.",objective,1
1846,"In this paper, to address this problem we present StoreSim, an information leakage aware storage system in multicloud.",method,2
1847,"StoreSim aims to store syntactically similar data on the same cloud, thus minimizing the user's information leakage across multiple clouds.",objective,1
1848,"We design an approximate algorithm to efficiently generate similarity-preserving signatures for data chunks based on MinHash and Bloom filter, and also design a function to compute the information leakage based on these signatures.",method,2
1849,"Next, we present an effective storage plan generation algorithm based on clustering for distributing data chunks with minimal information leakage across multiple clouds.",method,2
1850,"Finally, we evaluate our scheme using two real datasets from Wikipedia and GitHub.",result,3
1851,We show that our scheme can reduce the information leakage by up to 60% compared to unplanned placement.,result,3
1852,"In this paper we present eMir, digital signage (public electronic displays) that show human faces which react to audience emotion.",method,2
1853,"Using a camera installed at the sign, the system observes the audience and detects whether someone watches the display via face detection software.",method,2
1854,The face detection is able to classify facial expressions and determine gender.,method,2
1855,This information is used to let a human character on the screen react accordingly and encourage interaction with the face/sign.,method,2
1856,The system has been deployed for one month on a digital sign in a university building.,background,0
1857,"We present experiences with the system, our findings from the collected interaction data and results from interviews with eight users.",result,3
1858,"In this paper, the performance of a topological-metric visual-path-following framework is investigated in different environments.",background,0
1859,The framework relies on a monocular camera as the only sensing modality.,method,2
1860,The path is represented as a series of reference images such that each neighboring pair contains a number of common landmarks.,method,2
1861,Local 3-D geometries are reconstructed between the neighboring reference images to achieve fast feature prediction.,method,2
1862,This condition allows recovery from tracking failures.,method,2
1863,"During navigation, the robot is controlled using image-based visual servoing.",method,2
1864,"The focus of this paper is on the results from a number of experiments that were conducted in different environments, lighting conditions, and seasons.",objective,1
1865,The experiments with a robot car show that the framework is robust to moving objects and moderate illumination changes.,result,3
1866,It is also shown that the system is capable of online path learning.,result,3
1867,We introduce a neural network with a recurrent attention model over a possibly large external memory.,background,0
1868,"The architecture is a form of Memory Network [23] but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings.",method,2
1869,It can also be seen as an extension of RNNsearch [2] to the case where multiple computational steps (hops) are performed per output symbol.,method,2
1870,The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering [22] and to language modeling.,method,2
1871,"For the former our approach is competitive with Memory Networks, but with less supervision.",method,2
1872,"For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs.",result,3
1873,In both cases we show that the key concept of multiple computational hops yields improved results.,result,3
1874,"In this paper, a power density analysis is presented for 7nm FinFET technology node based on both shorted-gate (SG) and independent-gate (IG) standard cells operating in multiple supply voltage regimes.",background,0
1875,A Liberty-formatted standard cell library is established by selecting the appropriate number of fins for the pull-up and pull-down networks of each logic cell.,method,2
1876,The layout of both shorted-gate and independent-gate standard cells are then characterized according to lambda-based layout design rules for FinFET devices.,method,2
1877,"Finally, the power density of 7nm FinFET technology node is analyzed and compared with the 45 nm CMOS technology node for different circuits.",method,2
1878,Experimental result shows that the power density of each 7nm FinFET circuit is 3-20 times larger than that of 45nm CMOS circuit under the spacer-defined technology.,result,3
1879,Experimental result also shows that the back-gate signal enables a better control of power consumption for independent-gate FinFETs.,result,3
1880,"Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of “one-shot learning.",background,0
1881,”,other,4
1882,"Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training.",background,0
1883,"When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference.",method,2
1884,"Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models.",method,2
1885,"Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples.",method,2
1886,"We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms.",method,2
1887,In this paper we describe simple identification and signature schemes which enable any user to prove his identity and the authenticity of his messages to any other user without shared or public keys.,background,0
1888,"The schemes are provably secure against any known or chosen message attack if factoring is difficult, and typical implementations require only 1% to 4% of the number of modular multiplications required by the RSA scheme.",background,0
1889,"Due to their simplicity, security and speed, these schemes are ideally suited for microprocessor-based devices such as smart cards, personal computers, and remote control systems.",background,0
1890,"We presentconditional random fields, a framework for building probabilistic models to segment and label sequence data.",objective,1
1891,"Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models.",method,2
1892,"Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states.",method,2
1893,We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data.,result,3
1894,has slightly different meanings to different people.,background,0
1895,"Some believe a Web application is anything that uses Java, others consider a Web application anything that uses a Web server.",background,0
1896,The general consensus is somewhere in between.,background,0
1897,"In this article, a Web application will be loosely defined as a Web system (Web server, network, HTTP, browser) in which user input (navigation and data input) effects the state of the business.",objective,1
1898,"This definition attempts to establish that a Web application is a software system with business state, and that its front end is in large part delivered via a Web system.",objective,1
1899,The general architecture of a Web application is A new term has entered,background,0
1900,"Kaplan-Meier survival curves and the associated nonparametric log rank test statistic are methods of choice for unadjusted survival analyses, while the semiparametric Cox proportional hazards regression model is used ubiquitously as a method for covariate adjustment.",method,2
1901,"The Cox model extends naturally to include covariates, but there is no generally accepted method to graphically depict adjusted survival curves.",background,0
1902,The authors describe a method and provide a simple worked example using inverse probability weights (IPW) to create adjusted survival curves.,method,2
1903,"When the weights are non-parametrically estimated, this method is equivalent to direct standardization of the survival curves to the combined study population.",method,2
1904,The estimation of a vehiclepsilas dynamic state is one of the most fundamental data fusion tasks for intelligent traffic applications.,background,0
1905,"For that, motion models are applied in order to increase the accuracy and robustness of the estimation.",background,0
1906,This paper surveys numerous (especially curvilinear) models and compares their performance using a tracking tasks which includes the fusion of GPS and odometry data with an Unscented Kalman Filter.,method,2
1907,"For evaluation purposes, a highly accurate reference trajectory has been recorded using an RTK-supported DGPS receiver.",result,3
1908,"With this ground truth data, the performance of the models is evaluated in different scenarios and driving situations.",result,3
1909,This paper introduces an approach of creating face makeup upon a face image with another image as the style example.,background,0
1910,"Our approach is analogous to physical makeup, as we modify the color and skin detail while preserving the face structure.",background,0
1911,"More precisely, we first decompose the two images into three layers: face structure layer, skin detail layer, and color layer.",method,2
1912,"Thereafter, we transfer information from each layer of one image to corresponding layer of the other image.",method,2
1913,One major advantage of the proposed method lies in that only one example image is required.,method,2
1914,This renders face makeup by example very convenient and practical.,result,3
1915,"Equally, this enables some additional interesting applications, such as applying makeup by a portraiture.",result,3
1916,The experiment results demonstrate the effectiveness of the proposed approach in faithfully transferring makeup.,result,3
1917,"Research into online gaming has steadily increased over the last decade, although relatively little research has examined the relationship between online gaming addiction and personality factors.",background,0
1918,"This study examined the relationship between a number of personality traits (sensation seeking, self-control, aggression, neuroticism, state anxiety, and trait anxiety) and online gaming addiction.",objective,1
1919,Data were collected over a 1-month period using an opportunity sample of 123 university students at an East Midlands university in the United Kingdom.,method,2
1920,Gamers completed all the online questionnaires.,method,2
1921,"Results of a multiple linear regression indicated that five traits (neuroticism, sensation seeking, trait anxiety, state anxiety, and aggression) displayed significant associations with online gaming addiction.",result,3
1922,"The study suggests that certain personality traits may be important in the acquisition, development, and maintenance of online gaming addiction, although further research is needed to replicate the findings of the present study.",result,3
1923,Table detection is a crucial step in many document analysis applications as tables are used for presenting essential information to the reader in a structured manner.,background,0
1924,It is a hard problem due to varying layouts and encodings of the tables.,background,0
1925,Researchers have proposed numerous techniques for table detection based on layout analysis of documents.,method,2
1926,Most of these techniques fail to generalize because they rely on hand engineered features which are not robust to layout variations.,method,2
1927,"In this paper, we have presented a deep learning based method for table detection.",method,2
1928,"In the proposed method, document images are first pre-processed.",method,2
1929,These images are then fed to a Region Proposal Network followed by a fully connected neural network for table detection.,method,2
1930,"The proposed method works with high precision on document images with varying layouts that include documents, research papers, and magazines.",method,2
1931,We have done our evaluations on publicly available UNLV dataset where it beats Tesseract's state of the art table detection system by a significant margin.,result,3
1932,"In this paper, we study the linking patterns and discussion topics of political bloggers.",background,0
1933,"Our aim is to measure the degree of interaction between liberal and conservative blogs, and to uncover any differences in the structure of the two communities.",objective,1
1934,"Specifically, we analyze the posts of 40 ""A-list"" blogs over the period of two months preceding the U.S. Presidential Election of 2004, to study how often they referred to one another and to quantify the overlap in the topics they discussed, both within the liberal and conservative communities, and also across communities.",method,2
1935,"We also study a single day snapshot of over 1,000 political blogs.",method,2
1936,"This snapshot captures blogrolls (the list of links to other blogs frequently found in sidebars), and presents a more static picture of a broader blogosphere.",method,2
1937,"Most significantly, we find differences in the behavior of liberal and conservative blogs, with conservative blogs linking to each other more frequently and in a denser pattern.",result,3
1938,The field of privacy has seen rapid advances in recent years because of the increases in the ability to store data.,background,0
1939,"In particular, recent advances in the data mining field have lead to increased concerns about privacy.",background,0
1940,"While the topic of privacy has been traditionally studied in the context of cryptography and information-hiding, recent emphasis on data mining has lead to renewed interest in the field.",background,0
1941,"In this chapter, we will introduce the topic of privacy-preserving data mining and provide an overview of the different topics covered in this book.",objective,1
1942,"Sponsored recommendation blog posts, a form of online consumer review, are blog articles written by bloggers who receive benefits from sponsoring marketers to review and promote products on their personal blog.",background,0
1943,"Because national regulations require that marketer sponsorship must be revealed in the blog post, sponsored recommendation posts can no longer conceal their marketing intent.",background,0
1944,Consumer’s attitudes toward sponsored recommendation posts are thus a vital issue in assessing the effectiveness of the advertisement.,background,0
1945,This study uses a 2(sponsorship type) !,method,2
1946,2(product type) !,method,2
1947,2(brand awareness) experimental design and a total of 613 valid samples to examine consumer attitudes toward sponsored recommendation posts and purchase intention.,method,2
1948,"The results show that when products recommended in blog posts are search goods or have high brand awareness, consumers have highly positive attitudes toward sponsored recommendation posts, which improves purchase intention.",result,3
1949,The directly-monetary/ indirect-monetary benefits received by the bloggers have no significant effect on readership attitudes.,other,4
1950,Using these features in blog writings appears to improve online readers’ trust toward and the credibility of sponsored recommendation posts and thus can be a vital online marketing tool for marketers. !,result,3
1951,2014 Elsevier Ltd.,other,4
1952,"The purpose of this study was to examine force transmission from one of the major multi-articular muscles of the finger, flexor digitorum pro-fundus (FDP), to the index finger.",objective,1
1953,"Specifically, we examined whether the popular moment arm (MA)-joint torque technique of modeling muscle force transmission can accurately represent the effects of the FDP on finger movement.",method,2
1954,A dynamic finger model employing geometric MA values (model I) was compared with another model including realistic tendon force transformation mechanisms via pulley structures and joint reaction forces (model II).,method,2
1955,Finger flexion movements generated by these models were compared with those obtained from in vivo stimulation experiments.,method,2
1956,"The model with the force transformation mechanisms (model II) resulted in more realistic joint spatial coordination (i.e., proximal interphalangeal > metacarpophalangeal ges distal interphalangeal) than the MA-based model (model I) in relation to the movement patterns evoked by stimulation.",method,2
1957,"Also, the importance of the pulley structures and passive joint characteristics was confirmed in the model simulation; altering/eliminating these components significantly changed the spatial coordination of the joint angles during the resulting movements.",method,2
1958,"The results of this study emphasize the functional importance of the force transformation through various biomechanical components, and suggest the importance of including these components when investigating finger motor control, such as for examining injury mechanisms or designing rehabilitation protocols.",result,3
1959,"With the popularity of social media (e.g., Facebook and Flicker), users can easily share their check-in records and photos during their trips.",background,0
1960,"In view of the huge number of user historical mobility records in social media, we aim to discover travel experiences to facilitate trip planning.",background,0
1961,"When planning a trip, users always have specific preferences regarding their trips.",background,0
1962,"Instead of restricting users to limited query options such as locations, activities, or time periods, we consider arbitrary text descriptions as keywords about personalized requirements.",method,2
1963,"Moreover, a diverse and representative set of recommended travel routes is needed.",method,2
1964,Prior works have elaborated on mining and ranking existing routes from check-in data.,background,0
1965,"To meet the need for automatic trip organization, we claim that more features of Places of Interest (POIs) should be extracted.",method,2
1966,"Therefore, in this paper, we propose an efficient Keyword-aware Representative Travel Route framework that uses knowledge extraction from users’ historical mobility records and social interactions.",objective,1
1967,"Explicitly, we have designed a keyword extraction module to classify the POI-related tags, for effective matching with query keywords.",method,2
1968,We have further designed a route reconstruction algorithm to construct route candidates that fulfill the requirements.,method,2
1969,Deep learning is a broad set of techniques that uses multiple layers of representation to automatically learn relevant features directly from structured data.,background,0
1970,"Recently, such techniques have yielded record-breaking results on a diverse set of difficult machine learning tasks in computer vision, speech recognition, and natural language processing.",background,0
1971,"Despite the enormous success of deep learning, relatively little is understood theoretically about why these techniques are so successful at feature learning and compression.",background,0
1972,"Here, we show that deep learning is intimately related to one of the most important and successful techniques in theoretical physics, the renormalization group (RG).",background,0
1973,RG is an iterative coarse-graining scheme that allows for the extraction of relevant features (i.e. operators) as a physical system is examined at different length scales.,method,2
1974,"We construct an exact mapping from the variational renormalization group, first introduced by Kadanoff, and deep learning architectures based on Restricted Boltzmann Machines (RBMs).",method,2
1975,We illustrate these ideas using the nearest-neighbor Ising Model in one and two-dimensions.,method,2
1976,Our results suggests that deep learning algorithms may be employing a generalized RG-like scheme to learn relevant features from data.,result,3
1977,Social networking sites (SNS) provide opportunities for mood management through selective exposure.,background,0
1978,This study tested the prediction that negative mood fosters self-enhancing social comparisons to SNS profiles.,objective,1
1979,Participants were induced into positive or negative moods and then browsed manipulated profiles on an experimental SNS.,method,2
1980,"Profiles varied in a 2 2 within-subjects design along two dimensions, ratings of career success and attractiveness, allowing for upward comparisons (high ratings) and downward comparisons (low ratings).",method,2
1981,Selective exposure was measured in seconds spent viewing profiles.,method,2
1982,Negative mood led to less exposure to upward comparisons and more to downward comparisons than positive mood.,method,2
1983,The comparison dimension did not influence selective exposure.,method,2
1984,"Thus, in a negative mood, SNS users prefer self-enhancing social comparisons to manage their mood.",result,3
1985,2014 Elsevier Ltd.,other,4
1987,"In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing.",background,0
1988,"In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a efficiency and/or effectiveness perspective.",background,0
1989,"Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful.",objective,1
1990,"In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects.",background,0
1991,"We specifically examine the behavior of the commonly used Lk norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric (L1 norm) is consistently more preferable than the Euclidean distance metric (L2 norm) for high dimensional data mining applications.",method,2
1992,"Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lk norm to fractional distance metrics.",result,3
1993,We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective.,result,3
1994,The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.,result,3
1995,We describe an object detection system based on mixtures of multiscale deformable part models.,method,2
1996,Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges.,method,2
1997,"While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets.",background,0
1998,Our system relies on new methods for discriminative training with partially labeled data.,method,2
1999,We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM.,method,2
2000,A latent SVM is a reformulation of MI--SVM in terms of latent variables.,method,2
2001,"A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples.",method,2
2002,This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.,result,3
2003,"A new, large scale multiprocessor architecture is presented in this paper.",objective,1
2004,The architecture consists of hierarchies of shared buses and caches.,method,2
2005,Extended versions of shared bus multicache coherency protocols are used to maintain coherency among all caches in the system.,method,2
2006,"After explaining the basic operation of the strict hierarchical approach, a clustered system is introduced which distributes the memory among groups of processors.",method,2
2007,Results of simulations are presented which demonstrate that the additional coherency protocol overhead introduced by the clustered approach is small.,result,3
2008,The simulations also show that a 128 processor multiprocessor can be constructed using this architecture which will achieve a substantial fraction of its peak performance.,result,3
2009,"Finally, an analytic model is used to explore systems too large to simulate (with available hardware).",result,3
2010,The model indicates that a system of over 1000 usable MIPS can be constructed using high performance microprocessors.,result,3
2011,The Internet of Things (IoT) is changing human lives by connecting everyday objects together.,background,0
2012,"For example, in a grocery store, all items can be connected with each other, forming a smart shopping system.",background,0
2013,"In such an IoT system, an inexpensive radio frequency identification (RFID) tag can be attached to each product which, when placed into a smart shopping cart, can be automatically read by a cart equipped with an RFID reader.",background,0
2014,"As a result, billing can be conducted from the shopping cart itself, preventing customers from waiting in a long queue at checkout.",result,3
2015,"Additionally, smart shelving can be added into this system, equipped with RFID readers, and can monitor stock, perhaps also updating a central server.",result,3
2016,"Another benefit of this kind of system is that inventory management becomes much easier, as all items can be automatically read by an RFID reader instead of manually scanned by a laborer.",result,3
2017,"To validate the feasibility of such a system, in this paper we identify the design requirements of a smart shopping system, build a prototype system to test functionality, and design a secure communication protocol to make the system practical.",result,3
2018,"To the best of our knowledge, this is the first time a smart shopping system is proposed with security under consideration.",other,4
2019,This paper is concerned with the design of gain-scheduled controllers with guaranteed %$ performance for a class of linear parameter-varying (LPV) plants.,background,0
2020,Here the plant state-space matrices are assumed to depend affinely on a vector 8 of time-varying real parameters.,background,0
2021,"Assuming real-time measurement of these parameters, they can be fed to the controller to optimize the performance and robustness of the closed-loop system.",background,0
2022,The resulting controller is time-varying and automatically ‘gain-scheduled’ along parameter trajectories.,background,0
2023,"Based on the notion of quadratic %& performance, solvability conditions are obtained for continuousand discrete-time systems.",background,0
2024,In both cases the synthesis problem reduces to solving a system of linear matrix inequalities (LMIs).,background,0
2025,The main benefit of this approach is to bypass most difficulties associated with more classical schemes such as gain-interpolation or gain-scheduling techniques.,objective,1
2026,The methodology presented in this paper is applied to the gain scheduling of a missile autopilot.,method,2
2027,The missile has a large operating range and high angles of attack.,result,3
2028,The dificulty of the problem is reinforced by tight performance requirements as well as the presence of flexible modes that limit the control bandwidth.,result,3
2029,Much is known about the motor system and its role in simple movement execution.,background,0
2030,"However, little is understood about the neural systems underlying auditory-motor integration in the context of musical rhythm, or the enhanced ability of musicians to execute precisely timed sequences.",background,0
2031,"Using functional magnetic resonance imaging, we investigated how performance and neural activity were modulated as musicians and nonmusicians tapped in synchrony with progressively more complex and less metrically structured auditory rhythms.",method,2
2032,"A functionally connected network was implicated in extracting higher-order features of a rhythm's temporal structure, with the dorsal premotor cortex mediating these auditory-motor interactions.",method,2
2033,"In contrast to past studies, musicians recruited the prefrontal cortex to a greater degree than nonmusicians, whereas secondary motor regions were recruited to the same extent.",method,2
2034,We argue that the superior ability of musicians to deconstruct and organize a rhythm's temporal structure relates to the greater involvement of the prefrontal cortex mediating working memory.,result,3
2035,The least squares problem is formulated in terms of ℓ p quasi-norm regularization (0 < p < 1).,method,2
2036,Two formulations are considered: (i) an ℓ p-constrained optimization and (ii) an ℓ p-penalized (unconstrained) optimization.,method,2
2037,"Due to the nonconvexity of the ℓ p quasi-norm, the solution paths of the regularized least squares problem are not ensured to be continuous.",method,2
2038,"A critical path, which is a maximal continuous curve consisting of critical points, is therefore considered separately.",result,3
2039,"The critical paths are piecewise smooth, as can be seen from the viewpoint of the variational method, and generally contain non-optimal points such as saddle points and local maxima as well as global/local minima.",result,3
2040,"Along each critical path, the correspondence between the regularization parameters (which govern the 'strength' of regularization in the two formulations) is non-monotonic and, more specifically, it has multiplicity.",result,3
2041,Two paths of critical points connecting the origin and an ordinary least squares (OLS) solution are highlighted.,result,3
2042,"One is a main path starting at an OLS solution, and the other is a greedy path starting at the origin.",method,2
2043,Part of the greedy path can be constructed with a generalized Minkowskian gradient.,method,2
2044,"The breakpoints of the greedy path coincide with the step-by-step solutions generated by using orthogonal matching pursuit (OMP), thereby establishing a direct link between OMP and ℓ p-regularized least squares.",result,3
2045,"In the Internet of Things (IoT), resource-constrained things are connected to the unreliable and untrusted Internet via IPv6 and 6LoWPAN networks.",background,0
2046,"Even when they are secured with encryption and authentication, these things are exposed both to wireless attacks from inside the 6LoWPAN network and from the Internet.",background,0
2047,"Since these attacks may succeed, Intrusion Detection Systems (IDS) are necessary.",background,0
2048,"Currently, there are no IDSs that meet the requirements of the IPv6-connected IoT since the available approaches are either customized for Wireless Sensor Networks (WSN) or for the conventional Internet.",background,0
2049,"In this paper we design, implement, and evaluate a novel intrusion detection system for the IoT that we call SVELTE.",method,2
2050,"In our implementation and evaluation we primarily target routing attacks such as spoofed or altered information, sinkhole, and selective-forwarding.",result,3
2051,"However, our approach can be extended to detect other attacks.",result,3
2052,We implement SVELTE in the Contiki OS and thoroughly evaluate it.,result,3
2053,"Our evaluation shows that in the simulated scenarios, SVELTE detects all malicious nodes that launch our implemented sinkhole and/or selective forwarding attacks.",result,3
2054,"However, the true positive rate is not 100%, i.e., we have some false alarms during the detection of malicious nodes.",result,3
2055,The research field of technology acceptance and software acceptance is a fertile field in the discipline of MIS.,background,0
2056,Acceptance research is mainly affected by the technology acceptance model (TAM).,background,0
2057,The TAM is counted as the major guideline for acceptance research.,background,0
2058,But recently more researchers discover the deficits of former acceptance research.,background,0
2059,The main cause of the criticism is the focus on quantitative research methods.,objective,1
2060,We will show this with the help of former meta-studies and a literature review.,method,2
2061,Quantitative approaches are basically appropriate for the testing of theories.,method,2
2062,The development of new theories or constructs is followed to a lesser intent.,method,2
2063,In the article we will show how a qualitative approach can be used for theory-construction.,method,2
2064,We will introduce a qualitative research design and show how this approach can be used to develop new constructs of acceptance while some existing constructs taken from TAM and related theories cannot be confirmed.,method,2
2065,"In this paper the major components of every programming language are identified as: (1) the elementary program statement, (2) mechanisms for linking elementary statements together, (3) the means by which a program can obtain data inputs.",background,0
2066,"Several alternative forms of each of these components are also described, compared and evaluated.",objective,1
2067,"Many examples, frequently from list processing languages, illustrate the forms described.",method,2
2068,"The advantages, disadvantages and factors influencing the choice of a form of component for a language are discussed, and the paper concludes with the suggestion that programming languages evolve toward one which will permit all the most convenient ways of structuring programs, organizing systems and referencing data.",result,3
2069,Deep neural networks have made significant breakthroughs in many fields of artificial intelligence.,background,0
2070,"However, it has not been applied in the field of programming language processing.",background,0
2071,"In this paper, we propose the treebased convolutional neural network (TBCNN) to model programming languages, which contain rich and explicit tree structural information.",objective,1
2072,"In our model, program vector representations are learned by the “coding” pretraining criterion based on abstract syntax trees (ASTs); the convolutional layer explicitly captures neighboring features on the tree; with the “binary continuous tree” and “3-way pooling,” our model can deal with ASTs of different shapes and sizes.",method,2
2073,"We evaluate the program vector representations empirically, showing that the coding criterion successfully captures underlying features of AST nodes, and that program vector representations significantly speed up supervised learning.",result,3
2074,We also compare TBCNN to baseline methods; our model achieves better accuracy in the task of program classification.,result,3
2075,"To our best knowledge, this paper is the first to analyze programs with deep neural networks; we extend the scope of deep learning to the field of programming language processing.",background,0
2076,The experimental results validate its feasibility; they also show a promising future of this new research area.,result,3
2077,"Recently, MOEA/D (multi-objective evolutionary algorithm based on decomposition) has achieved great success in the field of evolutionary multi-objective optimization and has attracted a lot of attention.",background,0
2078,It decomposes a multi-objective optimization problem (MOP) into a set of scalar subproblems using uniformly distributed aggregation weight vectors and provides an excellent general algorithmic framework of evolutionary multi-objective optimization.,background,0
2079,"Generally, the uniformity of weight vectors in MOEA/D can ensure the diversity of the Pareto optimal solutions, however, it cannot work as well when the target MOP has a complex Pareto front (PF; i.e., discontinuous PF or PF with sharp peak or low tail).",background,0
2080,"To remedy this, we propose an improved MOEA/D with adaptive weight vector adjustment (MOEA/D-AWA).",method,2
2081,"According to the analysis of the geometric relationship between the weight vectors and the optimal solutions under the Chebyshev decomposition scheme, a new weight vector initialization method and an adaptive weight vector adjustment strategy are introduced in MOEA/D-AWA.",method,2
2082,The weights are adjusted periodically so that the weights of subproblems can be redistributed adaptively to obtain better uniformity of solutions.,method,2
2083,"Meanwhile, computing efforts devoted to subproblems with duplicate optimal solution can be saved.",method,2
2084,"Moreover, an external elite population is introduced to help adding new subproblems into real sparse regions rather than pseudo sparse regions of the complex PF, that is, discontinuous regions of the PF.",method,2
2085,"MOEA/D-AWA has been compared with four state of the art MOEAs, namely the original MOEA/D, Adaptive-MOEA/D, -MOEA/D, and NSGA-II on 10 widely used test problems, two newly constructed complex problems, and two many-objective problems.",result,3
2086,"Experimental results indicate that MOEA/D-AWA outperforms the benchmark algorithms in terms of the IGD metric, particularly when the PF of the MOP is complex.",result,3
2087,"Since the textual contents on online social media are highly unstructured, informal, and often misspelled, existing research on message-level offensive language detection cannot accurately detect offensive content.",background,0
2088,"Meanwhile, user-level offensiveness detection seems a more feasible approach but it is an under researched area.",background,0
2089,"To bridge this gap, we propose the Lexical Syntactic Feature (LSF) architecture to detect offensive content and identify potential offensive users in social media.",objective,1
2090,"We distinguish the contribution of pejoratives/profanities and obscenities in determining offensive content, and introduce hand-authoring syntactic rules in identifying name-calling harassments.",method,2
2091,"In particular, we incorporate a user's writing style, structure and specific cyber bullying content as features to predict the user's potentiality to send out offensive content.",method,2
2092,Results from experiments showed that our LSF framework performed significantly better than existing methods in offensive content detection.,result,3
2093,"It achieves precision of 98.24% and recall of 94.34% in sentence offensive detection, as well as precision of 77.9% and recall of 77.8% in user offensive detection.",result,3
2094,"Meanwhile, the processing speed of LSF is approximately 10msec per sentence, suggesting the potential for effective deployment in social media.",result,3
2095,Massive multiple-input multiple-output technology has been considered a breakthrough in wireless communication systems.,background,0
2096,It consists of equipping a base station with a large number of antennas to serve many active users in the same time-frequency block.,background,0
2097,"Among its underlying advantages is the possibility to focus transmitted signal energy into very short-range areas, which will provide huge improvements in terms of system capacity.",background,0
2098,"However, while this new concept renders many interesting benefits, it brings up new challenges that have called the attention of both industry and academia: channel state information acquisition, channel feedback, instantaneous reciprocity, statistical reciprocity, architectures, and hardware impairments, just to mention a few.",result,3
2099,"This paper presents an overview of the basic concepts of massive multiple-input multiple-output, with a focus on the challenges and opportunities, based on contemporary research.",objective,1
2100,An automated irrigation system was developed to optimize water use for agricultural crops.,method,2
2101,The system has a distributed wireless network of soil-moisture and temperature sensors placed in the root zone of the plants.,method,2
2102,"In addition, a gateway unit handles sensor information, triggers actuators, and transmits data to a web application.",method,2
2103,An algorithm was developed with threshold values of temperature and soil moisture that was programmed into a microcontroller-based gateway to control water quantity.,method,2
2104,The system was powered by photovoltaic panels and had a duplex communication link based on a cellular-Internet interface that allowed for data inspection and irrigation scheduling to be programmed through a web page.,method,2
2105,The automated system was tested in a sage crop field for 136 days and water savings of up to 90% compared with traditional irrigation practices of the agricultural zone were achieved.,result,3
2106,Three replicas of the automated system have been used successfully in other places for 18 months.,result,3
2107,"Because of its energy autonomy and low cost, the system has the potential to be useful in water limited geographically isolated areas.",result,3
2108,In this work we demonstrate the usefulness of the application of Recommender Systems in the financial domain.,result,3
2109,"Specifically we investigate a dataset, made available by a major European bank, containing the purchases of a large set of investment assets by 200k investors.",objective,1
2110,We also present some preliminary results of the application of network analysis via statistical validation to identify clusters of investment assets.,result,3
2111,"Reading strategies have been shown to improve comprehension levels, especially for readers lacking adequate prior knowledge.",background,0
2112,"Just as the process of knowledge accumulation is time-consuming for human readers, it is resource-demanding to impart rich general domain knowledge into a language model via pre-training (Radford et al., 2018; Devlin et al., 2018).",background,0
2113,"Inspired by reading strategies identified in cognitive science, and given limited computational resources — just a pre-trained model and a fixed number of training instances — we therefore propose three simple domain-independent strategies aimed to improve non-extractive machine reading comprehension (MRC): (i) BACK AND FORTH READING that considers both the original and reverse order of an input sequence, (ii) HIGHLIGHTING, which adds a trainable embedding to the text embedding of tokens that are relevant to the question and candidate answers, and (iii) SELF-ASSESSMENT that generates practice questions and candidate answers directly from the text in an unsupervised manner.",background,0
2114,"By fine-tuning a pre-trained language model (Radford et al., 2018) with our proposed strategies on the largest existing general domain multiple-choice MRC dataset RACE, we obtain a 5.8% absolute increase in accuracy over the previous best result achieved by the same pre-trained model fine-tuned on RACE without the use of strategies.",method,2
2115,"We further fine-tune the resulting model on a target task, leading to new stateof-the-art results on six representative nonextractive MRC datasets from different domains (i.e., ARC, OpenBookQA, MCTest, MultiRC, SemEval-2018, and ROCStories).",method,2
2116,These results indicate the effectiveness of the proposed strategies and the versatility ∗,result,3
2117,This work was done when the author was an intern at Tencent AI Lab and general applicability of our fine-tuned models that incorporate the strategies.,other,4
2118,Most additive manufacturing processes today operate by printing voxels (3D pixels) serially point-by-point to build up a 3D part.,background,0
2119,"In some more recently-developed techniques, for example optical printing methods such as projection stereolithography [Zheng et al. 2012], [Tumbleston et al. 2015], parts are printed layer-by-layer by curing full 2d (very thin in one dimension)",background,0
2120,layers of the 3d part in each print step.,background,0
2121,There does not yet exist a technique which is able to print arbitrarily-defined 3D geometries in a single print step.,background,0
2122,"If such a technique existed, it could be used to expand the range of printable geometries in additive manufacturing and relax constraints on factors such as overhangs in topology optimization.",background,0
2123,It could also vastly increase print speed for 3D parts.,background,0
2124,"In this work, we develop the principles for an approach for single exposure 3D printing of arbitrarily defined geometries.",objective,1
2125,"The approach, termed Computed Axial Lithgography (CAL), is based on tomographic reconstruction, with mathematical optimization to generate a set of projections to optically define an arbitrary dose distribution within a target volume.",method,2
2126,We demonstrate the potential ability of the technique to print 3D parts using a prototype CAL system based on sequential illumination from many angles.,method,2
2127,We also propose new hardware designs which will help us to realize true single-shot arbitrary-geometry 3D CAL.,result,3
2128,Learning to rank refers to machine learning techniques for training the model in a ranking task.,objective,1
2129,"Learning to rank is useful for many applications in Information Retrieval, Natural Language Processing, and Data Mining.",objective,1
2130,"Intensive studies have been conducted on the problem and significant progress has been made [1], [2].",method,2
2131,"This short paper gives an introduction to learning to rank, and it specifically explains the fundamental problems, existing approaches, and future work of learning to rank.",objective,1
2132,Several learning to rank methods using SVM techniques are described in details.,method,2
2133,"key words: Learning to rank, information retrieval, natural language processing, SVM",objective,1
2134,Discriminant analysis has been used for decades to extract features that preserve class separability.,background,0
2135,It is commonly defined as an optimization problem involving covariance matrices that represent the scatter within and between clusters.,background,0
2136,The requirement that one of these matrices be nonsingular limits its application to data sets with certain relative dimensions.,background,0
2137,"We examine a number of optimization criteria, and extend their applicability by using the generalized singular value decomposition to circumvent the nonsingularity requirement.",method,2
2138,The result is a generalization of discriminant analysis that can be applied even when the sample size is smaller than the dimension of the sample data.,method,2
2139,"We use classification results from the reduced representation to compare the effectiveness of this approach with some alternatives, and conclude with a discussion of their relative merits.",result,3
2140,"Social media platforms such as Twitter and Facebook enable the creation of virtual customer environments (VCEs) where online communities of interest form around specific firms, brands, or products.",background,0
2141,"While these platforms can be used as another means to deliver familiar e-commerce applications, when firms fail to fully engage their customers, they also fail to fully exploit the capabilities of social media platforms.",background,0
2142,"To gain business value, organizations need to incorporate community building as part of the implementation of social media.",result,3
2143,Attackers often create systems that automatically rewrite and reorder their malware to avoid detection.,background,0
2144,"Typical machine learning approaches, which learn a classifier based on a handcrafted feature vector, are not sufficiently robust to such reorderings.",background,0
2145,"We propose a different approach, which, similar to natural language modeling, learns the language of malware spoken through the executed instructions and extracts robust, time domain features.",objective,1
2146,Echo state networks (ESNs) and recurrent neural networks (RNNs) are used for the projection stage that extracts the features.,method,2
2147,These models are trained in an unsupervised fashion.,method,2
2148,A standard classifier uses these features to detect malicious files.,method,2
2149,"We explore a few variants of ESNs and RNNs for the projection stage, including Max-Pooling and Half-Frame models which we propose.",result,3
2150,"The best performing hybrid model uses an ESN for the recurrent model, Max-Pooling for non-linear sampling, and logistic regression for the final classification.",result,3
2151,"Compared to the standard trigram of events model, it improves the true positive rate by 98.3% at a false positive rate of 0.1%.",result,3
2152,Social media is continually emerging as a platform of information exchange around health challenges.,background,0
2153,We study mental health discourse on the popular social media: reddit.,background,0
2154,"Building on findings about health information seeking and sharing practices in online forums, and social media like Twitter, we address three research challenges.",background,0
2155,"First, we present a characterization of self-disclosure in mental illness communities on reddit.",method,2
2156,We observe individuals discussing a variety of concerns ranging from the daily grind to specific queries about diagnosis and treatment.,method,2
2157,"Second, we build a statistical model to examine the factors that drive social support on mental health reddit communities.",method,2
2158,"We also develop language models to characterize mental health social support, which are observed to bear emotional, informational, instrumental, and prescriptive information.",method,2
2159,"Finally, we study disinhibition in the light of the dissociative anonymity that reddit’s throwaway accounts provide.",method,2
2160,"Apart from promoting open conversations, such anonymity surprisingly is found to gather feedback that is more involving and emotionally engaging.",method,2
2161,"Our findings reveal, for the first time, the kind of unique information needs that a social media like reddit might be fulfilling when it comes to a stigmatic illness.",result,3
2162,Photorealistic images can now be created using advanced techniques in computer graphics (CG).,background,0
2163,Synthesized elements could easily be mistaken for photographic (real) images.,background,0
2164,Therefore we need to differentiate between CG and real images.,background,0
2165,"In our work, we propose and develop a new framework based on an aggregate of existing features.",objective,1
2166,"Our framework has a classification accuracy of 90% when tested on the de facto standard Columbia dataset, which is 4% better than the best results obtained by other prominent methods in this area.",result,3
2167,We further show that using feature selection it is possible to reduce the feature dimension of our framework from 557 to 80 without a significant loss in performance (≪ 1%).,method,2
2168,"We also investigate different approaches that attackers can use to fool the classification system, including creation of hybrid images and histogram manipulations.",objective,1
2169,"We then propose and develop filters to effectively detect such attacks, thereby limiting the effect of such attacks to our classification system.",result,3
2170,"In order to respond correctly to a free form factual question given a large collection of text data, one needs to understand the question to a level that allows determining some of the constraints the question imposes on a possible answer.",background,0
2171,These constraints may include a semantic classification of the sought after answer and may even suggest using different strategies when looking for and verifying a candidate answer.,background,0
2172,This work presents the first work on a machine learning approach to question classification.,objective,1
2173,"Guided by a layered semantic hierarchy of answer types, we develop a hierarchical classifier that classifies questions into fine-grained classes.",method,2
2174,This work also performs a systematic study of the use of semantic information sources in natural language classification tasks.,objective,1
2175,"It is shown that, in the context of question classification, augmenting the input of the classifier with appropriate semantic category information results in significant improvements to classification accuracy.",result,3
2176,We show accurate results on a large collection of free-form questions used in TREC 10 and 11.,result,3
2177,Competing theoretical perspectives regarding the effects of knowledge management (KM) on performance have underpinned past empirical studies.,background,0
2178,"By explicitly surfacing and comparing three such perspectives, we contribute to the theoretical advancement of the KM field.",objective,1
2179,"We develop hypotheses consistent with the underlying logics of universalistic, complementarity and contingency theories and we empirically test these hypotheses to determine which is best supported.",method,2
2180,Data was collected from a sample of hospitality services firms operating in South Africa.,method,2
2181,Our results show that the universalistic perspective is less preferred.,method,2
2182,We find support for the complementarity perspective by revealing that codification and human capital KM capabilities interact to influence customer service outcomes.,method,2
2183,The contingency perspective also received support as the links between KM capabilities and performance were found to be contingent on the business strategy of the firm.,method,2
2184,Our results suggest that future researchers should explicitly acknowledge the theoretical perspective from which they are observing the performance impacts of KM and ensure that empirical tests are consistent with the logic of the selected,result,3
2185,The problem this paper is concerned with is that of unsupervised learning.,objective,1
2186,"Mainly, what does it mean to learn a probability distribution?",objective,1
2187,The classical answer to this is to learn a probability density.,background,0
2188,"This is often done by defining a parametric family of densities (Pθ)θ∈Rd and finding the one that maximized the likelihood on our data: if we have real data examples {x}i=1, we would solve the problem",result,3
2189,"This paper reviews the problem of catastrophic forgetting (the loss or disruption of previously learned information when new information is learned) in neural networks, and explores rehearsal mechanisms (the retraining of some of the previously learned information as the new information is added) as a potential solution.",objective,1
2190,"We replicate some of the experiments described by Ratcliff (1990), including those relating to a simple “recency” based rehearsal regime.",background,0
2191,We then develop further rehearsal regimes which are more effective than recency rehearsal.,method,2
2192,In particular “sweep rehearsal” is very successful at minimising catastrophic forgetting.,method,2
2193,"One possible limitation of rehearsal in general, however, is that previously learned information may not be available for retraining.",method,2
2194,"We describe a solution to this problem, “pseudorehearsal”, a method which provides the advantages of rehearsal without actually requiring any access to the previously learned information (the original training population) itself.",method,2
2195,We then suggest an interpretation of these rehearsal mechanisms in the context of a function approximation based account of neural network learning.,method,2
2196,"Both rehearsal and pseudorehearsal may have practical applications, allowing new information to be integrated into an existing network with minimum disruption of old information.",result,3
2197,"Motivating students to learn computer networking concepts is often difficult because many students find the subject rather technical, dry, and boring.",background,0
2198,"To overcome this problem, the author has prepared some practical laboratory exercises (practicals) and other materials.",objective,1
2199,"They are designed around a network operating system and a multiuser, multitasking operating system and are suitable for classroom use in undergraduate computer networking courses.",method,2
2200,The effectiveness of these practicals has been evaluated both formally by students and informally in discussion within the teaching team.,result,3
2201,The implementation of the practicals was judged to be successful because of the positive student feedback and also because students scored better in the final exam.,result,3
2202,"This paper describes the practicals, their overall effectiveness, and plans for further projects.",result,3
2203,The impact of practicals on student learning and comprehension is also discussed,result,3
2204,"Time series classification (TSC), the problem of predicting class labels of time series, has been around for decades within the community of data mining and machine learning, and found many important applications such as biomedical engineering and clinical prediction.",background,0
2205,"However, it still remains challenging and falls short of classification accuracy and efficiency.",background,0
2206,"Traditional approaches typically involve extracting discriminative features from the original time series using dynamic time warping (DTW) or shapelet transformation, based on which an off-the-shelf classifier can be applied.",background,0
2207,"These methods are ad-hoc and separate the feature extraction part with the classification part, which limits their accuracy performance.",method,2
2208,"Plus, most existing methods fail to take into account the fact that time series often have features at different time scales.",method,2
2209,"To address these problems, we propose a novel end-to-end neural network model, Multi-scale Convolutional Neural Network (MCNN), which incorporates feature extraction and classification in a single framework.",method,2
2210,"Leveraging a novel multi-branch layer and learnable convolutional layers, MCNN automatically extracts features at different scales and frequencies, leading to superior feature representation.",method,2
2211,"MCNN is also computationally efficient, as it naturally leverages GPU computing.",result,3
2212,"We conduct comprehensive empirical evaluation with various existing methods on a large number of benchmark datasets, and show that MCNN advances the state-of-the-art by achieving superior accuracy performance than other leading methods.",result,3
2213,"Business processes can be described with diagrams, e.g. BPMN diagrams, or as text.",background,0
2214,Use cases are a text-based notation.,background,0
2215,They are semiformal: a business process is expressed as a sequence of steps and each step is presented in a natural language.,background,0
2216,In the paper two experiments are described that aimed at comparison of diagrambased and text-based notation.,background,0
2217,"Moreover, we describe some extensions to use cases which we have found interesting when working on description of business processes based on use cases.",method,2
2218,"Those extensions, among others, allow to describe actor metamorphosis and specify steps which must be performed before the main scenario is executed.",method,2
2219,The ideas described in the paper have been incorporated into UC Workbench – a tool supporting editing and animation of use-case-based models.,method,2
2220,Hammersmith Infant Neurological Examination (HINE) is a popular method to estimate the neurological development of infants aged less than two years.,background,0
2221,"Using HINE, especially for preterm or premature babies, the risk of neural disorder can be minimized through proper preventive measures.",background,0
2222,This paper presents the design of a semi-automatic application that can be used as an aid to doctors for efficiently conducting the examinations listed in the Hammersmith chart.,objective,1
2223,The user friendly version of the examination interface provides a platform for quantitative neurological assessment of the infants.,background,0
2224,It includes various simplified video and image based schemes that are suited to inexperienced staff.,method,2
2225,It provides an interface to go through the previous records of patients.,method,2
2226,Ten examinations are enlisted in the Hammersmith chart for neonatal babies.,method,2
2227,This paper examines a semi-automatic approach for posture estimation examination.,objective,1
2228,"For post neonatal infants, a follow-up management interface is designed that can be used to fetch / consult past records of the patients for better diagnosis.",method,2
2229,"The application is currently in operation at Neonatal Intensive Care Unit (NICU) of Institute of Post-Graduate Medical Education & Research (IPGME & R) and Seth Sukhlal Karnani Memorial (SSKM) Hospital, Kolkata, India.",result,3
2230,Business Process Management (BPM) is considered an essential strategy to create and maintain sustainable competitive advantage.,background,0
2231,"While researchers are anxious to identify critical success factors for the management of business process related projects, the risks associated with these projects have received considerably less attention.",background,0
2232,"This is a concern: Although BPM projects contain phases that relate to software development and deployment, simply applying risk mitigation strategies found in software engineering ignores the subsequent process management phases that follow upon the implementation and automation of processes.",background,0
2233,This paper provides an overview of risks associated with BPM projects along the phases of the BPM lifecycle.,objective,1
2234,"After a classification of the risks identified with the individual life cycle phases and transitions we discuss four strategies to deal with these risks: avoid, mitigate, transfer, and accept.",method,2
2235,The outlook of this paper discusses how assessment frameworks such as CobIT and COSO relate to the identified risks.,result,3
2236,"The Internet of Things (IoT) is experiencing exponential growth in research and industry, but it still suffers from privacy and security vulnerabilities.",background,0
2237,"Conventional security and privacy approaches tend to be inapplicable for IoT, mainly due to its decentralized topology and the resource-constraints of the majority of its devices.",background,0
2238,"BlockChain (BC) that underpin the cryptocurrency Bitcoin have been recently used to provide security and privacy in peer-to-peer networks with similar topologies to IoT. However, BCs are computationally expensive and involve high bandwidth overhead and delays, which are not suitable for IoT devices.",background,0
2239,"This position paper proposes a new secure, private, and lightweight architecture for IoT, based on BC technology that eliminates the overhead of BC while maintaining most of its security and privacy benefits.",objective,1
2240,The described method is investigated on a smart home application as a representative case study for broader IoT applications.,method,2
2241,"The proposed architecture is hierarchical, and consists of smart homes, an overlay network and cloud storages coordinating data transactions with BC to provide privacy and security.",method,2
2242,"Our design uses different types of BC’s depending on where in the network hierarchy a transaction occurs, and uses distributed trust methods to ensure a decentralized topology.",method,2
2243,Qualitative evaluation of the architecture under common threat models highlights its effectiveness in providing security and privacy for IoT applications.,result,3
2244,"The utilization of Information Technology (IT) is spreading in tourism industry with explosive growth of Internet, Social Network Service (SNS) through smart phone applications.",background,0
2245,"Especially, since intensive information has high value on tourism area, IT is becoming a crucial factor in the tourism industry.",background,0
2246,"The smart tourism is explained as an holistic approach that provide tour information, service related to travel, such as destination, food, transportation, reservation, travel guide, conveniently to tourists through IT devices.",background,0
2247,"In our research, we focus on the Korea Tourism Organization’s (KTO’s) smart tourism case.",objective,1
2248,This research concentrates on the necessity and effectiveness of smart tourism which delivers travel information in real-time base.,objective,1
2249,"Also, our study overview how KTO’s IT operation manages each channel, website, SNS, applications and finally suggests the smart tourism’s future direction for the successful realization.",method,2
2250,"5G will provide broadband access everywhere, entertain higher user mobility, and enable connectivity of massive number of devices (e.g. Internet of Things (IoT)) in an ultrareliable and affordable way.",background,0
2251,"The main technological enablers such as cloud computing, Software Defined Networking (SDN) and Network Function Virtualization (NFV) are maturing towards their use in 5G.",background,0
2252,"However, there are pressing security challenges in these technologies besides the growing concerns for user privacy.",background,0
2253,"In this paper, we provide an overview of the security challenges in these technologies and the issues of privacy in 5G.",method,2
2254,"Furthermore, we present security solutions to these challenges and future directions for secure 5G systems.",method,2
2255,Neural networks provide state-of-the-art results for most machine learning tasks.,background,0
2256,"Unfortunately, neural networks are vulnerable to adversarial examples: given an input x and any target classification t, it is possible to find a new input x' that is similar to x but classified as t. This makes it difficult to apply neural networks in security-critical areas.",background,0
2257,"Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from 95% to 0.5%.In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with 100% probability.",background,0
2258,"Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse).",method,2
2259,"Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation.",method,2
2260,We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples.,result,3
2261,"While numerous metrics for information retrieval are available in the case of binary relevance, there is only one commonly used metric for graded relevance, namely the Discounted Cumulative Gain (DCG).",background,0
2262,A drawback of DCG is its additive nature and the underlying independence assumption: a document in a given position has always the same gain and discount independently of the documents shown above it.,background,0
2263,"Inspired by the ""cascade"" user model, we present a new editorial metric for graded relevance which overcomes this difficulty and implicitly discounts documents which are shown below very relevant documents.",background,0
2264,"More precisely, this new metric is defined as the expected reciprocal length of time that the user will take to find a relevant document.",method,2
2265,This can be seen as an extension of the classical reciprocal rank to the graded relevance case and we call this metric Expected Reciprocal Rank (ERR).,method,2
2266,We conduct an extensive evaluation on the query logs of a commercial search engine and show that ERR correlates better with clicks metrics than other editorial metrics.,method,2
2267,Databases have been an integral component of Data Fusion from the outset when the JDL model was introduced.,background,0
2268,"As advances in High-Level fusion using Multi-Int data have been made, the original concept of databases as a static repository of Level 0/1 content has evolved to support heterogeneous data, and as a necessary enabler of High-Level fusion processes.",background,0
2269,"Relatively recent database technologies now support specialized storage for complex content such as multi-media, geospatial, and semantic data types.",background,0
2270,"Additionally, database functionality has been extended from what was once almost exclusively storage and retrieval, to include integrated forensic and predictive algorithms, as well as decision support frameworks such as the data cube.",method,2
2271,These data mining capabilities provide a rich tool-set from which to tailor a fusion application.,method,2
2272,"However, due to their inherent trade-off space, they present a significant design and integration challenge when implementing an enterprise architecture, which has to provide a comprehensive and cohesive framework across the entire fusion workflow, and which has to meet the needs of various Communities-of-Interest.",background,0
2273,"This paper expounds on the role of data architecture as a key discipline to help analyze and synthesize an enterprise fusion system-of-systems, and presents selected principles to maximize heterogeneous data exploitation.",objective,1
2274,"Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device.",background,0
2275,"For example, language models can improve speech recognition and text entry, and image models can automatically select good photos.",background,0
2276,"However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches.",background,0
2278,We term this decentralized approach Federated Learning.,method,2
2279,"We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets.",method,2
2280,These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting.,method,2
2281,"Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10–100× as compared to synchronized stochastic gradient descent.",result,3
2282,"The paper motivates, presents, demonstrates in use, and evaluates a methodology for conducting design science (DS) research in information systems.",objective,1
2283,DS is of importance in a discipline oriented to the creation of successful artifacts.,objective,1
2284,"Several IS researchers have pioneered DS research in IS, yet over the last 15 years little DS research has been done within the discipline.",objective,1
2285,The lack of a methodology to serve as a commonly accepted framework for DS research and of a template for its presentation may have contributed to its slow adoption.,objective,1
2286,"The design science research methodology (DSRM) presented here incorporates principles, practices, and procedures required to carry out such research and meets three objectives: it is consistent with prior literature, it provides a nominal process model for doing DS research, and it provides a mental model for presenting and evaluating DS research in IS.",method,2
2287,"The DS process includes six steps: problem identification and motivation, definition of the objectives for a solution, design and development, demonstration, evaluation, and communication.",result,3
2288,"We demonstrate and evaluate the methodology by presenting four case studies in terms of the DSRM, including cases that present the design of a database to support health assessment methods, a software reuse measure, an Internet video telephony application, and an IS planning method.",result,3
2289,The designed methodology effectively satisfies the three objectives and has the potential to help aid the acceptance of DS research in the IS discipline.,method,2
2290,We present a robust and real-time monocular six degree of freedom relocalization system.,background,0
2291,Our system trains a convolutional neural network to regress the 6-DOF camera pose from a single RGB image in an end-to-end manner with no need of additional engineering or graph optimisation.,background,0
2292,"The algorithm can operate indoors and outdoors in real time, taking 5ms per frame to compute.",method,2
2293,It obtains approximately 2m and 3 degrees accuracy for large scale outdoor scenes and 0.5m and 5 degrees accuracy indoors.,method,2
2294,"This is achieved using an efficient 23 layer deep convnet, demonstrating that convnets can be used to solve complicated out of image plane regression problems.",method,2
2295,This was made possible by leveraging transfer learning from large scale classification data.,method,2
2296,"We show that the PoseNet localizes from high level features and is robust to difficult lighting, motion blur and different camera intrinsics where point based SIFT registration fails.",result,3
2297,Furthermore we show how the pose feature that is produced generalizes to other scenes allowing us to regress pose with only a few dozen training examples.,result,3
2298,Phonemes are the standard modelling unit in HMM-based continuous speech recognition systems.,background,0
2299,"Visemes are the equivalent unit in the visual domain, but there is less agreement on precisely what visemes are, or how many to model on the visual side in audio-visual speech recognition systems.",background,0
2300,This paper compares the use of 5 viseme maps in a continuous speech recognition task.,background,0
2301,The focus of the study is visual-only recognition to examine the choice of viseme map.,method,2
2302,"All the maps are based on the phoneme-to-viseme approach, created either using a linguistic method or a data driven method.",method,2
2303,"DCT, PCA and optical flow are used to derive the visual features.",result,3
2304,The best visual-only recognition on the VidTIMIT database is achieved using a linguistically motivated viseme set.,method,2
2305,These initial experiments demonstrate that the choice of visual unit requires more careful attention in audio-visual speech recognition system development.,result,3
2306,We developed the project presented in this paper for an undergraduate computer architecture course specifically aimed at non-engineering students.,background,0
2307,"The project is designed to develop understanding of processor organisation at the functional unit level by building a series software execution driven simulators, from a single cycle sequential processor to a simple pipelined processor.",objective,1
2308,"The students are lead through the functional design process step by step, in a succession of carefully structured tasks.",method,2
2309,The project starts by building functional units of a processor.,result,3
2310,"These units are then used to construct a single cycle processor, a multi cycle processor, and finally a pipelined processor with data hazard detection and forwarding.",method,2
2311,"The main goal of the project is to give students a true insight into the fundamental ideas, which are the basis of the development of the modern microprocessor.",result,3
2312,Dynamics of human body skeletons convey significant information for human action recognition.,background,0
2313,"Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization.",background,0
2314,"In this work, we propose a novel model of dynamic skeletons called SpatialTemporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data.",objective,1
2315,This formulation not only leads to greater expressive power but also stronger generalization capability.,objective,1
2316,"On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.",result,3
2317,"This article proposes an approach to generate test cases from BPMN models, for automated testing of Web applications implemented with the support of BPM suites.",background,0
2318,The work is primarily focused on functional testing and has the following objectives: (i) identify execution paths from the flow analysis in the BPMN model and (ii) generate the initial code of test scripts to be run on a given Web application testing tool.,objective,1
2319,"Throughout the article, we describe the design and implementation of a solution to achieve these goals, targeting automated tests using Selenium and Cucumber as tools.",method,2
2320,The approach was applied to processes from a public repository and was able to generate test scenarios from different BPMN models.,result,3
2321,This paper develops and tests a model of consumer trust in an electronic commerce vendor.,background,0
2322,Building consumer trust is a strategic imperative for web-based vendors because trust strongly influences consumer intentions to transact with unfamiliar vendors via the web.,objective,1
2323,"Trust allows consumers to overcome perceptions of risk and uncertainty, and to engage in the following three behaviors that are critical to the realization of a web-based vendor’s strategic objectives: following advice offered by the web vendor, sharing personal information with the vendor, and purchasing from the vendor’s web site.",background,0
2324,"Trust in the vendor is defined as a multi-dimensional construct with two inter-related components—trusting beliefs (perceptions of the competence, benevolence, and integrity of the vendor), and trusting intentions—willingness to depend (that is, a decision to make oneself vulnerable to the vendor).",background,0
2325,"Three factors are proposed for building consumer trust in the vendor: structural assurance (that is, consumer perceptions of the safety of the web environment), perceived web vendor reputation, and perceived web site quality.",objective,1
2326,The model is tested in the context of a hypothetical web site offering legal advice.,method,2
2327,All three factors significantly influenced consumer trust in the web vendor.,result,3
2328,"That is, these factors, especially web site quality and reputation, are powerful levers that vendors can use to build consumer trust, in order to overcome the negative perceptions people often have about the safety of the web environment.",result,3
2329,The study also demonstrates that perceived Internet risk negatively affects consumer intentions to transact with a web-based vendor.,result,3
2330,q 2002 Elsevier Science B.V.,other,4
2331,A new technique for three-dimensional (3D) camera calibration for machine vision metrology using off-the-shelf TV cameras and lenses is described.,objective,1
2332,"The two-stage technique is aimed at efficient computation of camera external position and orientation relative to object reference coordinate system as well as the effective focal length, radial lens distortion, and image scanning parameters.",objective,1
2333,"The two-stage technique has advantage in terms of accuracy, speed, and versatility over existing state of the art.",objective,1
2334,A critical review of the state of the art is given in the beginning.,method,2
2335,"A theoretical framework is established, supported by comprehensive proof in five appendixes, and may pave the way for future research on 3D robotics vision.",method,2
2336,Test results using real data are described.,result,3
2337,Both accuracy and speed are reported.,result,3
2338,The experimental results are analyzed and compared with theoretical prediction.,result,3
2339,"Recent effort indicates that with slight modification, the two-stage calibration can be done in real time.",result,3
2340,"In Data Warehouse (DW) scenarios, ETL (Extraction, Transformation, Loading) processes are responsible for the extraction of data from heterogeneous operational data sources, their transformation (conversion, cleaning, normalization, etc.) and their loading into the DW.",background,0
2341,"In this paper, we present a framework for the design of the DW back-stage (and the respective ETL processes) based on the key observation that this task fundamentally involves dealing with the specificities of information at very low levels of granularity including transformation rules at the attribute level.",background,0
2342,"Specifically, we present a disciplined framework for the modeling of the relationships between sources and targets in different levels of granularity (including coarse mappings at the database and table levels to detailed inter-attribute mappings at the attribute level).",background,0
2343,"In order to accomplish this goal, we extend UML (Unified Modeling Language) to model attributes as first-class citizens.",objective,1
2344,"In our attempt to provide complementary views of the design artifacts in different levels of detail, our framework is based on a principled approach in the usage of UML packages, to allow zooming in and out the design of a scenario.",method,2
2345,Deep learning (DL) based semantic segmentation methods have been providing state-of-the-art performance in the last few years.,background,0
2346,"More specifically, these techniques have been successfully applied to medical image classification, segmentation, and detection tasks.",background,0
2347,"One deep learning technique, U-Net, has become one of the most popular for these applications.",background,0
2348,"In this paper, we propose a Recurrent Convolutional Neural Network (RCNN) based on U-Net as well as a Recurrent Residual Convolutional Neural Network (RRCNN) based on U-Net models, which are named RU-Net and R2U-Net respectively.",objective,1
2349,"The proposed models utilize the power of U-Net, Residual Network, as well as RCNN.",method,2
2350,There are several advantages of these proposed architectures for segmentation tasks.,method,2
2351,"First, a residual unit helps when training deep architecture.",method,2
2352,"Second, feature accumulation with recurrent residual convolutional layers ensures better feature representation for segmentation tasks.",method,2
2353,"Third, it allows us to design better U-Net architecture with same number of network parameters with better performance for medical image segmentation.",method,2
2354,"The proposed models are tested on three benchmark datasets such as blood vessel segmentation in retina images, skin cancer segmentation, and lung lesion segmentation.",objective,1
2355,A recent issue of a popular computing journal asked which laws would apply if a self-driving car killed a pedestrian.,background,0
2356,This paper considers the question of legal liability for artificially intelligent computer systems.,objective,1
2357,"It discusses whether criminal liability could ever apply; to whom it might apply; and, under civil law, whether an AI program is a product that is subject to product design legislation or a service to which the tort of negligence applies.",method,2
2358,The issue of sales warranties is also considered.,objective,1
2359,A discussion of some of the practical limitations that AI systems are subject to is also included.,result,3
2360,Artificial neural net models have been studied for many years in the hope of achieving human-like performance in the fields of speech and image recognition.,background,0
2361,These models are composed of many nonlinear computational elements operating in parallel and arranged in patterns reminiscent of biological neural nets.,background,0
2362,Computational elements or nodes are connected via weights that are typically adapted during use to improve performance.,background,0
2363,"There has been a recent resurgence in the field of artificial neural nets caused by new net topologies and algorithms, analog VLSI implementation techniques, and the belief that massive parallelism is essential for high performance speech and image recognition.",background,0
2364,This paper provides an introduction to the field of artificial neural nets by reviewing six important neural net models that can be used for pattern classification.,objective,1
2365,These nets are highly parallel building blocks that illustrate neural net components and design principles and can be used to construct more complex systems.,method,2
2366,"In addition to describing these nets, a major emphasis is placed on exploring how some existing classification and clustering algorithms can be performed using simple neuron-like components.",method,2
2367,Single-layer nets can implement algorithms required by Gaussian maximum-likelihood classifiers and optimum minimum-error classifiers for binary patterns corrupted by noise.,result,3
2368,"More generally, the decision regions required by any classification algorithm can be generated in a straightforward manner by three-layer feed-forward nets.",result,3
2369,Work ow systems hold the promise of facilitating the everyday operation of many enterprises and work environments.,background,0
2370,"As a result, many commercial work ow management systems have been developed.",background,0
2371,"These systems, although useful, do not scale well, have limited fault-tolerance, and are in exible in terms of interoperating with other work ow systems.",background,0
2372,"In this paper, we discuss the limitations of contemporary work ow management systems, and then elaborate on various directions for research and potential future extensions to the design and modeling of work ow management systems.",objective,1
2373,We present a hybrid algorithm for detection and tracking of text in natural scenes that goes beyond the full-detection approaches in terms of time performance optimization.,objective,1
2374,"A state-of-the-art scene text detection module based on Maximally Stable Extremal Regions (MSER) is used to detect text asynchronously, while on a separate thread detected text objects are tracked by MSER propagation.",method,2
2375,The cooperation of these two modules yields real time video processing at high frame rates even on low-resource devices.,result,3
2376,Online social networks have now become the most popular platforms for people to share information with others.,background,0
2377,"Along with this, there is a serious threat to individuals’ privacy.",background,0
2378,"One privacy risk comes from the sharing of co-owned data, i.e., when a user shares a data item that involves multiple users, some users’ privacy may be compromised, since different users generally have different opinions on who can access the data.",background,0
2379,How to design a collaborative management mechanism to deal with such a privacy issue has recently attracted much attention.,background,0
2380,"In this paper, we propose a trust-based mechanism to realize collaborative privacy management.",objective,1
2381,"Basically, a user decides whether or not to post a data item based on the aggregated opinion of all involved users.",method,2
2382,"The trust values between users are used to weight users’ opinions, and the values are updated according to users’ privacy loss.",method,2
2383,"Moreover, the user can make a tradeoff between data sharing and privacy preserving by tuning the parameter of the proposed mechanism.",method,2
2384,We formulate the selecting of the parameter as a multi-armed bandit problem and apply the upper confidence bound policy to solve the problem.,method,2
2385,"Simulation results demonstrate that the trust-based mechanism can encourage the user to be considerate of others’ privacy, and the proposed bandit approach can bring the user a high payoff.",result,3
2386,"In this paper, we consider the variable sized bin packing problem where the objective is to minimize the total cost of used bins when the cost of unit size of each bin does not increase as the bin size increases.",background,0
2387,"Two greedy algorithms are described, and analyzed in three special cases: (a) the sizes of items and bins are divisible, respectively, (b) only the sizes of bins are divisible, and (c) the sizes of bins are not divisible.",method,2
2388,"Here, we say that a list of numbers a1; a2; . .",method,2
2389,". ; am are divisible when aj exactly divides aj 1, for each 1 < j6m.",method,2
2390,"In the case of (a), the algorithms give optimal solutions, and in the case of (b), each algorithm gives a solution whose value is less than 11 9 CðB Þ þ 4 9 , where CðB Þ is the optimal value.",method,2
2391,"In the case of (c), each algorithm gives a solution whose value is less than 3 2 CðB Þ þ 1.",method,2
2392,2002 Elsevier Science B.V. All rights reserved.,other,4
2393,Imagine a large mass of nonhomogeneous metal.,background,0
2394,Imagine that it is struck a severe blow by a large hammer.,background,0
2395,The shock wave of the impact will travel throughout the mass and arrive at different parts at different times.,background,0
2396,"Furthermore, this shock wave will be reflected from boundaries and regions of nonhomogeneity.",background,0
2397,These reflected shock waves will affect some portions of the mass time and time again.,background,0
2398,"Occasionally, shock waves reflected from several directions will converge on some internal region to give an aftershock as great (or greater than) the original shock.",method,2
2399,Such shock waves may persist for a considerable time.,background,0
2400,We present a method for estimating the KL divergence between continuous densities and we prove it converges almost surely.,method,2
2401,Divergence estimation is typically solved estimating the densities first.,method,2
2402,"Our main result shows this intermediate step is unnecessary and that the divergence can be either estimated using the empirical cdf or k-nearest-neighbour density estimation, which does not converge to the true measure for finite k.",method,2
2403,"The convergence proof is based on describing the statistics of our estimator using waiting-times distributions, as the exponential or Erlang.",method,2
2404,"We illustrate the proposed estimators and show how they compare to existing methods based on density estimation, and we also outline how our divergence estimators can be used for solving the two-sample problem.",result,3
2405,"In 1979, David Fabian found a complete game of two-person Chinese Checkers in 30 moves (15 by each player).",background,0
2406,This solution requires that the two players cooperate to generate a win as quickly as possible for one of them.,objective,1
2407,"We show, using computational search techniques, that no shorter game is possible.",method,2
2408,We also consider a solitaire version of Chinese Checkers where one player attempts to move her pieces across the board in as few moves as possible.,method,2
2409,"In 1971, Octave Levenspiel found a solution in 27 moves; we demonstrate that no shorter solution exists.",result,3
2410,"To show optimality, we employ a variant of A* search, as well as bidirectional search.",result,3
2411,We propose and study a novel panoptic segmentation (PS) task.,objective,1
2412,Panoptic segmentation unifies the typically distinct tasks of semantic segmentation (assign a class label to each pixel) and instance segmentation (detect and segment each object instance).,background,0
2413,"The proposed task requires generating a coherent scene segmentation that is rich and complete, an important step toward real-world vision systems.",objective,1
2414,"While early work in computer vision addressed related image/scene parsing tasks, these are not currently popular, possibly due to lack of appropriate metrics or associated recognition challenges.",background,0
2415,"To address this, we first propose a novel panoptic quality (PQ) metric that captures performance for all classes (stuff and things) in an interpretable and unified manner.",method,2
2416,"Using the proposed metric, we perform a rigorous study of both human and machine performance for PS on three existing datasets, revealing interesting insights about the task.",method,2
2417,"Second, we are working to introduce panoptic segmentation tracks at upcoming recognition challenges.",result,3
2418,The aim of our work is to revive the interest of the community in a more unified view of image segmentation.,objective,1
2419,"In this paper, we propose ""SHAPIO""', a game controller that inputs and outputs game events through its three-dimensional shape.",objective,1
2420,"SHAPIO consists of multiple triangular prisms, and its three-dimensional shape can be freely changed by twisting each prism.",method,2
2421,"When a game player changes the shape of SHAPIO, the game system changes the shape of an item in the game into the same shape as SHAPIO, and vice versa.",method,2
2422,"The player can feel the sense of unity with the game character, because SHAPIO always has the same shape as the item.",result,3
2423,We confirmed that the shape of our prototype could go hand-in-hand with the corresponding game item in a practical response time.,result,3
2424,This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention.,objective,1
2425,"Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence.",method,2
2426,We also propose a self-attention mechanism and a special regularization term for the model.,method,2
2427,"As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding.",method,2
2428,"We evaluate our model on 3 different tasks: author profiling, sentiment classification and textual entailment.",result,3
2429,Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.,result,3
2430,Personal identification numbers are widely used for user authentication and security.,background,0
2431,"Password authentication using PINs requires users to physically input the PIN, which could be vulnerable to password cracking via shoulder surfing or thermal tracking.",background,0
2432,"PIN authentication with hands-off gaze-based PIN entry techniques, on the other hand, leaves no physical footprints behind and therefore offer a more secure password entry option.",background,0
2433,"Gaze-based authentication refers to finding the eye location across sequential image frames, and tracking eye center over time.",background,0
2434,"This paper presents a real-time application for gaze-based PIN entry, and eye detection and tracking for PIN identification using a smart camera.",objective,1
2435,Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform.,background,0
2436,"However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content.",background,0
2437,"Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis.",background,0
2438,The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information.,background,0
2439,"Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.",background,0
2440,"Gatys et al. recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called style transfer.",background,0
2441,"However, their framework requires a slow iterative optimization process, which limits its practical application.",background,0
2442,Fast approximations with feed-forward neural networks have been proposed to speed up neural style transfer.,background,0
2443,"Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles.",background,0
2444,"In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time.",objective,1
2445,At the heart of our method is a novel adaptive instance normalization (AdaIN) layer that aligns the mean and variance of the content features with those of the style features.,method,2
2446,"Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles.",method,2
2447,"In addition, our approach allows flexible user controls such as content-style trade-off, style interpolation, color & spatial controls, all using a single feed-forward neural network.",result,3
2448,"This paper presents a diffusion method for generating terrains from a set of parameterized curves that characterize the landform features such as ridge lines, riverbeds or cliffs.",method,2
2449,Our approach provides the user with an intuitive vector-based feature-oriented control over the terrain.,method,2
2450,"Different types of constraints (such as elevation, slope angle and roughness) can be attached to the curves so as to define the shape of the terrain.",method,2
2451,The terrain is generated from the curve representation by using an efficient multigrid diffusion algorithm.,method,2
2452,"The algorithm can be efficiently implemented on the GPU, which allows the user to interactively create a vast variety of landscapes.",result,3
2453,"With the rapid development of the computer technology, cloud-based services have become a hot topic.",background,0
2454,"Cloud-based services not only provide users with convenience, but also bring many security issues.",background,0
2455,"Therefore, the study of access control scheme to protect users' privacy in cloud environment is of great significance.",background,0
2456,"In this paper, we present an access control system with privilege separation based on privacy protection (PS-ACS).",method,2
2457,"In the PS-ACS scheme, we divide the users into personal domain (PSD) and public domain (PUD) logically.",method,2
2458,"In the PSD, we set read and write access permissions for users respectively.",method,2
2459,The Key-Aggregate Encryption (KAE) is exploited to implement the read access permission which improves the access efficiency.,method,2
2460,A high degree of patient privacy is guaranteed simultaneously by exploiting an Improved Attribute-based Signature (IABS) which can determine the users' write access.,result,3
2461,"For the users of PUD, a hierarchical attribute-based encryption (HABE) is applied to avoid the issues of single point of failure and complicated key distribution.",method,2
2462,Function and performance testing result shows that the PS-ACS scheme can achieve privacy protection in cloud-based services.,result,3
2463,A study on the steps to follow in linguistic decision analysis is presented in a context of multi-criteria=multi-person decision making.,background,0
2464,"Three steps are established for solving a multi-criteria decision making problem under linguistic information: (i) the choice of the linguistic term set with its semantic in order to express the linguistic performance values according to all the criteria, (ii) the choice of the aggregation operator of linguistic information in order to aggregate the linguistic performance values, and (iii) the choice of the best alternatives, which is made up by two phases: (a) the aggregation of linguistic information for obtaining a collective linguistic performance value on the alternatives, and (b) the exploitation of the collective linguistic performance value in order to establish a rank ordering among the alternatives for choosing the best alternatives.",method,2
2465,"Finally, an example is shown.",method,2
2466,c © 2000 Elsevier Science B.V.,other,4
2468,We show how to learn many layers of features on color images and we use these features to initialize deep autoencoders.,method,2
2469,We then use the autoencoders to map images to short binary codes.,method,2
2470,"Using semantic hashing [6], 28-bit codes can be used to retrieve images that are similar to a query image in a time that is independent of the size of the database.",method,2
2471,This extremely fast retrieval makes it possible to search using multiple di erent transformations of the query image.,method,2
2472,256-bit binary codes allow much more accurate matching and can be used to prune the set of images found using the 28-bit codes.,result,3
2473,"A graph G = (V,E) is a set V of vertices and a set E of edges, in which an edge joins a pair of vertices.",background,0
2474,"1 Normally, graphs are depicted with their vertices as points in a plane and their edges as line or curve segments connecting those points.",background,0
2475,"There are different styles of representation, suited to different types of graphs or different purposes of presentation.",background,0
2476,"We concentrate on the most general class of graphs: undirected graphs, drawn with straight edges.",background,0
2477,"In this paper, we introduce an algorithm that attempts to produce aesthetically-pleasing, two-dimensional pictures of graphs by doing simplified simulations of physical systems.",method,2
2478,We are concerned with drawing undirected graphs according to some generally accepted aesthetic criteria: 2,result,3
2479,We present a telerobotics research platform that provides complete access to all levels of control via open-source electronics and software.,background,0
2480,The electronics employs an FPGA to enable a centralized computation and distributed I/O architecture in which all control computations are implemented in a familiar development environment (Linux PC) and low-latency I/O is performed over an IEEE-1394a (FireWire) bus at speeds up to 400 Mbits/sec.,background,0
2481,The mechanical components are obtained from retired first-generation da Vinci ® Surgical Systems.,method,2
2482,"This system is currently installed at 11 research institutions, with additional installations underway, thereby creating a research community around a common open-source hardware and software platform.",result,3
2483,"The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods obtain similar performance on existing small-scale benchmarks.",background,0
2484,This paper re-evaluates state-of-the-art architectures in light of the new Kinetics Human Action Video dataset.,objective,1
2485,"Kinetics has two orders of magnitude more data, with 400 human action classes and over 400 clips per class, and is collected from realistic, challenging YouTube videos.",objective,1
2486,We provide an analysis on how current architectures fare on the task of action classification on this dataset and how much performance improves on the smaller benchmark datasets after pre-training on Kinetics.,objective,1
2487,"We also introduce a new Two-Stream Inflated 3D ConvNet (I3D) that is based on 2D ConvNet inflation: filters and pooling kernels of very deep image classification ConvNets are expanded into 3D, making it possible to learn seamless spatio-temporal feature extractors from video while leveraging successful ImageNet architecture designs and even their parameters.",method,2
2488,"We show that, after pre-training on Kinetics, I3D models considerably improve upon the state-of-the-art in action classification, reaching 80.2% on HMDB-51 and 97.9% on UCF-101.",result,3
2489,Cause-Effect Graphing (CEG) is used to identify test cases from a given specification to validate its corresponding implementation.,background,0
2490,This paper gives detail about this technique of software testing.,objective,1
2491,It also shows how the CEG technique can be used to test that software fulfill requirement specification or not.,objective,1
2492,This paper surveys how CEG converted into decision table.,objective,1
2493,The aim of this paper is to overcome existing algorithm's shortcomings and generate all possible test cases.,objective,1
2494,"Derived from rapid advances in computer vision and machine learning, video analysis tasks have been moving from inferring the present state to predicting the future state.",background,0
2495,"Vision-based action recognition and prediction from videos are such tasks, where action recognition is to infer human actions (present state) based upon complete action executions, and action prediction to predict human actions (future state) based upon incomplete action executions.",background,0
2496,"These two tasks have become particularly prevalent topics recently because of their explosively emerging real-world applications, such as visual surveillance, autonomous driving vehicle, entertainment, and video retrieval, etc.",background,0
2497,Many attempts have been devoted in the last a few decades in order to build a robust and effective framework for action recognition and prediction.,result,3
2498,"In this paper, we survey the complete state-of-the-art techniques in the action recognition and prediction.",result,3
2499,"Existing models, popular algorithms, technical difficulties, popular action databases, evaluation protocols, and promising future directions are also provided with systematic discussions.",result,3
2500,A facial recognition system is a computer application for automatically identifying or verifying a person from a digital image or a video frame from a video source.,background,0
2501,One of the way is to do this is by comparing selected facial features from the image and a facial database.,background,0
2502,It is typically used in security systems and can be compared to other biometrics such as fingerprint or eye iris recognition systems.,background,0
2503,In this paper we focus on 3-D facial recognition system and biometric facial recognision system.,objective,1
2504,We do critics on facial recognision system giving effectiveness and weaknesses.,objective,1
2505,This paper also introduces scope of recognision system in India.,result,3
2506,Keywords-3-D facial recognition; biometric facial recognition; alignment; matching;FRGC.,result,3
2507,1 Stanford University 2 Concordia University 3 Princeton University Abstract.,background,0
2508,We formalize the use of Bitcoin as a source of publiclyverifiable randomness.,objective,1
2509,"As a side-effect of Bitcoin’s proof-of-work-based consensus system, random values are broadcast every time new blocks are mined.",objective,1
2510,"We can derive strong lower bounds on the computational min-entropy in each block: currently, at least 68 bits of min-entropy are produced every 10 minutes, from which one can derive over 32 nearuniform bits using standard extractor techniques.",method,2
2511,"We show that any attack on this beacon would form an attack on Bitcoin itself and hence have a monetary cost that we can bound, unlike any other construction for a public randomness beacon in the literature.",method,2
2512,"In our simplest construction, we show that a lottery producing a single unbiased bit is manipulation-resistant against an attacker with a stake of less than 50 bitcoins in the output, or about US$12,000 today.",result,3
2513,"Finally, we propose making the beacon output available to smart contracts and demonstrate that this simple tool enables a number of interesting applications.",result,3
2514,"Although Bayesian analysis has been in use since Laplace, the Bayesian method of model-comparison has only recently been developed in depth.",background,0
2515,"In this paper, the Bayesian approach to regularization and model-comparison is demonstrated by studying the inference problem of interpolating noisy data.",background,0
2516,The concepts and methods described are quite general and can be applied to many other data modeling problems.,method,2
2517,Regularizing constants are set by examining their posterior probability distribution.,background,0
2518,Alternative regularizers (priors) and alternative basis sets are objectively compared by evaluating the evidence for them.,result,3
2519,Occam's razor is automatically embodied by this process.,objective,1
2520,The way in which Bayes infers the values of regularizing constants and noise levels has an elegant interpretation in terms of the effective number of parameters determined by the data set.,result,3
2521,This framework is due to Gull and Skilling.,background,0
2522,"Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph.",background,0
2523,"This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations.",background,0
2524,We propose a fully automatic approach that produces vibrant and realistic colorizations.,method,2
2525,We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result.,method,2
2526,The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images.,method,2
2527,"We evaluate our algorithm using a “colorization Turing test,” asking human participants to choose between a generated and ground truth color image.",result,3
2528,"Our method successfully fools humans on 32% of the trials, significantly higher than previous methods.",method,2
2529,"Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder.",result,3
2530,This approach results in state-of-the-art performance on several feature learning benchmarks.,result,3
2531,Blockchain has drawn attention as the next-generation financial technology due to its security that suits the informatization era.,background,0
2532,"In particular, it provides security through the authentication of peers that share virtual cash, encryption, and the generation of hash value.",background,0
2533,"According to the global financial industry, the market for security-based blockchain technology is expected to grow to about USD 20 billion by 2020.",background,0
2534,"In addition, blockchain can be applied beyond the Internet of Things (IoT) environment; its applications are expected to expand.",method,2
2535,Cloud computing has been dramatically adopted in all IT environments for its efficiency and availability.,method,2
2536,"In this paper, we discuss the concept of blockchain technology and its hot research trends.",method,2
2537,"In addition, we will study how to adapt blockchain security to cloud computing and its secure solutions in detail.",result,3
2538,"Organizational compliance with laws, industrial standards, procedures and enterprise architectures has become a highly relevant topic for both practitioners and academics.",background,0
2539,"However, both the fundamental insights into compliance as a concept and the tactics for bringing an organization into a compliant state have been described in a fragmented manner.",background,0
2540,"Using literature from various disciplines, this paper presents two contributions.",background,0
2541,"First, it describes the fundamental concepts regarding compliance.",objective,1
2542,"Second, it presents a framework in which the various tactics for achieving organizational compliance can be positioned.",result,3
2543,"In this paper we present a novel street scene semantic recognition framework, which takes advantage of 3D point clouds captured by a high-definition LiDAR laser scanner.",background,0
2544,An important problem in object recognition is the need for sufficient labeled training data to learn robust classifiers.,background,0
2545,In this paper we show how to significantly reduce the need for manually labeled training data by reduction of scene complexity using non-supervised ground and building segmentation.,method,2
2546,"Our system first automatically segments grounds point cloud, this is because the ground connects almost all other objects and we will use a connect component based algorithm to oversegment the point clouds.",method,2
2547,"Then, using binary range image processing building facades will be detected.",method,2
2548,Remained point cloud will grouped into voxels which are then transformed to super voxels.,method,2
2549,"Local 3D features extracted from super voxels are classified by trained boosted decision trees and labeled with semantic classes e.g. tree, pedestrian, car, etc.",method,2
2550,"The proposed method is evaluated both quantitatively and qualitatively on a challenging fixed-position Terrestrial Laser Scanning (TLS) Velodyne data set and two Mobile Laser Scanning (MLS), Paris-rue-Madam and NAVTEQ True databases.",method,2
2551,Robust scene parsing results are reported.,result,3
2552,"This paper presents ORB-SLAM, a feature-based monocular simultaneous localization and mapping (SLAM) system that operates in real time, in small and large indoor and outdoor environments.",objective,1
2553,"The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization.",method,2
2554,"Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all SLAM tasks: tracking, mapping, relocalization, and loop closing.",method,2
2555,"A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation.",method,2
2556,We present an exhaustive evaluation in 27 sequences from the most popular datasets.,result,3
2557,ORB-SLAM achieves unprecedented performance with respect to other state-of-the-art monocular SLAM approaches.,result,3
2558,"For the benefit of the community, we make the source code public.",result,3
2559,There are many different definitions and understandings of the concept of privacy.,background,0
2560,Here we bring all the different aspects of privacy together and propose a comprehensive definition thereof.,background,0
2561,"We also introduce the three different approaches to privacy preservation, and propose a comprehensive and multi-faceted approach in order to gain from the benefits of each and maximise privacy protection.",method,2
2562,We report on the evaluation of a prototype of such a privacy protective shopping environment.,result,3
2563,We introduce a complete pipeline for recognizing and classifying people’s clothing in natural scenes.,method,2
2564,"This has several interesting applications, including e-commerce, event and activity recognition, online advertising, etc.",method,2
2565,"The stages of the pipeline combine a number of state-of-the-art building blocks such as upper body detectors, various feature channels and visual attributes.",method,2
2566,The core of our method consists of a multi-class learner based on a Random Forest that uses strong discriminative learners as decision nodes.,method,2
2567,To make the pipeline as automatic as possible we also integrate automatically crawled training data from the web in the learning process.,method,2
2568,"Typically, multi-class learning benefits from more labeled data.",method,2
2569,"Because the crawled data may be noisy and contain images unrelated to our task, we extend Random Forests to be capable of transfer learning from different domains.",method,2
2570,"For evaluation, we define 15 clothing classes and introduce a benchmark data set for the clothing classification task consisting of over 80, 000 images, which we make publicly available.",result,3
2571,"We report experimental results, where our classifier outperforms an SVM baseline with 41.38 % vs 35.07 % average accuracy on challenging benchmark data.",result,3
2572,Credit is a widely used tool to finance personal and corporate projects.,background,0
2573,"The risk of default has motivated lenders to use a credit scoring system, which helps them make more efficient decisions about whom to extend credit.",background,0
2574,"Credit scores serve as a financial user model, and have been traditionally computed from the user’s past financial history.",background,0
2575,"As a result, people without any prior financial history might be excluded from the credit system.",background,0
2576,"In this paper we present MobiScore, an approach to build a model of the user’s financial risk from mobile phone usage data, which previous work has shown to convey information about e.g. personality and socioeconomic status.",method,2
2577,"MobiScore could replace traditional credit scores when no financial history is available, providing credit access to currently excluded population sectors, or be used as a complementary source of information to improve traditional finance-based scores.",method,2
2578,"We validate the proposed approach using real data from a telecommunications operator and a financial institution in a Latin American country, resulting in an accurate model of default comparable to traditional credit scoring techniques.",result,3
2579,"This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner.",background,0
2580,InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation.,background,0
2581,We derive a lower bound of the mutual information objective that can be optimized efficiently.,background,0
2582,"Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset.",background,0
2583,"It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset.",result,3
2584,Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing supervised methods.,method,2
2585,"For an up-to-date version of this paper, please see https://arxiv.org/abs/1606.03657.",other,4
2586,Emergence of peer-to-peer lending has opened an appealing option for micro-financing and is growing rapidly as an option in the financial industry.,background,0
2587,"However, peer-to-peer lending possesses a high risk of investment failure due to the lack of expertise on the borrowers' creditworthiness.",background,0
2588,"In addition, information asymmetry, the unsecured nature of loans as well as lack of rigid rules and regulations increase the credit risk in peer-to-peer lending.",background,0
2589,This paper proposes a credit scoring model using artificial neural networks in classifying peer-to-peer loan applications into default and non-default groups.,method,2
2590,The results indicate that the neural network-based credit scoring model performs effectively in screening default applications.,result,3
2591,Previous approaches for scene text detection have already achieved promising performances across various benchmarks.,background,0
2592,"However, they usually fall short when dealing with challenging scenarios, even when equipped with deep neural network models, because the overall performance is determined by the interplay of multiple stages and components in the pipelines.",result,3
2593,"In this work, we propose a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes.",method,2
2594,"The pipeline directly predicts words or text lines of arbitrary orientations and quadrilateral shapes in full images, eliminating unnecessary intermediate steps (e.g., candidate aggregation and word partitioning), with a single neural network.",background,0
2595,The simplicity of our pipeline allows concentrating efforts on designing loss functions and neural network architecture.,background,0
2596,"Experiments on standard datasets including ICDAR 2015, COCO-Text and MSRA-TD500 demonstrate that the proposed algorithm significantly outperforms state-of-the-art methods in terms of both accuracy and efficiency.",result,3
2597,"On the ICDAR 2015 dataset, the proposed algorithm achieves an F-score of 0.7820 at 13.2fps at 720p resolution.",result,3
2598,"The odds for success of a future CAI system (as well as the present CAI movement) are completely dependent on the quality of an underlying theory of innovation and the effectiveness of its tools, processes and models.",background,0
2599,"This paper establishes a set of requirements for such a theory, evaluates existing approaches, methodologies and theories (including TRIZ), and presents an overview of the General Theory of Innovation (GTI) that, in the author’s opinion, satisfies most of the established criteria.",background,0
2600,"The overview includes the theoretical foundation of GTI, a list of available applications, a list of future tasks, and other pertinent information.",result,3
2601,This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene.,method,2
2602,"The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination.",method,2
2603,"The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images.",method,2
2604,This paper also describes an approach to using these features for object recognition.,method,2
2605,"The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters.",method,2
2606,This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.,result,3
2607,"Computerized algorithms and solutions in processing and diagnosis mammography X-ray, cardiovascular CT/MRI scans, and microscopy image play an important role in disease detection and computer-aided decision-making.",background,0
2608,Machine learning techniques have powered many aspects in medical investigations and clinical practice.,background,0
2609,"Recently, deep learning is emerging a leading machine learning tool in computer vision and begins attracting considerable attentions in medical imaging.",background,0
2610,"In this chapter, we provide a snapshot of this fast growing field specifically for mammography, cardiovascular, and microscopy image analysis.",objective,1
2611,"We briefly explain the popular deep neural networks and summarize current deep learning achievements in various tasks such as detection, segmentation, and classification in these heterogeneous imaging modalities.",objective,1
2612,"In addition, we discuss the challenges and the potential future trends for ongoing work.",method,2
2613,2.,other,4
2614,"Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection.",background,0
2615,"Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objective.",background,0
2616,"In this paper we introduce a new anomaly detection method—Deep Support Vector Data Description—, which is trained on an anomaly detection based objective.",method,2
2617,"The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically.",method,2
2618,We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GTSRB stop signs.,result,3
2619,"The rapid development of the RF power electronics requires the introduction of wide bandgap material due to its potential in high output power density, high operation voltage and high input impedance.",background,0
2620,GaN-based RF power devices have made substantial progresses in the last decade.,background,0
2621,"This paper attempts to review the latest developments of the GaN HEMT technologies, including material growth, processing technologies, device epitaxial structures and MMIC designs, to achieve the state-of-the-art microwave and millimeter-wave performance.",objective,1
2622,The reliability and manufacturing challenges are also discussed.,result,3
2623,"In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding.",background,0
2624,"We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language.",method,2
2625,"We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark.",background,0
2626,"Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 24.2.",method,2
2627,We also release these models for the NLP and ML community to study and improve upon.,method,2
2628,The consumer electronics industry is a $ 240 billion global industry with a small number of highly competitive global players.,background,0
2629,We describe many of the risks associated with any global supply chain in this industry.,background,0
2630,"As illustration, we also list steps that Samsung Electronics and its subsidiary, Samsung Electronics UK, have taken to mitigate these risks.",method,2
2631,Our description of the risks and illustration of mitigation efforts provides the backdrop to identify areas of future research.,method,2
2632,Binomial filters are simple and efficient structures based on the binomial coefficients for implementing Gaussian filtering.,background,0
2633,They do not require multipliers and can therefore be implemented efficiently in programmable hardware.,background,0
2634,"There are many possible variations of the basic binomial filter structure, and they provide a wide range of space-time trade-offs; a number of these designs have been captured in a parametrised form and their features are compared.",background,0
2635,"This technique can be used for multi-dimensional filtering, provided that the filter is separable.",method,2
2636,"The numerical performance of binomial filters, and their implementation using field-programmable devices for an image processing application, are also discussed.",method,2
2637,"We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model.",background,0
2638,"The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning.",background,0
2639,All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks.,method,2
2640,"We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.",result,3
2641,The problem of position estimation from Time Difference Of Arrival (TDOA) measurements occurs in a range of applications from wireless communication networks to electronic warfare positioning.,background,0
2642,Correlation analysis of the transmitted signal to two receivers gives rise to one hyperbolic function.,background,0
2643,"With more than two receivers, we can compute more hyperbolic functions, which ideally intersect in one unique point.",objective,1
2644,"With TDOA measurement uncertainty, we face a non-linear estimation problem.",background,0
2645,We here suggest and compare both a Monte Carlo based method for positioning and a gradient search algorithm using a non-linear least squares framework.,method,2
2646,The former has the feature to be easily extended to a dynamic framework where a motion model of the transmitter is included.,method,2
2647,A small simulation study is presented.,method,2
2648,"Person re-identification across cameras remains a very challenging problem, especially when there are no overlapping fields of view between cameras.",background,0
2649,"In this paper, we present a novel multi-channel parts-based convolutional neural network (CNN) model under the triplet framework for person re-identification.",objective,1
2650,"Specifically, the proposed CNN model consists of multiple channels to jointly learn both the global full-body and local body-parts features of the input persons.",method,2
2651,"The CNN model is trained by an improved triplet loss function that serves to pull the instances of the same person closer, and at the same time push the instances belonging to different persons farther from each other in the learned feature space.",method,2
2652,"Extensive comparative evaluations demonstrate that our proposed method significantly outperforms many state-of-the-art approaches, including both traditional and deep network-based ones, on the challenging i-LIDS, VIPeR, PRID2011 and CUHK01 datasets.",result,3
2653,This paper is a survey of inductive rule learning algorithms that use a separate-and-conquer strategy.,background,0
2654,This strategy can be traced back to the AQ learning system and still enjoys popularity as can be seen from its frequent use in inductive logic programming systems.,background,0
2655,"We will put this wide variety of algorithms into a single framework and analyze them along three different dimensions, namely their search, language and overfitting avoidance biases.",background,0
2656,The chest X-ray is one of the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases.,background,0
2657,A tremendous number of X-ray imaging studies accompanied by radiological reports are accumulated and stored in many modern hospitals Picture Archiving and Communication Systems (PACS).,background,0
2658,"On the other side, it is still an open question how this type of hospital-size knowledge database containing invaluable imaging informatics (i.e., loosely labeled) can be used to facilitate the data-hungry deep learning paradigms in building truly large-scale high precision",background,0
2659,computer-aided diagnosis (CAD) systems.,method,2
2660,"In this paper, we present a new chest X-ray database, namely ChestX-ray8, which comprises 108,948 frontal-view X-ray images of 32,717 unique patients with the text-mined eight disease image labels (where each image can have multi-labels), from the associated radiological reports using natural language processing.",result,3
2661,"Importantly, we demonstrate that these commonly occurring thoracic diseases can be detected and even spatially-located via a unified weakly-supervised multi-label image classification and disease localization framework, which is validated using our proposed dataset.",result,3
2662,"Although the initial quantitative results are promising as reported, deep convolutional neural network based reading chest X-rays (i.e., recognizing and locating the common disease patterns trained with only image-level labels) remains a strenuous task for fully-automated high precision CAD systems.",result,3
2663,Email has now become the most-used communication tool in the world and has also become the primary business productivity applications for most organizations and individuals.,background,0
2664,"With the ever increasing popularity of emails, email over-load and prioritization becomes a major problem for many email users.",background,0
2665,"Users spend a lot of time reading, replying and organizing their emails.",background,0
2666,"To help users organize and prioritize their email messages, we propose a new framework; email reply prediction with unsupervised learning.",method,2
2667,"The goal is to provide concise, highly structured and prioritized emails, thus saving the user from browsing through each email one by one and help to save time.",objective,1
2668,"In this paper, we discuss the features used to differentiate emails, show promising initial results with unsupervised machine learning model, and outline future directions for this work.",method,2
2669,"This paper presents a design pattern of an adaptive scheduling based on the management of the tasks execution time, achieved through multiple versions of the tasks, applied to the real-time specification for Java.",background,0
2670,"A structure of classes is used to facilitate the development of tasks, while allowing the independence of the application code from the code responsible for the adaptive control.",method,2
2671,The design pattern is described through UML diagrams and an example implementation is presented.,method,2
2672,This paper addresses the problem of 3D human pose estimation from a single image.,background,0
2673,"We follow a standard two-step pipeline by first detecting the 2D position of the N body joints, and then using these observations to infer 3D pose.",method,2
2674,"For the first step, we use a recent CNN-based detector.",method,2
2675,"For the second step, most existing approaches perform 2N-to-3N regression of the Cartesian joint coordinates.",method,2
2676,"We show that more precise pose estimates can be obtained by representing both the 2D and 3D human poses using NxN distance matrices, and formulating the problem as a 2D-to-3D distance matrix regression.",background,0
2677,"For learning such a regressor we leverage on simple Neural Network architectures, which by construction, enforce positivity and symmetry of the predicted matrices.",result,3
2678,The approach has also the advantage to naturally handle missing observations and allowing to hypothesize the position of non-observed joints.,method,2
2679,Quantitative results on Humaneva and Human3.6M datasets demonstrate consistent performance gains over state-of-the-art.,result,3
2680,"Qualitative evaluation on the images in-the-wild of the LSP dataset, using the regressor learned on Human3.6M, reveals very promising generalization results.",result,3
2681,Heart rate is an important indicator of people's physiological state.,background,0
2682,"Recently, several papers reported methods to measure heart rate remotely from face videos.",background,0
2683,"Those methods work well on stationary subjects under well controlled conditions, but their performance significantly degrades if the videos are recorded under more challenging conditions, specifically when subjects' motions and illumination variations are involved.",background,0
2684,We propose a framework which utilizes face tracking and Normalized Least Mean Square adaptive filtering methods to counter their influences.,objective,1
2685,We test our framework on a large difficult and public database MAHNOB-HCI and demonstrate that our method substantially outperforms all previous methods.,method,2
2686,We also use our method for long term heart rate monitoring in a game evaluation scenario and achieve promising results.,result,3
2687,We consider the following scheduling problem.,background,0
2688,There are m parallel machines and n independent jobs.,background,0
2689,Each job is to be assigned to one of the machines.,objective,1
2690,The processing of job j on machine i requires time pij.,method,2
2691,The objective is to find a schedule that minimizes the makespan.,objective,1
2692,Our main result is a polynomial algorithm which constructs a schedule that is guaranteed to be no longer than twice the optimum.,method,2
2693,We also present a polynomial approximation scheme for the case that the number of machines is fixed.,background,0
2694,Both approximation results are corollaries of a theorem about the relationship of a class of integer programming problems and their linear programming relaxations.,result,3
2695,"In particular, we give a polynomial method to round the fractional extreme points of the linear program to integral points that nearly satisfy the constraints.",method,2
2696,"In contrast to our main result, we prove that no polynomial algorithm can achieve a worst-case ratio less than 3/2 unless P = NP.",result,3
2697,The landscape of cloud computing has significantly changed over the last decade.,background,0
2698,"Not only have more providers and service offerings crowded the space, but also cloud infrastructure that was traditionally limited to single provider data centers is now evolving.",background,0
2699,"In this paper, we firstly discuss the changing cloud infrastructure and consider the use of infrastructure from multiple providers and the benefit of decentralising computing away from data centers.",objective,1
2700,These trends have resulted in the need for a variety of new computing architectures that will be offered by future cloud infrastructure.,objective,1
2701,"These architectures are anticipated to impact areas, such as connecting people and devices, data-intensive computing, the service space and self-learning systems.",objective,1
2702,"Finally, we lay out a roadmap of challenges thatwill need to be addressed for realising the potential of next generation cloud systems.",method,2
2703,© 2017 Elsevier B.V.,other,4
2705,With the increase in available data parallel machine learning has become an increasingly pressing problem.,background,0
2706,In this paper we present the first parallel stochastic gradient descent algorithm including a detailed analysis and experimental evidence.,background,0
2707,"Unlike prior work on parallel optimization algorithms [5, 7] our variant comes with parallel acceleration guarantees and it poses no overly tight latency constraints, which might only be available in the multicore setting.",background,0
2708,Our analysis introduces a novel proof technique — contractive mappings to quantify the speed of convergence of parameter distributions to their asymptotic limits.,method,2
2709,"As a side effect this answers the question of how quickly stochastic gradient descent algorithms reach the asymptotically normal regime [1, 8].",result,3
2710,"Unobtrusive, contactless recordings of physiological signals are very important for many health and human-computer interaction applications.",background,0
2711,Most current systems require sensors which intrusively touch the user's skin.,background,0
2712,Recent advances in contact-free physiological signals open the door to many new types of applications.,background,0
2713,This technology promises to measure heart rate (HR) and respiration using video only.,objective,1
2714,"The effectiveness of this technology, its limitations, and ways of overcoming them deserves particular attention.",result,3
2715,"In this paper, we evaluate this technique for measuring HR in a controlled situation, in a naturalistic computer interaction session, and in an exercise situation.",result,3
2716,"For comparison, HR was measured simultaneously using an electrocardiography device during all sessions.",method,2
2717,"The results replicated the published results in controlled situations, but show that they cannot yet be considered as a valid measure of HR in naturalistic human-computer interaction.",result,3
2718,We propose a machine learning approach to improve the accuracy of HR detection in naturalistic measurements.,objective,1
2719,The results demonstrate that the root mean squared error is reduced from 43.76 to 3.64 beats/min using the proposed method.,result,3
2720,This paper presents a comprehensive physical characterization and modeling of the three-phase common-mode (CM) inductors along with the equivalent circuits that are relevant for their design.,objective,1
2721,"Modeling issues that are treated sparsely in previous literature are explained in this paper, and novel insightful aspects are presented.",background,0
2722,"The calculation of the leakage inductance is reviewed, along with the magnetic core saturation issues, and a new expression for the leakage flux path is derived.",method,2
2723,"The influence of the core material characteristics on the performance of the component is discussed, and a new method for the selection of the material for the minimized volume CM inductors is proposed in order to simplify the design procedure.",method,2
2724,Experimental results which validate the model are presented.,result,3
2725,Trading rules have been utilized in the stock market to make profit for more than a century.,background,0
2726,"However, only using a single trading rule may not be sufficient to predict the stock price trend accurately.",background,0
2727,"Although some complex trading strategies combining various classes of trading rules have been proposed in the literature, they often pick only one rule for each class, which may lose valuable information from other rules in the same class.",background,0
2728,"In this paper, a complex stock trading strategy, namely weight reward strategy (WRS), is proposed.",objective,1
2729,WRS combines the two most popular classes of trading rules-moving average (MA) and trading range break-out (TRB).,method,2
2730,"For both MA and TRB, WRS includes different combinations of the rule parameters to get a universe of 140 component trading rules in all.",method,2
2731,Each component rule is assigned a start weight and a reward/penalty mechanism based on profit is proposed to update these rules' weights over time.,method,2
2732,"To determine the best parameter values of WRS, we employ an improved time variant Particle Swarm Optimization (PSO) algorithm with the objective of maximizing the annual net profit generated by WRS.",result,3
2733,The experiments show that our proposed WRS optimized by PSO outperforms the best moving average and trading range break-out rules.,result,3
2734,Forecasting performances of feed-forward and recurrent neural networks (NN) trained with different learning algorithms are analyzed and compared using the Mackey-Glass nonlinear chaotic time series.,background,0
2735,This system is a known benchmark test whose elements are hard to predict.,background,0
2736,Multi-layer Perceptron NN was chosen as a feed-forward neural network because it is still the most commonly used network in financial forecasting models.,method,2
2737,"It is compared with the modified version of the so-called Dynamic Multi-layer Perceptron NN characterized with a dynamic neuron model, i.e., Auto Regressive Moving Average filter built into the hidden layer neurons.",method,2
2738,"Thus, every hidden layer neuron has the ability to process previous values of its own activity together with new input signals.",method,2
2739,The obtained results indicate satisfactory forecasting characteristics of both networks.,result,3
2740,"However, recurrent NN was more accurate in practically all tests using less number of hidden layer neurons than the feed-forward NN.",result,3
2741,This study once again confirmed a great effectiveness and potential of dynamic neural networks in modeling and predicting highly nonlinear processes.,result,3
2742,Their application in the design of financial forecasting models is therefore most recommended.,result,3
2743,"In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs).",objective,1
2744,The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images.,background,0
2745,"By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast.",background,0
2746,"These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient.",objective,1
2747,"Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance.",method,2
2748,"We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data.",method,2
2749,We present a novel CNN architecture which differs from those traditionally used in computer vision.,method,2
2750,Our CNN exploits both local features as well as more global contextual features simultaneously.,method,2
2751,"Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up.",method,2
2752,We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels.,method,2
2753,"In this paper, it is proposed a new methodology based on invariant moments and multi-class support vector machine (MCSVM) for classification of human parasite eggs in microscopic images.",objective,1
2754,The MCSVM is one of the most used classifiers but it has not used for classification of human parasite eggs to date.,method,2
2755,This method composes four stages.,method,2
2756,"These are pre-processing stage, feature extraction stage, classification stage, and testing stage.",method,2
2757,"In pre-processing stage, the digital image processing methods, which are noise reduction, contrast enhancement, thresholding, and morphological and logical processes.",method,2
2758,"In feature extraction stage, the invariant moments of pre-processed parasite images are calculated.",method,2
2759,"Finally, in classification stage, the multi-class support vector machine (MCSVM) classifier is used for classification of features extracted feature extraction stage.",method,2
2760,We used MATLAB software for estimating the success classification rate of proposed approach in this study.,method,2
2761,"For this aim, proposed approach was tested by using test data.",method,2
2762,"At end of test, 97.70% overall success rates were obtained.",result,3
2763,"Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis.",background,0
2764,"We define this task as being able to classify a tweet as racist, sexist or neither.",background,0
2765,The complexity of the natural language constructs makes this task very challenging.,background,0
2766,We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity.,method,2
2767,Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ∼18 F1 points.,method,2
2768,"Software architecture has become a centerpiece subject for software engineers, both researchers and practitioners alike.",background,0
2769,"At the heart of every software system is its software architecture, i.e., ""the set of principal design decisions about the system"".",background,0
2770,"Architecture permeates all major facets of a software system, for principal design decisions may potentially be made at any time during a system's lifetime, and potentially by any stakeholder.",background,0
2771,"Such decisions encompass structural concerns, such as the system's high-level building blocks---components, connectors, and configurations; the system's deployment; the system's non-functional properties; and the system's evolution patterns, including runtime adaptation.",background,0
2772,"Software architectures found particularly useful for families of systems---product lines---are often codified into architectural patterns, architectural styles, and reusable, parameterized reference architectures.",background,0
2773,"This tutorial affords the participant an extensive treatment of the field of software architecture, its foundation, principles, and elements, including those mentioned above.",method,2
2774,"Additionally, the tutorial introduces the participants to the state-of-the-art as well as the state-of-the-practice in software architecture, and looks at emerging and likely future trends in this field.",method,2
2775,The discussion is illustrated with numerous real-world examples.,method,2
2776,"One example given prominent treatment is the architecture of the World Wide Web and its underlying architectural style, REpresentational State Transfer (REST).",result,3
2777,Years of heavy regulation and bureaucratic inefficiency have slowed innovation for electronic medical records (EMRs).,background,0
2778,"We now face a critical need for such innovation, as personalization and data science prompt patients to engage in the details of their healthcare and restore agency over their medical data.",background,0
2779,"In this paper, we propose MedRec: a novel, decentralized record management system to handle EMRs, using blockchain technology.",objective,1
2780,"Our system gives patients a comprehensive, immutable log and easy access to their medical information across providers and treatment sites.",method,2
2781,"Leveraging unique blockchain properties, MedRec manages authentication, confidentiality, accountability and data sharing- crucial considerations when handling sensitive information.",method,2
2782,"A modular design integrates with providers' existing, local data storage solutions, facilitating interoperability and making our system convenient and adaptable.",method,2
2783,"We incentivize medical stakeholders (researchers, public health authorities, etc.) to participate in the network as blockchain “miners”.",method,2
2784,"This provides them with access to aggregate, anonymized data as mining rewards, in return for sustaining and securing the network via Proof of Work.",method,2
2785,"MedRec thus enables the emergence of data economics, supplying big data to empower researchers while engaging patients and providers in the choice to release metadata.",method,2
2786,"The purpose of this short paper is to expose, prior to field tests, a working prototype through which we analyze and discuss our approach.",result,3
2787,"Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images.",background,0
2788,"However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind.",background,0
2789,Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets.,background,0
2790,We introduce two such tools here.,objective,1
2791,The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream).,method,2
2792,We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work.,method,2
2793,The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space.,method,2
2794,"Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations.",method,2
2795,Both tools are open source and work on a pretrained convnet with minimal setup.,result,3
2796,"Published in the Deep Learning Workshop, 31 st International Conference on Machine Learning, Lille, France, 2015.",other,4
2797,The design and implementation of high gain 2.4GHz patch antenna array for wireless communications application in rural area is presented.,objective,1
2798,The patch antenna array with high gain is expected to minimize the need of tower that almost requires high cost of construction.,objective,1
2799,"In order to achieve high gain, the proposed antenna is constructed by 4×4 rectangular patches fed by microstrip line corporate feeding network which is developed using a λ/4 transformer impedance matching technique.",method,2
2800,"The antenna structure is then deployed on a Flame Retardant (FR) 4 Epoxy dielectric substrate which the thickness and dielectric constant of 1.6mm, and 4.4, respectively.",method,2
2801,"Prior hardware realization, some antenna parameters including return loss, voltage standing wave ratio (VSWR), radiation pattern, and gain are characterized through simulation to obtain an optimum design of antenna.",method,2
2802,"While from the measurement, it shows that the characteristics of realized patch antenna array have good agreements with the design results in which the realized antenna has the measured gain of 15.59dB at the center frequency with the return loss of 19.52dB which corresponds to VSWR of 1.24 and the bandwidth response of 130MHz ranges from the frequency of 2.31GHz-2.44GHz.",result,3
2803,"Automatic story comprehension is a fundamental challenge in Natural Language Understanding, and can enable computers to learn about social norms, human behavior and commonsense.",background,0
2804,"In this paper, we present a story comprehension model that explores three distinct semantic aspects: (i) the sequence of events described in the story, (ii) its emotional trajectory, and (iii) its plot consistency.",objective,1
2805,"We judge the model’s understanding of real-world stories by inquiring if, like humans, it can develop an expectation of what will happen next in a given story.",method,2
2806,"Specifically, we use it to predict the correct ending of a given short story from possible alternatives.",method,2
2807,The model uses a hidden variable to weigh the semantic aspects in the context of the story.,method,2
2808,"Our experiments demonstrate the potential of our approach to characterize these semantic aspects, and the strength of the hidden variable based approach.",result,3
2809,The model outperforms the stateof-the-art approaches and achieves best results on a publicly available dataset.,result,3
2810,"Although deep learning has historical roots going back decades, neither the term “deep learning” nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton’s now classic 2012 (Krizhevsky, Sutskever, & Hinton, 2012)deep net model of Imagenet.",background,0
2811,What has the field discovered in the five subsequent years?,background,0
2812,"Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence. !",background,0
2813,"Departments of Psychology and Neural Science, New York University, gary.marcus at nyu.edu.",other,4
2814,"I thank Christina 1 Chen, François Chollet, Ernie Davis, Zack Lipton, Stefano Pacifico, Suchi Saria, and Athena Vouloumanos for sharp-eyed comments, all generously supplied on short notice during the holidays at the close of 2017.",other,4
2815,Distributed Network Protocol (DNP3) is the predominant SCADA protocol in the energy sector – more than 75% of North American electric utilities currently use DNP3 for industrial control applications.,result,3
2816,This paper presents a taxonomy of attacks on the protocol.,other,4
2817,"The attacks are classified based on targets (control center, outstation devices and network/communication paths) and threat categories (interception, interruption, modification and fabrication).",method,2
2818,"To facilitate risk analysis and mitigation strategies, the attacks are associated with the specific DNP3 protocol layers they exploit.",result,3
2819,"Also, the operational impact of the attacks is categorized in terms of three key SCADA objectives: process confidentiality, process awareness and process control.",result,3
2820,"The attack taxonomy clarifies the nature and scope of the threats to DNP3 systems, and can provide insights into the relative costs and benefits of implementing mitigation strategies.",result,3
2821,"A revision is currently being undertaken of ISO 9241-11, published in 1998 to provide guidance on usability.",background,0
2822,"ISO-9241-11 defines usability in terms of effectiveness, efficiency and satisfaction in a particular context of use.",background,0
2823,The intention was to emphasise that usability is an outcome of interaction rather than a property of a product.,objective,1
2824,This is now widely accepted.,objective,1
2825,"However, the standard also places emphasis on usability measurement and it is now appreciated that there is more to usability evaluation than measurement.",background,0
2826,Other developments include an increasing awareness of the importance of the individual user's emotional experience as discretionary usage of complex consumer products and use of the World Wide Web have became more widespread.,background,0
2827,"From an organisational perspective, it is now appreciated that usability plays an important role in managing the potentials risks that can arise from inappropriate outcomes of interaction.",background,0
2828,The revision of ISO 9241-11 takes account of these issues and other feedback.,other,4
2829,"Noise is always presents in digital images during image acquisition, coding, transmission, and processing steps.",background,0
2830,Noise is very difficult to remove it from the digital images without the prior knowledge of noise model.,background,0
2831,"That is why, review of noise models are essential in the study of image denoising techniques.",method,2
2832,"In this paper, we express a brief overview of various noise models.",objective,1
2833,These noise models can be selected by analysis of their origin.,method,2
2834,"In this way, we present a complete and quantitative analysis of noise models available in digital images.",result,3
2835,The increasing diffusion of digital technologies throughout industries and aspects of life is transforming businesses even in areas that always have been dependent on physical materiality.,background,0
2836,"In this paper, by conducting an exploratory Delphi study in collaboration with 19 industry experts, we aim to shed light on the specific managerial challenges associated with the impact of digital transformation in the industrial-age, physical product–manufacturing automotive industry.",objective,1
2837,"Our results point to three key themes: (1) the radicalization of IT-enabled business transformation going beyond intraorganizational challenges, (2) the transformation of industrial business through digital innovation, and (3) the emergence of physical–digital paradoxes.",result,3
2838,"With our study, we extend the knowledge in IT-enabled business transformation literature by relating it to the emergent topic of digital innovation.",result,3
2839,We find organizational ambidexterity to be of specific importance when dealing with emergent challenges that arise from the combination of the physical and digital worlds.,result,3
2840,Convolutional neural networks (CNNs) have recently emerged as a popular building block for natural language processing (NLP).,background,0
2841,"Despite their success, most existing CNN models employed in NLP are not expressive enough, in the sense that all input sentences share the same learned (and static) set of filters.",background,0
2842,"Motivated by this problem, we propose an adaptive convolutional filter generation framework for natural language understanding, by leveraging a meta network to generate inputaware filters.",objective,1
2843,We further generalize our framework to model question-answer sentence pairs and propose an adaptive question answering (AdaQA) model; a novel two-way feature abstraction mechanism is introduced to encapsulate co-dependent sentence representations.,method,2
2844,"We investigate the effectiveness of our framework on document categorization and answer sentence-selection tasks, achieving state-of-the-art performance on several",result,3
2845,"As mobile ad hoc network applications are deployed, security emerges as a central requirement.",background,0
2846,"In this paper, we introduce the wormhole attack, a severe attack in ad hoc networks that is particularly challenging to defend against.",background,0
2847,"The wormhole attack is possible even if the attacker has not compromised any hosts, and even if all communication provides authenticity and confidentiality.",background,0
2848,"In the wormhole attack, an attacker records packets (or bits) at one location in the network, tunnels them (possibly selectively) to another location, and retransmits them there into the network.",background,0
2849,"The wormhole attack can form a serious threat in wireless networks, especially against many ad hoc network routing protocols and location-based wireless security systems.",background,0
2850,"For example, most existing ad hoc network routing protocols, without some mechanism to defend against the wormhole attack, would be unable to find routes longer than one or two hops, severely disrupting communication.",background,0
2851,"We present a general mechanism, called packet leashes, for detecting and, thus defending against wormhole attacks, and we present a specific protocol, called TIK, that implements leashes.",method,2
2852,"We also discuss topology-based wormhole detection, and show that it is impossible for these approaches to detect some wormhole topologies.",method,2
2853,"Scattering in participating media, such as fog or haze, generates volumetric lighting effects known as crepuscular or god rays.",background,0
2854,"Rendering such effects greatly enhances the realism in virtual scenes, but is inherently costly as scattering events occur at every point in space and thus it requires costly integration of the light scattered towards the observer.",background,0
2855,This is typically done using ray marching which is too expensive for every pixel on the screen for interactive applications.,objective,1
2856,"We propose a rendering technique for textured light sources in single-scattering media, that draws from the concept of epipolar geometry to place samples in image space: the inscattered light varies orthogonally to crepuscular rays, but mostly smoothly along these rays.",objective,1
2857,These are epipolar lines of a plane of light rays that projects onto one line on the image plane.,method,2
2858,"Our method samples sparsely along epipolar lines and interpolates between samples where adequate, but preserves high frequency details that are caused by shadowing of light rays.",method,2
2859,"We show that our method is very simple to implement on the GPU, yields high quality images, and achieves high frame rates.",method,2
2860,"Compared to scanned images, document pictures captured by camera can suffer from distortions due to perspective and page warping.",background,0
2861,It is necessary to restore a frontal planar view of the page before other OCR techniques can be applied.,method,2
2862,In this paper we describe a novel approach for flattening a curved document in a single picture captured by an uncalibrated camera.,objective,1
2863,To our knowledge this is the first reported method able to process general curved documents in images without camera calibration.,method,2
2864,"We propose to model the page surface by a developable surface, and exploit the properties (parallelism and equal line spacing) of the printed textual content on the page to recover the surface shape.",method,2
2865,Experiments show that the output images are much more OCR friendly than the original ones.,result,3
2866,"While our method is designed to work with any general developable surfaces, it can be adapted for typical special cases including planar pages, scans of thick books, and opened books.",method,2
2867,"This paper presents the concepts, issues on development, and future perspectives of a novel musculoskeletal humanoid `Kotaro'.",background,0
2868,"The specifications and advantages of Kotaro include muscle-driven endoskeletal structure, multiple degrees of freedom, variable physical softness, the multiple-joint spine, easily configurable muscles, distributed onbody controllers, various sorts of many sensors including eyes, ears, and whole-body tactile sensors, and so on.",background,0
2869,"These characteristics would achieve a flexible body, litheness of motions, safety, and adaptability and applicability to diverse tasks which would very often appear in human's daily lives",objective,1
2870,"Digital forensics is a relatively new scientific discipline, but one that has matured greatly over the past decade.",background,0
2871,"In any field of human endeavor, it is important to periodically pause and review the state of the discipline.",background,0
2872,This paper examines where the discipline of digital forensics is at this point in time and what has been accomplished in order to critically analyze what has been done well and what ought to be done better.,objective,1
2873,"The paper also takes stock of what is known, what is not known and what needs to be known.",objective,1
2874,"It is a compilation of the author’s opinion and the viewpoints of twenty-one other practitioners and researchers, many of whom are leaders in the field.",method,2
2875,"In synthesizing these professional opinions, several consensus views emerge that provide valuable insights into the “state of the discipline.”",result,3
2876,Neural networks are typically designed to deal with data in tensor forms.,background,0
2877,"In this paper, we propose a novel neural network architecture accepting graphs of arbitrary structure.",objective,1
2878,"Given a dataset containing graphs in the form of (G, y) where G is a graph and y is its class, we aim to develop neural networks that read the graphs directly and learn a classification function.",result,3
2879,"There are two main challenges: 1) how to extract useful features characterizing the rich information encoded in a graph for classification purpose, and 2) how to sequentially read a graph in a meaningful and consistent order.",method,2
2880,"To address the first challenge, we design a localized graph convolution model and show its connection with two graph kernels.",method,2
2881,"To address the second challenge, we design a novel SortPooling layer which sorts graph vertices in a consistent order so that traditional neural networks can be trained on the graphs.",method,2
2882,Experiments on benchmark graph classification datasets demonstrate that the proposed architecture achieves highly competitive performance with state-of-the-art graph kernels and other graph neural network methods.,result,3
2883,"Moreover, the architecture allows end-to-end gradient-based training with original graphs, without the need to first transform graphs into vectors.",result,3
2884,"For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems.",background,0
2885,"In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments.",background,0
2886,"We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than 1% of our agent’s interactions with the environment.",background,0
2887,This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems.,result,3
2888,"To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time.",result,3
2889,These behaviors and environments are considerably more complex than any which have been previously learned from human feedback.,result,3
2890,"In this paper, we adopt 3D CNNs to segment the pancreas in CT images.",background,0
2891,"Although deep neural networks have been proven to be very effective on many 2D vision tasks, it is still challenging to apply them to 3D applications due to the limited amount of annotated 3D data and limited computational resources.",background,0
2892,We propose a novel 3D-based coarseto-fine framework for volumetric pancreas segmentation to tackle these challenges.,background,0
2893,The proposed 3D-based framework outperforms the 2D counterpart to a large margin since it can leverage the rich spatial information along all three axes.,background,0
2894,"We conduct experiments on two datasets which include healthy and pathological pancreases respectively, and achieve the state-of-the-art in terms of Dice-Sørensen Coefficient (DSC).",result,3
2895,"Moreover, the worst case of DSC on the NIH dataset was improved by 7% to reach almost 70%, which indicates the reliability of our framework in clinical applications.",result,3
2897,It is not only to fulfil the duties that you need to finish in deadline time.,background,0
2900,Reading elements of distributed computing is also a way as one of the collective books that gives many advantages.,background,0
2902,This article provides an overview of the mainstream deep learning approaches and research directions proposed over the past decade.,background,0
2903,"It is important to emphasize that each approach has strengths and ""weaknesses, depending on the application and context in ""which it is being used.",background,0
2904,"Thus, this article presents a summary on the current state of the deep machine learning field and some perspective into how it may evolve.",background,0
2905,Convolutional Neural Networks (CNNs) and Deep Belief Networks (DBNs) (and their respective variations) are focused on primarily because they are well established in the deep learning field and show great promise for future work.,result,3
2906,"Today‘s business environment is very much dynamic, and organizations are constantly changing their software requirements to adjust with new environment.",background,0
2907,They also demand for fast delivery of software products as well as for accepting changing requirements.,background,0
2908,"In this aspect, traditional plan-driven developments fail to meet up these requirements.",background,0
2909,"Though traditional software development methodologies, such as life cycle-based structured and object oriented approaches, continue to dominate the systems development few decades and much research has done in traditional methodologies, Agile software development brings its own set of novel challenges that must be addressed to satisfy the customer through early and continuous delivery of the valuable software.",method,2
2910,"It‘s a set of software development methods based on iterative and incremental development process, where requirements and development evolve through collaboration between self-organizing, cross-functional teams that allows rapid delivery of high quality software to meet customer needs and also accommodate changes in the requirements.",method,2
2911,"In this paper, we significantly indentify and describe the major factors, that Agile development approach improves software development process to meet the rapid changing business environments.",method,2
2912,"We also provide a brief comparison of agile development methodologies with traditional systems development methodologies, and discuss current state of adopting agile methodologies.",method,2
2913,The requirement of detection and identification of tables from document images is crucial to any document image analysis and digital library system.,background,0
2914,Here in this paper we report a very simple but extremely powerful approach to detect any table in any form that may be present in a document page.,objective,1
2915,The algorithm rely on the observation that the tables has distinct columns whose physical implication is in the presence of substantially larger gaps between the fields than the gaps between the words in text lines.,method,2
2916,This deceptively simple observation has led to the design of a simple but powerful table detection system with a low computation cost and achieving an efficiency close to 100%.,method,2
2917,"Moreover, mathematical foundation of the approach is also established including formation of a regular expression for ease of implementation.",method,2
2918,Manual analysis and decryption of enciphered documents is a tedious and error prone work.,background,0
2919,Often—even after spending large amounts of time on a particular cipher—no decipherment can be found.,background,0
2920,"Automating the decryption of various types of ciphers makes it possible to sift through the large number of encrypted messages found in libraries and archives, and to focus human effort only on a small but potentially interesting subset of them.",objective,1
2921,"In this work, we train a classifier that is able to predict which encipherment method has been used to generate a given ciphertext.",method,2
2922,We are able to distinguish 50 different cipher types (specified by the American Cryptogram Association) with an accuracy of 58.5%.,method,2
2923,This is a 11.2% absolute improvement over the best previously published classifier.,result,3
2924,Instant messaging (IM) has become one of the most popular forms of computer-mediated communication (CMC) and is especially prevalent on college campuses.,background,0
2925,Previous research suggests that IM users often multitask while conversing online.,background,0
2926,"To date, no one has yet examined the cognitive effect of concurrent IM use.",background,0
2927,Participants in the present study (N = 69) completed a reading comprehension task uninterrupted or while concurrently holding an IM conversation.,background,0
2928,"Participants who IMed while performing the reading task took significantly longer to complete the task, indicating that concurrent IM use negatively affects efficiency.",method,2
2929,Concurrent IM use did not affect reading comprehension scores.,method,2
2930,"Additional analyses revealed that the more time participants reported spending on IM, the lower their reading comprehension scores.",result,3
2931,"Finally, we found that the more time participants reported spending on IM, the lower their self-reported GPA.",result,3
2932,Implications and future directions are discussed.,other,4
2933,Clustering is a solution for classifying enormous data when there is not any early knowledge about classes.,method,2
2934,"With emerging new concepts like cloud computing and big data and their vast applications in recent years, research works have been increased on unsupervised solutions like clustering algorithms to extract knowledge from this avalanche of data.",background,0
2935,Clustering time-series data has been used in diverse scientific areas to discover patterns which empower data analysts to extract valuable information from complex and massive datasets.,objective,1
2936,"In case of huge datasets, using supervised classification solutions is almost impossible, while clustering can solve this problem using unsupervised approaches.",method,2
2937,"In this research work, the focus is on time-series data, which is one of the popular data types in clustering problems and is broadly used from gene expression data in biology to stock market analysis in finance.",result,3
2938,"This review will expose four main components of time-series clustering and is aimed to represent an updated investigation on the trend of improvements in efficiency, quality and complexity of clustering time-series approaches during the last decade and enlighten new paths for",objective,1
2939,"TreeView is a simple, easy to use phylogenetic tree viewing utility that runs under both MacOS (on Apple Macintosh computers) and under Microsoft Windows on Intel based computers, the two most common personal computers used by biologists.",background,0
2940,"Some phylogeny programs, such as PAUP (Swofford, 1993) and MacClade (Maddison and Maddison, 1992) already provide excellent tree drawing and printing facilities, however at present these programs are restricted to Apple Macintosh computers.",background,0
2941,"Furthermore, they require the user to load a data set before any trees can be displayed which is inconvenient if the user simply wants to view the trees.",background,0
2942,"More portable programs, such as DRAWGRAM and DRAWTREE in the PHYLIP package (Felsenstein, 1993) can run on both MacOS and Windows computers, but make little, if any use of the graphical interface features available under those operating systems.",background,0
2943,"TreeView runs as a native application on either MacOS or Windows computers, enables the user to use the standard fonts installed on their machine, their printer, and supports the relevant native graphics format (PICT and Windows metafile) for either creating graphics files or pasting pictures to other applications via the clipboard.",method,2
2944,"The program also supports standard file operations, such as 'drag and drop' whereby dragging a file's icon onto the program opens that file.",method,2
2945,TreeView can read a range of tree file formats (see below) and can display trees in a range of styles (Fig. 1).,result,3
2946,"Additional information, such as edge lengths and internal node labels can also be displayed.",result,3
2947,"The order of the terminal taxa in the tree can be altered, and the tree can be rerooted.",method,2
2948,If the tree file contains more than one tree the user can view each tree in turn.,result,3
2949,John Trono published a new exercise in concurrent programming—the Santa Claus problem—and provided a solution based on semaphores [12].,background,0
2950,His solution is incorrect because it assumes that a process released from waiting on a semaphore will necessarily be scheduled for execution.,background,0
2951,We give a simple solution in Ada 95 using higher order synchronization primitives: protected objects and rendezvous.,method,2
2952,"We then give solution in Java, though this solution is not as elegant as the Ada 95 solution because the Java synchronization primitives are rather limited.",method,2
2953,"The problem demonstrates that semaphores, designed for low-level mutual exclusion, are not appropriate for solving difficult concurrent programming problems.",result,3
2954,In this paper we present an approach to organize and classify e-mails using self-organizing maps.,background,0
2955,"The aim is on the one hand to provide an intuitive visual profile of the considered mailing lists and on the other hand to offer an intuitive navigation tool, were similar e-mails are located close to each other, so that the user can scan easily for e-mails similar in content.",objective,1
2956,To be able to evaluate this approach we have developed a prototypical software tool that imports messages from a mailing list and arranges/ groups these e-mails based on a similarity measure.,method,2
2957,The tool combines conventional keyword search methods with a visualization of the considered e-mail collection.,method,2
2958,"The prototype was developed based on externally growing self-organizing maps, which solve some problems of conventional self-organizing maps and which are computationally viable.",result,3
2959,Besides the underlying algorithms we present and discuss some system evaluations in order to show the capabilities of the approach.,background,0
2960,# 2005 Elsevier B.V. All rights reserved.,other,4
2961,"We compare three common dispute resolution processes – negotiation, mediation, and arbitration – in the framework of Crawford and Sobel (1982).",background,0
2962,"Under negotiation, the two parties engage in (possibly arbitrarily long) face-to-face cheap talk.",background,0
2963,"Under mediation, the parties communicate with a neutral third party who makes a non-binding recommendation.",method,2
2964,"Under arbitration, the two parties commit to conform to the third party recommendation.",method,2
2965,We characterize and compare the optimal mediation and arbitration procedures.,method,2
2966,"Both mediators and arbitrators should optimally filter information, but mediators should also add noise to it.",method,2
2967,We find that unmediated negotiation performs as well as mediation if and only if the degree of conflict between the parties is low.,result,3
2968,Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks.,background,0
2969,"However, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify.",background,0
2970,"In this work, we formalize the space of adversaries against deep neural networks (DNNs) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs.",objective,1
2971,"In an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 97% adversarial success rate while only modifying on average 4.02% of the input features per sample.",result,3
2972,We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure.,result,3
2973,"Finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.",result,3
2974,Scaling the distributed deep learning to a massive GPU cluster level is challenging due to the instability of the large mini-batch training and the overhead of the gradient synchronization.,background,0
2975,We address the instability of the large mini-batch training with batch size control.,method,2
2976,We address the overhead of the gradient synchronization with 2D-Torus all-reduce.,method,2
2977,"Specifically, 2D-Torus all-reduce arranges GPUs in a logical 2D grid and performs a series of collective operation in different orientations.",method,2
2978,These two techniques are implemented with Neural Network Libraries (NNL) 1 .,method,2
2979,We have successfully trained ImageNet/ResNet-50 in 224 seconds without significant accuracy loss on ABCI cluster.,result,3
2980,The effects of e-commerce institutional mechanisms on trust and online purchase have traditionally been understood in the initial online purchase context.,background,0
2981,This study extends this literature by exploring the role of ecommerce institutional mechanisms in the online repurchase context.,background,0
2982,"In doing so, it responds to the emerging call for understanding the institutional context under which customer trust operates in an e-commerce environment.",background,0
2983,"Specifically, this study introduces a key moderator, perceived effectiveness of e-commerce institutional mechanisms (PEEIM), to the relationships between trust, satisfaction, and repurchase intention.",method,2
2984,"Drawing on the theory of organizational trust, and based on a survey of 362 returning online customers, we find that PEEIM negatively moderates the relationship between trust in an online vendor and online customer repurchase intention, as it decreases the importance of trust to promoting repurchase behavior.",other,4
2985,We also find that,other,4
2986,"This study assessed motives for social network site (SNS) use, group belonging, collective self-esteem, and gender effects among older adolescents.",background,0
2987,Communication with peer group members was the most important motivation for SNS use.,background,0
2988,Participants high in positive collective self-esteem were strongly motivated to communicate with peer group via SNS.,method,2
2989,"Females were more likely to report high positive collective self-esteem, greater overall use, and SNS use to communicate with peers.",background,0
2990,"Females also posted higher means for group-in-self, passing time, and entertainment.",method,2
2991,"Negative collective self-esteem correlated with social compensation, suggesting that those who felt negatively about their social group used SNS as an alternative to communicating with other group members.",method,2
2992,Males were more likely than females to report negative collective self-esteem and SNS use for social compensation and social identity gratifications.,method,2
2993,Internet of Things (IoT) technology has attracted much attention in recent years for its potential to alleviate the strain on healthcare systems caused by an aging population and a rise in chronic illness.,background,0
2994,"Standardization is a key issue limiting progress in this area, and thus this paper proposes a standard model for application in future IoT healthcare systems.",background,0
2995,"This survey paper then presents the state-of-the-art research relating to each area of the model, evaluating their strengths, weaknesses, and overall suitability for a wearable IoT healthcare system.",objective,1
2996,"Challenges that healthcare IoT faces including security, privacy, wearability, and low-power operation are presented, and recommendations are made for future research directions.",result,3
2997,"In microblogging services such as Twitter, the users may become overwhelmed by the raw data.",background,0
2998,One solution to this problem is the classification of short text messages.,objective,1
2999,"As short texts do not provide sufficient word occurrences, traditional classification methods such as ""Bag-Of-Words"" have limitations.",background,0
3000,"To address this problem, we propose to use a small set of domain-specific features extracted from the author's profile and text.",method,2
3001,"The proposed approach effectively classifies the text to a predefined set of generic classes such as News, Events, Opinions, Deals, and Private Messages.",result,3
3002,Recent advances have given rise to the popularity and success of cloud computing.,background,0
3003,"However, when outsourcing the data and business application to a third party causes the security and privacy issues to become a critical concern.",background,0
3004,"Throughout the study at hand, the authors obtain a common goal to provide a comprehensive review of the existing security and privacy issues in cloud environments.",background,0
3005,"We have identified five most representative security and privacy attributes (i.e., confidentiality, integrity, availability, accountability, and privacy-preservability).",method,2
3006,"Beginning with these attributes, we present the relationships among them, the vulnerabilities that may be exploited by attackers, the threat models, as well as existing defense strategies in a cloud scenario.",method,2
3007,Future research directions are previously determined for each attribute.,method,2
3008,Tomlinson-Harashima precoding (THP) is a nonlinear processing technique employed at the transmit side to implement the concept of dirty paper coding (DPC).,background,0
3009,The application of THP is restricted by the dimensionality constraint that the number of transmit antennas has to be greater or equal to the total number of receive antennas.,background,0
3010,"In this paper, we propose an iterative coordinate THP algorithm for overloaded scenarios in which the total number of receive antennas is larger than the number of transmit antennas.",method,2
3011,"The proposed algorithm is implemented on two types of THP structures, the decentralized THP (dTHP) with diagonal weighted filters at the receivers of the users, and the centralized THP (cTHP) with diagonal weighted filter at the transmitter.",method,2
3012,Simulation results show that a significantly better bit error rate (BER) and sum-rate performances can be achieved by the proposed iterative coordinate THP algorithm as compared to previously reported techniques.,result,3
3013,"This paper presents a learning approach, i.e. negative correlation learning, for neural network ensembles.",background,0
3014,"Unlike previous learning approaches for neural network ensembles, negative correlation learning attempts to train individual networks in an ensemble and combines them in the same learning process.",background,0
3015,"In negative correlation learning, all the individual networks in the ensemble are trained simultaneously and interactively through the correlation penalty terms in their error functions.",objective,1
3016,"Rather than producing unbiased individual networks whose errors are uncorrelated, negative correlation learning can create negatively correlated networks to encourage specialisation and cooperation among the individual networks.",method,2
3017,Empirical studies have been carried out to show why and how negative correlation learning works.,method,2
3018,The experimental results show that negative correlation learning can produce neural network ensembles with good generalisation ability.,result,3
3019,"Supervisory Control and Data Acquisition (SCADA) honeypots are key tools not only for determining threats which pertain to SCADA devices in the wild, but also for early detection of potential malicious tampering within a SCADA device network.",background,0
3020,"An analysis of one such SCADA honeypot, Conpot, is conducted to determine its viability as an effective SCADA emulating device.",objective,1
3021,A long-term analysis is conducted and a simple scoring mechanism leveraged to evaluate the Conpot honeypot.,result,3
3022,"In this paper, a concept of integer fast Fourier transform ( IntFFT ) for approximating the discrete Fourier transform is introduced.",background,0
3023,"Unlike the fixed-point fast Fourier transform (FxpFFT ), the new transform has the properties that it is an integer-to-integer mapping, is power adaptable and is reversible.",background,0
3024,The lifting scheme is used to approximate complex multiplications appearing in the FFT lattice structures where the dynamic range of the lifting coefficients can be controlled by proper choices of lifting factorizations.,background,0
3025,"Split-radix FFT is used to illustrate the approach for the case of 2 -point FFT, in which case, an upper bound of the minimal dynamic range of the internal nodes, which is required by the reversibility of the transform, is presented and confirmed by a simulation.",objective,1
3026,The transform can be implemented by using only bit shifts and additions but no multiplication.,method,2
3027,A method for minimizing the number of additions required is presented.,method,2
3028,"While preserving the reversibility, the IntFFT is shown experimentally to yield the same accuracy as the FxpFFT when their coefficients are quantized to a certain number of bits.",method,2
3029,Complexity of the IntFFT is shown to be much lower than that of the FxpFFT in terms of the numbers of additions and shifts.,result,3
3030,"Finally, they are applied to noise reduction applications, where the IntFFT provides significantly improvement over theFxpFFT at low power and maintains similar results at high power.",result,3
3031,Active database systems support mechanisms that enable them to respond automatically to events that are taking place either inside or outside the database system itself.,background,0
3032,"Considerable effort has been directed towards improving understanding of such systems in recent years, and many different proposals have been made and applications suggested.",background,0
3033,"This high level of activity has not yielded a single agreed-upon standard approach to the integration of active functionality with conventional database systems, but has led to improved understanding of active behavior description languages, execution models, and architectures.",method,2
3034,"This survey presents the fundamental characteristics of active database systems, describes a collection of representative systems within a common framework, considers the consequences for implementations of certain design decisions, and discusses tools for developing active applications.",result,3
3035,Impedance and Admittance Control are two distinct implementations of the same control goal.,background,0
3036,It is well known that their stability and performance properties are complementary.,background,0
3037,"In this paper, we present a hybrid system approach, which incorporates Impedance and Admittance Control as two extreme cases of one family of controllers.",objective,1
3038,This approach allows to continuously switch and interpolate between Impedance and Admittance Control.,objective,1
3039,We compare the basic stability and performance properties of the resulting controllers by means of an extensive case study of a one-dimensional system and present an experimental evaluation using the KUKA-DLR-lightweight arm.,result,3
3040,Software architects struggle to choose an adequate architectural style for multi-tenant software systems.,background,0
3041,"Bad choices result in poor performance, low scalability, limited flexibility, and obstruct software evolution.",background,0
3042,"We present a comparison of 12 Multi-Tenant Architecture (MTA) patterns that supports architects in choosing the most suitable architectural pattern, using 17 assessment criteria.",objective,1
3043,Both patterns and criteria were evaluated by domain experts.,method,2
3044,"Five architecture assessment rules of thumb are presented in the paper, aimed at making fast and efficient design decisions.",method,2
3045,"The comparison provides architects with an effective method for selecting the applicable multi-tenant architecture pattern, saving them effort, time, and mitigating the effects of making wrong decisions.",result,3
3046,Feature selection has been the focus of interest for quite some time and much work has been done.,background,0
3047,"With the creation of huge databases and the consequent requirements for good machine learning techniques, new problems arise and novel approaches to feature selection are in demand.",background,0
3048,This survey is a comprehensive overview of many existing methods from the 1970’s to the present.,background,0
3049,"It identifies four steps of a typical feature selection method, and categorizes the different existing methods in terms of generation procedures and evaluation functions, and reveals hitherto unattempted combinations of generation procedures and evaluation functions.",method,2
3050,Representative methods are chosen from each category for detailed explanation and discussion via example.,method,2
3051,Benchmark datasets with different characteristics are used for comparative study.,method,2
3052,The strengths and weaknesses of different methods are explained.,method,2
3053,Guidelines for applying feature selection methods are given based on data types and domain characteristics.,method,2
3054,"This survey identifies the future research areas in feature selection, introduces newcomers to this field, and paves the way for practitioners who search for suitable methods for solving domain-specific real-world applications.",method,2
3055,"(Intelligent Data Analysis, Vol.",other,4
3056,The healthcare milieu of most developing countries is often characterized by multiplicity of health programs supported by myriad of donors geared towards reversing disease trends in these countries.,background,0
3057,"However, donor policies tend to support implementation of vertical programs which maintain their own management structures and information systems.",background,0
3058,"The emerging picture overtime is proliferation of multiple and uncoordinated health information systems (HIS), that are often in conflict with the primary health care goals of integrated district based health information systems.",background,0
3059,"As a step towards HIS strengthening, most countries are pursuing an integration strategy of the vertical HIS.",background,0
3060,"Nevertheless, the challenges presented by the vertical reporting HIS reinforced by funds from the donors renders the integration initiatives ineffective, some ending up as total failure or as mere pilot projects.",background,0
3061,The failure of the systems after implementation transcends technical fixes.,background,0
3062,This paper drew on an empirical case to analyze the challenges associated with the effort to integrate the HIS in a context characterized by multiple vertical health programs.,objective,1
3063,The study revealed the tensions that exists between the ministry of health which strived to standardize and integrate the HIS and the vertical programs which pushed the agenda to maintain their systems alongside the national HIS.,result,3
3064,"However, as implied from the study, attaining integration entails the ability to strike a balance between the two forces, which can be achieved by strengthening communication and collaboration linkages between the stakeholders.",result,3
3065,Deep learning (DL) is a powerful state-of-the-art technique for image processing including remote sensing (RS) images.,background,0
3066,This letter describes a multilevel DL architecture that targets land cover and crop type classification from multitemporal multisource satellite imagery.,method,2
3067,"The pillars of the architecture are unsupervised neural network (NN) that is used for optical imagery segmentation and missing data restoration due to clouds and shadows, and an ensemble of supervised NNs.",background,0
3068,"As basic supervised NN architecture, we use a traditional fully connected multilayer perceptron (MLP) and the most commonly used approach in RS community random forest, and compare them with convolutional NNs (CNNs).",method,2
3069,Experiments are carried out for the joint experiment of crop assessment and monitoring test site in Ukraine for classification of crops in a heterogeneous environment using nineteen multitemporal scenes acquired by Landsat-8 and Sentinel-1A RS satellites.,method,2
3070,"The architecture with an ensemble of CNNs outperforms the one with MLPs allowing us to better discriminate certain summer crop types, in particular maize and soybeans, and yielding the target accuracies more than 85% for all major crops (wheat, maize, sunflower, soybeans, and sugar beet).",result,3
3071,"We present a micro-traffic simulation (named “DeepTraffic”) where the perception, control, and planning systems for one of the cars are all handled by a single neural network as part of a model-free, off-policy reinforcement learning process.",background,0
3072,"The primary goal of DeepTraffic is to make the hands-on study of deep reinforcement learning accessible to thousands of students, educators, and researchers in order to inspire and fuel the exploration and evaluation of DQN variants and hyperparameter configurations through large-scale, open competition.",objective,1
3073,This paper investigates the crowd-sourced hyperparameter tuning of the policy network that resulted from the first iteration of the DeepTraffic competition where thousands of participants actively searched through the hyperparameter space with the objective of their neural network submission to make it onto the top-10 leaderboard.,method,2
3074,Social media for news consumption is a double-edged sword.,background,0
3075,"On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media.",background,0
3076,"On the other hand, it enables the wide spread of \fake news"", i.e., low quality news with intentionally false information.",background,0
3077,The extensive spread of fake news has the potential for extremely negative impacts on individuals and society.,background,0
3078,"Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention.",background,0
3079,Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ine ective or not applicable.,background,0
3080,"First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination.",method,2
3081,"Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy.",method,2
3082,"Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem.",result,3
3083,"In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets.",result,3
3084,"This research compared social networking site (SNS) use in a collectivistic culture, China, and an individualistic culture, the United States (US).",background,0
3085,"Over 400 college student participants from a Southwestern University in Chongqing, China, and 490 college participants from a Midwestern University in the US completed a survey about their use of SNSs – time spent, importance and motives for use.",method,2
3086,"They then rated themselves on a variety of personal characteristics, namely the Big Five Personality factors, Loneliness, Shyness and Life Satisfaction.",method,2
3087,Results revealed cultural differences in SNS use.,result,3
3088,"US participants spent more time in SNS, considered them to be more important and had more friends in SNSs than did Chinese participants.",result,3
3089,Self-ratings of personal characteristics also differed in the two cultures as did the personal characteristics that predicted SNS use.,result,3
3090,"In general, personal characteristics were less effective in predicting SNS use in China than in the US.",method,2
3091,"Findings suggest that in collectivistic cultures the importance of the family, friends and one’s groups may be partly responsible for Chinese participants’ lesser use of SNSs, whereas in individualistic cultures the importance of self and having more but less close and enduring friendships may be partly responsible for US participants’ greater use of SNSs.",result,3
3092,"Personal characteristics predicted SNS use in both cultures but were stronger predictors in an individualistic culture than in a collectivistic, consistent with the emphasis on self in the former and on family, friends and one’s groups in the latter.",result,3
3093,Future research is needed to identify whether cultural values always take precedence over personal characteristics and motives in determining behavior in the virtual world.,result,3
3094,Waterfall development is still a widely used way of working in software development companies.,background,0
3095,Many problems have been reported related to the model.,background,0
3096,Commonly accepted problems are for example to cope with change and that defects all too often are detected too late in the software development process.,background,0
3097,"However, many of the problems mentioned in literature are based on beliefs and experiences, and not on empirical evidence.",background,0
3098,"To address this research gap, we compare the problems in literature with the results of a case study at Ericsson AB in Sweden, investigating issues in the waterfall model.",method,2
3099,The case study aims at validating or contradicting the beliefs of what the problems are in waterfall development through empirical research.,result,3
3100,"For many organizations, Information Technology (IT) enabled business initiatives and IT infrastructure constitute major investments that, if not managed properly, may impair rather than enhance the organization's competitive position.",background,0
3101,"Especially since the advent of Sarbanes–Oxley (SOX), both management and IT professionals are concerned with design, implementation, and assessment of IT governance strategies to ensure that technology truly serves the needs of the business.",background,0
3102,"Via an in-depth study within one organisation, this research explores the factors influencing IT governance structures, processes, and outcome metrics.",objective,1
3103,Interview responses to open-ended questions indicated that more effective IT governance performance outcomes are associated with a shared understanding of business and IT objectives; active involvement of IT steering committees; a balance of business and IT representatives in IT decisions; and comprehensive and well-communicated IT strategies and policies.,result,3
3104,IT governance also plays a prominent role in fostering project success and delivering business value.,result,3
3105,© 2007 Elsevier Inc.,other,4
3107,Compressed sensing magnetic resonance imaging (CS-MRI) is an active research topic in the field of inverse problems.,background,0
3108,Conventional CS-MRI algorithms usually exploit the sparse nature of MRI in an iterative manner.,background,0
3109,"These optimizationbased CS-MRI methods are often time-consuming at test time, and are based on fixed transform bases or shallow dictionaries, which limits modeling capacity.",objective,1
3110,"Recently, deep models have been introduced to the CS-MRI problem.",result,3
3111,One main challenge for CS-MRI methods based on deep learning is the trade-off between model performance and network size.,method,2
3112,We propose a recursive dilated network (RDN) for CS-MRI that achieves good performance while reducing the number of network parameters.,method,2
3113,We adopt dilated convolutions in each recursive block to aggregate multi-scale information within the MRI.,method,2
3114,We also adopt a modified shortcut strategy to help features flow into deeper layers.,result,3
3115,Experimental results show that the proposed RDN model achieves state-of-the-art performance in CS-MRI while using far fewer parameters than previously required.,result,3
3116,Integrated injection logic or merged transistor logic is a novel bipolar circuit design approach to achieve high-density large-scale integration.,background,0
3117,As the basic logic units it uses multicollector npn transistors which are powered from merged multicollector lateral pnp transistors.,method,2
3118,I2L can be fabricated with standard buried collector technology and is therefore compatible with conventional bipolar circuitry on the same chip.,method,2
3119,The feature of having special interface circuitry—digital and/or linear—on the same chip renders I2L a powerful LSI technique.,method,2
3120,An approach to error-based testing is described that uses simple programmer error models and focus-directed methods for detecting the effects of errors.,background,0
3121,"Errors are associated with forgetting, ignorance, bandwidth and perversity.",background,0
3122,The focus-directed approach was motivated by the observation that focus is more important than methodology in detecting such errors.,objective,1
3123,"The strengths and weaknesses of error-based versus more methodological methods are compared using three underlying assumptions called the faith, coincidence and hindsight effects.",method,2
3124,The weaknesses of error-based testing are compensated for by establishment of an expertise-based foundation that uses research from the study of natural decision making.,method,2
3125,"Examples of the application of error-based methods are given from projects in which the author had access to the programmers, making it possible to track failure back to both defect and error.",method,2
3126,"The relationship of error-based testing to contemporary methods, such as context-driven and exploratory testing, is described.",result,3
3127,Recent discussion in the public sphere about algorithmic cl assification has involved tension between competing notions of what it means for a probabilistic class ification to be fair to different groups.,background,0
3128,"We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satis fy these three conditions simultaneously.",background,0
3129,"Moreover, even satisfying all three conditions approximat ely requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem.",method,2
3130,"These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them.",result,3
3131,"In emotion classification of speech signals, the popular features employed are statistics of fundamental frequency, energy contour, duration of silence and voice quality.",background,0
3132,"However, the performance of systems employing these features degrades substantially when more than two categories of emotion are to be classified.",background,0
3133,"In this paper, a text independent method of emotion classification of speech is proposed.",method,2
3134,The proposed method makes use of short time log frequency power coefficients (LFPC) to represent the speech signals and a discrete hidden Markov model (HMM) as the classifier.,method,2
3135,The emotions are classified into six categories.,method,2
3136,"The category labels used are, the archetypal emotions of Anger, Disgust, Fear, Joy, Sadness and Surprise.",method,2
3137,"Adatabase consisting of 60 emotional utterances, each from twelve speakers is constructed and used to train and test the proposed system.",result,3
3138,Performance of the LFPC feature parameters is compared with that of the linear prediction Cepstral coefficients (LPCC) and mel-frequency Cepstral coefficients (MFCC) feature parameters commonly used in speech recognition systems.,result,3
3139,Results show that the proposed system yields an average accuracy of 78% and the best accuracy of 96% in the classification of six emotions.,result,3
3140,This is beyond the 17% chances by a random hit for a sample set of 6 categories.,result,3
3141,The deep reinforcement learning community has made several independent improvements to the DQN algorithm.,background,0
3142,"However, it is unclear which of these extensions are complementary and can be fruitfully combined.",background,0
3143,This paper examines six extensions to the DQN algorithm and empirically studies their combination.,method,2
3144,"Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance.",result,3
3145,We also provide results from a detailed ablation study that shows the contribution of each component to overall per-,result,3
3146,Understanding and discovering knowledge from GPS (Global Positioning System) traces of human activities is an essential topic in mobility-based urban computing.,objective,1
3147,We propose TrajectoryNet—a neural network architecture for point-based trajectory classication to infer real world human transportation modes from GPS traces.,method,2
3148,"To overcome the challenge of capturing the underlying latent factors in the low-dimensional and heterogeneous feature space imposed by GPS data, we develop a novel representation that embeds the original feature space into another space that can be understood as a form of basis expansion.",method,2
3149,We also enrich the feature space via segment-based information and use Maxout activations to improve the predictive power of Recurrent Neural Networks (RNNs).,method,2
3150,"We achieve over 98% classication accuracy when detecting four types of transportation modes, outperforming existing models without additional sensory data or location-based prior knowledge.",result,3
3151,Video compression currently is dominated by engineering and fine-tuned heuristic methods.,background,0
3152,"In this paper, we propose to instead apply the well-developed machinery of machine learning in order to support the optimization of existing video encoders and the creation of new ones.",objective,1
3153,"Exemplarily, we show how by machine learning we can improve one encoding step that is crucial for the performance of all current video standards: macroblock mode decision.",method,2
3154,"By formulating the problem in a Bayesian setup, we show that macroblock mode decision can be reduced to a classification problem with a cost function for misclassification that is sample dependent.",result,3
3155,We demonstrate how to apply different machine learning techniques to obtain suitable classifiers and we show in detailed experiments that all of these perform better than the state-of-the-art heuristic method,result,3
3156,"The experiments aimed to compare three methods to create ensemble models implemented in a popular data mining system WEKA, were carried out.",objective,1
3157,"Six common algorithms comprising two neural network algorithms, two decision trees for regression, and linear regression and support vector machine were used to generate individual committees.",method,2
3158,All algorithms were employed to actual data sets derived from the cadastral system and the registry of real estate transactions.,result,3
3159,Nonparametric Wilcoxon signed-rank tests to evaluate the differences between ensembles and original models were conducted.,result,3
3160,The results obtained show there is no single algorithm which produces the best ensembles and it is worth to seek an optimal hybrid multi-model solution.,result,3
3161,Data warehouses and data marts have long been considered as the unique solution for providing end-users with decisional information.,background,0
3162,"More recently, data lakes have been proposed in order to govern data swamps.",background,0
3163,"However, no formal definition has been proposed in the literature.",background,0
3164,Existing works are not complete and miss important parts of the topic.,background,0
3165,"In particular, they do not focus on the influence of the data gravity, the infrastructure role of those solutions and of course are proposing divergent definitions and positioning regarding the usage and the interaction with existing decision support system.",background,0
3166,"In this paper, we propose a novel definition of data lakes, together with a comparison with other over several criteria as the way to populate them, how to use, what is the Data Lake end user profile.",objective,1
3167,We claim that data lakes are complementary components in decisional information systems and we discuss their position and interactions regarding the other components by proposing an interaction model.,method,2
3168,The market for mobile devices is growing rapidly nowadays.,background,0
3169,Constant technological improvements provide great opportunities for the creation of mobile applications.,background,0
3170,"For the success of a mobile application or website, one of the main concerns, besides security issues, is usability.",method,2
3171,Poor usability decreases user productivity and consequently causes loss of users.,background,0
3172,"In order to avoid these problems, usability aspects have to be considered already during the design phase of the application, e.g. by following predefined usability guidelines.",method,2
3173,"Although usability guidelines for web development are already in place since the 1990s, structured and evaluated usability guidelines for mobile applications can rarely be found in scientific literature.",method,2
3174,"Thus, in this paper we introduce a catalogue of usability guidelines for mobile applications and websites, and subsequently demonstrate their usage by applying them in two case studies: the development of a mobile application and a mobile website.",result,3
3175,Humans gather information by engaging in conversations involving a series of interconnected questions and answers.,background,0
3176,"For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions.",background,0
3177,"We introduce CoQA, a novel dataset for building Conversational Question Answering systems.1 Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains.",result,3
3178,"The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage.",result,3
3179,"We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets, e.g., coreference and pragmatic reasoning.",result,3
3180,We evaluate strong conversational and reading comprehension models on CoQA.,result,3
3181,"The best system obtains an F1 score of 65.1%, which is 23.7 points behind human performance (88.8%), indicating there is ample room for improvement.",result,3
3182,We launch CoQA as a challenge to the community at https://stanfordnlp.,other,4
3183,github.io/coqa/.,other,4
3184,Recommendation systems that model users and their interests are often used to improve various user services.,background,0
3185,Such systems are usually based on automatic prediction of user ratings of the items provided by the service.,background,0
3186,This paper presents an overview of some of the methods for automatic ratings prediction in the domain of movie ratings.,background,0
3187,The chosen methods are based on various approaches described in related papers.,method,2
3188,During the prediction process both the user and item features can be used.,method,2
3189,"For the purpose of this paper, data was gathered from the publicly available movie database IMDb.",method,2
3190,The paper encompasses the implementation of the chosen methods and their evaluation using the gathered data.,objective,1
3191,The results show an improvement in comparison to the chosen baseline methods.,result,3
3192,The problem of road or lane perception is a crucial enabler for advanced driver assistance systems.,background,0
3193,"As such, it has been an active field of research for the past two decades with considerable progress made in the past few years.",background,0
3194,"The problem was confronted under various scenarios, with different task definitions, leading to usage of diverse sensing modalities and approaches.",background,0
3195,In this paper we survey the approaches and the algorithmic techniques devised for the various modalities over the last 5 years.,objective,1
3196,We present a generic break down of the problem into its functional building blocks and elaborate the wide range of proposed methods within this scheme.,method,2
3197,"For each functional block, we describe the possible implementations suggested and analyze their underlying assumptions.",method,2
3198,"While impressive advancements were demonstrated at limited scenarios, inspection into the needs of next generation systems reveals significant gaps.",result,3
3199,We identify these gaps and suggest research directions that may bridge them.,result,3
3200,We present a review of the state of the art of segmentation and partitioning techniques of boundary meshes.,background,0
3201,"Recently, these have become a part of many mesh and object manipulation algorithms in computer graphics, geometric modeling and computer aided design.",background,0
3202,"We formulate the segmentation problem as an optimization problem and identify two primarily distinct types of mesh segmentation, namely part segmentation and surface-patch segmentation.",method,2
3203,"We classify previous segmentation solutions according to the different segmentation goals, the optimization criteria and features used, and the various algorithmic techniques employed.",method,2
3204,We also present some generic algorithms for the major segmentation techniques.,result,3
3205,Visual notations form an integral part of the language of software engineering (SE).,background,0
3206,"Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation.",background,0
3207,"In evaluating and comparing notations, details of visual syntax are rarely discussed.",background,0
3208,"In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought.",background,0
3209,"Typically, no design rationale, scientific or otherwise, is provided for visual representation choices.",background,0
3210,"While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax.",method,2
3211,This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving.,result,3
3212,"Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties.",method,2
3213,The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate.,objective,1
3214,"They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones.",result,3
3215,We present a method for automatically learning a set of discriminatory facial components for face recognition.,background,0
3216,The algorithm performs an iterative growing of components starting with small initial components located around pre-selected points in the face.,background,0
3217,The direction of growing is determined by the gradient of the cross-validation error of the component classifiers.,background,0
3218,In experiments we analyze how the shape of the components and their discriminatory power changes across different individuals and views.,method,2
3219,"Cyber-physical systems are ubiquitous in power systems, transportation networks, industrial control processes, and critical infrastructures.",background,0
3220,These systems need to operate reliably in the face of unforeseen failures and external malicious attacks.,objective,1
3221,"In this paper: (i) we propose a mathematical framework for cyber-physical systems, attacks, and monitors; (ii) we characterize fundamental monitoring limitations from system-theoretic and graph-theoretic perspectives; and (ii) we design centralized and distributed attack detection and identification monitors.",method,2
3222,"Finally, we validate our findings through compelling examples.",result,3
3223,This paper presents the modeling of wind energy systems using MATLAB Simulink.,background,0
3224,"The model considers the MPPT (Maximum Power Point Tracking) technique to track the maximum power that could be extracted from the wind energy, due the non-linear characteristic of the wind turbine.",objective,1
3225,"The model consists of wind generation model, converter model (DC-DC converter), and MPPT controller.",background,0
3226,"The main contribution of our work is in the model of DC-DC converter (buck converter) which is developed in rather details, which allows the MPPT controller output (duty cycle) adjusts the voltage input of the converter to track the maximum power point of the wind generator.",objective,1
3227,The simulation results show that the developed model complies with the theoretical one.,result,3
3228,Further the MPPT control shows a higher power output compared to the system without MPPT.,result,3
3229,The digital divide refers to the separation between those who have access to digital information and communications technology (ICT) and those who do not.,background,0
3230,"Many believe that universal access to ICT would bring about a global community of interaction, commerce, and learning resulting in higher standards of living and improved social welfare.",background,0
3231,"However, the digital divide threatens this outcome, leading many public policy makers to debate the best way to bridge the divide.",background,0
3232,"Much of the research on the digital divide focuses on first order effects regarding who has access to the technology, but some work addresses the second order effects of inequality in the ability to use the technology among those who do have access.",background,0
3233,"In this paper, we examine both first and second order effects of the digital divide at three levels of analysis  the individual level, the organizational level, and the global level.",objective,1
3234,"At each level, we survey the existing research noting the theoretical perspective taken in the work, the research methodology employed, and the key results that were obtained.",result,3
3235,"We then suggest a series of research questions at each level of analysis to guide researchers seeking to further examine the digital divide and how it impacts citizens, managers, and economies.",method,2
3236,Broad classes of statistical classification algorithms have been developed and applied successfully to a wide range of real world domains.,background,0
3237,"In general, ensuring that the particular classification algorithm matches the properties of the data is crucial in providing results that meet the needs of the particular application domain.",background,0
3238,"One way in which the impact of this algorithm/application match can be alleviated is by using ensembles of classifiers, where a variety of classifiers (either different types of classifiers or different instantiations of the same classifier) are pooled before a final classification decision is made.",method,2
3239,"Intuitively, classifier ensembles allow the different needs of a difficult problem to be handled by classifiers suited to those particular needs.",method,2
3240,"Mathematically, classifier ensembles provide an extra degree of freedom in the classical bias/variance tradeoff, allowing solutions that would be difficult (if not impossible) to reach with only a single classifier.",method,2
3241,"Because of these advantages, classifier ensembles have been applied to many difficult real world problems.",background,0
3242,"In this paper, we survey select applications of ensemble methods to problems that have historically been most representative of the difficulties in classification.",objective,1
3243,"In particular, we survey applications of ensemble methods to remote sensing, person recognition, one vs. all recognition, and medicine.",method,2
3244,We have developed a hip exoskeleton for seniors with difficulties in walking due to muscle weakness.,background,0
3245,The exoskeleton is lightweight and moderate in assistance power compared to other hip exoskeletons in the literature.,background,0
3246,"Its controller estimates user gait phase, walking speed, and ground inclinations to generate assistance torque adaptively.",method,2
3247,"To assess the physiological effect of the gait assistance, we compared metabolic energy consumption for 5 adults for walking on a treadmill with and without the exoskeleton at the same speed: the exoskeleton reduced metabolic cost of walking by 13% (p = 0:0024).",method,2
3248,The step length and the stride time increased under the assistance.,objective,1
3249,Our analysis for the result suggests that the efficiency of hip exoskeletons on saving metabolic energy can be twice as high as that of ankle exoskeletons possibly because muscle-tendon unit in the hip joint is less energy-efficient than in the ankle joint.,result,3
3250,"Given hyper-competition and rapid environmental changes, one of the most critical sources of competitive advantage is attracting and retaining talented workers.",objective,1
3251,E-recruiting is one of the most rapidly growing areas of e-business.,background,0
3252,"To promote an understanding of the use of e-recruiting technologies and management practices utilized by leading business organizations, this study investigates the evolution of e-recruiting systems and analyzes the corporate career Web sites of Fortune 100 companies.",method,2
3253,"Thirty-three attributes that characterize corporate career Web sites were identified, named, and organized around four major categories: recruiting methods, job search tools, job application tools, and information on organizational attributes.",result,3
3254,"While all Fortune 100 companies practice e-recruiting, our content analysis indicates that most of them need to further develop the e-recruiting system in order to improve their recruiting performance.",result,3
3255,A mathematical tool to build a fuzzy model of a system where fuzzy implications and reasoning are used is presented.,objective,1
3256,The premise of an implication is the description of fuzzy subspace of inputs and its consequence is a linear input-output relation.,background,0
3257,The method of identification of a system using its input-output data is then shown.,method,2
3258,Two applications of the method to industrial processes are also discussed: a water cleaning process and a converter in a steel-making process.,method,2
3259,The Internet of Things (IoT) being a promising technology of the future is expected to connect billions of devices.,background,0
3260,The increased number of communication is expected to generate mountains of data and the security of data can be a threat.,background,0
3261,The devices in the architecture are essentially smaller in size and low powered.,background,0
3262,"Conventional encryption algorithms are generally computationally expensive due to their complexity and requires many rounds to encrypt, essentially wasting the constrained energy of the gadgets.",background,0
3263,"Less complex algorithm, however, may compromise the desired integrity.",background,0
3264,In this paper we propose a lightweight encryption algorithm named as Secure IoT (SIT).,background,0
3265,It is a 64-bit block cipher and requires 64-bit key to encrypt the data.,result,3
3266,The architecture of the algorithm is a mixture of feistel and a uniform substitution-permutation network.,background,0
3267,Simulations result shows the algorithm provides substantial security in just five encryption rounds.,background,0
3268,"The hardware implementation of the algorithm is done on a low cost 8-bit micro-controller and the results of code size, memory utilization and encryption/decryption execution cycles are compared with benchmark encryption algorithms.",result,3
3269,The purpose of this article is to offer some reflections on the relationships between digital technologies and learning.,objective,1
3270,"It is argued that activities of learning, as they have been practised within institutionalized schooling, are coming under increasing pressure from the developments of digital technologies and the capacities to store, access and manipulate information that such resources offer.",background,0
3271,"Thus, the technologies do not merely support learning; they transform how we learn and how we come to interpret learning.",objective,1
3272,"The metaphors of learning currently emerging as relevant in the new media ecology emphasize the transformational and performative nature of such activities, and of knowing in general.",result,3
3273,"These developments make the hybrid nature of human knowing and learning obvious; what we know and master is, to an increasing extent, a function of the mediating tools we are familiar with.",result,3
3274,"At a theoretical and practical level, this implies that the interdependences between human agency, minds, bodies and technologies have to serve as foundations when attempting to understand and improve learning.",objective,1
3275,Attempts to account for what people know without integrating their mastery of increasingly sophisticated technologies into the picture will lack ecological validity.,result,3
3276,Progress in Mobile Commerce is heavily dependent upon effective and reliable payment mechanisms.,background,0
3277,"Security concerns loom as a major impediment to widespread and rapid adoption, and there is accordingly an urgent need for a framework within which security issues in mobile commerce can be evaluated.",background,0
3278,This paper draws on lessons from prior payment mechanisms in order to present such a framework.,objective,1
3279,It provides insights into the use of the framework by performing a test application.,method,2
3280,"Implications for policy, practice and research are drawn.",result,3
3281,Developing a good speaker embedding has received tremendous interest in the speech community.,background,0
3282,"Speaker representations such as i-vector, d-vector have shown their superiority in speaker recognition, speaker adaptation and other related tasks.",background,0
3283,"However, not much is known about which properties are exactly encoded in these speaker embeddings.",background,0
3284,"In this work, we make an in-depth investigation on three kinds of speaker embeddings, i.e. i-vector, d-vector and RNN/LSTM based sequence-vector (s-vector).",objective,1
3285,Classification tasks are carefully designed to facilitate better understanding of these encoded speaker representations.,method,2
3286,"Their abilities of encoding different properties are revealed and compared, such as speaker identity, gender, speaking rate, text content and channel information.",objective,1
3287,"Moreover, a new architecture is proposed to integrate different speaker embeddings, so that the advantages can be combined.",method,2
3288,"The new advanced speaker embedding (i-s-vector) outperforms the others, and shows a more than 50% EER reduction compared to the i-vector baseline on the RSR2015 content mismatch trials.",result,3
3289,"In the last couple of years, the interest of Mobile IT has arisen tremendously and future directions point towards an explosive expansive area.",background,0
3290,The objective with this paper is to explore how mobile eCommerce services map customers' requirements in geographical bound retailing.,objective,1
3291,"This is done through WineGuide, a geographically bound recommendation service for wine and food adapted to mobile phones.",method,2
3292,"The service addresses well-known problems within the area of shopping, by: (1) offering expert recommendations; (2) notifying the user where products are available; (3) distributing information in appropriate situations; (4) letting the user search for products.",method,2
3293,The findings of the study indicate that the full potential of mobile eCommerce services can only be established through a complete eCommerce transaction implementation.,result,3
3294,"The mobile phone gets the role of a remote controller, where products are ordered, paid for and home delivered through a few pressings on the",result,3
3295,"In real-world crowd counting applications, the crowd densities vary greatly in spatial and temporal domains.",background,0
3296,"A detection based counting method will estimate crowds accurately in low density scenes, while its reliability in congested areas is downgraded.",background,0
3297,"A regression based approach, on the other hand, captures the general density information in crowded regions.",background,0
3298,"Without knowing the location of each person, it tends to overestimate the count in low density areas.",background,0
3299,"Thus, exclusively using either one of them is not sufficient to handle all kinds of scenes with varying densities.",background,0
3300,"To address this issue, a novel end-to-end crowd counting framework, named DecideNet (DEteCtIon and Density Estimation Network) is proposed.",objective,1
3301,It can adaptively decide the appropriate counting mode for different locations on the image based on its real density conditions.,method,2
3302,DecideNet starts with estimating the crowd density by generating detection and regression based density maps separately.,method,2
3303,"To capture inevitable variation in densities, it incorporates an attention module, meant to adaptively assess the reliability of the two types of estimations.",method,2
3304,The final crowd counts are obtained with the guidance of the attention module to adopt suitable estimations from the two kinds of density maps.,result,3
3305,Users typically rate only a small fraction of all available items.,background,0
3306,"We show that the absence of ratings carries useful information for improving the top-k hit rate concerning all items, a natural accuracy measure for recommendations.",objective,1
3307,"As to test recommender systems, we present two performance measures that can be estimated, under mild assumptions, without bias from data even when ratings are missing not at random (MNAR).",objective,1
3308,"As to achieve optimal test results, we present appropriate surrogate objective functions for efficient training on MNAR data.",method,2
3309,Their main property is to account for all ratings - whether observed or missing in the data.,method,2
3310,"Concerning the top-k hit rate on test data, our experiments indicate dramatic improvements over even sophisticated methods that are optimized on observed ratings only.",result,3
3311,Learning methods based on dynamic programming (DP) are receiving increasing attention in arti cial intelligence.,background,0
3312,"Researchers have argued that DP provides the appropriate basis for compiling planning results into reactive strategies for real-time control, as well as for learning such strategies when the system being controlled is incompletely known.",background,0
3313,"We introduce an algorithm based on DP, which we call Real-Time DP (RTDP), by which an embedded system can improve its performance with experience.",method,2
3314,RTDP generalizes Korf's Learning-Real-Time-A* algorithm to problems involving uncertainty.,background,0
3315,We invoke results from the theory of asynchronous DP to prove that RTDP achieves optimal behavior in several di erent classes of problems.,method,2
3316,We also use the theory of asynchronous DP to illuminate aspects of other DP-based reinforcement learning methods such as Watkins' Q-Learning algorithm.,method,2
3317,A secondary aim of this article is to provide a bridge between AI research on real-time planning and learning and relevant concepts and algorithms from control theory.,objective,1
3318,1,other,4
3319,"In this paper, we propose an architecture and a scheme of smart hospital based on Internet of Things (IOT) in order to overcome the disadvantages of the present hospital information system, such as the fixed information point, inflexible networking mode and so on.",objective,1
3320,The key technologies and construction of smart hospital is presented based on understanding of the connotation and architecture of smart hospital.,background,0
3321,"Furthermore, taking a third grade-A hospital as an example, a scheme of smart hospital is given, and its logic structure, application framework, the construction of basic network environment etc.",method,2
3322,are described in detail.,method,2
3323,Experiment proves that deployment of smart hospital can effectively solve the prominent problems existing the diagnosis and treatment of hospital and it brings a positive and profound effect for the present diagnosis and treatment mode in hospital.,result,3
3324,"Internet of Things (IoT) is now in its initial stage but very soon, it is going to influence almost every day-to-day items we use.",background,0
3325,"The more it will be included in our lifestyle, more will be the threat of it being misused.",background,0
3326,There is an urgent need to make IoT devices secure from getting cracked.,background,0
3327,Very soon IoT is going to expand the area for the cyber-attacks on homes and businesses by transforming objects that were used to be offline into online systems.,background,0
3328,Existing security technologies are just not enough to deal with this problem.,background,0
3329,Blockchain has emerged as the possible solution for creating more secure IoT systems in the time to come.,background,0
3330,"In this paper, first an overview of the blockchain technology and its implementation has been explained; then we have discussed the infrastructure of IoT which is based on Blockchain network and at last a model has been provided for the security of internet of things using blockchain.",result,3
3331,Chief Digital Officers (CDOs) are establishing themselves as new executives at the top management level of companies that go through a digital transformation.,background,0
3332,The full article is based on six case studies of CDOs and describes how they fulfill their positions.,background,0
3333,Five of the cases are from the “CDO Recommended” region of the figure and one from the “CDO Can be Helpful” region.,background,0
3334,"From these cases, we identify the main factors that drive the employment of CDOs, the three role types that CDOs primarily play and the skills and competencies they should have for each role type.",method,2
3335,We also present four key lessons that will ensure businesses equip their CDOs with the skills to successfully navigate through their digital transformation journeys.,result,3
3336,"A reciprocal frame (RF) is a self-supported three-dimensional structure made up of three or more sloping rods, which form a closed circuit, namely an RF-unit.",background,0
3337,Large RF-structures built as complex grillages of one or a few similar RF-units have an intrinsic beauty derived from their inherent self-similar and highly symmetric patterns.,background,0
3338,Designing RF-structures that span over large domains is an intricate and complex task.,objective,1
3339,"In this paper, we present an interactive computational tool for designing RF-structures over a 3D guiding surface, focusing on the aesthetic aspect of the design.",method,2
3340,There are three key contributions in this work.,method,2
3341,"First, we draw an analogy between RF-structures and plane tiling with regular polygons, and develop a computational scheme to generate coherent RF-tessellations from simple grammar rules.",method,2
3342,"Second, we employ a conformal mapping to lift the 2D tessellation over a 3D guiding surface, allowing a real-time preview and efficient exploration of wide ranges of RF design parameters.",method,2
3343,"Third, we devise an optimization method to guarantee the collinearity of contact joints along each rod, while preserving the geometric properties of the RF-structure.",method,2
3344,"Our tool not only supports the design of wide variety of RF pattern classes and their variations, but also allows preview and refinement through interactive controls.",result,3
3345,This paper presents a robust but simple object pose tracking algorithm based on Kalman filtering.,background,0
3346,"Compared to markerless pose tracking, a fiducial marker called ArUco provides a fast and accurate solution to the problem.",background,0
3347,"With these advantages, this marker-based technique is ready to be used in virtual reality and operate in low-cost wearable devices.",background,0
3348,"However, it still suffers from the problem of occlusion and noise.",objective,1
3349,"If a large part of the marker is occluded, no pose information can be acquired for the moment.",result,3
3350,Noises due to hand shaking also affect the quality of the resulting pose.,result,3
3351,This is not desirable in a real-time environment.,result,3
3352,We tackle the problems by employing a linear Kalman filter.,method,2
3353,The pose information can be estimated even if the camera view is blocked temporarily.,result,3
3354,We have performed real experiments to demonstrate the effects of the application of Kalman filter.,method,2
3355,Smartphone usage is a hot topic in pervasive computing due to their popularity and personal aspect.,background,0
3356,"We present our initial results from analyzing how individual differences, such as gender and age, affect smartphone usage.",background,0
3357,"The dataset comes from a large scale longitudinal study, the Menthal project.",background,0
3358,"We select a sample of 30, 677 participants, from which 16, 147 are males and 14, 523 are females, with a median age of 21 years.",method,2
3359,These have been tracked for at least 28 days and they have submitted their demographic data through a questionnaire.,method,2
3360,The ongoing experiment has been started in January 2014 and we have used our own mobile data collection and analysis framework.,method,2
3361,"Females use smartphones for longer periods than males, with a daily mean of 166.78 minutes vs. 154.26 minutes.",result,3
3362,Younger participants use their phones longer and usage is directed towards entertainment and social interactions through specialized apps.,result,3
3363,Older participants use it less and mainly for getting information or using it as a classic phone.,result,3
3364,The fast evolution pace for cloud computing software is on a collision course with our growing reliance on cloud computing.,background,0
3365,"On one hand, cloud software must have the agility to evolve rapidly, in order to remain competitive; on the other hand, more and more critical services become dependent on the cloud and demand high availability through firm Service Level Agreements (SLAs) for cloud infrastructures.",background,0
3366,This race between the needs to increase both the cloud upgrade frequency and the service availability is unsustainable.,background,0
3367,In this paper we highlight challenges and opportunities for upgrades in the cloud.,method,2
3368,"We survey the release histories of several cloud applications to analyze their evolution pace, and we discuss the shortcomings with current cloud upgrade mechanisms.",method,2
3369,"We outline several solutions for sustaining this evolution while improving availability, by focusing on the novel characteristics of cloud computing.",method,2
3370,"By discussing several promising directions for realizing this vision, we propose a research agenda for the future of software upgrades in the cloud.",result,3
3371,The growing interest in Structured Equation Modeling (SEM) techniques and recognition of their importance in IS research suggests the need to compare and contrast different types of SEM techniques so that research designs can be selected appropriately.,background,0
3372,"After assessing the extent to which these techniques are currently being used in IS research, the article presents a running example which analyzes the same dataset via three very different statistical techniques.",result,3
3373,It then compares two classes of SEM: covariance-based SEM and partial-least-squaresbased SEM.,method,2
3374,"Finally, the article discusses linear regression models and offers guidelines as to when SEM techniques and when regression techniques should be used.",objective,1
3375,"The article concludes with heuristics and rule of thumb thresholds to guide practice, and a discussion of the extent to which practice is in accord with these guidelines.",result,3
3376,Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning.,background,0
3377,"In this work, we propose a combined bottom-up and topdown attention mechanism that enables attention to be calculated at the level of objects and other salient image regions.",background,0
3378,This is the natural basis for attention to be considered.,background,0
3379,"Within our approach, the bottom-up mechanism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while the top-down mechanism determines feature weightings.",method,2
3380,"Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, improving the best published result in terms of CIDEr score from 114.7 to 117.9 and BLEU-4 from 35.2 to 36.9.",method,2
3381,"Demonstrating the broad applicability of the method, applying the same approach to VQA we obtain a new state-of-the-art on the VQA v2.0 dataset with 70.2% overall accuracy.",result,3
3382,We present a decision tree based approach to function approximation in reinforcement learning.,objective,1
3383,We compare our approach with table lookup and a neural network function approximator on three problems: the well known mountain car and pole balance problems as well as a simulated automobile race car.,method,2
3384,We find that the decision tree can provide better learning performance than the neural network function approximation and can solve large problems that are infeasible using table lookup.,result,3
3385,Social network information is now being used in ways for which it may have not been originally intended.,background,0
3386,"In particular, increased use of smartphones capable ofrunning applications which access social network information enable applications to be aware of a user's location and preferences.",background,0
3387,"However, current models forexchange of this information require users to compromise their privacy and security.",background,0
3388,"We present several of these privacy and security issues, along withour design and implementation of solutions for these issues.",objective,1
3389,"Our work allows location-based services to query local mobile devices for users' social network information, without disclosing user identity or compromising users' privacy and security.",objective,1
3390,We contend that it is important that such solutions be acceptedas mobile social networks continue to grow exponentially.,result,3
3391,"This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words.",background,0
3392,This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data.,background,0
3393,"The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter.",method,2
3394,"We also describe two neural learning architectures suitable for analyzing this dataset, and provide benchmark performance on the task of selecting the best next response.",result,3
3395,Multiplication is a key fundamental function for many error-tolerant applications.,background,0
3396,Approximate multiplication is considered to be an efficient technique for trading off energy against performance and accuracy.,background,0
3397,This paper proposes an accuracy-controllable multiplier whose final product is generated by a carry-maskable adder.,objective,1
3398,The proposed scheme can dynamically select the length of the carry propagation to satisfy the accuracy requirements flexibly.,background,0
3399,The partial product tree of the multiplier is approximated by the proposed tree compressor.,background,0
3400,An 8×8 multiplier design is implemented by employing the carry-maskable adder and the compressor.,method,2
3401,"Compared with a conventional Wallace tree multiplier, the proposed multiplier reduced power consumption by between 47.3% and 56.2% and critical path delay by between 29.9% and 60.5%, depending on the required accuracy.",result,3
3402,Its silicon area was also 44.6% smaller.,result,3
3403,"In addition, results from an image processing application demonstrate that the quality of the processed images can be controlled by the proposed multiplier design.",result,3
3404,"MOTIVATION In recent years, several methods have been proposed for aligning two protein sequence profiles, with reported improvements in alignment accuracy and homolog discrimination versus sequence-sequence methods (e.g. BLAST) and profile-sequence methods (e.g. PSI-BLAST).",background,0
3405,Profile-profile alignment is also the iterated step in progressive multiple sequence alignment algorithms such as CLUSTALW.,background,0
3406,"However, little is known about the relative performance of different profile-profile scoring functions.",background,0
3407,"In this work, we evaluate the alignment accuracy of 23 different profile-profile scoring functions by comparing alignments of 488 pairs of sequences with identity < or =30% against structural alignments.",objective,1
3408,We optimize parameters for all scoring functions on the same training set and use profiles of alignments from both PSI-BLAST and SAM-T99.,method,2
3409,Structural alignments are constructed from a consensus between the FSSP database and CE structural aligner.,method,2
3410,"We compare the results with sequence-sequence and sequence-profile methods, including BLAST and PSI-BLAST.",method,2
3411,RESULTS We find that profile-profile alignment gives an average improvement over our test set of typically 2-3% over profile-sequence alignment and approximately 40% over sequence-sequence alignment.,result,3
3412,No statistically significant difference is seen in the relative performance of most of the scoring functions tested.,result,3
3413,Significantly better results are obtained with profiles constructed from SAM-T99 alignments than from PSI-BLAST alignments.,result,3
3414,Java reflection enables us to write reusable programs that are independent of certain classes.,background,0
3415,"However, when runtime performance is a big concern, we propose to use compile-time reflection for writing metaprograms that generate non-reflective class/type specific code, which has lower runtime cost.",objective,1
3416,"We proposed both compile-time reflection and metaprogramming for Java, and extended our previous work on pattern-based traits.",background,0
3417,Pattern-based traits integrate pattern-based reflection with flexible composition of traits.,background,0
3418,They are capable of pattern-matching over class members and generating expressive code.,background,0
3419,"We add and formalize pattern-based reflection at the statement-level, which enables a meta program to generate statements.",method,2
3420,"We add reified generics for pattern-based traits, which enables a pattern to iterate over any class when traits are instantiated.",method,2
3421,We implemented an ORM tool (called PtjORM) using pattern-based traits.,method,2
3422,PtjORM uses compile-time reflection and our benchmark tests show that it has competitive runtime performance compared to the mainstream Java ORM tools.,result,3
3423,"Deep learning methods have recently achieved great empirical success on machine translation, dialogue response generation, summarization, and other text generation tasks.",background,0
3424,"At a high level, the technique has been to train end-to-end neural network models consisting of an encoder model to produce a hidden representation of the source text, followed by a decoder model to generate the target.",background,0
3425,"While such models have significantly fewer pieces than earlier systems, significant tuning is still required to achieve good performance.",method,2
3426,"For text generation models in particular, the decoder can behave in undesired ways, such as by generating truncated or repetitive outputs, outputting bland and generic responses, or in some cases producing ungrammatical gibberish.",result,3
3427,"This paper is intended as a practical guide for resolving such undesired behavior in text generation models, with the aim of helping enable real-world applications.",result,3
3428,"Computer applications in the field of psychological test administration have significant ethical implications for clinicians, client/responders, and computerized test construction and administration.",background,0
3429,Lack of awareness of computer-related issues may undermine clinicians’ ability to ethically perform computerized psychological assessments.,background,0
3430,"Graduate training in computerized testing is limited, and clinicians should be exposed to ethical concerns, potential judgment errors, and possible pitfalls in evaluating computer-generated reports.",background,0
3431,Recommendations for clinical research and practice are offered.,method,2
3432,Computerization clearly presents a series of dilemmas for psychologists conducting clinical assessments that will continue well into the future.,method,2
3433,Increased awareness of relevant issues will enhance the chances that ethical dilemmas will be successfully navigated.,method,2
3434,# 2003 Elsevier Ltd.,other,4
3436,Biometric identification is a reliable and convenient way of identifying individuals.,background,0
3437,"The widespread adoption of biometric identification requires solid privacy protection against possible misuse, loss, or theft of biometric data.",background,0
3438,"Existing techniques for privacy-preserving biometric identification primarily rely on conventional cryptographic primitives such as homomorphic encryption and oblivious transfer, which inevitably introduce tremendous cost to the system and are not applicable to practical large-scale applications.",background,0
3439,"In this paper, we propose a novel privacy-preserving biometric identification scheme which achieves efficiency by exploiting the power of cloud computing.",objective,1
3440,"In our proposed scheme, the biometric database is encrypted and outsourced to the cloud servers.",method,2
3441,"To perform a biometric identification, the database owner generates a credential for the candidate biometric trait and submits it to the cloud.",method,2
3442,The cloud servers perform identification over the encrypted database using the credential and return the result to the owner.,method,2
3443,"During the identification, cloud learns nothing about the original private biometric data.",result,3
3444,"Because the identification operations are securely outsourced to the cloud, the realtime computational/communication costs at the owner side are minimal.",method,2
3445,Thorough analysis shows that our proposed scheme is secure and offers a higher level of privacy protection than related solutions such as kNN search in encrypted databases.,result,3
3446,"We present a method for a completely new kind of steganalysis to determine who, out of a large number of actors each transmitting a large number of objects, is hiding payload inside some of them.",background,0
3447,"It has significant challenges, including unknown embedding parameters and natural deviation between innocent cover sources, which are usually avoided in steganalysis tested under laboratory conditions.",background,0
3448,"Our method uses standard steganalysis features, the maximum mean discrepancy measure of distance, and ranks the actors by their degree of deviation from the rest: we show that it works reliably, completely unsupervised, when tested against some of the standard steganography methods available to nonexperts.",method,2
3449,We also determine good parameters for the detector and show that it creates a two-player game between the guilty actor and the steganalyst.,result,3
3450,"False information can be created and spread easily through the web and social media platforms, resulting in widespread real-world impact.",background,0
3451,Characterizing how false information proliferates on social platforms and why it succeeds in deceiving readers are critical to develop efficient detection algorithms and tools for early detection.,background,0
3452,"A recent surge of research in this area has aimed to address the key issues using methods based on feature engineering, graph mining, and information modeling.",background,0
3453,"Majority of the research has primarily focused on two broad categories of false information: opinion-based (e.g., fake reviews), and fact-based (e.g., false news and hoaxes).",background,0
3454,"Therefore, in this work, we present a comprehensive survey spanning diverse aspects of false information, namely (i) the actors involved in spreading false information, (ii) rationale behind successfully deceiving readers, (iii) quantifying the impact of false information, (iv) measuring its characteristics across different dimensions, and finally, (iv) algorithms developed to detect false information.",method,2
3455,"In doing so, we create a unified framework to describe these recent methods and highlight a number of important directions for future research.1",result,3
3456,"The Mouse Genome Database (MGD) is one component of the Mouse Genome Informatics (MGI) system (http://www.informatics.jax.org), a community database resource for the laboratory mouse.",background,0
3457,MGD strives to provide a comprehensive knowledgebase about the mouse with experiments and data annotated from both literature and online sources.,background,0
3458,"MGD curates and presents consensus and experimental data representations of genetic, genotype (sequence) and phenotype information including highly detailed reports about genes and gene products.",background,0
3459,"Primary foci of integration are through representations of relationships between genes, sequences and phenotypes.",method,2
3460,MGD collaborates with other bioinformatics groups to curate a definitive set of information about the laboratory mouse and to build and implement the data and semantic standards that are essential for comparative genome analysis.,result,3
3461,"Recent developments in MGD discussed here include an extensive integration of the mouse sequence data and substantial revisions in the presentation, query and visualization of sequence data.",result,3
3462,Blockchain technology has shown its considerable adaptability in recent years as a variety of market sectors sought ways of incorporating its abilities into their operations.,background,0
3463,"While so far most of the focus has been on the financial services industry, several projects in other service related areas such as healthcare show this is beginning to change.",background,0
3464,Numerous starting points for Blockchain technology in the healthcare industry are the focus of this report.,method,2
3465,"With examples for public healthcare management, user-oriented medical research and drug counterfeiting in the pharmaceutical sector, this report aims to illustrate possible influences, goals and potentials connected to this disruptive technology.",method,2
3466,This paper considers recursive tracking of one mobile emitter using a sequence of time difference of arrival (TDOA) and frequency difference of arrival (FDOA) measurement pairs obtained by one pair of sensors.,background,0
3467,We consider only a single emitter without data association issues (no missed detections or false measurements).,method,2
3468,Each TDOA measurement defines a region of possible emitter locations around a unique hyperbola.,result,3
3469,"This likelihood function is approximated by a Gaussian mixture, which leads to a dynamic bank of Kalman filters tracking algorithm.",method,2
3470,The FDOA measurements update relative probabilities and estimates of individual Kalman filters.,result,3
3471,"This approach results in a better track state probability density function approximation by a Gaussian mixture, and tracking results near the Cramer-Rao lower bound.",result,3
3472,Proposed algorithm is also applicable in other cases of nonlinear information fusion.,objective,1
3473,"The performance of proposed Gaussian mixture approach is evaluated using a simulation study, and compared with a bank of EKF filters and the Cramer-Rao lower bound.",result,3
3474,This work presents the evolution of a solution for predictive maintenance to a Big Data environment.,objective,1
3475,The proposed adaptation aims for predicting failures on wind turbines using a data-driven solution deployed in the cloud and which is composed by three main modules.,objective,1
3476,(i) A predictive model generator which generates predictive models for each monitored wind turbine by means of Random Forest algorithm.,method,2
3477,(ii) A monitoring agent that makes predictions every 10 minutes about failures in wind turbines during the next hour.,method,2
3478,"Finally, (iii) a dashboard where given predictions can be visualized.",method,2
3479,"To implement the solution Apache Spark, Apache Kafka, Apache Mesos and HDFS have been used.",result,3
3480,"Therefore, we have improved the previous work in terms of data process speed, scalability and automation.",result,3
3481,"In addition, we have provided fault-tolerant functionality with a centralized access point from where the status of all the wind turbines of a company localized all over the world can be monitored, reducing O&M costs.",result,3
3482,Understanding individual reactions to computing technology is a central concern of information systems research.,background,0
3483,"This research seeks to understand these reactions from the perspective of Social Cognitive Theory (Bandura 1977, 1978, 1982, 1986), a widely accepted theory of behavior in Social Psychology and Industrial/Organizational Psychology.",objective,1
3484,"The theory holds that behavior, environment, and cognitive and other individual factors are engaged in an ongoing reciprocal interaction.",method,2
3485,"Two cognitive factors in particular are given prominence in the theory: (1) outcome expectations, or beliefs about the consequences of behavior and (2) self-efficacy, beliefs about one's ability to successfully execute particular behaviors.",method,2
3486,A model of individual reactions to computing technology based on this theory was tested on a sample of 940 Canadian knowledge workers.,method,2
3487,Eleven of the fourteen hypotheses were supported by the analysis.,method,2
3488,"Key findings were that self-efficacy, outcome expectations, affect and anxiety all had a direct influence on computer use.",result,3
3489,"In addition, outcome expectations and self-efficacy were found to indirectly influence computer use through affect and anxiety.",result,3
3490,Tile behavior and influence of others in the individuals' reference groups was found to exert a small influence on selfefficacy and outcome expectations.,result,3
3491,This paper consider the nonlinear state estimate problem for tracking maneuvering targets.,background,0
3492,Two methods are introduced to overcome the difficulty of non-linear model.,method,2
3493,"The first method uses Interacting Multiple Model (IMM) which includes 2, 3, 4 and 10 models.",method,2
3494,"These models are linear, each model stands for an operation point of the nonlinear model.",method,2
3495,Two model sets are designed using Equal-Distance Model-Set Design for each.,method,2
3496,"The effect of increasing the number of models, separation between them and noise effect on the accuracy is introduced.",method,2
3497,The second method uses Second order Extended Kalman Filter (EKF2) which is a single nonlinear filter.,method,2
3498,Both methods are evaluated by simulation using two scenarios.,result,3
3499,"A comparison between them is evaluated by computing their accuracy, change of operation range and computational complexity (computational time) at different measurement noise.",result,3
3500,"Based on this study for small range of variation of nonlinear parameter, and low noise the EKF2 introduced quick and accurate tracking.",result,3
3501,"We present a new machine learning framework called ""self-taught learning"" for using unlabeled data in supervised classification tasks.",background,0
3502,We do not assume that the unlabeled data follows the same class labels or generative distribution as the labeled data.,background,0
3503,"Thus, we would like to use a large number of unlabeled images (or audio samples, or text documents) randomly downloaded from the Internet to improve performance on a given image (or audio, or text) classification task.",method,2
3504,"Such unlabeled data is significantly easier to obtain than in typical semi-supervised or transfer learning settings, making self-taught learning widely applicable to many practical learning problems.",background,0
3505,We describe an approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data.,background,0
3506,These features form a succinct input representation and significantly improve classification performance.,background,0
3507,"When using an SVM for classification, we further show how a Fisher kernel can be learned for this representation.",method,2
3508,The first radar has been patented 110 years ago.,background,0
3509,Meanwhile the applications became numerous and the system concepts have been adopted to the available technologies.,background,0
3510,"Typical applications are speed control, air traffic control, synthetic aperture radar, airborne and spaceborne missions, military applications and remote sensing.",method,2
3511,Research for medical radar applications is well progressing for breast cancer detection and tumor localization.,objective,1
3512,Automobile radar for save and autonomous driving are meanwhile produced in millions per year.,background,0
3513,In the next years the state-of-the-art radar system concepts will experience almost a revolution.,objective,1
3514,"Despite the significant advancements, the radar system technology did not develop like communications or other technologies during the last 20 years.",objective,1
3515,Some of these new technologies will within a few years penetrate radar and revolutionize radar system concepts.,background,0
3516,This will then allow for new radar features and radar signal processing approaches.,result,3
3517,Yair Weiss School of CS & Engr.,background,0
3518,The Hebrew Univ.,background,0
3519,yweiss@cs.huji.ac.il Despite many empirical successes of spectral clustering methodsalgorithms that cluster points using eigenvectors of matrices derived from the datathere are several unresolved issues.,background,0
3520,"First , there are a wide variety of algorithms that use the eigenvectors in slightly different ways.",background,0
3521,"Second, many of these algorithms have no proof that they will actually compute a reasonable clustering.",background,0
3522,"In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab.",method,2
3523,"Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well.",method,2
3524,We also show surprisingly good experimental results on a number of challenging clustering problems.,result,3
3525,Urban children all over the world seem to acquire computing skills without adult intervention.,background,0
3526,Indeed this form of self-instruction has produced hackers – children who can penetrate high tech security systems.,background,0
3527,Is this kind of learning dependent only on the availability of technology?,background,0
3528,We provided slum children in New Delhi with Internet access in their settlement.,method,2
3529,The paper describes the results obtained in the first month of unsupervised and unguided access.,result,3
3530,It is observed that children seem to understand and use the technology fluently.,result,3
3531,Language and formal education do not seem to make any significant difference.,result,3
3532,Relationship is one of the most basic needs of human being.,background,0
3533,"When our relationship suffers, we tend to turn to online game as an alternative to fulfill our unmet need.",background,0
3534,"Massive Multi-user Online Role-playing Games (MMORPGs) environment is an ideal platform for multiple players to interact, to make friends, and to complete a task together.",background,0
3535,Social Learning Theory deposits that behaviors are learned by observing others in a social context.,method,2
3536,Gamers learn to be addicts when they constantly associate with online friends who are game addicts.,method,2
3537,This paper focus on how the offline and online social relationship contribute to online game addiction.,method,2
3538,Examining social relationship factors that lead to online game addiction allows practitioners the opportunity to identify ways to help pathological individuals breaking away from the game addiction.,result,3
3539,Researchers could expand our proposed model to further study what specific relationship factors contribute the most to game addiction.,result,3
3540,Pure sine wave inverters are demand of modern era whenever it comes to utilization of DC power sources for both low and high power applications.,background,0
3541,These invertors not only increase the efficiency of the power system but also prevent the electrical components from damaging.,background,0
3542,Research has been carried out on producing cost-effective and efficient pure sine wave inverter in recent times and this paper proposes a design that is highly useful for low power based applications.,background,0
3543,"Paper focuses on utilizing renewable solar energy by incorporating Multi vibrator IC (NE 555), in this case operating in A-stable mode, for the PWM generation technique used to drive pure sine wave inverter.",method,2
3544,It is shown that the design is easy to implement and proves to be cost effective for low power applications.,result,3
3545,"This paper reports on our research towards an economic analysis of money laundering schemes utilizing cryptocurrencies, which are convertible decentralized virtual currencies based on cryptographic operations.",background,0
3546,"They gain ground as means to offer enterprises and its customers new payment methods, investing opportunities and some are even intended as substitutes for centrally controlled governmentissued fiat currencies.",background,0
3547,"Our starting point is the observation that their increasing popularity attracts the attention of practitioners and scholars, particularly because of raising anti-money laundering concerns.",method,2
3548,"Consequently, work has already been conducted in this area, mainly focusing on implications on anti-money laundering efforts.",background,0
3549,"However, we argue that the potential benefits for criminal individuals are an important, yet neglected factor in the dissemination of cryptocurrencies as money laundering instrument.",method,2
3550,"Addressing this issue, the paper firstly presents the structure of the money laundering process and introduces prevailing anti money-laundering controls.",objective,1
3551,This forms the basis for the subsequent analysis of contextual and transactional factors with respect to their influence on the incentives of criminals to utilize cryptocurrencies for money laundering.,result,3
3552,"This aims at providing an answer to the open question, whether cryptocurrencies constitute a driver for money laundering.",result,3
3553,In this paper we describe a database that consists of handwritten English sentences.,background,0
3554,It is based on the Lancaster-Oslo/Bergen (LOB) corpus.,objective,1
3555,This corpus is a collection of texts that comprise about one million word instances.,objective,1
3556,"The database includes 1,066 forms produced by approximately 400 different writers.",background,0
3557,"A total of 82,227 word instances out of a vocabulary of 10,841 words occur in the collection.",background,0
3558,The database consists of full English sentences.,result,3
3559,It can serve as a basis for a variety of handwriting recognition tasks.,result,3
3560,"However, it is expected that the database would be particularly useful for recognition tasks where linguistic knowledge beyond the lexicon level is used, because this knowledge can be automatically derived from the underlying corpus.",result,3
3561,The database also includes a few image-processing procedures for extracting the handwritten text from the forms and the segmentation of the text into lines and words.,result,3
3562,This paper investigates important problems involved in the design of a CML buffer as well as a chain of tapered CML buffers.,background,0
3563,A new design procedure to systematically design a chain of tapered CML buffers is proposed.,method,2
3564,"The differential architecture of a CML buffer makes it functionally robust in the presence of environmental noise sources (e.g., crosstalk, power/ground noise).",background,0
3565,The circuit design issues in regard to the CML buffer are compared with those in a conventional CMOS inverter.,method,2
3566,"It is shown, both through the experiments and by using efficient analytical models, why CML buffers are better than CMOS inverters in high-speed lowvoltage applications.",background,0
3567,"We introduce the author-topic model, a generative model for documents that extends Latent Dirichlet Allocation (LDA; Blei, Ng, & Jordan, 2003) to include authorship information.",objective,1
3568,Each author is associated with a multinomial distribution over topics and each topic is associated with a multinomial distribution over words.,objective,1
3569,A document with multiple authors is modeled as a distribution over topics that is a mixture of the distributions associated with the authors.,method,2
3570,"We apply the model to a collection of 1,700 NIPS conference papers and 160,000 CiteSeer abstracts.",method,2
3571,Exact inference is intractable for these datasets and we use Gibbs sampling to estimate the topic and author distributions.,method,2
3572,"We compare the performance with two other generative models for documents, which are special cases of the author-topic model: LDA (a topic model) and a simple author model in which each author is associated with a distribution over words rather than a distribution over topics.",result,3
3573,"We show topics recovered by the authortopic model, and demonstrate applications to computing similarity between authors and entropy of author output.",result,3
3574,We propose a novel deep network structure called “Network In Network”(NIN) to enhance model discriminability for local patches within the receptive field.,objective,1
3575,The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input.,background,0
3576,"Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field.",method,2
3577,"We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator.",method,2
3578,The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer.,method,2
3579,Deep NIN can be implemented by stacking mutiple of the above described structure.,method,2
3580,"With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers.",method,2
3581,"We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.",result,3
3582,Database management systems are today’s most reliable mean to organize data into collections that can be searched and updated.,background,0
3583,"However, many DBMS systems are available on the market each having their pros and cons in terms of reliability, usability, security, and performance.",background,0
3584,This paper presents a comparative study on the performance of the top DBMS systems.,background,0
3585,"They are mainly MS SQL Server 2008, Oracle 11g, IBM DB2, MySQL 5.5, and MS Access 2010.",background,0
3586,The testing is aimed at executing different SQL queries with different level of complexities over the different five DBMSs under test.,objective,1
3587,"This would pave the way to build a head-to-head comparative evaluation that shows the average execution time, memory usage, and CPU utilization of each DBMS after completion of the test.",objective,1
3588,The multi-scan resting state fMRI (rs-fMRI) dataset was recently released; thus the test-retest (TRT) reliability of rs-fMRI measures can be assessed.,result,3
3589,"However, because this dataset was acquired only from a single group under a single condition, we cannot directly evaluate whether the rs-fMRI measures can generate reproducible between-condition or between-group results.",result,3
3590,"Because the modulation of resting state activity has gained increasing attention, it is important to know whether one rs-fMRI metric can reliably detect the alteration of the resting activity.",method,2
3591,"Here, we shared a public Eyes-Open (EO)/Eyes-Closed (EC) dataset for evaluating the split-half reproducibility of the rs-fMRI measures in detecting changes of the resting state activity between EO and EC.",result,3
3592,"As examples, we assessed the split-half reproducibility of three widely applied rs-fMRI metrics: amplitude of low frequency fluctuation, regional homogeneity, and seed-based correlation analysis.",result,3
3593,"Our results demonstrated that reproducible patterns of EO-EC differences can be detected by all three measures, suggesting the feasibility of the EO/EC dataset for performing reproducibility assessment for other rs-fMRI measures.",result,3
3594,"We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks.",background,0
3595,Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks.,background,0
3596,"We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges.",background,0
3597,"We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges.",method,2
3598,"We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",result,3
3599,We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks.,method,2
3600,This method balances the generator and discriminator during training.,method,2
3601,"Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality.",method,2
3602,We also derive a way of controlling the trade-off between image diversity and visual quality.,method,2
3603,"We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions.",method,2
3604,This is achieved while using a relatively simple model architecture and a standard training procedure.,method,2
3605,Summary form only given.,background,0
3606,"The emerging concept of semantic Web services aims at more sophisticated Web Service technologies: on basis of semantic description frameworks, intelligent mechanisms are envisioned for discovery, composition, and contracting of Web services.",background,0
3607,The tutorial explains the current state of the art in semantic Web services on basis of the Web service modeling ontology WSMO and related initiatives.,method,2
3608,"Commencing from the vision and arising challenges for semantic Web services, the tutorial in detail explains the specifications of recent frameworks for semantic Web services and presents the Web service execution environment WSMX as the WSMO reference implementation.",method,2
3609,The tutorial consists of three main sections that subsequently provide a complete overview of semantic Web services and the latest status of WSMO.,method,2
3610,The tutorial addresses academic as well as industrial researches and developers that are working with Web services and are interested in semantic Web services.,method,2
3611,"Although considerable work has been done in recent years to drive the state of the art in facial recognition towards operation on fully unconstrained imagery, research has always been restricted by a lack of datasets in the public domain.",background,0
3612,"In addition, traditional biometrics experiments such as single image verification and closed set recognition do not adequately evaluate the ways in which unconstrained face recognition systems are used in practice.",background,0
3613,"The IARPA Janus Benchmark–C (IJB-C) face dataset advances the goal of robust unconstrained face recognition, improving upon the previous public domain IJB-B dataset, by increasing dataset size and variability, and by introducing end-to-end protocols that more closely model operational face recognition use cases.",method,2
3614,"IJB-C adds 1,661 new subjects to the 1,870 subjects released in IJB-B, with increased emphasis on occlusion and diversity of subject occupation and geographic origin with the goal of improving representation of the global population.",objective,1
3615,"Annotations on IJB-C imagery have been expanded to allow for further covariate analysis, including a spatial occlusion grid to standardize analysis of occlusion.",result,3
3616,"Due to these enhancements, the IJB-C dataset is significantly more challenging than other datasets in the public domain and will advance the state of the art in unconstrained face recognition.",result,3
3617,We describe several software side-channel attacks based on inter-process leakage through the state of the CPU’s memory cache.,background,0
3618,"This leakage reveals memory access patterns, which can be used for cryptanalysis of cryptographic primitives that employ data-dependent table lookups.",background,0
3619,"The attacks allow an unprivileged process to attack other processes running in parallel on the same processor, despite partitioning methods such as memory protection, sandboxing and virtualization.",background,0
3620,"Some of our methods require only the ability to trigger services that perform encryption or MAC using the unknown key, such as encrypted disk partitions or secure network links.",method,2
3621,"Moreover, we demonstrate an extremely strong type of attack, which requires knowledge of neither the specific plaintexts nor ciphertexts, and works by merely monitoring the effect of the cryptographic process on the cache.",method,2
3622,"We discuss in detail several such attacks on AES, and experimentally demonstrate their applicability to real systems, such as OpenSSL and Linux’s dm-crypt encrypted partitions (in the latter case, the full key can be recovered after just 800 writes to the partition, taking 65 milliseconds).",result,3
3623,"Finally, we describe several countermeasures which can be used to mitigate such attacks.",result,3
3624,Conversational agents are exploding in popularity.,background,0
3625,"However, much work remains in the area of non goal-oriented conversations, despite significant growth in research interest over recent years.",background,0
3626,"To advance the state of the art in conversational AI, Amazon launched the Alexa Prize, a 2.5-million dollar university competition where sixteen selected university teams built conversational agents to deliver the best social conversational experience.",background,0
3627,Alexa Prize provided the academic community with the unique opportunity to perform research with a live system used by millions of users.,background,0
3628,The subjectivity associated with evaluating conversations is key element underlying the challenge of building non-goal oriented dialogue systems.,objective,1
3629,"In this paper, we propose a comprehensive evaluation strategy with multiple metrics designed to reduce subjectivity by selecting metrics which correlate well with human judgement.",result,3
3630,"The proposed metrics provide granular analysis of the conversational agents, which is not captured in human ratings.",result,3
3631,We show that these metrics can be used as a reasonable proxy for human judgment.,result,3
3632,"We provide a mechanism to unify the metrics for selecting the top performing agents, which has also been applied throughout the Alexa Prize competition.",objective,1
3633,"To our knowledge, to date it is the largest setting for evaluating agents with millions of conversations and hundreds of thousands of ratings from users.",method,2
3634,In this work we present an end-to-end system for text spotting—localising and recognising text in natural scene images—and text based image retrieval.,background,0
3635,This system is based on a region proposal mechanism for detection and deep convolutional neural networks for recognition.,background,0
3636,"Our pipeline uses a novel combination of complementary proposal generation techniques to ensure high recall, and a fast subsequent filtering stage for improving precision.",method,2
3637,"For the recognition and ranking of proposals, we train very large convolutional neural networks to perform word recognition on the whole proposal region at the same time, departing from the character classifier based systems of the past.",method,2
3638,"These networks are trained solely on data produced by a synthetic text generation engine, requiring no human labelled data.",method,2
3639,"Analysing the stages of our pipeline, we show state-of-the-art performance throughout.",result,3
3640,"We perform rigorous experiments across a number of standard end-to-end text spotting benchmarks and text-based image retrieval datasets, showing a large improvement over all previous methods.",result,3
3641,"Finally, we demonstrate a real-world application of our text spotting system to allow thousands of hours of news footage to be instantly searchable via a text query.",result,3
3643,It is not only to fulfil the duties that you need to finish in deadline time.,background,0
3646,Reading computational geometry algorithms and applications is also a way as one of the collective books that gives many advantages.,result,3
3648,Facial makeup transfer aims to translate the makeup style from a given reference makeup face image to another non-makeup one while preserving face identity.,objective,1
3649,"Such an instance-level transfer problem is more challenging than conventional domain-level transfer tasks, especially when paired data is unavailable.",background,0
3650,"Makeup style is also different from global styles (e.g., paintings) in that it consists of several local styles/cosmetics, including eye shadow, lipstick, foundation, and so on.",background,0
3651,Extracting and transferring such local and delicate makeup information is infeasible for existing style transfer methods.,method,2
3652,"We address the issue by incorporating both global domain-level loss and local instance-level loss in an dual input/output Generative Adversarial Network, called BeautyGAN.",method,2
3653,"Specifically, the domain-level transfer is ensured by discriminators that distinguish generated images from domains' real samples.",method,2
3654,The instance-level loss is calculated by pixel-level histogram loss on separate local facial regions.,method,2
3655,We further introduce perceptual loss and cycle consistency loss to generate high quality faces and preserve identity.,method,2
3656,The overall objective function enables the network to learn translation on instance-level through unsupervised adversarial learning.,method,2
3657,We also build up a new makeup dataset that consists of 3834 high-resolution face images.,result,3
3658,"We propose ClausIE, a novel, clause-based approach to open information extraction, which extracts relations and their arguments from natural language text.",background,0
3659,ClausIE fundamentally differs from previous approaches in that it separates the detection of ``useful'' pieces of information expressed in a sentence from their representation in terms of extractions.,objective,1
3660,"In more detail, ClausIE exploits linguistic knowledge about the grammar of the English language to first detect clauses in an input sentence and to subsequently identify the type of each clause according to the grammatical function of its constituents.",method,2
3661,"Based on this information, ClausIE is able to generate high-precision extractions; the representation of these extractions can be flexibly customized to the underlying application.",method,2
3662,"ClausIE is based on dependency parsing and a small set of domain-independent lexica, operates sentence by sentence without any post-processing, and requires no training data (whether labeled or unlabeled).",method,2
3663,"Our experimental study on various real-world datasets suggests that ClausIE obtains higher recall and higher precision than existing approaches, both on high-quality text as well as on noisy text as found in the web.",result,3
3664,"This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform.",background,0
3665,"Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop.",background,0
3666,"However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties.",objective,1
3667,"These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming.",method,2
3668,"With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite.",method,2
3669,"DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world.",method,2
3670,"DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations.",method,2
3671,We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.,result,3
3672,"Neural networks are known to be vulnerable to adversarial examples, inputs that have been intentionally perturbed to remain visually similar to the source input, but cause a misclassification.",background,0
3673,"Until now, black-box attacks against neural networks have relied on transferability of adversarial examples.",background,0
3674,White-box attacks are used to generate adversarial examples on a substitute model and then transferred to the black-box target model.,background,0
3675,"In this paper, we introduce a direct attack against black-box neural networks, that uses another attacker neural network to learn to craft adversarial examples.",method,2
3676,"We show that our attack is capable of crafting adversarial examples that are indistinguishable from the source input and are misclassified with overwhelming probability reducing accuracy of the black-box neural network from 99.4% to 0.77% on the MNIST dataset, and from 91.4% to 6.8% on the CIFAR-10 dataset.",method,2
3677,"Our attack can adapt and reduce the effectiveness of proposed defenses against adversarial examples, requires very little training data, and produces adversarial examples that can transfer to different machine learning models such as Random Forest, SVM, and K-Nearest Neighbor.",method,2
3678,"To demonstrate the practicality of our attack, we launch a live attack against a target black-box model hosted online by Amazon: the crafted adversarial examples reduce its accuracy from 91.8% to 61.3%.",method,2
3679,"Additionally, we show attacks proposed in the literature have unique, identifiable distributions.",result,3
3680,We use this information to train a classifier that is robust against such attacks.,result,3
3681,"The objective of this study is to examine all aspects of fraud triangle using the data mining techniques and employ the available and public information to proxy variables to evaluate such attributes as pressure/incentive, opportunity, and attitude/rationalization, based on the findings from prior studies in this subject field and also the Statement on Auditing Standards.",objective,1
3682,The second objective is to discuss whether or not the suggestion of the experts agrees with the results obtained from adopting those novel techniques.,objective,1
3683,"In specific, this study uses both expert questionnaires and data mining techniques to sort out the different fraud factors and then rank the importance of them.",method,2
3684,"The data mining methods employed in this research include Logistic Regression, Decision Trees (CART), and Artificial Neural Networks (ANNs).",method,2
3685,"Empirically, the ANNs and CART approaches work with the training and testing samples in a correct classification rate of 91.2% (ANNs) & 90.4% (CART) and 92.8% (ANNs) & 90.3% (CART), respectively, which is more accurate than the logistic model that only reaches 83.7% and 88.5% of the correct classification in assessing the fraud presence.",method,2
3686,"In addition, type II error of ANNs drops significantly to 23.9% from 43.3% and 27.8% compared to the ones using CART and logistic models.",method,2
3687,"Finally, the differences between different data mining tools and expert judgments are also compared to provide more insights as a research contribution.",result,3
3688,2015 Elsevier B.V. All rights reserved.,other,4
3689,This paper presents a general trainable framework for object detection in static images of cluttered scenes.,background,0
3690,The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances.,method,2
3691,"By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as an input to a suppori vector machine classifier.",objective,1
3692,This representation overcomes both the problem of in-class variability and provides a low false detection rate in unconstrained environments.,method,2
3693,We demonstrate the capabilities of the technique i n two domains whose inherent information content differs significantly.,result,3
3694,"The first system is face detection and the second is the domain of people which, in contrast to faces, vary greatly in color, texture, and patterns.",result,3
3695,"Unlike previous approaches, this system learns from examples and does not rely on any a priori (handcrafted) models or motion-based segmentation.",result,3
3696,The paper also presents a motion-based extension to enhance the performance of the detection algorithm over video sequences.,result,3
3697,The results presented here suggest that this architecture may well be quite general.,result,3
3698,"This paper addresses two significant proximity effects, well proximity and STI stress, as they relate to analog circuit design.",objective,1
3699,"Device performance is impacted by layout features located near, but not part of the device.",objective,1
3700,This adds new complexities to analog design.,method,2
3701,"In either case, bias points can shift by 20-30%, causing potentially catastrophic failures in circuits.",result,3
3702,"We show, for the first time, that a MOSFET placed close to a well-edge creates a graded channel",result,3
3703,"Named Entity Recognition (NER) is a key component in NLP systems for question answering, information retrieval, relation extraction, etc.",background,0
3704,"NER systems have been studied and developed widely for decades, but accurate systems using deep neural networks (NN) have only been introduced in the last few years.",background,0
3705,"We present a comprehensive survey of deep neural network architectures for NER, and contrast them with previous approaches to NER based on feature engineering and other supervised or semi-supervised learning algorithms.",background,0
3706,"Our results highlight the improvements achieved by neural networks, and show how incorporating some of the lessons learned from past work on feature-based NER systems can yield further improvements.",result,3
3707,"After establishing of various possibilities of abstraction in HDLs (on values, time, and structure) many years ago, SystemVerilog as a combined HDVL offers a new approach to support also abstraction on ports.",background,0
3708,"This interface concept extends the feasibilities for encapsulation when designing, connecting, and verifying the numerous interfaces in modern SoC designs.",background,0
3709,"This can be done on an abstract, non-synthesizable level but also on RT level.",background,0
3710,The introduction of interfaces into SystemVerilog allows a more effective methodology for the implementation and verification of designs.,method,2
3711,"First, an interface can be designed independently on the subblocks, which should be connected later.",method,2
3712,It contains not only the protocols for the transfers but also assertions derived from the specification to check all these transfers.,method,2
3713,"Then, BFMs can be implemented using the interfaces and can be verified against the interface assertions.",method,2
3714,"After implementation of the RTL code, this RTL code can be verified by using the BFMs and the assertions.",method,2
3715,"Later, sub-designs are connected hierarchically whereby the assertion and the BFMs are used as the lowest level of the testbench hierarchy.",method,2
3716,"SystemVerilog has a lot of benefits against traditional HDLs as VHDL or Verilog and also against HVLs, as it combines many well-known concepts in a pragmatic way.",result,3
3717,"In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks.",method,2
3718,Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps.,objective,1
3719,"In SAGAN, details can be generated using cues from all feature locations.",method,2
3720,"Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other.",method,2
3721,"Furthermore, recent work has shown that generator conditioning affects GAN performance.",result,3
3722,"Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics.",result,3
3723,"The proposed SAGAN achieves the state-ofthe-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Fréchet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset.",result,3
3724,Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.,result,3
3725,"In the recent years, different web knowledge graphs, both free and commercial, have been created, with DBpedia, YAGO, and Freebase being among the most prominent ones.",background,0
3726,"Those graphs are often constructed from semi-structured knowledge, such as Wikipedia, or harvested from the web with a combination of statistical and NLP methods.",method,2
3727,The result are large-scale knowledge graphs that try to make a good trade-off between completeness and correctness.,result,3
3728,"In order to further increase the utility of knowledge graphs, various refinement methods have been proposed, which try to infer and add missing knowledge to the graph, or identify erroneous pieces of information.",method,2
3729,"In this article, we provide a survey of such knowledge graph refinement approaches, with a dual look at both the methods being proposed as well as the evaluation methodologies used.",method,2
3730,We propose an approach for traffic sign detection based on Convolutional Neural Networks (CNN).,objective,1
3731,"We first transform the original image into the gray scale image by using support vector machines, then use convolutional neural networks with fixed and learnable layers for detection and recognition.",method,2
3732,"The fixed layer can reduce the amount of interest areas to detect, and crop the boundaries very close to the borders of traffic signs.",method,2
3733,The learnable layers can increase the accuracy of detection significantly.,background,0
3734,"Besides, we use bootstrap methods to improve the accuracy and avoid overfitting problem.",method,2
3735,"In the German Traffic Sign Detection Benchmark, we obtained competitive results, with an area under the precision-recall curve(AUC) of 99.73% in the category “Danger”, and an AUC of 97.62% in the category “Mandatory”.",result,3
3736,We present a state-of-the-art speech recognition system developed using end-toend deep learning.,background,0
3737,"Our architecture is significantly simpler than traditional speech systems, which rely on laboriously engineered processing pipelines; these traditional systems also tend to perform poorly when used in noisy environments.",objective,1
3738,"In contrast, our system does not need hand-designed components to model background noise, reverberation, or speaker variation, but instead directly learns a function that is robust to such effects.",method,2
3739,"We do not need a phoneme dictionary, nor even the concept of a “phoneme.",method,2
3740,”,other,4
3741,"Key to our approach is a well-optimized RNN training system that uses multiple GPUs, as well as a set of novel data synthesis techniques that allow us to efficiently obtain a large amount of varied data for training.",method,2
3742,"Our system, called Deep Speech, outperforms previously published results on the widely studied Switchboard Hub5’00, achieving 16.0% error on the full test set.",result,3
3743,"Deep Speech also handles challenging noisy environments better than widely used, state-of-the-art commercial speech systems.",result,3
3744,"With the rapid growth of the Web, users easily get lost in the rich hyper structure.",background,0
3745,Providing the relevant information to users to cater to their needs is the primary goal of Website owners.,background,0
3746,"Therefore, finding the content of the Web and retrieving the users' interests and needs from their behavior have become increasingly important.",background,0
3747,"Web mining is used to categorize users and pages by analyzing user behavior, the content of the pages, and the order of the URLs that tend to be accessed.",background,0
3748,Web structure mining plays an important role in this approach.,background,0
3749,"Two page ranking algorithms, HITS and PageRank, are commonly used in Web structure mining.",method,2
3750,Both algorithms treat all links equally when distributing rank scores.,method,2
3751,Several algorithms have been developed to improve the performance of these methods.,method,2
3752,"The weighted PageRank algorithm (WPR), an extension to the standard PageRank algorithm, is introduced.",method,2
3753,WPR takes into account the importance of both the inlinks and the outlinks of the pages and distributes rank scores based on the popularity of the pages.,method,2
3754,Scene parsing is challenging for unrestricted open vocabulary and diverse scenes.,background,0
3755,"In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet).",background,0
3756,"Our global prior representation is effective to produce good quality results on the scene parsing task, while PSPNet provides a superior framework for pixel-level prediction.",background,0
3757,The proposed approach achieves state-of-the-art performance on various datasets.,objective,1
3758,"It came first in ImageNet scene parsing challenge 2016, PASCAL VOC 2012 benchmark and Cityscapes benchmark.",result,3
3759,A single PSPNet yields the new record of mIoU accuracy 85.4% on PASCAL VOC 2012 and accuracy 80.2% on Cityscapes.,result,3
3760,A recommender system aims to provide users with personalized online product or service recommendations to handle the increasing online information overload problem and improve customer relationship management.,objective,1
3761,"Various recommender system techniques have been proposed since the mid-1990s, and many sorts of recommender system software have been developed recently for a variety of applications.",background,0
3762,"Researchers and managers recognize that recommender systems offer great opportunities and challenges for business, government, education, and other domains, with more recent successful developments of recommender systems for real-world applications becoming apparent.",background,0
3763,"It is thus vital that a high quality, instructive review of current trends should be conducted, not only of the theoretical research results but more importantly of the practical developments in recommender systems.",method,2
3764,"This paper therefore reviews up-to-date application developments of recommender systems, clusters their applications into eight main categories: e-government, e-business, e-commerce/e-shopping, e-library, e-learning, e-tourism, e-resource services and e-group activities, and summarizes the related recommendation techniques used in each category.",method,2
3765,"It systematically examines the reported recommender systems through four dimensions: recommendation methods (such as CF), recommender systems software (such as BizSeeker), real-world application domains (such as e-business) and application platforms (such as mobile-based platforms).",method,2
3766,Some significant new topics are identified and listed as new directions.,method,2
3767,"By providing a state-of-the-art knowledge, this survey will directly support researchers and practical professionals in their understanding of developments in recommender system applications.",result,3
3768,Time series clustering has been shown effective in providing useful information in various domains.,background,0
3769,There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research.,background,0
3770,"To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains.",method,2
3771,"The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters.",method,2
3772,"The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data.",method,2
3773,The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified.,method,2
3774,"Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used.",method,2
3775,It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research.,result,3
3776,2005 Pattern Recognition Society.,other,4
3777,Published by Elsevier Ltd.,other,4
3778,"In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter’s field-of-view as well as control the resolution of feature responses computed by Deep Convolutional Neural Networks, in the application of semantic image segmentation.",background,0
3779,"To handle the problem of segmenting objects at multiple scales, we design modules which employ atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple atrous rates.",objective,1
3780,"Furthermore, we propose to augment our previously proposed Atrous Spatial Pyramid Pooling module, which probes convolutional features at multiple scales, with image-level features encoding global context and further boost performance.",method,2
3781,We also elaborate on implementation details and share our experience on training our system.,method,2
3782,The proposed ‘DeepLabv3’ system significantly improves over our previous DeepLab versions without DenseCRF post-processing and attains comparable performance with other state-of-art models on the PASCAL VOC 2012 semantic image segmentation benchmark.,result,3
3783,"After a decade of fundamental interdisciplinary research in machine learning, the spadework in this field has been done; the 1990s should see the widespread exploitation of knowledge discovery as an aid to assembling knowledge bases.",result,3
3784,The contributors to the AAAI Press book Knowledge Discovery in Databases were excited at the potential benefits of this research.,result,3
3785,"The editors hope that some of this excitement will communicate itself to ""AI Magazine readers of this article.",result,3
3786,Autoregressive integrated moving average (ARIMA) is one of the popular linear models in time series forecasting during the past three decades.,background,0
3787,Recent research activities in forecasting with arti/cial neural networks (ANNs) suggest that ANNs can be a promising alternative to the traditional linear methods.,background,0
3788,ARIMA models and ANNs are often compared with mixed conclusions in terms of the superiority in forecasting performance.,background,0
3789,"In this paper, a hybrid methodology that combines both ARIMA and ANN models is proposed to take advantage of the unique strength of ARIMA and ANN models in linear and nonlinear modeling.",objective,1
3790,Experimental results with real data sets indicate that the combined model can be an e5ective way to improve forecasting accuracy achieved by either of the models used separately.,result,3
3791,c © 2002 Elsevier Science B.V.,other,4
3793,"In this paper, high-voltage (HV)-tolerant level shifters with combinational functionality are proposed based on differential cascode voltage switch logic (DCVSL).",objective,1
3794,These level shifters are tolerant to supply voltages higher than the process limit for individual CMOS transistors.,background,0
3795,"The proposed HV DCVSL level shifters are particularly useful when it is mandatory to constrain the output using a logic function during out of the normal mode periods (power-up, power-down, reset, etc.).",method,2
3796,"These HV-tolerant logic circuits were used in the power block of a buck converter designed in a standard 3.3-V 0.13-mum CMOS process, powered by an input voltage range from 2.7 to 4.2 V. Simulation and experimental results of the buck are analyzed, and the topology is evaluated.",result,3
3797,"Link prediction is an important task for analying social networks which also has applications in other domains like, information retrieval, bioinformatics and e-commerce.",objective,1
3798,"There exist a variety of techniques for link prediction, ranging from feature-based classi cation and kernel-based method to matrix factorization and probabilistic graphical models.",method,2
3799,"These methods differ from each other with respect to model complexity, prediction performance, scalability, and generalization ability.",method,2
3800,"In this article, we survey some representative link prediction methods by categorizing them by the type of the models.",method,2
3801,"We largely consider three types of models: rst, the traditional (non-Bayesian) models which extract a set of features to train a binary classi cation model.",method,2
3802,"Second, the probabilistic approaches which model the joint-probability among the entities in a network by Bayesian graphical models.",method,2
3803,"And, nally the linear algebraic approach which computes the similarity between the nodes in a network by rank-reduced similarity matrices.",result,3
3804,We discuss various existing link prediction models that fall in these broad categories and analyze their strength and weakness.,method,2
3805,We conclude the survey with a discussion on recent developments and future research direction.,result,3
3806,The Self-Organizing Map (SOM) algorithm has attracted an ever increasing amount of interest among researches and practitioners in a wide variety of elds.,background,0
3807,"The SOM and a variant of it, the LVQ, have been analyzed extensively, a number of variants of them have been developed and, perhaps most notably, they have been applied extensively within elds ranging from engineering sciences to medicine, biology, and economics.",background,0
3808,"We have collected a comprehensive list of 3343 scienti c papers that use the algorithms, have bene ted from them, or contain analyses of them.",method,2
3809,The list is intended to serve as a source for literature surveys.,method,2
3810,We have provided both a thematic and a keyword index to help nding articles of interest.,result,3
3811,MapReduce environments offer great scalability by restricting the programming model to only map and reduce operators.,background,0
3812,"This abstraction simplifies many difficult problems occuring in generic dis-ion simplifies many difficult problems occuring in generic distributed computations like fault tolerance and synchronization, hiding them from the programmer.",background,0
3813,"There are, however, algorithms that cannot be easily or efficiently expressed in MapReduce, such as recursive functions.",background,0
3814,In this paper we extend the Apache Spark runtime so that it can support recursive queries.,method,2
3815,"We also introduce a new parallel and more lightweight scheduling mechanism, ideal for scheduling a very large set of tiny tasks.",method,2
3816,We implemented the aformentioned scheduler and found that it simplifies the code for recursive computation and can perform up to 2.1× faster than the default Spark scheduler.,method,2
3817,"Presently, educational institutions compile and store huge volumes of data, such as student enrolment and attendance records, as well as their examination results.",background,0
3818,Mining such data yields stimulating information that serves its handlers well.,background,0
3819,Rapid growth in educational data points to the fact that distilling massive amounts of data requires a more sophisticated set of algorithms.,background,0
3820,This issue led to the emergence of the field of educational data mining (EDM).,background,0
3821,"Traditional data mining algorithms cannot be directly applied to educational problems, as they may have a specific objective and function.",method,2
3822,This implies that a preprocessing algorithm has to be enforced first and only then some specific data mining methods can be applied to the problems.,method,2
3823,One such preprocessing algorithm in EDM is clustering.,result,3
3824,Many studies on EDM have focused on the application of various data mining algorithms to educational attributes.,method,2
3825,"Therefore, this paper provides over three decades long (1983–2016) systematic literature review on clustering algorithm and its applicability and usability in the context of EDM.",result,3
3826,"Future insights are outlined based on the literature reviewed, and avenues for further research are identified.",result,3
3827,A long landing is one type of flight incident that will multiply the risk of a runway excursion.,background,0
3828,It occurs frequently but receives little attention in research due to difficulty in obtaining the real flight data.,background,0
3829,The aim of this paper is to discover key flight parameter features of long landing incidents by analyzing Quick Access Recorder (QAR) data and put forward prevention measures from the perspective of pilot operation at the same time.,objective,1
3830,"First, 73 flight performance parameter variables and 4 operation parameter variables were defined, covering major landing stages from 1500 ft to touchdown.",method,2
3831,Then 128 cases of selected QAR data were divided into two groups according to the threshold of identifying normal and long landing.,result,3
3832,"Second, each flight parameter variable of these 128 flights was compared between groups and then the logistic and linear regression models were developed respectively to further examine the links between touchdown distance and these flight parameter variables.",method,2
3833,"Third, potential flight operation causing performance difference of long landing incidents was also analyzed.",method,2
3834,Finally results indicate that the period of 200 ft to touchdown is the key stage of landing and flare is the most critical operation affecting touchdown distance.,method,2
3835,It is suggested that the pilot should inspect the ratio of descent rate and groundspeed carefully at the height of 50 ft and pilot's faster and steady pulling up columns is probably helpful for an excellent flare and landing.,result,3
3836,The findings are expected to be applied into flight operation practice for further preventing long landing incidents and even the runway excursion accidents.,result,3
3837,Prior work on criminal incident prediction has relied primarily on the historical crime record and various geospatial and demographic information sources.,background,0
3838,"Although promising, these models do not take into account the rich and rapidly expanding social media context that surrounds incidents of interest.",background,0
3839,This paper presents a preliminary investigation of Twitter-based criminal incident prediction.,result,3
3840,"Our approach is based on the automatic semantic analysis and understanding of natural language Twitter posts, combined with dimensionality reduction via latent Dirichlet allocation and prediction via linear modeling.",result,3
3841,We tested our model on the task of predicting future hit-and-run crimes.,method,2
3842,Evaluation results indicate that the model comfortably outperforms a baseline model that predicts hit-and-run incidents uniformly across all days.,result,3
3843,“Industry 4.0” is recognized as the future of industrial production in which concepts as Smart Factory and Decentralized Decision,background,0
3844,Making are fundamental.,objective,1
3845,"This paper proposes a novel strategy to support decentralized decision, whilst identifying opportunities and challenges of Industry 4.0 contextualizing the potential that represents industrial digitalization and how technological advances can contribute for a new perspective on manufacturing production.",objective,1
3846,"It is analysed a set of barriers to the full implementation of Industry 4.0 vision, identifying areas in which decision support is vital.",method,2
3847,"Then, for each of the identified areas, the authors propose a strategy, characterizing it together with the level of complexity that is involved in the different processes.",method,2
3848,The strategies proposed are derived from the needs of two of Industry 4.0 main characteristics: horizontal integration and vertical integration.,method,2
3849,"For each case, decision approaches are proposed concerning the type of decision required (strategic, tactical, operational and real-time).",method,2
3850,Validation results are provided together with a discussion on the main challenges that might be an obstacle for a successful decision strategy.,result,3
3851,"Lifelong Machine Learning, or LML, considers systems that can learn many tasks from one or more domains over its lifetime.",background,0
3852,The goal is to sequentially retain learned knowledge and to selectively transfer that knowledge when learning a new task so as to develop more accurate hypotheses or policies.,objective,1
3853,"Following a review of prior work on LML, we propose that it is now appropriate for the AI community to move beyond learning algorithms to more seriously consider the nature of systems that are capable of learning over a lifetime.",objective,1
3854,Reasons for our position are presented and potential counter-arguments are discussed.,objective,1
3855,"The remainder of the paper contributes by defining LML, presenting a reference framework that considers all forms of machine learning, and listing several key challenges for and benefits from LML research.",other,4
3856,We conclude with ideas for next steps to advance the field.,result,3
3857,Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance.,background,0
3858,"ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research.",background,0
3859,"Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice.",background,0
3860,The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.,objective,1
3861,2005 Elsevier B.V. All rights reserved.,other,4
3862,Aspect-level sentiment classification is a finegrained task in sentiment analysis.,background,0
3863,"Since it provides more complete and in-depth results, aspect-level sentiment analysis has received much attention these years.",background,0
3864,"In this paper, we reveal that the sentiment polarity of a sentence is not only determined by the content but is also highly related to the concerned aspect.",objective,1
3865,"For instance, “The appetizers are ok, but the service is slow.”, for aspect taste, the polarity is positive while for service, the polarity is negative.",background,0
3866,"Therefore, it is worthwhile to explore the connection between an aspect and the content of a sentence.",method,2
3867,"To this end, we propose an Attention-based Long Short-Term Memory Network for aspect-level sentiment classification.",method,2
3868,The attention mechanism can concentrate on different parts of a sentence when different aspects are taken as input.,background,0
3869,We experiment on the SemEval 2014 dataset and results show that our model achieves state-ofthe-art performance on aspect-level sentiment classification.,result,3
3870,Much of previous attention on decision trees focuses on the splitting criteria and optimization of tree sizes.,background,0
3871,The dilemma between overfitting and achieving maximum accuracy is seldom resolved.,background,0
3872,A method to construct a decision tree based classifier is proposed that maintains highest accuracy on training data and improves on generalization accuracy as it grows in complexity.,objective,1
3873,"The classifier consists of multiple trees constructed systematically by pseudorandomly selecting subsets of components of the feature vector, that is, trees constructed in randomly chosen subspaces.",method,2
3874,"The subspace method is compared to single-tree classifiers and other forest construction methods by experiments on publicly available datasets, where the method’s superiority is demonstrated.",method,2
3875,We also discuss independence between trees in a forest and relate that to the combined classification accuracy.,result,3
3876,"Flexpad is an interactive system that combines a depth camera and a projector to transform sheets of plain paper or foam into flexible, highly deformable, and spatially aware handheld displays.",background,0
3877,We present a novel approach for tracking deformed surfaces from depth images in real time.,objective,1
3878,"It captures deformations in high detail, is very robust to occlusions created by the user's hands and fingers, and does not require any kind of markers or visible texture.",objective,1
3879,"As a result, the display is considerably more deformable than in previous work on flexible handheld displays, enabling novel applications that leverage the high expressiveness of detailed deformation.",objective,1
3880,"We illustrate these unique capabilities through three application examples: curved cross-cuts in volumetric images, deforming virtual paper characters, and slicing through time in videos.",method,2
3881,Results from two user studies show that our system is capable of detecting complex deformations and that users are able to perform them quickly and precisely.,result,3
3882,"Research in machine learning, statistics and related fields has produced a wide variety of algorithms for classification.",background,0
3883,"However, most of these algorithms assume that all errors have the same cost, which is seldom the case in KDD problems.",background,0
3884,"Individually making each classification learner costsensitive is laborious, and often non-trivial.",background,0
3885,In this paper we propose a principled method for making an arbitrary classifier cost-sensitive by wrapping a cost-minimizing procedure around it.,objective,1
3886,"This procedure, called MetaCost, treats the underlying classifier as a black box, requiring no knowledge of its functioning or change to it.",method,2
3887,"Unlike stratification, MetaCost, is applicable to any number of classes and to arbitrary cost matrices.",method,2
3888,Empirical trials on a large suite of benchmark databases show that MetaCost almost always produces large cost reductions compared to the cost-blind classifier used (C4.5RULES) and to two forms of stratification.,result,3
3889,Further tests identify the key components of MetaCost and those that can be varied without substantial loss.,result,3
3890,Experiments on a larger database indicate that MetaCost scales well.,result,3
3891,"We introduce a new text-indexing data structure, the String B-Tree, that can be seen as a link between some traditional external-memory and string-matching data structures.",background,0
3892,"In a short phrase, it is a combination of B-trees and Patricia tries for internal-node indices that is made more effective by adding extra pointers to speed up search and update operations.",background,0
3893,"Consequently, the String B-Tree overcomes the theoretical limitations of inverted files, B-trees, prefix B-trees, suffix arrays, compacted tries and suffix trees.",background,0
3894,String B-trees have the same worst-case performance as B-trees but they manage unbounded-length strings and perform much more powerful search operations such as the ones supported by suffix trees.,method,2
3895,String B-trees are also effective in main memory (RAM model) because they improve the online suffix tree search on a dynamic set of strings.,result,3
3896,They also can be successfully applied to database indexing and software duplication.,objective,1
3897,Digital forensics have become increasingly important as an approach to investigate cyber- and computer-assisted crime.,background,0
3898,"Whilst many tools exist and much research is being undertaken, many questions exist regarding the future of the domain.",background,0
3899,"Indeed, prior literature has widely published the challenges that exist within the domain, from the increasing volume of data (e.g. SANs, hard drive capacities, databases) to the varying technology platforms and systems that exist (e.g. tablets, mobile phones, embedded systems, cloud computing).",background,0
3900,"However, little effort has focused upon understanding the reality of these challenges.",background,0
3901,"The paper presents research that seeks to identify, quantify and prioritise these challenges so that future efforts can be concentrated on the issues that actually affect the domain.",objective,1
3902,The study undertook a survey of researchers and practitioners (both law enforcement and organisational) to examine the real-challenges from the perceived challenges and to understand what effect the future will have upon the digital forensic domain.,objective,1
3903,A total of 42 participants undertook the study with 55% having 3 or more years of of experience.,result,3
3904,"45% were academic researchers, 16% law enforcement and 31% had a forensic role within an organisation.",result,3
3905,"Overwhelmingly, 93% of participants felt that the number and complexity of investigations would increase in the future.",method,2
3906,"Apart from the plethora of findings elaborated in the paper, the principal future challenge priorities included cloud computing, anti-forensics and encryption.",method,2
3907,Information technology and the Internet have had a dramatic effect on business operations.,background,0
3908,Companies are making large investments in e-commerce applications but are hard pressed to evaluate the success of their e-commerce systems.,background,0
3909,The DeLone & McLean Information Systems Success Model can be adapted to the measurement challenges of the new e-commerce world.,background,0
3910,The six dimensions of the updated model are a parsimonious framework for organizing the e-commerce success metrics identified in the literature.,method,2
3911,Two case examples demonstrate how the model can be used to guide the identification and specification of e-commerce success metrics.,result,3
3912,Partially observable Markov decision processes (pomdp's) model decision problems in which an agent tries to maximize its reward in the face of limited and/or noisy sensor feedback.,background,0
3913,"While the study of pomdp's is motivated by a need to address realistic problems, existing techniques for nding optimal behavior do not appear to scale well and have been unable to nd satisfactory policies for problems with more than a dozen states.",background,0
3914,"After a brief review of pomdp's, this paper discusses several simple solution methods and shows that all are capable of nding near-optimal policies for a selection of extremely small pomdp's taken from the learning literature.",method,2
3915,"In contrast, we show that none are able to solve a slightly larger and noisier problem based on robot navigation.",method,2
3916,We nd that a combination of two novel approaches performs well on these problems and suggest methods for scaling to even larger and more complicated domains.,method,2
3917,We present a route planning technique solely based on the concept of node contraction.,background,0
3918,We contract or remove one node at a time out of the graph and add shortcut edges to the remaining graph to preserve shortest paths distances.,background,0
3919,"The resulting contraction hierarchy (CH), the original graph plus shortcuts, also defines an order of “importance” among all nodes through the node selection.",background,0
3920,We apply a modified bidirectional Dijkstra algorithm that takes advantage of this node order to obtain shortest paths.,method,2
3921,The search space is reduced by relaxing only edges leading to more important nodes in the forward search and edges coming from more important nodes in the backward search.,method,2
3922,Both search scopes eventually meet at the most important node on a shortest path.,method,2
3923,"We use a simple but extensible heuristic to obtain the node order: a priority queue whose priority function for each node is a linear combination of several terms, e.g. one term weights nodes depending on the sparsity of the remaining graph after the contraction.",method,2
3924,Another term regards the already contracted nodes to allow a more uniform contraction.,result,3
3925,Depending on the application we can select the combination of the priority terms to obtain the required hierarchy.,result,3
3926,"We have five times lower query times than the best previous hierarchical Dijkstra-based speedup techniques and a negative space overhead, i.e., the data structure for distance computation needs less space than the input graph.",other,4
3927,"The past decade has witnessed the rapid evolution in blockchain technologies, which has attracted tremendous interests from both the research communities and industries.",background,0
3928,"The blockchain network was originated from the Internet financial sector as a decentralized, immutable ledger system for transactional data ordering.",background,0
3929,"Nowadays, it is envisioned as a powerful backbone/framework for decentralized data processing and datadriven self-organization in flat, open-access networks.",background,0
3930,"In particular, the plausible characteristics of decentralization, immutability and self-organization are primarily owing to the unique decentralized consensus mechanisms introduced by blockchain networks.",background,0
3931,This survey is motivated by the lack of a comprehensive literature review on the development of decentralized consensus mechanisms in blockchain networks.,objective,1
3932,"In this survey, we provide a systematic vision of the organization of blockchain networks.",objective,1
3933,"By emphasizing the unique characteristics of incentivized consensus in blockchain networks, our in-depth review of the state-ofthe-art consensus protocols is focused on both the perspective of distributed consensus system design and the perspective of incentive mechanism design.",method,2
3934,"From a game-theoretic point of view, we also provide a thorough review on the strategy adoption for self-organization by the individual nodes in the blockchain backbone networks.",method,2
3935,"Consequently, we provide a comprehensive survey on the emerging applications of the blockchain networks in a wide range of areas.",method,2
3936,We highlight our special interest in how the consensus mechanisms impact these applications.,objective,1
3937,Generative adversarial networks have gained a lot of attention in general computer vision community due to their capability of data generation without explicitly modelling the probability density function and robustness to overfitting.,background,0
3938,"The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into the training and imposing higher order consistency that is proven to be useful in many cases, such as in domain adaptation, data augmentation, and image-to-image translation.",background,0
3939,These nice properties have attracted researcher in the medical imaging community and we have seen quick adoptions in many traditional tasks and some novel applications.,background,0
3940,This trend will continue to grow based on our observation therefore we conducted a review of the recent advances in medical imaging using the adversarial training scheme in the hope of benefiting researchers that are interested in this technique.,method,2
3941,We develop a novel cross-modality generation framework that learns to generate predicted modalities from given modalities in MR images without real acquisition.,objective,1
3942,Our proposed method performs image-to-image translation by means of a deep learning model that leverages conditional generative adversarial networks (cGANs).,method,2
3943,"Our framework jointly exploits the low-level features (pixel-wise information) and high-level representations (e.g. brain tumors, brain structure like gray matter, etc.) between cross modalities which are important for resolving the challenging complexity in brain structures.",method,2
3944,"Based on our proposed framework, we first propose a method for cross-modality registration by fusing the deformation fields to adopt the cross-modality information from predicted modalities.",method,2
3945,"Second, we propose an approach for MRI segmentation, translated multichannel segmentation (TMS), where given modalities, along with predicted modalities, are segmented by fully convolutional networks (FCN) in a multi∗These four authors contribute equally to the study ∗∗Corresponding author Email addresses:",method,2
3946,"QianyeYang@buaa.edu.cn (Qianye Yang), nannanli@buaa.edu.cn (Nannan Li), zixuzhao1218@gmail.com (Zixu Zhao), xingyu.fan02@gmail.com (Xingyu Fan), echang@microsoft.com (Eric I-Chao Chang), xuyan04@gmail.com (Yan Xu) Preprint submitted to Medical Image Analysis January 23, 2018 ar X iv :1 80 1.",other,4
3947,06 94 0v 1 [ cs .C V ] 2 2 Ja n 20 18 channel manner.,other,4
3948,Both these two methods successfully adopt the cross-modality information to improve the performance without adding any extra data.,method,2
3949,Experiments demonstrate that our proposed framework advances the state-of-the-art on five MRI datasets.,result,3
3950,We also observe encouraging results in cross-modality registration and segmentation on some widely adopted datasets.,result,3
3951,"As has been extensively shown, acoustic features for speech recognition can be learned from neural networks with multiple hidden layers.",background,0
3952,"However, the learned transformations may not sufficiently generalize to test sets that have a significant mismatch to the training data.",background,0
3953,"Gabor features, on the other hand, are generated from spectro-temporal filters designed to model human auditory processing.",method,2
3954,"In previous work, these features are used as inputs to neural networks, which improved word accuracy for speech recognition in the presence of noise.",method,2
3955,Here we propose a neural network architecture called a Gabor Convolutional Neural Network (GCNN) that incorporates Gabor functions into convolutional filter kernels.,objective,1
3956,"In this architecture, a variety of Gabor features served as the multiple feature maps of the convolutional layer.",method,2
3957,The filter coefficients are further tuned by back-propagation training.,method,2
3958,"Experiments used two noisy versions of the WSJ corpus: Aurora 4, and RATS re-noised WSJ.",method,2
3959,"In both cases, the proposed architecture performs better than other noise-robust features that we have tried, namely, ETSI-AFE, PNCC, Gabor features without the CNN-based approach, and our best neural network features that don’t incorporate Gabor functions.",result,3
3960,Digital communication techniques make the process of modulating a message feasible for transmission.,background,0
3961,"However, a common problem with commonly used techniques, such as Pulse Coded Modulation (PCM) and Linear Delta Modulation (LDM), is that they negatively affect the communication process by causing quantization error, slope overload distortion, and granular noise.",background,0
3962,"This paper discusses the implementation of two modulation systems, Adaptive Delta Modulation (ADM) and Differential Pulse Coded Modulation (DPCM), in order to solve the aforementioned problems.",objective,1
3963,The latter solves the quantization error faced by the PCM and the former solves the slope overload distortion and granular noise faced by LDM.,method,2
3964,"These two systems are implemented using Simulink (The Math Works, Inc., Natick, MA, USA) on a multithreaded processor computer, are tested in real-time, and are subjected to different kinds of noise.",method,2
3965,HomeNetToo is a longitudinal field study designed to examine the antecedents and consequences of home Internet use in low-income families (http://www.HomeNetToo.org).,background,0
3966,The study was done between December 2000 and June 2002.,background,0
3967,Among the consequences considered was children's academic performance.,background,0
3968,"Participants were 140 children, mostly African American (83%), mostly boys (58%), and most living in single-parent households (75%) in which the median annual income was 15,000 (U.S. dollars) or less.",method,2
3969,Average age was 13.8 years.,result,3
3970,"Ages ranged between 10 and 18 years, Internet use was continuously recorded, and multiple measures of academic performance were obtained during the 16-month trial.",method,2
3971,"Findings indicated that children who used the Internet more had higher scores on standardized tests of reading achievement and higher grade point averages 6 months, 1 year, and 16 months later than did children who used it less.",result,3
3972,"Older children used the Internet more than did younger children, but age had no effect on the nature or the academic performance benefits of Internet use.",result,3
3973,"Implications for the digital ""use"" divide are discussed.",other,4
3974,"This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART.",background,0
3975,These top 10 algorithms are among the most influential data mining algorithms in the research community.,background,0
3976,"With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm.",method,2
3977,"These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development.",method,2
3978,"Gamification, the application of game elements to non-game settings, continues to grow in popularity as a method to increase student engagement in the classroom.",method,2
3979,"We tested students across two courses, measuring their motivation, social comparison, effort, satisfaction, learner empowerment, and academic performance at four points during a 16-week semester.",method,2
3980,"One course received a gamified curriculum, featuring a leaderboard and badges, whereas the other course received the same curriculum without the gamified elements.",method,2
3981,"Our results found that students in the gamified course showed less motivation, satisfaction, and empowerment over time than those in the non-gamified class.",result,3
3982,"The effect of course type on students' final exam scores was mediated by students' levels of intrinsic motivation, with students in the gamified course showing less motivation and lower final exam scores than the non-gamified class.",result,3
3983,This suggests that some care should be taken when applying certain gamification mechanics to educational settings.,result,3
3984,© 2014 Elsevier Ltd.,other,4
3986,"First Fit Decreasing is a classical bin packing algorithm: the items are ordered into their nonincreasing order, and then in this order the next item is always packed into the first bin where it fits.",background,0
3987,"For an instance I let FFD(I) and OPT (I) denote the number of the used bins by algorithm FFD, and an optimal algorithm, respectively.",result,3
3988,"We show in this paper that FFD(I) ≤ 11/9OPT (I) + 6/9, (1) and that this bound is tight.",result,3
3989,The tight bound of the additive constant was an open question for many years.,result,3
3990,"Medical professionals diagnose depression by interpreting the responses of individuals to a variety of questions, probing lifestyle changes and ongoing thoughts.",background,0
3991,"Like professionals, an effective automated agent must understand that responses to queries have varying prognostic value.",background,0
3992,In this study we demonstrate an automated depression-detection algorithm that models interviews between an individual and agent and learns from sequences of questions and answers without the need to perform explicit topic modeling of the content.,method,2
3993,"We utilized data of 142 individuals undergoing depression screening, and modeled the interactions with audio and text features in a Long-Short Term Memory (LSTM) neural network model to detect depression.",method,2
3994,"Our results were comparable to methods that explicitly modeled the topics of the questions and answers which suggests that depression can be detected through sequential modeling of an interaction, with minimal information on the structure of the interview.",result,3
3995,This paper proposes a system architecture based on deep convolutional neural network (CNN) for road detection and segmentation from aerial images.,background,0
3996,These images are acquired by an unmanned aerial vehicle implemented by the authors.,background,0
3997,The algorithm for image segmentation has two phases: the learning phase and the operating phase.,method,2
3998,"The input aerial images are decomposed in their color components, preprocessed in Matlab on Hue channel and next partitioned in small boxes of dimension 33 × 33 pixels using a sliding box algorithm.",method,2
3999,These boxes are considered as inputs into a deep CNN.,background,0
4000,"The CNN was designed using MatConvNet and has the following structure: four convolutional layers, four pooling layers, one ReLu layer, one full connected layer, and a Softmax layer.",background,0
4001,"The whole network was trained using a number of 2,000 boxes.",method,2
4002,The CNN was implemented using programming in MATLAB on GPU and the results are promising.,result,3
4003,The proposed system has the advantage of processing speed and simplicity.,result,3
4004,"Given a state-of-the-art deep neural network classifier, we show the existence of a universal (image-agnostic) and very small perturbation vector that causes natural images to be misclassified with high probability.",background,0
4005,"We propose a systematic algorithm for computing universal perturbations, and show that state-of-the-art deep neural networks are highly vulnerable to such perturbations, albeit being quasi-imperceptible to the human eye.",method,2
4006,"We further empirically analyze these universal perturbations and show, in particular, that they generalize very well across neural networks.",method,2
4007,The surprising existence of universal perturbations reveals important geometric correlations among the high-dimensional decision boundary of classifiers.,result,3
4008,It further outlines potential security breaches with the existence of single directions in the input space that adversaries can possibly exploit to break a classifier on most natural images.,result,3
4009,ÐWe describe a real-time computer vision and machine learning system for modeling and recognizing human behaviors in a visual surveillance task [1].,background,0
4010,The system is particularly concerned with detecting when interactions between people occur and classifying the type of interaction.,objective,1
4011,"Examples of interesting interaction behaviors include following another person, altering one's path to meet another, and so forth.",background,0
4012,"Our system combines top-down with bottom-up information in a closed feedback loop, with both components employing a statistical Bayesian approach [2].",method,2
4013,"We propose and compare two different state-based learning architectures, namely, HMMs and CHMMs for modeling behaviors and interactions.",method,2
4014,The CHMM model is shown to work much more efficiently and accurately.,method,2
4015,"Finally, to deal with the problem of limited training data, a synthetic aAlife-styleo training system is used to develop flexible prior models for recognizing human interactions.",method,2
4016,We demonstrate the ability to use these a priori models to accurately classify real human behaviors and interactions with no additional tuning or training.,result,3
4017,"Index TermsÐVisual surveillance, people detection, tracking, human behavior recognition, Hidden Markov Models.",result,3
4018,"one component of intelligent transportation systems, IV systems use sensing and intelligent algorithms to understand the vehicle’s immediate environment, either assisting the driver or fully controlling the vehicle.",background,0
4019,"Following the success of information-oriented systems, IV systems will likely be the “next wave” for ITS, functioning at the control layer to enable the driver–vehicle “subsystem” to operate more effectively.",method,2
4020,This column provides a broad overview of applications and selected activities in this field.,method,2
4021,IV application areas,other,4
4022,"To stand up for the brands they support, members of brand communities develop “oppositional brand loyalty” towards other rival brands.",background,0
4023,"This study identifies how the interaction characteristics of brand community affect the perceived benefits of community members, and whether the perceived benefits cause members to develop community commitment, as well as the relationship between community commitment and oppositional brand loyalty.",objective,1
4024,"This study examined members of online automobile communities in Taiwan, and obtained a total of 283 valid samples.",result,3
4025,"The analytical results reveal that interaction characteristics of brand community make members perceive many benefits, with “brand community engagement” being the most noticeable.",result,3
4026,"Furthermore, hedonic, social, and learning benefits are the main factors to form community commitments.",objective,1
4027,"When members have community commitments, they will form oppositional brand loyalty to other rival brands.",result,3
4028,"Based on the analytical results, this study provides suggestions to enterprises regarding online brand community operations.",result,3
4029,© 2013 Elsevier Ltd.,other,4
4031,The purpose of this paper is to analyze shifts in the producer– consumer relationship resulting from the increased use of digital technologies.,objective,1
4032,"In this study, we aim to understand how this relationship is fundamentally changing and the role of digital technologies in such a change.",objective,1
4033,"Therefore, we provide a state-of-the-art review of information systems and management literature using analysis techniques borrowed from the method of grounded theory.",method,2
4034,"The results of our study indicate that the constructs of digital density, digital interconnectedness, and consumer-centricity are key drivers of changes in the producer–consumer relationship.",result,3
4035,"With the growing role of digital technologies in both society and organizations, our study contributes with implications for information technology and business managers, offering them insights on how to deal with this phenomenon.",result,3
4036,"Finally, our study provides a useful framework for future interdisciplinary research in this field.",result,3
4037,Paleness or pallor is a manifestation of blood loss or low hemoglobin concentrations in the human blood that can be caused by pathologies such as anemia.,background,0
4038,"This work presents the first automated screening system that utilizes pallor site images, segments, and extracts color and intensity-based features for multi-class classification of patients with high pallor due to anemia-like pathologies, normal patients and patients with other abnormalities.",background,0
4039,This work analyzes the pallor sites of conjunctiva and tongue for anemia screening purposes.,objective,1
4040,"First, for the eye pallor site images, the sclera and conjunctiva regions are automatically segmented for regions of interest.",objective,1
4041,"Similarly, for the tongue pallor site images, the inner and outer tongue regions are segmented.",objective,1
4042,"Then, color-plane based feature extraction is performed followed by machine learning algorithms for feature reduction and image level classification for anemia.",method,2
4043,"In this work, a suite of classification algorithms image-level classifications for normal (class 0), pallor (class 1) and other abnormalities (class 2).",method,2
4044,"The proposed method achieves 86% accuracy, 85% precision and 67% recall in eye pallor site images and 98.2% accuracy and precision with 100% recall in tongue pallor site images for classification of images with pallor.",method,2
4045,The proposed pallor screening system can be further fine-tuned to detect the severity of anemia-like pathologies using controlled set of local images that can then be used for future benchmarking purposes.,result,3
4046,This work presents a new efficient method for fitting ellipses to scattered data.,objective,1
4047,Previous algorithms either fitted general conics or were computationally expensive.,background,0
4048,By minimizing the algebraic distance subject to the constraint 4 2 1 the new method incorporates the ellipticity constraint into the normalization factor.,method,2
4049,"The new method combines several advantages: (i) It is ellipse-specific so that even bad data will always return an ellipse; (ii) It can be solved naturally by a generalized eigensystem and (iii) it is extremely robust, efficient and easy to implement.",method,2
4050,We compare the proposed method to other approaches and show its robustness on several examples in which other non-ellipse-specific approaches would fail or require computationally expensive iterative refinements.,method,2
4051,"Source code for the algorithm is supplied and a demonstration is available on ! """,other,4
4052,!,other,4
4053,"$#% '& () ""*) & +, ./10 0 32, . 4) ""*) ""*) % 5* 0",other,4
4054,A new method for automatic indexing and retrieval is described.,method,2
4055,The approach is to take advantage of implicit higher-order structure in the association of terms with documents (“semantic structure”) in order to improve the detection of relevant documents on the basis of terms found in queries.,method,2
4056,"The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca.",method,2
4057,100 orthogonal factors from which the original matrix can be approximated by linear combination.,method,2
4058,Documents are represented by ca.,method,2
4059,100 item vectors of factor weights.,result,3
4060,"Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned.",method,2
4061,initial tests find this completely automatic method for retrieval to be promising.,result,3
4062,"A supervised learning algorithm (Scaled Conjugate Gradient, SCG) with superlinear convergence rate is introduced.",background,0
4063,The algorithm is based upon a class of optimization techniques well known in numerical analysis as the Conjugate Gradient Methods.,background,0
4064,"SCG uses second order information from the neural network but requires only O(N) memory usage, where N is the number of weights in the network.",objective,1
4065,"The performance of SCG is benchmarked against the performance of the standard backpropagation algorithm (BP) [13], the conjugate gradient backpropagation (CGB) [6] and the one-step Broyden-Fletcher-Goldfarb-Shanno memoryless quasi-Newton algorithm (BFGS) [1].",method,2
4066,SCG yields a speed-up of at least an order of magnitude relative to BP.,objective,1
4067,"The speed-up depends on the convergence criterion, i.e., the bigger demand for reduction in error the bigger the speed-up.",objective,1
4068,"SCG is fully automated including no user dependent parameters and avoids a time consuming line-search, which CGB and BFGS uses in each iteration in order to determine an appropriate step size.",method,2
4069,Incorporating problem dependent structural information in the architecture of a neural network often lowers the overall complexity.,background,0
4070,"The smaller the complexity of the neural network relative to the problem domain, the bigger the possibility that the weight space contains long ravines characterized by sharp curvature.",result,3
4071,"While BP is inefficient on these ravine phenomena, it is shown that SCG handles them effectively.",result,3
4072,People are reciprocal if they reward kind actions and punish unkind ones.,background,0
4073,In this paper we a formal theory of reciprocity.,background,0
4074,It takes into account that people evaluate the kindness of an act only by its consequences but also by its underlying intention.,background,0
4075,"The theory is in line with the re stylized facts of a wide range of experimental games, such as the ultimatum game, the gift-ex game, a reduced best-shot game, the dictator game, the prisoner’s dilemma, and public good Furthermore, it predicts that identical consequences trigger different reciprocal responses in d environments.",method,2
4076,"Finally, the theory explains why outcomes tend to be fair in bilateral intera whereas extremely unfair distributions may arise in competitive markets.",result,3
4077, 2005 Elsevier Inc. All rights reserved.,other,4
4078,JEL classification:C7; C91; C92; D64; H41,other,4
4079,"During the past decades, the virtual reality community has based its development on a synthesis of earlier work in interactive 3D graphics, user interfaces, and visual simulation.",background,0
4080,"Currently, the VR field is transitioning into work influenced by video games.",background,0
4081,"Because much of the research and development being conducted in the games community parallels the VR community's efforts, it has the potential to affect a greater audience.",background,0
4082,"Given these trends, VR researchers who want their work to remain relevant must realign to focus on game research and development.",objective,1
4083,"Leveraging technology from the visual simulation and virtual reality communities, serious games provide a delivery system for organizational video game instruction and training.",objective,1
4084,"Virtualized Radio Access Network (vRAN) architectures constitute a promising solution for the densification needs of 5G networks, as they decouple Base Stations (BUs) functions from Radio Units (RUs) allowing the processing power to be pooled at cost-efficient Central Units (CUs).",background,0
4085,"vRAN facilitates the flexible function relocation (split selection), and therefore enables splits with less stringent network requirements compared to state-of-the-art fully Centralized (C-RAN) systems.",background,0
4086,"In this paper, we study the important and challenging vRAN design problem.",objective,1
4087,"We propose a novel modeling approach and a rigorous analytical framework, FluidRAN, that minimizes RAN costs by jointly selecting the splits and the RUs-CUs routing paths.",method,2
4088,"We also consider the increasingly relevant scenario where the RAN needs to support multi-access edge computing (MEC) services, that naturally favor distributed RAN (D-RAN) architectures.",method,2
4089,Our framework provides a joint vRAN/MEC solution that minimizes operational costs while satisfying the MEC needs.,method,2
4090,"We follow a data-driven evaluation method, using topologies of 3 operational networks.",method,2
4091,"Our results reveal that (i) pure C-RAN is rarely a feasible upgrade solution for existing infrastructure, (ii) FluidRAN achieves significant cost savings compared to D-RAN systems, and (iii) MEC can increase substantially the operator's cost as it pushes vRAN function placement back to RUs.",result,3
4092,This paper presents the modeling of the light-weight BioRob robot arm with series elastic actuation for simulation and controller design.,background,0
4093,We describe the kinematic coupling introduced by the cable actuation and the robot arm dynamics including the elastic actuator and motor and gear model.,method,2
4094,"We show how the inverse dynamics model derived from these equations can be used as a basis for a position tracking controller that is able to sufficiently damp the oscillations caused by the high, nonlinear joint elasticity.",method,2
4095,We presents results from simulation and briefly describe the implementation for a real world application.,result,3
4096,"Motivated by machine learning problems over large data sets and distributed optimization over networks, we develop and analyze a new method called incremental Newton method for minimizing the sum of a large number of strongly convex functions.",background,0
4097,We show that our method is globally convergent for a variable stepsize rule.,background,0
4098,"We further show that under a gradient growth condition, convergence rate is linear for both variable and constant stepsize rules.",result,3
4099,"By means of an example, we show that without the gradient growth condition, incremental Newton method cannot achieve linear convergence.",method,2
4100,"Our analysis can be extended to study other incremental methods: in particular, we obtain a linear convergence rate result for the incremental Gauss-Newton algorithm under a variable stepsize rule.",result,3
4101,Core Insurance Service Layer (CISL) is a project to create a common but extensible service layer catalog for insurance processes.,background,0
4102,It follows the REST principles to define services and a datamodel which are exposed by new or existing insurance backends and that can easily be consumed by front end applications.,background,0
4103,The project provides a REST Meta-Model and tools to facilitate the adaption of CISL and the reuse across organizational units within Allianz.,background,0
4104,"While social Virtual Reality (VR) applications such as Facebook Spaces are becoming popular, they are not compatible with classic mobile-or cloud-based solutions due to their processing of tremendous data and exchange of delay-sensitive metadata.",background,0
4105,"Edge computing may fulfill these demands better, but it is still an open problem to deploy social VR applications in an edge infrastructure while supporting economic operations of the edge clouds and satisfactory quality-of-service for the users.",background,0
4106,This paper presents the first formal study of this problem.,objective,1
4107,We model and formulate a combinatorial optimization problem that captures all intertwined goals.,method,2
4108,"We propose ITEM, an iterative algorithm with fast and big “moves” where in each iteration, we construct a graph to encode all the costs and convert the cost optimization into a graph cut problem.",method,2
4109,"By obtaining the minimum s-t cut via existing max-flow algorithms, we can simultaneously determine the placement of multiple service entities, and thus, the original problem can be addressed by solving a series of graph cuts.",method,2
4110,"Our evaluations with large-scale, real-world data traces demonstrate that ITEM converges fast and outperforms baseline approaches by more than 2 × in one-shot placement and around 1.3 × in dynamic, online scenarios where users move arbitrarily in the system.",result,3
4111,The multidisciplinary field of quantum computing strives to exploit some of the uncanny aspects of quantum mechanics to expand our computational horizons.,background,0
4112,Quantum Computing for Computer Scientists takes readers on a tour of this fascinating area of cutting-edge research.,background,0
4113,"Written in an accessible yet rigorous fashion, this book employs ideas and techniques familiar to every student of computer science.",background,0
4114,The reader is not expected to have any advanced mathematics or physics background.,method,2
4115,"After presenting the necessary prerequisites, the material is organized to look at different aspects of quantum computing from the specific standpoint of computer science.",method,2
4116,"There are chapters on computer architecture, algorithms, programming languages, theoretical computer science, cryptography, information theory, and hardware.",method,2
4117,"The text has step-by-step examples, more than two hundred exercises with solutions, and programming drills that bring the ideas of quantum computing alive for today’s computer science students and researchers.",result,3
4118,"Automotive radars, along with other sensors such as lidar, (which stands for ""light detection and ranging""), ultrasound, and cameras, form the backbone of self-driving cars and advanced driver assistant systems (ADASs).",background,0
4119,These technological advancements are enabled by extremely complex systems with a long signal processing path from radars/sensors to the controller.,background,0
4120,"Automotive radar systems are responsible for the detection of objects and obstacles, their position, and speed relative to the vehicle.",background,0
4121,The development of signal processing techniques along with progress in the millimeter-wave (mm-wave) semiconductor technology plays a key role in automotive radar systems.,method,2
4122,"Various signal processing techniques have been developed to provide better resolution and estimation performance in all measurement dimensions: range, azimuth-elevation angles, and velocity of the targets surrounding the vehicles.",method,2
4123,"This article summarizes various aspects of automotive radar signal processing techniques, including waveform design, possible radar architectures, estimation algorithms, implementation complexity-resolution trade off, and adaptive processing for complex environments, as well as unique problems associated with automotive radars such as pedestrian detection.",method,2
4124,We believe that this review article will combine the several contributions scattered in the literature to serve as a primary starting point to new researchers and to give a bird's-eye view to the existing research community.,objective,1
4125,0 7 4 0 7 4 5 9 / 0 3 / $ 1 7 .,other,4
4126,"0 0 © 2 0 0 3 I E E E After initial salvage attempts, the ship was largely forgotten until Anders Franzen located it in 1956.1 In 1961, 333 years after it sank, the Vasa was raised; it was so well preserved that it could float after the gun portals were sealed and water and mud were pumped from it.",background,0
4127,"The sheltered harbor had protected the ship from storms, and the Baltic Sea’s low salinity prevented worms from infesting and destroying the wooden vessel.",background,0
4128,"Today it is housed in the Vasa Museum (www.vasamuseet.se), near the site where it foundered.2 Figures 1 and 2 show the restored ship and a recreation of its sinking.",background,0
4129,Researchers have extensively analyzed the Vasa and examined historical records concerning its construction.,result,3
4130,"It sank, of course, because it was unstable.",result,3
4131,"The reasons it was unstable, and launched when known to be unstable, are numerous and varied.",result,3
4132,"Although we may never know the exact details surrounding the Vasa, this article depicts our “most probable scenario” based on the extensive and remarkably well-preserved documents of the time, evidence collected during visits to the Vasa Museum, information from the referenced Web sites, and publications by those who have investigated the circumstances of the Vasa’s sinking.",result,3
4133,"The problems encountered are as relevant to our modernday attempts to build large, complex software systems as they were to the 17th-century art and craft of building warships.",result,3
4134,"This paper examines the literature on computer games and serious games in regard to the potential positive impacts of gaming on users aged 14 years or above, especially with respect to learning, skill enhancement and engagement.",objective,1
4135,Search terms identified 129 papers reporting empirical evidence about the impacts and outcomes of computer games and serious games with respect to learning and engagement and a multidimensional approach to categorizing games was developed.,objective,1
4136,"The findings revealed that playing computer games is linked to a range of perceptual, cognitive, behavioural, affective and motivational impacts and outcomes.",result,3
4137,The most frequently occurring outcomes and impacts were knowledge acquisition/content understanding and affective and motivational outcomes.,result,3
4138,"The range of indicators and measures used in the included papers are discussed, together with methodological limitations and recommendations for further work in this area.",method,2
4139,2012 Published by Elsevier Ltd.,other,4
4140,Most classifiers work well when the class distribution in the response variable of the dataset is well balanced.,background,0
4141,Problems arise when the dataset is imbalanced.,background,0
4142,"This paper applied four methods: Oversampling, Undersampling, Bagging and Boosting in handling imbalanced datasets.",method,2
4143,"The cardiac surgery dataset has a binary response variable (1=Died, 0=Alive).",result,3
4144,The sample size is 4976 cases with 4.2% (Died) and 95.8% (Alive) cases.,result,3
4145,"CART, C5 and CHAID were chosen as the classifiers.",result,3
4146,"In classification problems, the accuracy rate of the predictive model is not an appropriate measure when there is imbalanced problem due to the fact that it will be biased towards the majority class.",result,3
4147,"Thus, the performance of the classifier is measured using sensitivity and precision Oversampling and undersampling are found to work well in improving the classification for the imbalanced dataset using decision tree.",result,3
4148,"Meanwhile, boosting and bagging did not improve the Decision Tree performance.",result,3
4149,"KeywordsBagging, Boosting, Oversampling, Undersampling, Imbalanced data",other,4
4150,Previous studies showed the effects of psychological variables such as depression and loneliness on game addiction.,background,0
4151,"Likewise, the effect of aggression on game addiction has also been reported.",background,0
4152,"However, little research has empirically proved the role of aggression between the psychological variables and game addiction.",background,0
4153,"In addition, in the context of game addiction, few studies have investigated their relationships in an integrated model using sub-factors of each construct.",background,0
4154,"With survey data of 789 subjects, focused on the psychosocial variables (e.g., aggression, depression, and loneliness), the current study analyzed a path model to examine 1) the effects of loneliness and depression on aggression, 2) the psychosocial variables' effect on game addiction, and 3) mediation role of aggression between psychological variables (e.g., depression and loneliness) and game addiction.",result,3
4155,Results showed the important roles of aggression in the model.,result,3
4156,"Aggression was significantly affected by both loneliness and depression, and in turn, aggression was the strongest determinant on game addiction among the three variables.",result,3
4157,"Notably, aggression played a mediation role between depression and game addiction.",objective,1
4158,Results and implications were discussed.,result,3
4159,BE-Tree is a novel dynamic tree data structure designed to efficiently index Boolean expressions over a high-dimensional discrete space.,background,0
4160,BE-Tree copes with both high-dimensionality and expressiveness of Boolean expressions by introducing a novel two-phase space-cutting technique that specifically utilizes the discrete and finite domain properties of the space.,background,0
4161,"Furthermore, BE-Tree employs self-adjustment policies to dynamically adapt the tree as the workload changes.",objective,1
4162,We conduct a comprehensive evaluation to demonstrate the superiority of BE-Tree in comparison with state-of-the-art index structures designed for matching Boolean expressions.,result,3
4163,"Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain.",background,0
4164,In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group.,background,0
4165,"In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian.",method,2
4166,"We show through experiments that for lowdimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.",method,2
4167,This paper brings into question whether information systems should be centralized or decentralized in order to provide greater support for different business processes.,objective,1
4168,During the last century companies and organizations have used different approaches for centralization and decentralization; a simple answer to the question does not exist.,background,0
4169,"This paper provides a survey of the evolution of centralized and decentralized approaches, mainly in a Nordic perspective.",method,2
4170,Based on critical reflections on the situation in the end of the century we can discuss what we can learn from history to achieve alignment between centralized and decentralized systems and the business structure.,method,2
4171,"The conclusion is that theories, management and practice for decisions on centralization or decentralization of information systems must be improved.",result,3
4172,"A conscious management and control of centralization /decentralization of IT support is a vital question in the company or the organization, and this is not a task that can be handled only by IT-specialists.",result,3
4173,There is a need for business oriented IT management of centralization/decentralization.,result,3
4174,New expressions are derived for the exact symbol error probability and bit-error probability for optimum combining with multiple phase-shift keying.,background,0
4175,The expressions are for any numbers of equal-power cochannel interferers and receive branches.,background,0
4176,It is assumed that the aggregate interference and noise is Gaussian and that both the desired signal and interference are subject to flat Rayleigh fading.,background,0
4177,"The new expressions have low computational complexity, as they contain only a single integral form with finite limits and finite integrand.",background,0
4178,The usage of Likert-type scales has become widespread practice in current IS research.,background,0
4179,"Those scales require individuals to choose between a limited number of choices, and have been criticized in the literature for causing loss of information, allowing the researcher to affect responses by determining the range, and being ordinal in nature.",background,0
4180,"The use of online surveys allows for the easy implementation of continuous rating scales, which have a long history in psychophysical measurement but were rarely used in IS surveys.",background,0
4181,"This type of measurement requires survey participants to express their opinion in a visual form, i.e. to place a mark at an appropriate position on a continuous line.",method,2
4182,"That not only solves the problems of information loss, but also allows for applying advanced robust statistical analyses.",background,0
4183,"In this 1 Augasse 2-6, A-1090 Vienna, Austria Tel.",other,4
4184,: +43/1/31336/4480 Fax: +43/1/31336/746 E-Mail: Horst.Treiblmaier@wu.ac.at,other,4
4185,0 7 4 0 7 4 5 9 / 0 1 / $ 1 0 .,other,4
4186,"0 0 © 2 0 0 1 I E E E T his month’s column is simply a collection of what I consider to be facts— truths, if you will—about software engineering.",result,3
4187,"I’m presenting this software engineering laundry list because far too many people who call themselves software engineers, or computer scientists, or programmers, or whatever nom du jour you prefer, either aren’t familiar with these facts or have forgotten them.",other,4
4188,I don’t expect you to agree with all these facts; some of them might even upset you.,other,4
4189,Great!,other,4
4190,Then we can begin a dialog about which facts really are facts and which are merely figments of my vivid loyal opposition imagination!,other,4
4191,Enough preliminaries.,other,4
4192,Here are the most frequently forgotten fundamental facts about software engineering.,other,4
4193,Some are of vital importance—,other,4
4194,we forget them at considerable risk.,other,4
4195,"Recently, deep learning approaches have demonstrated remarkable progresses for action recognition in videos.",background,0
4196,"Most existing deep frameworks equally treat every volume i.e. spatial-temporal video clip, and directly assign a video label to all volumes sampled from it.",background,0
4197,"However, within a video, discriminative actions may occur sparsely in a few key volumes, and most other volumes are irrelevant to the labeled action category.",background,0
4198,Training with a large proportion of irrelevant volumes will hurt performance.,background,0
4199,"To address this issue, we propose a key volume mining deep framework to identify key volumes and conduct classification simultaneously.",objective,1
4200,"Specifically, our framework is trained is optimized in an alternative way integrated to the forward and backward stages of Stochastic Gradient Descent (SGD).",objective,1
4201,"In the forward pass, our network mines key volumes for each action class.",method,2
4202,"In the backward pass, it updates network parameters with the help of these mined key volumes.",method,2
4203,"In addition, we propose ""Stochastic out"" to model key volumes from multi-modalities, and an effective yet simple ""unsupervised key volume proposal"" method for high quality volume sampling.",method,2
4204,"Our experiments show that action recognition performance can be significantly improved by mining key volumes, and we achieve state-of-the-art performance on HMDB51 and UCF101 (93.1%).",result,3
4205,This paper examines vertical integration and its impact on profitability and shareholder value in the global banking industry.,objective,1
4206,We derive a measure for vertical integration using a sample of 859 banks from 9 Anglo-Saxon and European countries covering the timeframe 1997-2002.,background,0
4207,Our results suggest that banks either operating on highly integrated or highly disintegrated levels of vertical integration display superior performance figures and stock market evaluations.,result,3
4208,"Additionally, vertically integrated banks show lower levels of firm risk.",result,3
4209,"As our results suggest an interrelation between vertical integration and outsourcing, banks need clear determined strategies whether to engage into outsourcing activities or not.",result,3
4210,We describe the first mobile app for identifying plant species using automatic visual recognition.,background,0
4211,The system – called Leafsnap – identifies tree species from photographs of their leaves.,method,2
4212,"Key to this system are computer vision components for discarding non-leaf images, segmenting the leaf from an untextured background, extracting features representing the curvature of the leaf’s contour over multiple scales, and identifying the species from a dataset of the 184 trees in the Northeastern United States.",method,2
4213,Our system obtains state-of-the-art performance on the real-world images from the new Leafsnap Dataset – the largest of its kind.,method,2
4214,"Throughout the paper, we document many of the practical steps needed to produce a computer vision system such as ours, which currently has nearly a million users.",result,3
4215,Lack of trust has been identified as a major obstacle to the adoption of online shopping.,background,0
4216,"However, there is paucity of research that investigates the effectiveness of various trust building mechanisms, especially the interactions amongst these mechanisms.",background,0
4217,"In this study, three trust building mechanisms (i.e., third-party certification, reputation, and return policy) were examined.",objective,1
4218,Scenario survey method was used for data collection.,method,2
4219,463 usable questionnaires were collected from respondents with diverse backgrounds.,method,2
4220,Regression results show that all three trust building mechanisms have significant positive effects on trust in the online vendor.,result,3
4221,Their effects are not simple ones; the different trust building mechanisms interact with one another to produce an overall effect on the level of trust.,result,3
4222,These results have both theoretical and practical implications.,result,3
4223,We address semantic segmentation of road-objects from 3D LiDAR point clouds.,background,0
4224,"In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists.",objective,1
4225,"We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer.",method,2
4226,Instance-level labels are then obtained by conventional clustering algorithms.,other,4
4227,"Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI.",method,2
4228,"To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto $\boldsymbol{V}$ (GTA-V), a popular video game, to synthesize large amounts of realistic training data.",result,3
4229,"Our experiments show that SqueezeSeg achieves high accuracy with astonishingly fast and stable runtime ($8.7\pm 0.5$ ms per frame), highly desirable for autonomous driving.",result,3
4230,"Furthermore, additionally training on synthesized data boosts validation accuracy on real-world data.",other,4
4231,Our source code is open-source released111https://github.com/BichenWuUCB/SqueezeSeg.,result,3
4232,The paper is accompanied by a video222https://youtu.be/Xyn5Zd31m6s containing a high level introduction and demonstrations of this work.,result,3
4233,"In this paper, we review the functions and architectures of control centers: their past, present, and likely future.",objective,1
4234,"The evolving changes in power system operational needs require a distributed control center that is decentralized, integrated, flexible, and open.",objective,1
4235,Present-day control centers are moving in that direction with varying degrees of success.,method,2
4236,The technologies employed in today's control centers to enable them to be distributed are briefly reviewed.,method,2
4237,"With the rise of the Internet age, the trend in information and communication technologies is moving toward Grid computing and Web services, or Grid services.",method,2
4238,A Grid service-based future control center is stipulated.,result,3
4239,The expected proliferation of local-area networks has created a need for network database servers.,background,0
4240,It is reasonable to view local-area network data servers as extensions of backend database systems.,background,0
4241,"This paper addresses several critical data-server design issues: distribution of functionality, high availability, security, and performance.",objective,1
4242,Particular consideration is given to applying experience with backend databases to the problems of data servers.,objective,1
4243,"Several design alternatives are proposed and evaluated in terms of their impact on reliability, security, and performance in a gross sense.",method,2
4244,The concluding section emphasizes the need for greater practical experience with local-area networks in order to more accurately weigh the tradeoffs of different data-server configurations.,result,3
4245,This paper addresses the problem of geocasting in mobile ad hoc network (MANET) environments.,objective,1
4246,Geocasting is a variant of the conventional multicasting problem.,background,0
4247,"For multicasting, conventional protocols define a multicast group as a collection of hosts which register to a multicast group address.",method,2
4248,"However, for geocasting, the group consists of the set of all nodes within a specified geographical region.",method,2
4249,Hosts within the specified region at a given time form the geocast group at that time.,background,0
4250,"We present two different algorithms for delivering packets to such a group, and present simulation results.",result,3
4251,"We propose SfM-Net, a geometry-aware neural network for motion estimation in videos that decomposes frameto-frame pixel motion in terms of scene and object depth, camera motion and 3D object rotations and translations.",background,0
4252,"Given a sequence of frames, SfM-Net predicts depth, segmentation, camera and rigid object motions, converts those into a dense frame-to-frame motion field (optical flow), differentiably warps frames in time to match pixels and back-propagates.",background,0
4253,"The model can be trained with various degrees of supervision: 1) self-supervised by the reprojection photometric error (completely unsupervised), 2) supervised by ego-motion (camera motion), or 3) supervised by depth (e.g., as provided by RGBD sensors).",objective,1
4254,SfMNet extracts meaningful depth estimates and successfully estimates frame-to-frame camera rotations and translations.,objective,1
4255,"It often successfully segments the moving objects in the scene, even though such supervision is never provided.",result,3
4256,Early research on online self-presentation mostly focused on identity constructions in anonymous online environments.,background,0
4257,Such studies found that individuals tended to engage in role-play games and anti-normative behaviors in the online world.,background,0
4258,More recent studies have examined identity performance in less anonymous online settings such as Internet dating sites and reported different findings.,background,0
4259,"The present study investigates identity construction on Facebook, a newly emerged nonymous online environment.",background,0
4260,"Based on content analysis of 63 Facebook accounts, we find that the identities produced in this nonymous environment differ from those constructed in the anonymous online environments previously reported.",objective,1
4261,Facebook users predominantly claim their identities implicitly rather than explicitly; they ‘‘show rather than tell” and stress group and consumer identities over personally narrated ones.,background,0
4262,The characteristics of such identities are described and the implications of this finding are discussed.,objective,1
4263,Published by Elsevier Ltd.,other,4
4264,"This research aimed to investigate factors that affect computer crime protection behavior, based on the protection motivation theory.",objective,1
4265,"Personal factors were considered, including: conscientious personality, perceived value of data, prior experience, and environmental factors.",method,2
4266,"In addition, other factors were evaluated, including: subjective norm, security knowledge, and safeguard costs.",result,3
4267,These factors are mediated by threat appraisal and coping appraisal.,result,3
4268,The data were collected from 600 personal computer users by use of a questionnaire.,result,3
4269,Data were analyzed using structural equation modeling.,result,3
4270,Findings showed that all factors had significant effects on the computer crime protection behavior.,result,3
4271,"In addition, the results showed that security knowledge, one of the environmental factors, had the strongest effects on coping appraisal which subsequently had the strongest impact on protection behavior.",result,3
4272,Deep web refers to the hidden part of the Web that remains unavailable for standard Web crawlers.,background,0
4273,To obtain content of Deep Web is challenging and has been acknowledged as a significant gap in the coverage of search engines.,background,0
4274,"To this end, the paper proposes a novel deep web crawling framework based on reinforcement learning, in which the crawler is regarded as an agent and deep web database as the environment.",background,0
4275,The agent perceives its current state and selects an action (query) to submit to the environment according to Q-value.,method,2
4276,"The framework not only enables crawlers to learn a promising crawling strategy from its own experience, but also allows for utilizing diverse features of query keywords.",result,3
4277,Experimental results show that the method outperforms the state of art methods in terms of crawling capability and breaks through the assumption of full-text search implied by existing methods.,result,3
4278,"In this paper, the recent progress on the understandings of the switching mechanisms in oxide resistive switching memory (RRAM) is reviewed.",objective,1
4279,"Several representative device modeling approaches including numerical discretized models, numerical continuous models and analytical compact models are discussed using HfOx bipolar RRAM as a model system.",method,2
4280,The future challenges of RRAM modeling are finally discussed.,result,3
4281,This paper addresses the Internet of Things.,background,0
4282,Main enabling factor of this promising paradigm is the integration of several technologies and communications solutions.,background,0
4283,"Identification and tracking technologies, wired and wireless sensor and actuator networks, enhanced communication protocols (shared with the Next Generation Internet), and distributed intelligence for smart objects are just the most relevant.",background,0
4284,"As one can easily imagine, any serious contribution to the advance of the Internet of Things must necessarily be the result of synergetic activities conducted in different fields of knowledge, such as telecommunications, informatics, electronics and social science.",background,0
4285,"In such a complex scenario, this survey is directed to those who want to approach this complex discipline and contribute to its development.",objective,1
4286,Different visions of this Internet of Things paradigm are reported and enabling technologies reviewed.,method,2
4287,What emerges is that still major issues shall be faced by the research community.,method,2
4288,The most relevant among them are addressed in details.,result,3
4289,2010 Elsevier B.V. All rights reserved.,other,4
4290,"In modern face recognition, the conventional pipeline consists of four stages: detect => align => represent => classify.",background,0
4291,"We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network.",objective,1
4292,"This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers.",result,3
4293,"Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4, 000 identities.",result,3
4294,"The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier.",background,0
4295,"Our method reaches an accuracy of 97.35% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27%, closely approaching human-level performance.",method,2
4296,"The logic construction of a double-edge-triggered (DET) flip-flop, which can receive input signal at two levels of the clock, is analyzed and a new circuit design of CMOS DET flip-flop is proposed.",objective,1
4297,"Simulation using SPICE and a 1p technology shows that this DET flip-flop has ideal logic functionality, a simpler structure, lower delay time, and higher maximum data rate compared to other existing CMOS DET flip-flops.",method,2
4298,"By simulating and comparing the proposed DET flipflop with the traditional single-edge-triggered (SET) flip-flop, it is shown that the proposed DET flip-flop reduces power dissipation by half while keeping the same date rate.",result,3
4299,Crowdsourcing systems which utilize the human intelligence to solve complex tasks have gained considerable interest and adoption in recent years.,background,0
4300,"However, the majority of existing crowdsourcing systems rely on central servers, which are subject to the weaknesses of traditional trust-based model, such as single point of failure.",background,0
4301,They are also vulnerable to distributed denial of service (DDoS) and Sybil attacks due to malicious users involvement.,background,0
4302,"In addition, high service fees from the crowdsourcing platform may hinder the development of crowdsourcing.",background,0
4303,How to address these potential issues has both research and substantial value.,background,0
4304,"In this paper, we conceptualize a blockchain-based decentralized framework for crowdsourcing named CrowdBC, in which a requester’s task can be solved by a crowd of workers without relying on any third trusted institution, users’ privacy can be guaranteed and only low transaction fees are required.",method,2
4305,"In particular, we introduce the architecture of our proposed framework, based on which we give a concrete scheme.",method,2
4306,We further implement a software prototype on Ethereum public test network with real-world dataset.,method,2
4307,"Experiment results show the feasibility, usability and scalability of our proposed crowdsourcing system.",result,3
4308,"Reconstructing shape and reflectance properties from images is a highly under-constrained problem, and has previously been addressed by using specialized hardware to capture calibrated data or by assuming known (or highly constrained) shape or reflectance.",background,0
4309,"In contrast, we demonstrate that we can recover non-Lambertian, spatially-varying BRDFs and complex geometry belonging to any arbitrary shape class, from a single RGB image captured under a combination of unknown environment illumination and flash lighting.",background,0
4310,We achieve this by training a deep neural network to regress shape and reflectance from the image.,objective,1
4311,"Our network is able to address this problem because of three novel contributions: first, we build a large-scale dataset of procedurally generated shapes and real-world complex SVBRDFs that approximate real world appearance well.",method,2
4312,"Second, single image inverse rendering requires reasoning at multiple scales, and we propose a cascade network structure that allows this in a tractable manner.",method,2
4313,"Finally, we incorporate an in-network rendering layer that aids the reconstruction task by handling global illumination effects that are important for real-world scenes.",method,2
4314,"Together, these contributions allow us to tackle the entire inverse rendering problem in a holistic manner and produce state-of-the-art results on both synthetic and real data.",result,3
4315,"The design of electromagnetic interference (EMI) input filters, needed for switched power converters to fulfill the regulatory standards, is typically associated with high development effort.",background,0
4316,This paper presents a guideline for a simplified differential-mode (DM) filter design.,background,0
4317,"First, a procedure to estimate the required filter attenuation based on the total input rms current using only a few equations is given.",method,2
4318,"Second, a volume optimization of the needed DM filter based on the previously calculated filter attenuation and volumetric component parameters is introduced.",method,2
4319,It is shown that a minimal volume can be found for a certain optimal number of filter stages.,method,2
4320,"The considerations are exemplified for two single-phase power factor correction converters operated in continuous and discontinuous conduction modes, respectively.",result,3
4321,"Finally, EMI measurements done with a 300-W power converter prototype prove the proposed filter design method.",result,3
4322,Computer Forensics is essential for the successful prosecution of computer criminals.,background,0
4323,For a forensic investigation to be performed successfully there are a number of important steps that have to be considered and taken.,background,0
4324,"The aim of this paper is to define a clear, step-by-step framework for the collection of evidence suitable for presentation in a court of law.",objective,1
4325,"Existing forensic models will be surveyed and then adapted to create a specific application framework for single computer, entry point forensics.",method,2
4326,"Zero-shot methods in language, vision and other domains rely on a cross-space mapping function that projects vectors from the relevant feature space (e.g., visualfeature-based image representations) to a large semantic word space (induced in an unsupervised way from corpus data), where the entities of interest (e.g., objects images depict) are labeled with the words associated to the nearest neighbours of the mapped vectors.",background,0
4327,"Zero-shot cross-space mapping methods hold great promise as a way to scale up annotation tasks well beyond the labels in the training data (e.g., recognizing objects that were never seen in training).",method,2
4328,"However, the current performance of cross-space mapping functions is still quite low, so that the strategy is not yet usable in practical applications.",method,2
4329,"In this paper, we explore some general properties, both theoretical and empirical, of the cross-space mapping function, and we build on them to propose better methods to estimate it.",result,3
4330,"In this way, we attain large improvements over the state of the art, both in cross-linguistic (word translation) and cross-modal (image labeling) zero-shot experiments.",result,3
4331,"A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented.",objective,1
4332,Multiscale image features are combined into a single topographical saliency map.,method,2
4333,A dynamical neural network then selects attended locations in order of decreasing saliency.,method,2
4334,"The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.",result,3
4335,"In this paper, we study the use of recurrent neural networks (RNNs) for modeling and forecasting time series.",background,0
4336,"We first illustrate the fact that standard sequence-to-sequence RNNs neither capture well periods in time series nor handle well missing values, even though many real life times series are periodic and contain missing values.",background,0
4337,We then propose an extended attention mechanism that can be deployed on top of any RNN and that is designed to capture periods and make the RNN more robust to missing values.,method,2
4338,We show the effectiveness of this novel model through extensive experiments with multiple univariate and multivariate datasets.,result,3
4339,The high cost of attracting new customers on the Internet and the relative difficulty in retaining them make customer loyalty an essential asset for many online vendors.,background,0
4340,"In the non-Internet marketplace, customer loyalty is primarily the product of superior service quality and the trust that such service entails.",background,0
4341,This study examines whether the same applies with online vendors even though their service is provided by a website interface notably lacking a human service provider.,method,2
4342,"As hypothesized, customer loyalty to a specific online vendor increased with perceived better service quality both directly and through increased trust.",method,2
4343,"However, the data suggest that the five dimensions of service quality in SERVQUAL collapse to three with online service quality: (1) tangibles, (2) a combined dimension of responsiveness, reliability, and assurance, and (3) empathy.",result,3
4344,"The first dimension is the most important one in increasing customer loyalty, and the second in increasing customer trust.",objective,1
4345,Implications are discussed.,other,4
4346,"We recently reported a successful correlation of the normal boiling points of 298 organic compounds containing O, N, Cl, and Br with two molecular descriptors.",background,0
4347,"1 In the present study the applicability of these two descriptors for the prediction of boiling points for various other classes of organic compounds was investigated further by employing a diverse data set of 612 organic compounds containing C, H, N, O, S, F, Cl, Br, and I. The data set was divided into 9 subsets, and additional descriptors were sought for each subset, which, together with the gravitation index and the charged surface area of hydrogen-donor atoms, would model the boiling points.",objective,1
4348,The additional descriptors were then each tested for global relevance and retained only if this was found.,method,2
4349,A final eight-parameter correlation model was thus deduced which had R2 ) 0.965 and a standard error of 15.5 K approaching the estimated average experimental error for the data set.,method,2
4350,The model appears to be general for a wide variety of organic compounds.,result,3
4351,The determinantal point process (DPP) is an elegant probabilistic model of repulsion with applications in various machine learning tasks including summarization and search.,background,0
4352,"However, the maximum a posteriori (MAP) inference for DPP which plays an important role in many applications is NP-hard, and even the popular greedy algorithm can still be too computationally expensive to be used in largescale real-time scenarios.",background,0
4353,"To overcome the computational challenge, in this paper, we propose a novel algorithm to greatly accelerate the greedy MAP inference for DPP.",objective,1
4354,"In addition, our algorithm also adapts to scenarios where the repulsion is only required among nearby few items in the result sequence.",objective,1
4355,We apply the proposed algorithm to generate relevant and diverse recommendations.,method,2
4356,"Experimental results show that our proposed algorithm is significantly faster than state-of-the-art competitors, and provides a better relevance-diversity trade-off on several public datasets, which is also confirmed in an online A/B test.",result,3
4357,"European aircraft manufacturer, Airbus, has started a program to develop the largest aircraft ever built, the Airbus A380, which would be able to carry between 550 to 800 passengers on two decks.",background,0
4358,The six components of the airplane are to be produced in different European cities.,background,0
4359,"They need to be transported from these cities to Toulouse, France, for assembly, and several means of transportation have been investigated.",background,0
4360,"The sizes of the freights, the length of the itinerary, and the narrowness of the critical passages constitute a challenge that classical transportation techniques in the domain of oversized convoys cannot easily overcome.",background,0
4361,"Therefore, Airbus and the French national agency in charge of road management launched a research and development project divided into two parts.",background,0
4362,The objective of the first part is to adapt functions first to develop for mobile robots to the complex kinematics of trailer-truck systems and integrating these functions into a software platform.,objective,1
4363,The second part of the project aims to define and develop a computer-aided driving system on board the vehicles in order to help the drivers carry out their task.,objective,1
4364,"This paper provides a brief overview of the state of the art in trajectory planning for mobile robots and vehicles, and discusses the development of original solutions to address both the kinematic complexity of one of the vehicles and the need to optimize the distance to obstacles.",method,2
4365,"Malicious URL, a.k.a.",background,0
4366,"malicious website, is a common and serious threat to cybersecurity.",background,0
4367,"Malicious URLs host unsolicited content (spam, phishing, drive-by exploits, etc.) and lure unsuspecting users to become victims of scams (monetary loss, theft of private information, and malware installation), and cause losses of billions of dollars every year.",background,0
4368,It is imperative to detect and act on such threats in a timely manner.,background,0
4369,"Traditionally, this detection is done mostly through the usage of blacklists.",background,0
4370,"However, blacklists cannot be exhaustive, and lack the ability to detect newly generated malicious URLs.",background,0
4371,"To improve the generality of malicious URL detectors, machine learning techniques have been explored with increasing attention in recent years.",background,0
4372,This article aims to provide a comprehensive survey and a structural understanding of Malicious URL Detection techniques using machine learning.,objective,1
4373,"We present the formal formulation of Malicious URL Detection as a machine learning task, and categorize and review the contributions of literature studies that addresses different dimensions of this problem (feature representation, algorithm design, etc.).",method,2
4374,"Further, this article provides a timely and comprehensive survey for a range of different audiences, not only for machine learning researchers and engineers in academia, but also for professionals and practitioners in cybersecurity industry, to help them understand the state of the art and facilitate their own research and practical applications.",method,2
4375,"In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words.",background,0
4376,"Those distributions are called ""topics"" because, when fit to data, they capture the salient themes that run through the collection.",background,0
4377,"We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process (HDP).",method,2
4378,We discuss two extensions of topic models to time-series data-one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change.,method,2
4379,"Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis.",result,3
4380,"Nowadays, the use of agile software development methods like Scrum is common in industry and academia.",background,0
4381,"Considering the current attacking landscape, it is clear that developing secure software should be a main concern in all software development projects.",background,0
4382,"In traditional software projects, security issues require detailed planning in an initial planning phase, typically resulting in a detailed security analysis (e.g., threat and risk analysis), a security architecture, and instructions for security implementation (e.g., specification of key sizes and cryptographic algorithms to use).",background,0
4383,"Agile software development methods like Scrum are known for reducing the initial planning phases (e.g., sprint 0 in Scrum) and for focusing more on producing running code.",method,2
4384,Scrum is also known for allowing fast adaption of the emerging software to changes of customer wishes.,background,0
4385,"For security, this means that it is likely that there are no detailed security architecture or security implementation instructions from the start of the project.",background,0
4386,It also means that a lot of design decisions will be made during the runtime of the project.,background,0
4387,"Hence, to address security in Scrum, it is necessary to consider security issues throughout the whole software development process.",background,0
4388,Secure Scrum is a variation of the Scrum framework with special focus on the development of secure software throughout the whole software development process.,objective,1
4389,It puts emphasis on implementation of security related issues without the need of changing the underlying Scrum process or influencing team dynamics.,result,3
4390,The term “Distributed Software Engineering” is ambiguous .,background,0
4391,"It includes both the engineering of distributed software and the process of distributed development of software, such as cooperative work.",background,0
4392,"This paper concentrates on the former, giving an indication of the special needs and rewards in distributed computing.",objective,1
4393,"In essence, we argue that the structure of these systems as interacting components is a blessing which forces software engineers towards compositional techniques which offer the best hope for constructing scalable and evolvable systems in an incremental manner .",method,2
4394,"We offer some guidance and recommendations as to the approaches which seem most appropriate, particularly in languages for distributed programming, specification and analysis techniques for modelling and distributed paradigms for",method,2
4395,In this paper we report on the development of an efficient and portable implementation of Strassen's matrix multiplication algorithm for matrices of arbitrary size.,background,0
4396,"Our technique for defining the criterion which stops the recursions is more detailed than those generally used, thus allowing enhanced performance for a larger set of input sizes.",method,2
4397,"In addition, we deal with odd matrix dimensions using a method whose usefulness had previously been in question and had not so far been demonstrated.",method,2
4398,"Our memory requirements have also been reduced, in certain cases by 40 to more than 70 percent over other similar implementations.",background,0
4399,"We measure performance of our code on the IBM RS/6000, CRAY YMP C90, and CRAY T3D single processor, and offer comparisons to other codes.",method,2
4400,"Finally, we demonstrate the usefulness of our implementation by using it to perform the matrix multiplications in a large application code.",result,3
4401,"We present Swapnet, a framework to transfer garments across images of people with arbitrary body pose, shape, and clothing.",background,0
4402,Garment transfer is a challenging task that requires (i) disentangling the features of the clothing from the body pose and shape and (ii) realistic synthesis of the garment texture on the new body.,background,0
4403,We present a neural network architecture that tackles these sub-problems with two task-specific sub-networks.,background,0
4404,"Since acquiring pairs of images showing the same clothing on different bodies is difficult, we propose a novel weaklysupervised approach that generates training pairs from a single image via data augmentation.",objective,1
4405,We present the first fully automatic method for garment transfer in unconstrained images without solving the difficult 3D reconstruction problem.,method,2
4406,We demonstrate a variety of transfer results and highlight our advantages over traditional image-to-image and anal-,result,3
4407,Our technology keeps advancing towards a future where everything is connected together.,background,0
4408,The Internet of Things (IoT) goal is to make every device accessible from the Internet.,objective,1
4409,"Even the most common electrical appliances, such as ovens, light bulbs, will have their own IP address,, will be reachable remotely.",objective,1
4410,"While this enhanced connectivity will definitely improve our quality of life, it also raises serious security, privacy, trustworthiness questions, the resource constrained nature of IoT entities makes traditional security techniques impractical.",method,2
4411,"In this paper, we propose an intrusion detection architecture for the IoT. We discuss the feasibility of employing a commodity device as the core component of the architecture.",method,2
4412,"In particular, we evaluated the performance of the Raspberry Pi, one of the most used commodity single-board computers, while running Snort, a widely known, open source Intrusion Detection System (IDS).",result,3
4413,"Our experiments show that our proposed architecture based on resource constrained devices, such as the Raspberry Pi, can effectively serve as IDS in a distributed system such as IoT.",result,3
4414,Young adults (18–25 years old) spend a majority of their waking hours with technology and young adulthood is an important developmental time period for establishing lasting health behaviors.,background,0
4415,"Considering the relevance of technology and health during young adulthood the current study explored young adults (N = 34) perceptions of social media’s (e.g., social networking) influence on their health behaviors (i.e., diet and exercise) using a social ecological framework.",result,3
4416,Data was collected through eight focus groups and four individual interviews.,method,2
4417,Three themes were identified through phenomenological qualitative analysis.,method,2
4418,Young adults perceived that technology could be both a barrier and a motivator for exercise.,method,2
4419,"Social media was also credited with expanding food choices through creating access to a variety of recipes, providing a venue for showcasing the food young adults eat or prepare, and distracting young adults from making positive food choices.",method,2
4420,Participants also reported that it is common to post statuses or pictures relating to exercise practices on social media during young adulthood.,result,3
4421,"Young adults indicated that these posts could be inspirational or misused, depending on the context.",result,3
4422,Results are discussed in terms of theory and preliminary implications.,result,3
4423,2014 Elsevier Ltd.,other,4
4424,We propose a novel approach to synthesizing images that are effective for training object detectors.,objective,1
4425,"Starting from a small set of real images, our algorithm estimates the rendering parameters required to synthesize similar images given a coarse 3D model of the target object.",method,2
4426,"These parameters can then be reused to generate an unlimited number of training images of the object of interest in arbitrary 3D poses, which can then be used to increase classification performances.",result,3
4427,"A key insight of our approach is that the synthetically generated images should be similar to real images, not in terms of image quality, but rather in terms of features used during the detector training.",method,2
4428,"We show in the context of drone, plane, and car detection that using such synthetically generated images yields significantly better performances than simply perturbing real images or even synthesizing images in such way that they look very realistic, as is often done when only limited amounts of training data are available.",result,3
4429,2015 Elsevier Inc. All rights reserved.,other,4
4430,Optimality Theory is a general model of how grammars are structured.,background,0
4431,"This article surveys the motivations for OT, its core principles, and the basics of analysis.",objective,1
4432,It also addresses some frequently asked questions about this theory and offers suggestions for further reading.,objective,1
4433,"Among the various human factors impinging upon making a decision in an uncertain environment, risk and trust are surely crucial ones.",background,0
4434,Several models for trust have been proposed in the literature but few explicitly take risk into account.,background,0
4435,This paper analyses the relationship between the two concepts by first looking at how a decision is made to enter into a transaction based on the risk information.,method,2
4436,We then draw a model of the invested fraction of the capital function of a decision surface.,method,2
4437,We finally define a model of trust composed of a reliability trust as the probability of transaction success and a decision trust derived from the decision surface.,result,3
4438,"In this paper, we present a column-and-constraint generation algorithm to solve twostage robust optimization problems.",objective,1
4439,"Compared with existing Benders-style cutting plane methods, the column-and-constraint generation algorithm is a general procedure with a unified approach to deal with optimality and feasibility.",method,2
4440,A computational study on a twostage robust location-transportation problem shows that it performs an order of magnitude faster.,result,3
4441,A number of image processing techniques (IPTs) have been implemented for detecting civil infrastructure defects to partially replace human-conducted onsite inspections.,method,2
4442,"These IPTs are primarily used to manipulate images to extract defect features, such as cracks in concrete and steel surfaces.",background,0
4443,"However, the extensively varying real-world situations (e.g., lighting and shadow changes) can lead to challenges to the wide adoption of IPTs.",background,0
4444,"To overcome these challenges, this article proposes a vision-based method using a deep architecture of convolutional neural networks (CNNs) for detecting concrete cracks without calculating the defect features.",method,2
4445,"As CNNs are capable of learning image features automatically, the proposed method works without the conjugation of IPTs for extracting features.",method,2
4446,"The designed CNN is trained on 40 K images of 256 × 256 pixel resolutions and, consequently, records with about 98% accuracy.",method,2
4447,The trained CNN is combined with a sliding window technique to scan any image size larger than 256 × 256 pixel resolutions.,method,2
4448,"The robustness and adaptability of the proposed approach are tested on 55 images of 5,888× 3,584 pixel resolutions taken from a different structure which is not used for training and validation processes under various conditions (e.g., strong light spot, shadows, and very thin cracks).",result,3
4449,Comparative studies are conducted to examine the performance of the proposed CNN using traditional Canny and Sobel edge detection methods.,result,3
4450,The results show that the proposed method shows ∗To whom correspondence should be addressed.,result,3
4451,"In order to further advance research within management accounting and integrated information systems (IIS), an understanding of what research has already been done and what research is needed is of particular importance.",objective,1
4452,"The purpose of this paper is to uncover, classify and interpret current research within management accounting and IIS.",objective,1
4453,This is done partly to identify research gaps and propose directions for future research and partly to guide researchers and practitioners investigating and making decisions on how to better synthesise the two areas.,objective,1
4454,Based on the strengths of existing frameworks covering elements of management accounting and IIS a new and more comprehensive theoretical framework is developed.,method,2
4455,This is used as a basis for classifying and presentation of the reviewed literature in structured form.,other,4
4456,The outcome of the review is an identification of research gaps and a proposal of research opportunities within different research paradigms and with the use of different methods.,other,4
4457,© 2007 Elsevier Inc.,other,4
4459,"This chapter describes data mining in finance by discussing financial tasks, specifics of methodologies and techniques in this data mining area.",background,0
4460,"It includes time dependence, data selection, forecast horizon, measures of success, quality of patterns, hypothesis evaluation, problem ID, method profile, attribute-based and relational methodologies.",background,0
4461,The second part of the chapter discusses data mining models and practice in finance.,background,0
4462,"It covers use of neural networks in portfolio management, design of interpretable trading rules and discovering money laundering schemes using decision rules and relational data mining methodology.",objective,1
4463,This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates.,background,0
4464,This work is distinguished by three key contributions.,background,0
4465,The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly.,method,2
4466,"The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers[6].",method,2
4467,The third contribution is a method for combining increasingly more complex classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions.,method,2
4468,The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest.,method,2
4469,In the domain of face detection the system yields detection rates comparable to the best previous systems.,result,3
4470,"Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.",result,3
4471,"Large-pose face alignment is a very challenging problem in computer vision, which is used as a prerequisite for many important vision tasks, e.g, face recognition and 3D face reconstruction.",background,0
4472,"Recently, there have been a few attempts to solve this problem, but still more research is needed to achieve highly accurate results.",background,0
4473,"In this paper, we propose a face alignment method for large-pose face images, by combining the powerful cascaded CNN regressor method and 3DMM.",method,2
4474,"We formulate the face alignment as a 3DMM fitting problem, where the camera projection matrix and 3D shape parameters are estimated by a cascade of CNN-based regressors.",method,2
4475,The dense 3D shape allows us to design pose-invariant appearance features for effective CNN learning.,method,2
4476,"Extensive experiments are conducted on the challenging databases (AFLW and AFW), with comparison to the state of the art.",result,3
4477,Feature selection is an important problem for pattern classification systems.,background,0
4478,We study how to select good features according to the maximal statistical dependency criterion based on mutual information.,background,0
4479,"Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection.",method,2
4480,"Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e.g., wrappers).",method,2
4481,This allows us to select a compact set of superior features at very low cost.,method,2
4482,"We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues).",method,2
4483,The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.,result,3
4484,This paper presents two fuzzy portfolio selection models where the objective is to minimize the downside risk constrained by a given expected return.,objective,1
4485,"We assume that the rates of returns on securities are approximated as LR-fuzzy numbers of the same shape, and that the expected return and risk are evaluated by interval-valued means.",method,2
4486,We establish the relationship between those mean-interval definitions for a given fuzzy portfolio by using suitable ordering relations.,method,2
4487,"Finally, we formulate the portfolio selection problem as a linear program when the returns on the assets are of trapezoidal form.",result,3
4488,© 2006 Elsevier B.V. All rights reserved.,other,4
4489,"We present RINGS, a technique for visualizing large trees.",background,0
4490,We introduce a new ringed circular layout of nodes to make more efficient use of limited display space.,objective,1
4491,"RINGS provides the user with the means to specify areas of primary and secondary focus, and is able to show multiple foci without compromising understanding of the graph.",objective,1
4492,The strength of RINGS is its ability to show more area in focus and more contextual information than existing techniques.,objective,1
4493,We demonstrate the effectiveness of RINGS by applying it to the visualization of a Unix file directory.,result,3
4494,"Stereo matching algorithms usually consist of four steps, including matching cost calculation, matching cost aggregation, disparity calculation, and disparity refinement.",background,0
4495,"Existing CNN-based methods only adopt CNN to solve parts of the four steps, or use different networks to deal with different steps, making them difficult to obtain the overall optimal solution.",method,2
4496,"In this paper, we propose a network architecture to incorporate all steps of stereo matching.",method,2
4497,The network consists of three parts.,method,2
4498,The first part calculates the multi-scale shared features.,method,2
4499,"The second part performs matching cost calculation, matching cost aggregation and disparity calculation to estimate the initial disparity using shared features.",method,2
4500,The initial disparity and the shared features are used to calculate the prior and posterior feature constancy.,method,2
4501,"The initial disparity, the prior and posterior feature constancy are then fed to a sub-network to refine the initial disparity through a Bayesian inference process.",method,2
4502,The proposed method has been evaluated on the Scene Flow and KITTI datasets.,method,2
4503,It achieves the state-of-the-art performance on the KITTI 2012 and KITTI 2015 benchmarks while maintaining a very fast running time.,result,3
4504,It this paper we revisit the fast stylization method introduced in Ulyanov et al. (2016).,background,0
4505,We show how a small change in the stylization architecture results in a significant qualitative improvement in the generated images.,background,0
4506,"The change is limited to swapping batch normalization with instance normalization, and to apply the latter both at training and testing times.",method,2
4507,The resulting method can be used to train high-performance architectures for real-time image generation.,method,2
4508,The code will be made available at https://github.com/DmitryUlyanov/texture_nets.,other,4
4509,Community detection is an important issue due to its wide use in designing network protocols such as data forwarding in Delay Tolerant Networks (DTN) and worm containment in Online Social Networks (OSN).,background,0
4510,"However, most of the existing community detection algorithms focus on binary networks.",background,0
4511,"Since most networks are naturally weighted such as DTN or OSN, in this article, we address the problems of community detection in weighted networks, exploit community for data forwarding in DTN and worm containment in OSN, and demonstrate how community can facilitate these network designs.",background,0
4512,"Specifically, we propose a novel community detection algorithm, and introduce two metrics: intra-centrality and inter-centrality, to characterize nodes in communities, based on which we propose an efficient data forwarding algorithm for DTN and a worm containment strategy for OSN.",method,2
4513,"Extensive trace-driven simulation results show that the proposed community detection algorithm, the data forwarding algorithm, and the worm containment strategy significantly outperform existing works.",result,3
4514,Using big data analytics is generally considered to improve organizational performance.,background,0
4515,"However, we argue here that the role of fit between different organizational resources associated with big data use needs to be better understood in order to explore how organizations can create value, increase agility, and ultimately improve overall performance from the use of big data analytics.",background,0
4516,"This research-inprogress study draws on the theory of resource-based view (RBV) and the person-environment (P-E) fit perspective to develop a theoretical model explaining the impacts of fit between various elements including (i.e., tools, data, tasks, employees) on organizational performance.",objective,1
4517,A survey-based methodology is outlined to empirically validate the proposed research model using structural equation modeling techniques.,method,2
4518,Potential contributions from this research to theory and practice are also outlined.,method,2
4519,"This paper discusses Supply Chain Network (SCN) design problem under uncertainty, and presents a critical review of the optimization models proposed in the literature.",objective,1
4520,"Some drawbacks and missing aspects in the literature are pointed out, thus motivating the development of a comprehensive SCN design methodology.",method,2
4521,"Through an analysis of supply chains uncertainty sources and risk exposures, the paper reviews key random environmental factors and discusses the nature of major disruptive events threatening SCN.",method,2
4522,"It also discusses relevant strategic SCN design evaluation criteria, and it reviews their use in existing models.",method,2
4523,We argue for the assessment of SCN robustness as a necessary condition to ensure sustainable value creation.,result,3
4524,"Several definitions of robustness, responsiveness and resilience are reviewed, and the importance of these concepts for SCN design is discussed.",method,2
4525,This paper contributes to framing the foundations for a robust SCN design methodology.,result,3
4526,"Convolutional neural networks (CNNs) have recently been very successful in a variety of computer vision tasks, especially on those linked to recognition.",background,0
4527,Optical flow estimation has not been among the tasks CNNs succeeded at.,background,0
4528,In this paper we construct CNNs which are capable of solving the optical flow estimation problem as a supervised learning task.,method,2
4529,We propose and compare two architectures: a generic architecture and another one including a layer that correlates feature vectors at different image locations.,objective,1
4530,"Since existing ground truth data sets are not sufficiently large to train a CNN, we generate a large synthetic Flying Chairs dataset.",method,2
4531,"We show that networks trained on this unrealistic data still generalize very well to existing datasets such as Sintel and KITTI, achieving competitive accuracy at frame rates of 5 to 10 fps.",method,2
4532,"There is an ongoing discussion in HCI on the need for new theories, methods and techniques to assist researchers and practitioners in both the design of better digital artifacts and effective evaluation of them.",background,0
4533,"As part of this discussion we observe a recent trend where researchers from the IT domain present various definitions of ecologies, approaching the question, “What is a digital ecology?",background,0
4534,” from various perspectives.,background,0
4535,"This paper reviews existing definitions, comparing their strengthens and weaknesses and presents a unified definition of digital ecologies, through a theoretical discussion based on systems thinking.",objective,1
4536,It is our ambition that this paper will inspire deeper consideration on what constitutes a digital ecology and how this view of technology affects existing design and evaluation methods and techniques.,result,3
4537,We investigated how shape features in natural images influence emotions aroused in human beings.,background,0
4538,"Shapes and their characteristics such as roundness, angularity, simplicity, and complexity have been postulated to affect the emotional responses of human beings in the field of visual arts and psychology.",background,0
4539,"However, no prior research has modeled the dimensionality of emotions aroused by roundness and angularity.",background,0
4540,Our contributions include an in depth statistical analysis to understand the relationship between shapes and emotions.,method,2
4541,Through experimental results on the International Affective Picture System (IAPS) dataset we provide evidence for the significance of roundness-angularity and simplicity-complexity on predicting emotional content in images.,result,3
4542,We combine our shape features with other state-of-the-art features to show a gain in prediction and classification accuracy.,method,2
4543,We model emotions from a dimensional perspective in order to predict valence and arousal ratings which have advantages over modeling the traditional discrete emotional categories.,method,2
4544,"Finally, we distinguish images with strong emotional content from emotionally neutral images with high accuracy.",result,3
4545,"This artic,le introduces Adaptive Resonance Theor) 2-A (ART 2-A), an efjCicient algorithm that emulates the self-organizing pattern recognition and hypothesis testing properties of the ART 2 neural network architect~~rc, hut at a speed two to three orders of magnitude fbster.",background,0
4546,Analysis and simulations show how’ the ART 2-A systems correspond to ART 2 rivnamics at both the fast-learn limit and at intermediate learning rate.r.,background,0
4547,"Intermediate ieurning rates permit fust commitment of category nodes hut slow recoding, analogous to properties of word frequency effects.",background,0
4548,"encoding specificity ef@cts, and episodic memory.",method,2
4549,Better noise tolerunce is hereby achieved ti’ithout a loss of leurning stability.,method,2
4550,The ART 2 and ART 2-A systems are contrasted with the leader algorithm.,method,2
4551,The speed of ART 2-A makes pructical the use of ART 2 modules in large scale neural computation.,method,2
4552,"Keywords-Neural networks, Pattern recognition.",method,2
4553,Category formation.,other,4
4554,"Fast learning, Adaptive resonance.",other,4
4555,User profiles or user models are vital in many areas in which it is essential to obtain knowledge about users of software applications.,background,0
4556,"Examples of these areas are intelligent agents, adaptive systems, intelligent tutoring systems, recommender systems, intelligent e-commerce applications, and knowledge management systems.",background,0
4557,In this chapter we study the main issues regarding user profiles from the perspectives of these research fields.,objective,1
4558,We examine what information constitutes a user profile; how the user profile is represented; how the user profile is acquired and built; and how the profile information is used.,method,2
4559,We also discuss some challenges and future trends in the intelligent user profiling area.,objective,1
4560,Neural network models have been demonstrated to be capable of achieving remarkable performance in sentence and document modeling.,background,0
4561,"Convolutional neural network (CNN) and recurrent neural network (RNN) are two mainstream architectures for such modeling tasks, which adopt totally different ways of understanding natural languages.",background,0
4562,"In this work, we combine the strengths of both architectures and propose a novel and unified model called C-LSTM for sentence representation and text classification.",method,2
4563,"C-LSTM utilizes CNN to extract a sequence of higher-level phrase representations, and are fed into a long short-term memory recurrent neural network (LSTM) to obtain the sentence representation.",method,2
4564,C-LSTM is able to capture both local features of phrases as well as global and temporal sentence semantics.,method,2
4565,We evaluate the proposed architecture on sentiment classification and question classification tasks.,background,0
4566,The experimental results show that the C-LSTM outperforms both CNN and LSTM and can achieve excellent performance on these tasks.,result,3
4567,Millimeter wave (mmWave) signals experience orders-of-magnitude more pathloss than the microwave signals currently used in most wireless applications and all cellular systems.,background,0
4568,"MmWave systems must therefore leverage large antenna arrays, made possible by the decrease in wavelength, to combat pathloss with beamforming gain.",background,0
4569,"Beamforming with multiple data streams, known as precoding, can be used to further improve mmWave spectral efficiency.",background,0
4570,Both beamforming and precoding are done digitally at baseband in traditional multi-antenna systems.,background,0
4571,"The high cost and power consumption of mixed-signal devices in mmWave systems, however, make analog processing in the RF domain more attractive.",background,0
4572,This hardware limitation restricts the feasible set of precoders and combiners that can be applied by practical mmWave transceivers.,background,0
4573,"In this paper, we consider transmit precoding and receiver combining in mmWave systems with large antenna arrays.",method,2
4574,We exploit the spatial structure of mmWave channels to formulate the precoding/combining problem as a sparse reconstruction problem.,method,2
4575,"Using the principle of basis pursuit, we develop algorithms that accurately approximate optimal unconstrained precoders and combiners such that they can be implemented in low-cost RF hardware.",method,2
4576,"We present numerical results on the performance of the proposed algorithms and show that they allow mmWave systems to approach their unconstrained performance limits, even when transceiver hardware constraints are considered.",result,3
4577,"In this paper, we demonstrate that image reconstruction can be expressed in terms of neural networks.",background,0
4578,We show that filtered backprojection can be mapped identically onto a deep neural network architecture.,background,0
4579,"As for the case of iterative reconstruction, the straight forward realization as matrix multiplication is not feasible.",method,2
4580,"Thus, we propose to compute the back-projection layer efficiently as fixed function and its gradient as projection operation.",method,2
4581,This allows a data-driven approach for joint optimization of correction steps in projection domain and image domain.,method,2
4582,"As a proof of concept, we demonstrate that we are able to learn weightings and additional filter layers that consistently reduce the reconstruction error of a limited angle reconstruction by a factor of two while keeping the same computational complexity as filtered back-projection.",result,3
4583,We believe that this kind of learning approach can be extended to any common CT artifact compensation heuristic and will outperform hand-crafted artifact correction methods in the future.,result,3
4584,Human emotions and their modelling are increasingly understood to be a crucial aspect in the development of intelligent systems.,background,0
4585,"Over the past years, in fact, the adoption of psychological models of emotions has become a common trend among researchers and engineers working in the sphere of affective computing.",background,0
4586,"Because of the elusive nature of emotions and the ambiguity of natural language, however, psychologists have developed many different affect models, which often are not suitable for the design of applications in fields such as affective HCI, social data mining, and sentiment analysis.",method,2
4587,"To this end, we propose a novel biologically-inspired and psychologically-motivated emotion categorisation model that goes beyond mere categorical and dimensional approaches.",objective,1
4588,"Such model represents affective states both through labels and through four independent but concomitant affective dimensions, which can potentially describe the full range of emotional experiences that are rooted in any of us.",result,3
4589,"The combined use of 3D scanning lasers with 2D cameras has become increasingly popular in mobile robotics, as the sparse depth measurements of the former augment the dense color information of the latter.",background,0
4590,"Sensor fusion requires precise 6DOF transforms between the sensors, but hand-measuring these values is tedious and inaccurate.",background,0
4591,"In addition, autonomous robots can be rendered inoperable if their sensors’ calibrations change over time.",background,0
4592,"Yet previously published camera-laser calibration algorithms are offline only, requiring significant amounts of data and/or specific calibration targets; they are thus unable to correct calibration errors that occur during live operation.",background,0
4593,"In this paper, we introduce two new real-time techniques that enable camera-laser calibration online, automatically, and in arbitrary environments.",method,2
4594,The first is a probabilistic monitoring algorithm that can detect a sudden miscalibration in a fraction of a second.,method,2
4595,"The second is a continuous calibration optimizer that adjusts transform offsets in real time, tracking gradual sensor drift as it occurs.",method,2
4596,"Although the calibration objective function is not globally convex and cannot be optimized in real time, in practice it is always locally convex around the global optimum, and almost everywhere else.",objective,1
4597,"Thus, the local shape of the objective function at the current parameters can be used to determine whether the sensors are calibrated, and allows the parameters to be adjusted gradually so as to maintain the global optimum.",method,2
4598,"In several online experiments on thousands of frames in real markerless scenes, our method automatically detects miscalibrations within one second of the error exceeding .25 deg or 10cm, with an accuracy of 100%.",method,2
4599,"This article covers the Xbox 360's high-level technical requirements, a short system overview, and details of the CPU and the GPU.",background,0
4600,The Xbox 360 contains an aggressive hardware architecture and implementation targeted at game console workloads.,background,0
4601,The core silicon implements the product designers' goal of providing game developers a hardware platform to implement their next-generation game ambitions.,method,2
4602,"The core chips include the standard conceptual blocks of CPU, graphics processing unit (GPU), memory, and I/O. Each of these components and their interconnections are customized to provide a user-friendly game console product.",method,2
4603,The authors describe their architectural trade-offs and summarize the system's software programming support,method,2
4604,Determinants of online consumer’s purchase decisions are of long-term interest to researchers and practitioners.,background,0
4605,"Since product photos directly aid consumers’ understanding of products, retailers often put a lot of effort into polishing them.",background,0
4606,"However, there is limited research on the impact of product photos on purchase decisions.",background,0
4607,"Most previous studies took an experiment-based approach, which delivered strict theories on some aspects of product photos.",background,0
4608,This research takes advantage of image-processing techniques to study product photos’ impact.,objective,1
4609,These techniques allow us to investigate a large set of photo characteristics simultaneously in an empirical study.,method,2
4610,"To rule out possible confounding factors, we collect a dataset from a social shopping Website, which has a simple interface allowing users to judge products mainly based on their photos.",result,3
4611,"We examine product photo characteristics from the aspects of information, emotion, aesthetics, and social presence.",result,3
4612,"We found that consumers prefer product photos with a larger key object, lower entropy on key objects, a warmer color, a higher contrast, a higher depth-of-field, and more social presences.",result,3
4613,This research introduces a Big Data-based approach to study the impact of e-commerce systems’ visual features on consumers.,result,3
4614,Here we introduce a new model of natural textures based on the feature spaces of convolutional neural networks optimised for object recognition.,objective,1
4615,Samples from the model are of high perceptual quality demonstrating the generative power of neural networks trained in a purely discriminative fashion.,objective,1
4616,"Within the model, textures are represented by the correlations between feature maps in several layers of the network.",objective,1
4617,We show that across layers the texture representations increasingly capture the statistical properties of natural images while making object information more and more explicit.,result,3
4618,The model provides a new tool to generate stimuli for neuroscience and might offer insights into the deep representations learned by convolutional neural networks.,result,3
4619,The widespread deployment and use of wireless data communications causes the need for middleware to interconnect the components that comprise a mobile application.,background,0
4620,Middleware for mobile computing must deal with the increased complexity that comes with a dynamically changing population of application components and the resulting dynamic reconfiguration of the connections between these components.,background,0
4621,"This paper presents an overview of two communication paradigms that are well suited as the basis for middleware for mobile computing, namely the event-based communication model and proximity-based group communication.",objective,1
4622,Internet addiction is a recently recognized disorder which has received increasing attention worldwide over the past two decades.,background,0
4623,"This focus has led to the development of several screening tools measuring different aspects of Internet use, and more particularly Internet addiction.",background,0
4624,"However, a synthesis of the information regarding the validity and usefulness of these different scales is lacking and would help inform researchers and clinicians in their choice of measures when assessing for Internet addiction.",background,0
4625,The main goal of this study was therefore to identify all the existing measures of Internet addiction and to review the psychometric properties of the most frequently used ones.,objective,1
4626,"Five electronic databases were searched using the key words: internet use disorder, Internet addiction, problematic internet use, pathologic internet use, cyber dependence, and scale, test, questionnaire, tool, assessment and inventory.",method,2
4627,"Forty-five tools assessing Internet addiction were identified, of which only seventeen had been evaluated more than once in terms of their psychometric properties.",method,2
4628,Most of the existing scales for Internet addiction require further validation work but some of them already demonstrate promising psychometric properties.,result,3
4629,"Given the interest in this phenomenon, it seems important for the field to promote the use of validated and well-established measures.",result,3
4631,We present purely functional implementations of queues and double-ended queues (deques) requiring only O(1) time per operation in the worst case.,objective,1
4632,Our algorithms are considerably simpler than previous designs with the same bounds.,background,0
4633,The inspiration for our approach is the incremental behavior of certain functions on lazy lists.,method,2
4634,The growing relevance of data quality has revealed the need for adequate measurement since quantifying data quality is essential for planning quality measures in an economic manner.,background,0
4635,This paper analyzes how data quality can be quantified with respect to particular dimensions.,objective,1
4636,"Firstly, several requirements are stated (e.g. normalization, interpretability) for designing adequate metrics.",method,2
4637,"Secondly, we analyze metrics in literature and discuss them with regard to the requirements.",method,2
4638,"Thirdly, based on existing approaches new metrics for the dimensions correctness and timeliness that meet the defined requirements are designed.",method,2
4639,"Finally, we evaluate our metric for timeliness in a case study: In cooperation with a major German mobile services provider, the approach was applied in campaign management to improve both success rates and profits.",result,3
4640,Accurate maps of the static environment are essential for many advanced driver-assistance systems.,background,0
4641,A new method for the fast computation of occupancy grid maps with laser range-finders and radar sensors is proposed.,method,2
4642,The approach utilizes the Graphics Processing Unit to overcome the limitations of classical occupancy grid computation in automotive environments.,method,2
4643,It is possible to generate highly accurate grid maps in just a few milliseconds without the loss of sensor precision.,method,2
4644,"Moreover, in the case of a lower resolution radar sensor it is shown that it is suitable to apply super-resolution algorithms to achieve the accuracy of a higher resolution laser-scanner.",method,2
4645,"Finally, a novel histogram based approach for road boundary detection with lidar and radar sensors is presented.",method,2
4646,Big data refers to data volumes in the range of exabytes (1018) and beyond.,background,0
4647,Such volumes exceed the capacity of current on-line storage systems and processing systems.,background,0
4648,"Data, information, and knowledge are being created and collected at a rate that is rapidly approaching the exabyte/year range.",result,3
4649,"But, its creation and aggregation are accelerating and will approach the zettabyte/year range within a few years.",result,3
4650,"Volume is only one aspect of big data; other attributes are variety, velocity, value, and complexity.",result,3
4651,"Storage and data transport are technology issues, which seem to be solvable in the near-term, but represent longterm challenges that require research and new paradigms.",result,3
4652,We analyze the issues and challenges as we begin a collaborative research program into methodologies for big data analysis and design.,result,3
4653,Abstracf-The scale-space technique introduced by Witkin involves generating coarser resolution images by convolving the original image with a Gaussian kernel.,background,0
4654,This approach has a major drawback: it is difficult to obtain accurately the locations of the “semantically meaningful” edges at coarse scales.,background,0
4655,"In this paper we suggest a new definition of scale-space, and introduce a class of algorithms that realize it using a diffusion process.",objective,1
4656,The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing in preference to interregion smoothing.,method,2
4657,It is shown that the “no new maxima should be generated at coarse scales” property of conventional scale space is preserved.,method,2
4658,"As the region boundaries in our approach remain sharp, we obtain a high quality edge detector which successfully exploits global information.",method,2
4659,Experimental results are shown on a number of images.,result,3
4660,"The algorithm involves elementary, local operations replicated over the image making parallel hardware implementations feasible.",result,3
4661,Object proposals are an ensemble of bounding boxes with high potential to contain objects.,background,0
4662,"In order to determine a small set of proposals with a high recall, a common scheme is extracting multiple features followed by a ranking algorithm which however, incurs two major challenges: 1) The ranking model often imposes pairwise constraints between each proposal, rendering the problem away from an efficient training/testing phase; 2) Linear kernels are utilized due to the computational and memory bottleneck of training a kernelized model.",method,2
4663,"In this paper, we remedy these two issues by suggesting a kernelized partial ranking model.",method,2
4664,"In particular, we demonstrate that i) our partial ranking model reduces the number of constraints from O(n) to O(nk) where n is the number of all potential proposals for an image but we are only interested in top-k of them that has the largest overlap with the ground truth; ii) we permit non-linear kernels in our model which is often superior to the linear classifier in terms of accuracy.",method,2
4665,"For the sake of mitigating the computational and memory issues, we introduce a consistent weighted sampling (CWS) paradigm that approximates the non-linear kernel as well as facilitates an efficient learning.",method,2
4666,"In fact, as we will show, training a linear CWS model amounts to learning a kernelized model.",method,2
4667,"Extensive experiments demonstrate that equipped with the non-linear kernel and the partial ranking algorithm, recall at top-k proposals can be substantially improved.",result,3
4668,"A new design for an energy harvesting device is proposed in this paper, which enables scavenging energy from radiofrequency (RF) electromagnetic waves.",background,0
4669,"Compared to common alternative energy sources like solar and wind, RF harvesting has the least energy density.",background,0
4670,"The existing state-of-the-art solutions are effective only over narrow frequency ranges, are limited in efficiency response, and require higher levels of input power.",background,0
4671,This paper has a twofold contribution.,objective,1
4672,"First, we propose a dual-stage energy harvesting circuit composed of a seven-stage and ten-stage design, the former being more receptive in the low input power regions, while the latter is more suitable for higher power range.",method,2
4673,"Each stage here is a modified voltage multiplier, arranged in series and our design provides guidelines on component choice and precise selection of the crossover operational point for these two stages between the high (20 dBm) and low power (-20 dBm) extremities.",background,0
4674,"Second, we fabricate our design on a printed circuit board to demonstrate how such a circuit can run a commercial Mica2 sensor mote, with accompanying simulations on both ideal and non-ideal conditions for identifying the upper bound on achievable efficiency.",result,3
4675,"With a simple yet optimal dual-stage design, experiments and characterization plots reveal approximately 100% improvement over other existing designs in the power range of -20 to 7 dBm.",result,3
4676,"Internet of Things (IoT) is a new paradigm that integrates the Internet and physical objects belonging to different domains such as home automation, industrial process, human health and environmental monitoring.",background,0
4677,"It deepens the presence of Internetconnected devices in our daily activities, bringing, in addition to many benefits, challenges related to security issues.",background,0
4678,"For more than two decades, Intrusion Detection Systems (IDS) have been an important tool for the protection of networks and information systems.",method,2
4679,"However, applying traditional IDS techniques to IoT is difficult due to its particular characteristics such as constrained-resource devices, specific protocol stacks, and standards.",method,2
4680,"In this paper, we present a survey of IDS research efforts for IoT. Our objective is to identify leading trends, open issues, and future research possibilities.",objective,1
4681,"We classified the IDSs proposed in the literature according to the following attributes: detection method, IDS placement strategy, security threat and validation strategy.",method,2
4682,"We also discussed the different possibilities for each attribute, detailing aspects of works that either propose specific IDS schemes for IoT or develop attack detection strategies for IoT threats that might be embedded in IDSs.",result,3
4683,This paper deals with the problem of airfare prices prediction.,background,0
4684,"For this purpose a set of features characterizing a typical flight is decided, supposing that these features affect the price of an air ticket.",method,2
4685,"The features are applied to eight state of the art machine learning (ML) models, used to predict the air tickets prices, and the performance of the models is compared to each other.",method,2
4686,"Along with the prediction accuracy of each model, this paper studies the dependency of the accuracy on the feature set used to represent an airfare.",method,2
4687,For the experiments a novel dataset consisting of 1814 data flights of the Aegean Airlines for a specific international destination (from Thessaloniki to Stuttgart) is constructed and used to train each ML model.,result,3
4688,"The derived experimental results reveal that the ML models are able to handle this regression problem with almost 88% accuracy, for a certain type of flight features.",result,3
4689,Web scraping is the set of techniques used to automatically get some information from a website instead of manually copying it.,background,0
4690,"The goal of a Web scraper is to look for certain kinds of information, extract, and aggregate it into new Web pages.",objective,1
4691,"In particular, scrapers are focused on transforming unstructured data and save them in structured databases.",background,0
4692,"In this paper, among others kind of scraping, we focus on those techniques that extract the content of a Web page.",objective,1
4693,"In particular, we adopt scraping techniques in the Web advertising field.",method,2
4694,"To this end, we propose a collaborative filtering-based Web advertising system aimed at finding the most relevant ads for a generic Web page by exploiting Web scraping.",method,2
4695,"To illustrate how the system works in practice, a case study is presented.",result,3
4696,"This paper introduces GEOS, the first automated system to solve unaltered SAT geometry questions by combining text understanding and diagram interpretation.",objective,1
4697,"We model the problem of understanding geometry questions as submodular optimization, and identify a formal problem description likely to be compatible with both the question text and diagram.",objective,1
4698,GEOS then feeds the description to a geometric solver that attempts to determine the correct answer.,method,2
4699,"In our experiments, GEOS achieves a 49% score on official SAT questions, and a score of 61% on practice questions.1 Finally, we show that by integrating textual and visual information, GEOS boosts the accuracy of dependency and semantic parsing of the question text.",result,3
4700,"Deep learning algorithms are a subset of the machine learning algorithms, which aim at discovering multiple levels of distributed representations.",background,0
4701,"Recently, numerous deep learning algorithms have been proposed to solve traditional artificial intelligence problems.",background,0
4702,This work aims to review the state-of-theart in deep learning algorithms in computer vision by highlighting the contributions and challenges from over 210 recent research papers.,objective,1
4703,"It first gives an overview of various deep learning approaches and their recent developments, and then briefly describes their applications in diverse vision tasks, such as image classification, object detection, image retrieval, semantic segmentation and human pose estimation.",result,3
4704,"Finally, the paper summarizes the future trends and challenges in designing and training deep neural networks.",method,2
4705,& 2015 Elsevier B.V. All rights reserved.,other,4
4706,In recent years the proportion and complexity of software in medical devices has increased considerably.,background,0
4707,This has presented an opportunity for software development organisations to expand into the medical device domain.,background,0
4708,"Due to the high level of risk associated with medical devices, strict regulations must be adhered to in order to market such products.",objective,1
4709,One key aspect of these regulations is the necessity to have in place a Quality Management System to help ensure an organisations’ ability to consistently meet customer and regulatory requirements.,method,2
4710,"This paper presents a roadmap which can be used to assist organisations, wishing to develop medical device software to implement a Quality Management System.",result,3
4711,"Sentence similarity measures play an increasingly important role in text-related research and applications in areas such as text mining, Web page retrieval, and dialogue systems.",background,0
4712,Existing methods for computing sentence similarity have been adopted from approaches used for long text documents.,method,2
4713,"These methods process sentences in a very high-dimensional space and are consequently inefficient, require human input, and are not adaptable to some application domains.",method,2
4714,This paper focuses directly on computing the similarity between very short texts of sentence length.,objective,1
4715,It presents an algorithm that takes account of semantic information and word order information implied in the sentences.,method,2
4716,The semantic similarity of two sentences is calculated using information from a structured lexical database and from corpus statistics.,method,2
4717,The use of a lexical database enables our method to model human common sense knowledge and the incorporation of corpus statistics allows our method to be adaptable to different domains.,method,2
4718,The proposed method can be used in a variety of applications that involve text knowledge representation and discovery.,method,2
4719,Experiments on two sets of selected sentence pairs demonstrate that the proposed method provides a similarity measure that shows a significant correlation to human intuition,result,3
4720,We present a novel approach to ray tracing execution on commodity graphics hardware using CUDA.,background,0
4721,We decompose a standard ray tracing algorithm into several data-parallel stages that are mapped efficiently to the massively parallel architecture of modern GPUs.,method,2
4722,"These stages include: ray sorting into coherent packets, creation of frustums for packets, breadth-first frustum traversal through a bounding volume hierarchy for the scene, and localized ray-primitive intersections.",method,2
4723,"We utilize the well known parallel primitives scan and segmented scan in order to process irregular data structures, to remove the need for a stack, and to minimize branch divergence in all stages.",method,2
4724,"Our ray sorting stage is based on applying hash values to individual rays, ray stream compression, sorting and decompression.",method,2
4725,Our breadth-first BVH traversal is based on parallel frustum-bounding box intersection tests and parallel scan per each BVH level.,method,2
4726,We demonstrate our algorithm with area light sources to get a soft shadow effect and show that our concept is reasonable for coherent and incoherent rays.,method,2
4727,For the same data sets and ray-primitive intersection routines our pipeline is ~3x faster than an optimized standard depth first ray tracing implemented in one kernel.,result,3
4728,Our proposed deeply-supervised nets (DSN) method simultaneously minimizes classification error while making the learning process of hidden layers direct and transparent.,method,2
4729,We make an attempt to boost the classification performance by studying a new formulation in deep networks.,method,2
4730,"Three aspects in convolutional neural networks (CNN) style architectures are being looked at: (1) transparency of the intermediate layers to the overall classification; (2) discriminativeness and robustness of learned features, especially in the early layers; (3) effectiveness in training due to the presence of the exploding and vanishing gradients.",method,2
4731,"We introduce “companion objective” to the individual hidden layers, in addition to the overall objective at the output layer (a different strategy to layer-wise pre-training).",method,2
4732,We extend techniques from stochastic gradient methods to analyze our algorithm.,method,2
4733,"The advantage of our method is evident and our experimental result on benchmark datasets shows significant performance gain over existing methods (e.g. all state-of-the-art results on MNIST, CIFAR-10, CIFAR-100, and SVHN).",result,3
4734,We introduce and motivate machine learning (ML) communications systems that aim to improve on and to even replace the vast expert knowledge in the field of communications using modern machine learning techniques.,objective,1
4735,"These have recently achieved breakthroughs in many different domains, but not yet in communications.",objective,1
4736,"By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about radio communications system design as an end-to-end reconstruction optimization task that seeks to jointly optimize transmitter and receiver components in a single process.",method,2
4737,We further present the concept of Radio Transformer Networks (RTNs) as a means to incorporate expert domain knowledge in the ML model and study the application of convolutional neural networks (CNNs) on raw IQ time-series data for modulation classification.,method,2
4738,We conclude the paper with a deep discussion of open challenges and areas for future investigation.,result,3
4739,Purpose – Apart from information retrieval there is virtually no other area of information science that has occasioned as much research effort and writing as “user studies”.,background,0
4740,Within user studies the investigation of “information needs” has been the subject of much debate and no little confusion.,background,0
4741,The aim of this paper is to attempt to reduce this confusion by devoting attention to the definition of some concepts and by proposing the basis for a theory of the motivations for information-seeking behaviour.,objective,1
4742,Design/methodology/approach – The paper describes the issues of user studies and information needs within the context of information science.,method,2
4743,"Findings – The paper finds that the problem seems to lie, not so much with the lack of a single definition, as with a failure to use a definition appropriate to the level, and purpose of the investigation.",result,3
4744,"Originality/value – The analysis may be used as a springboard to research based upon a wider, holistic view of the information user.",result,3
4745,"Zadoff-Chu (ZC) sequences have been used as synchronization sequences in modern wireless communication systems, replacing the conventional pseudorandom noise sequences due to their perfect autocorrelation properties.",background,0
4746,"We first study the problem of ambiguity between a timing offset and a frequency offset, which arises when a ZC sequence is used as a synchronization signal.",result,3
4747,"We then show how a frequency offset can impair the timing property of a ZC sequence, causing irreducible timing errors.",method,2
4748,"An analytical framework, particularly the timing spectrum, is developed, which fully characterizes a ZC sequence's timing properties and its fundamental limitations as a time synchronization sequence in the presence of a frequency offset between the transmitter and the receiver.",method,2
4749,This analytical framework provides a powerful analytical tool for timing signal design and performance analysis of ZC sequences.,result,3
4750,"A data model, called the entity-relationship model, is proposed.",background,0
4751,This model incorporates some of the important semantic information in the real world.,background,0
4752,A special diagramatic technique is introduced as a tool for data base design.,method,2
4753,An example of data base design and description using the model and the diagramatic technique is given.,method,2
4754,"Some implications on data integrity, information retrieval, and data manipulation are discussed.",background,0
4755,"The entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model.",result,3
4756,Semantic ambiguities in these models are analyzed.,result,3
4757,Possible ways to derive their views of data from the entity-relationship model are presented.,method,2
4758,"This paper provides an in-depth view of Terahertz Band (0.1–10 THz) communication, which is envisioned as a key technology to satisfy the increasing demand for higher speed wireless communication.",background,0
4759,"THz Band communication will alleviate the spectrum scarcity and capacity limitations of current wireless systems, and enable new applications both in classical networking domains as well as in novel nanoscale communication paradigms.",background,0
4760,"In this paper, the device design and development challenges for THz Band are surveyed first.",method,2
4761,The limitations and possible solutions for high-speed transceiver architectures are highlighted.,objective,1
4762,The challenges for the development of new ultra-broadband antennas and very large antenna arrays are explained.,objective,1
4763,"When the devices are finally developed, then they need to communicate in the THz band.",method,2
4764,"There exist many novel communication challenges such as propagation modeling, capacity analysis, modulation schemes, and other physical and link layer solutions, in the THz band which can be seen as a new frontier in the communication research.",objective,1
4765,These challenges are treated in depth in this paper explaining the existing plethora of work and what still needs to be tackled.,result,3
4766,© 2014 Published by Elsevier B.V.,result,3
4767,Context: Big data has become the new buzzword in the information and communication technology industry.,background,0
4768,Researchers and major corporations are looking into big data applications to extract the maximum value from the data available to them.,background,0
4769,"However, developing and maintaining stable and scalable big data applications is still a distant milestone.",background,0
4770,"Objective: To look at existing research on how software engineering concepts, namely the phases of the software development project life cycle (SDPLC), can help build better big data application projects.",objective,1
4771,Method: A literature survey was performed.,method,2
4772,"A manual search covered papers returned by search engines resulting in approximately 2,000 papers being searched and 170 papers selected for review.",result,3
4773,Results: The search results helped in identifying data rich application projects that have the potential to utilize big data successfully.,result,3
4774,The review helped in exploring SDPLC phases in the context of big data applications and performing a gap analysis of the phases that have yet to see detailed research efforts but deserve attention.,result,3
4775,"Smile detection from facial images is a specialized task in facial expression analysis with many potential applications such as smiling payment, patient monitoring and photo selection.",background,0
4776,"The current methods on this study are to represent face with low-level features, followed by a strong classifier.",method,2
4777,"However, these manual features cannot well discover information implied in facial images for smile detection.",method,2
4778,"In this paper, we propose to extract high-level features by a well-designed deep convolutional networks (CNN).",method,2
4779,"A key contribution of this work is that we use both recognition and verification signals as supervision to learn expression features, which is helpful to reduce same-expression variations and enlarge different-expression differences.",method,2
4780,"Our method is end-to-end, without complex pre-processing often used in traditional methods.",method,2
4781,"High-level features are taken from the last hidden layer neuron activations of deep CNN, and fed into a soft-max classifier to estimate.",method,2
4782,"Experimental results show that our proposed method is very effective, which outperforms the state-of-the-art methods.",result,3
4783,"On the GENKI smile detection dataset, our method reduces the error rate by 21% compared with the previous best method.",result,3
4784,Video games are often regarded as promising teaching and learning tools for the 21st century.,background,0
4785,One of the main arguments is that video games are appealing to contemporary students.,background,0
4786,"However, there are indications that video game acceptance cannot be taken for granted.",objective,1
4787,"In this study, a path model to examine and predict student acceptance of video games is proposed, and empirically tested by involving 858 secondary school students.",objective,1
4788,"The results show that students’ preference for using video games in the classroom is affected directly by a number of factors: the perceptions of students regarding the usefulness, ease of use, learning opportunities, and personal experience with video games in general.",background,0
4789,"Gender effects are found as well, but appear to be mediated by experience and ease of use.",background,0
4790,2009 Elsevier Ltd.,other,4
4792,The classifier built from a data set with a highly skewed class distribution generally predicts the more frequently occurring classes much more often than the infrequently occurring classes.,background,0
4793,This is largely due to the fact that most classifiers are designed to maximize accuracy.,background,0
4794,"In many instances, such as for medical diagnosis, this classification behavior is unacceptable because the minority class is the class of primary interest (i.e., it has a much higher misclassification cost than the majority class).",background,0
4795,In this paper we compare three methods for dealing with data that has a skewed class distribution and nonuniform misclassification costs.,method,2
4796,The first method incorporates the misclassification costs into the learning algorithm while the other two methods employ oversampling or undersampling to make the training data more balanced.,method,2
4797,In this paper we empirically compare the effectiveness of these methods in order to determine which produces the best overall classifier—and under what circumstances.,result,3
4798,"In this paper, we present a series of programming projects based on the Linux kernel for students in a senior-level undergraduate operating systems course.",background,0
4799,"The projects we describe cover several key operating systems concepts, including process scheduling, I/O scheduling, memory management, and device drivers.",background,0
4800,"In addition, we assess these projects along several dimensions, from their difficulty to their capacity to help students understand operating systems concepts, based on six terms (three years) of detailed student exit surveys along with observations and anecdotal evidence.",method,2
4801,"Through this assessment, we conclude that our Linux-based projects are an effective means by which to teach operating systems concepts and, additionally, that students' response to these projects is overwhelmingly positive.",result,3
4802,The Internet of Things (IoT) is stepping out of its infancy into full maturity and establishing itself as a part of the future Internet.,background,0
4803,One of the technical challenges of having billions of devices deployed worldwide is the ability to manage them.,background,0
4804,"Although access management technologies exist in IoT, they are based on centralized models which introduce a new variety of technical limitations to manage them globally.",background,0
4805,"In this paper, we propose a new architecture for arbitrating roles and permissions in IoT. The new architecture is a fully distributed access control system for IoT based on blockchain technology.",method,2
4806,The architecture is backed by a proof of concept implementation and evaluated in realistic IoT scenarios.,result,3
4807,The results show that the blockchain technology could be used as access management technology in specific scalable IoT scenarios.,result,3
4808,"Predictive analytics embraces an extensive range of techniques including statistical modeling, machine learning, and data mining and is applied in business intelligence, public health, disaster management and response, and many other fields.",background,0
4809,"To date, visualization has been broadly used to support tasks in the predictive analytics pipeline.",background,0
4810,"Primary uses have been in data cleaning, exploratory analysis, and diagnostics.",background,0
4811,"For example, scatterplots and bar charts are used to illustrate class distributions and responses.",background,0
4812,"More recently, extensive visual analytics systems for feature selection, incremental learning, and various prediction tasks have been proposed to support the growing use of complex models, agent-specific optimization, and comprehensive model comparison and result exploration.",method,2
4813,Such work is being driven by advances in interactive machine learning and the desire of end-users to understand and engage with the modeling process.,result,3
4814,"In this state-of-the-art report, we catalogue recent advances in the visualization community for supporting predictive analytics.",result,3
4815,"First, we define the scope of predictive analytics discussed in this article and describe how visual analytics can support predictive analytics tasks in a predictive visual analytics (PVA) pipeline.",method,2
4816,We then survey the literature and categorize the research with respect to the proposed PVA pipeline.,method,2
4817,"Systems and techniques are evaluated in terms of their supported interactions, and interactions specific to predictive analytics are discussed.",method,2
4818,"A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module.",background,0
4819,Building these components often requires extensive domain expertise and may contain brittle design choices.,background,0
4820,"In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters.",objective,1
4821,"Given <text, audio> pairs, the model can be trained completely from scratch with random initialization.",method,2
4822,We present several key techniques to make the sequence-tosequence framework perform well for this challenging task.,method,2
4825,Cloud computing an emerging approach by sharing infrastructure is an overwhelming trend.,background,0
4826,"While in the process of cloud deployment, the security issues can not be underestimated.",background,0
4827,Traditional Intrusion Detection System (IDS) because of lower detection rate and higher false rate couldn’t be suitable the cloud here.,method,2
4828,Extensibility is the main requirement for IDS framework of cloud environment in this paper as follows.,objective,1
4829,"First the cross-platform and strong isolation properties of virtualization have been fully reflected here, that is to say, an extensible VM-based multiple IDSs are deployed in each layer to monitor specific virtual component.",result,3
4830,"Moreover, during the process, we also propose the cloud alliance concept by the communication agents exchanging the mutual alerts mainly to resist Denialof-Service (DoS) and Distributed Denial-of-Service (DDoS) the single point attack of failure.",result,3
4831,"On this basis, we have the identity certification of the communication agents to improve the reliability of the alerts.",result,3
4832,"Through the comparison of simulation results, the proposed system framework has a great advantage for monitoring VMs on the detection rate.",result,3
4833,"Over the past couple of years, clicking and posting selfies has become a popular trend.",background,0
4834,"However, since March 2014, 127 people have died and many have been injured while trying to click a selfie.",background,0
4835,"Researchers have studied selfies for understanding the psychology of the authors, and understanding its effect on social media platforms.",objective,1
4836,"In this work, we perform a comprehensive analysis of the selfie-related casualties and infer various reasons behind these deaths.",objective,1
4837,"We use inferences from incidents and from our understanding of the features, we create a system to make people more aware of the dangerous situations in which these selfies are taken.",method,2
4838,"We use a combination of text-based, image-based and location-based features to classify a particular selfie as dangerous or not.",method,2
4839,"Our method ran on 3,155 annotated selfies collected on Twitter gave 73% accuracy.",method,2
4840,Individually the image-based features were the most informative for the prediction task.,method,2
4841,The combination of image-based and location-based features resulted in the best accuracy.,result,3
4842,We have made our code and dataset available at http://labs.precog.iiitd.edu.in/killfie.,other,4
4843,"We have already encountered the sampling theorem and, arguing purely from a trigonometric-identity point of view have established the Nyquist sampling cri-terion for sinusoidal signals.",background,0
4844,"However, we have not fully addressed the sampling of more general signals, nor provided a general proof.",background,0
4845,Nor have we indicated how to reconstruct a signal from its samples.,objective,1
4846,With the tools of Fourier transforms and Fourier series available to us we are now ready to nish the job that was started months ago.,result,3
4847,"As projects for developing information systems are getting larger and more complicated, we need to have more advanced development methods suitable for every development situation.",background,0
4848,"Method engineering is the discipline to construct new methods from parts of existing methods, called method fragments.",background,0
4849,"To achieve this objective, we need to clarify how to model the existing methods and how to assemble method fragments into new project-specific methods, so-called situational methods.",objective,1
4850,"Especially, to produce meaningful methods, we should impose some constraints or rules on method assembly processes.",method,2
4851,"In this paper, we propose a framework for hierarchical method modelling (meta-modelling) from three orthogonal dimensions: perspectives, abstraction and granularity.",method,2
4852,"According to each dimension, methods and/or method fragments are hierarchically modelled and classified.",method,2
4853,"Furthermore, we present a method assembly mechanism and its formalization as a set of rules.",method,2
4854,These rules are presented in first order predicate logic and play an important role in the assembly process of meaningful methods from existing method fragments.,method,2
4855,"The benefit of our technique is illustrated by an example of method assembly, namely the integration of the Object Model and Harel's Statechart into Objectcharts.",result,3
4856,Electronic communications have become the most important kind of communications in business.,background,0
4857,"However, trust, privacy and security have become the great challenges for business and governments around the globe.",background,0
4858,The Public Key Infrastructure (PKI) model tries to solve these issues and make the Internet more secure.,objective,1
4859,This paper explains the main purposes of PKI and addresses some of the major issues and obstacles that face PKI technology today.,objective,1
4860,We investigated whether multitasking with media was a unique predictor of depression and social anxiety symptoms.,background,0
4861,"Participants (N=318) completed measures of their media use, personality characteristics, depression, and social anxiety.",background,0
4862,"Regression analyses revealed that increased media multitasking was associated with higher depression and social anxiety symptoms, even after controlling for overall media use and the personality traits of neuroticism and extraversion.",result,3
4863,The unique association between media multitasking and these measures of psychosocial dysfunction suggests that the growing trend of multitasking with media may represent a unique risk factor for mental health problems related to mood and anxiety.,result,3
4864,"Further, the results strongly suggest that future research investigating the impact of media use on mental health needs to consider the role that multitasking with media plays in the relationship.",result,3
4865,"This paper discusses a novel hybrid approach for text categorization that combines a machine learning algorithm, which provides a base model trained with a labeled corpus, with a rule-based expert system, which is used to improve the results provided by the previous classifier, by filtering false positives and dealing with false negatives.",background,0
4866,The main advantage is that the system can be easily fine-tuned by adding specific rules for those noisy or conflicting categories that have not been successfully trained.,background,0
4867,"We also describe an implementation based on k-Nearest Neighbor and a simple rule language to express lists of positive, negative and relevant (multiword) terms appearing in the input text.",objective,1
4868,"The system is evaluated in several scenarios, including the popular Reuters-21578 news corpus for comparison to other approaches, and categorization using IPTC metadata, EUROVOC thesaurus and others.",method,2
4869,"Results show that this approach achieves a precision that is comparable to top ranked methods, with the added value that it does not require a demanding human expert workload to train.",result,3
4870,"Recent solutions for sentiment analysis have relied on feature selection methods ranging from lexicon-based approaches where the set of features are generated by humans, to approaches that use general statistical measures where features are selected solely on empirical evidence.",background,0
4871,"The advantage of statistical approaches is that they are fully automatic, however, they often fail to separate features that carry sentiment from those that do not.",background,0
4872,In this paper we propose a set of new feature selection schemes that use a Content and Syntax model to automatically learn a set of features in a review document by separating the entities that are being reviewed from the subjective expressions that describe those entities in terms of polarities.,objective,1
4873,"By focusing only on the subjective expressions and ignoring the entities, we can choose more salient features for document-level sentiment analysis.",method,2
4874,The results obtained from using these features in a maximum entropy classifier are competitive with the state-of-the-art machine learning approaches.,result,3
4875,We propose a deep learning method for single image superresolution (SR).,objective,1
4876,Our method directly learns an end-to-end mapping between the low/high-resolution images.,method,2
4877,The mapping is represented as a deep convolutional neural network (CNN) [15] that takes the lowresolution image as the input and outputs the high-resolution one.,method,2
4878,We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network.,method,2
4879,"But unlike traditional methods that handle each component separately, our method jointly optimizes all layers.",method,2
4881,Accurate cardinality estimates are essential for a successful query optimization.,background,0
4882,This is not only true for relational DBMSs but also for RDF stores.,background,0
4883,"An RDF database consists of a set of triples and, hence, can be seen as a relational database with a single table with three attributes.",method,2
4884,This makes RDF rather special in that queries typically contain many self joins.,method,2
4885,We show that relational DBMSs are not well-prepared to perform cardinality estimation in this context.,method,2
4886,"Further, there are hardly any special cardinality estimation methods for RDF databases.",background,0
4887,"To overcome this lack of appropriate cardinality estimation methods, we introduce characteristic sets together with new cardinality estimation methods based upon them.",result,3
4888,We then show experimentally that the new methods are-in the RDF context-highly superior to the estimation methods employed by commercial DBMSs and by the open-source RDF store RDF-3X.,result,3
4889,"Almost 30 years after the introduction of the CIO position, the ideal CIO reporting structure (whether the CIO should report to the CEO or the CFO) is yet to be identified.",background,0
4890,"There is an intuitive assumption among some proponents of IT that the CIO should always report to the CEO to promote the importance of IT and the CIO’s clout in the firm, while some adversaries of IT call for a CIO–CFO reporting structure to keep a tab on IT spending.",background,0
4891,"However, we challenge these two ad hoc prescriptions by arguing that neither CIO reporting structure is necessarily optimal, and that the CIO reporting structure should not be used to gauge the strategic role of IT in the firm.",background,0
4892,"Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images.",background,0
4893,We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound.,method,2
4894,We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence.,method,2
4895,"We validate the use of attention with state-of-theart performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO.",result,3
4896,Posting pictures is a necessary part of advertising a home for sale.,background,0
4897,Agents typically sort through dozens of images from which to pick the most complimentary ones.,background,0
4898,"This is a manual effort involving annotating images accompanied by descriptions (bedroom, bathroom, attic, etc.).",background,0
4899,"When volumes are small, manual annotation is not a problem, but there is a point where this becomes too burdensome and ultimately infeasible.",background,0
4900,"Here, we propose an approach based on computer vision methodology to radically increase the efficiency of such tasks.",objective,1
4901,"We present a high-confidence image classification framework, whose inputs are images and outputs are labels.",method,2
4902,"The core of the classification algorithm is long short term memory (LSTM), and fully connected neural networks, along with a substantial preprocessing using 'contrast-limited adaptive histogram equalization (CLAHE) for image enhancement.",method,2
4903,"Since, there is no standard benchmark containing a comprehensive dataset of well-annotated real estate images, we introduce Real Estate Image (REI) database for evaluating the image classification algorithms.",result,3
4904,"Therein we demonstrate empirics based on our proposed framework on the new REI dataset, as well as on the SUN dataset.",result,3
4905,Clustering is an important data mining problem.,background,0
4906,Most of the earlier work on clustering focussed on numeric attributes which have a natural ordering on their attribute values.,background,0
4907,"Recently, clustering data with categorical attributes, whose attribute values do not have a natural ordering, has received some attention.",background,0
4908,"However, previous algorithms do not give a formal description of the clusters they discover and some of them assume that the user post-processes the output of the algorithm to identify the final clusters.",background,0
4909,"In this paper, we introduce a novel formalization of a cluster for categorical attributes by generalizing a definition of a cluster for numerical attributes.",method,2
4910,We then describe a very fast summarizationbased algorithm called CACTUS that discovers exactly such clusters in the data.,method,2
4911,CACTUS has two important characteristics.,method,2
4912,"First, the algorithm requires only two scans of the dataset, and hence is very fast and scalable.",method,2
4913,Our experiments on a variety of datasets show that CACTUS outperforms previous work by a factor of 3 to 10.,result,3
4914,"Second, CACTUS can find clusters in subsets of all attributes and can thus perform a subspace clustering of the data.",method,2
4915,ts oby 200 Abstract.,other,4
4916,Digital Still Color Cameras sample the color spectrum using a monolithic array of color filters overlaid on a charge coupled device array such that each pixel samples only one color band.,background,0
4917,The resulting mosaic of color samples is processed to produce a high resolution color image such that the values of the color bands not sampled at a certain location are estimated from its neighbors.,background,0
4918,This process is often referred to as demosaicking.,background,0
4919,This paper introduces and compares a few commonly used demosaicking methods using error metrics like mean squared error in the RGB color space and perceived error in the CIELAB color space.,method,2
4920,© 2002 SPIE and IS&T. [DOI: 10.1117/1.1484495],other,4
4921,This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation.,objective,1
4922,Principle shortcomings of the concept of mutative strategy parameter control and two levels of derandomization are reviewed.,method,2
4923,Basic demands on the self-adaptation of arbitrary (normal) mutation distributions are developed.,objective,1
4924,"Applying arbitrary, normal mutation distributions is equiv-alent to applying a general, linear problem encoding.",method,2
4925,The underlying objective of mutative strategy parameter control is roughly to favor previously selected mutation steps in the future.,objective,1
4926,"If this objective is pursued rigor-ously, a completely derandomized self-adaptation scheme results, which adapts arbitrary normal mutation distributions.",result,3
4927,"This scheme, called covariance matrix adaptation (CMA), meets the previously stated demands.",result,3
4928,It can still be considerably improved by cumulation - utilizing an evolution path rather than single search steps.,result,3
4929,Simulations on various test functions reveal local and global search properties of the evolution strategy with and without covariance matrix adaptation.,result,3
4930,Their performances are comparable only on perfectly scaled functions.,result,3
4931,"Software-defined networking (SDN) is a new networking paradigm that decouples the forwarding and control planes, traditionally coupled with one another, while adopting a logically centralized architecture aiming to increase network agility and programability.",background,0
4932,"While many efforts are currently being made to standardize this emerging paradigm, careful attention needs to be paid to security at this early design stage too, rather than waiting until the technology becomes mature, thereby potentially avoiding previous pitfalls made when designing the Internet in the 1980s.",background,0
4933,This article focuses on the security aspects of SDN networks.,objective,1
4934,We begin by discussing the new security advantages that SDN brings and by showing how some of the long-lasting issues in network security can be addressed by exploiting SDN capabilities.,objective,1
4935,Then we describe the new security threats that SDN is faced with and discuss possible techniques that can be used to prevent and mitigate such threats.,method,2
4936,"We consider a generalization of low-rank matrix completion to the case where the data belongs to an algebraic variety, i.e., each data point is a solution to a system of polynomial equations.",background,0
4937,"In this case the original matrix is possibly high-rank, but it becomes low-rank after mapping each column to a higher dimensional space of monomial features.",background,0
4938,"Many well-studied extensions of linear models, including a ne subspaces and their union, can be described by a variety model.",method,2
4939,"In addition, varieties can be used to model a richer class of nonlinear quadratic and higher degree curves and surfaces.",background,0
4940,We study the sampling requirements for matrix completion under a variety model with a focus on a union of a ne subspaces.,method,2
4941,We also propose an e cient matrix completion algorithm that minimizes a convex or non-convex surrogate of the rank of the matrix of monomial features.,method,2
4942,Our algorithm uses the wellknown “kernel trick” to avoid working directly with the high-dimensional monomial matrix.,method,2
4943,We show the proposed algorithm is able to recover synthetically generated data up to the predicted sampling complexity bounds.,method,2
4944,The proposed algorithm also outperforms standard low rank matrix completion and subspace clustering techniques in experiments with real data.,method,2
4945,"In this paper, we present an efficient general-purpose objective no-reference (NR) image quality assessment (IQA) framework based on unsupervised feature learning.",background,0
4946,The goal is to build a computational model to automatically predict human perceived image quality without a reference image and without knowing the distortion present in the image.,objective,1
4947,Previous approaches for this problem typically rely on hand-crafted features which are carefully designed based on prior knowledge.,objective,1
4948,"In contrast, we use raw-image-patches extracted from a set of unlabeled images to learn a dictionary in an unsupervised manner.",method,2
4949,We use soft-assignment coding with max pooling to obtain effective image representations for quality estimation.,method,2
4950,"The proposed algorithm is very computationally appealing, using raw image patches as local descriptors and using soft-assignment for encoding.",method,2
4951,"Furthermore, unlike previous methods, our unsupervised feature learning strategy enables our method to adapt to different domains.",method,2
4952,"CORNIA (Codebook Representation for No-Reference Image Assessment) is tested on LIVE database and shown to perform statistically better than the full-reference quality measure, structural similarity index (SSIM) and is shown to be comparable to state-of-the-art general purpose NR-IQA algorithms.",result,3
4953,"This paper addresses the task of user classification in social media, with an application to Twitter.",objective,1
4954,"We automatically infer the values of user attributes such as political orientation or ethnicity by leveraging observable information such as the user behavior, network structure and the linguistic content of the user’s Twitter feed.",method,2
4955,We employ a machine learning approach which relies on a comprehensive set of features derived from such user information.,method,2
4956,"We report encouraging experimental results on 3 tasks with different characteristics: political affiliation detection, ethnicity identification and detecting affinity for a particular business.",result,3
4957,"Finally, our analysis shows that rich linguistic features prove consistently valuable across the 3 tasks and show great promise for additional user classification needs.",result,3
4958,Recent years have seen a rapid proliferation of mass-market consumer software that takes inspiration from video games.,background,0
4959,"Usually summarized as ""gamification"", this trend connects to a sizeable body of existing concepts and research in human-computer interaction and game studies, such as serious games, pervasive games, alternate reality games, or playful design.",background,0
4960,"However, it is not clear how ""gamification"" relates to these, whether it denotes a novel phenomenon, and how to define it.",background,0
4961,"Thus, in this paper we investigate ""gamification"" and the historical origins of the term in relation to precursors and similar concepts.",objective,1
4962,"It is suggested that ""gamified"" applications provide insight into novel, gameful phenomena complementary to playful phenomena.",background,0
4963,"Based on our research, we propose a definition of ""gamification"" as the use of game design elements in non-game contexts.",result,3
4964,"Audit logs are an important part of any secure system, and they need to be carefully designed in order to give a faithful representation of past system activity.",background,0
4965,This is especially true in the presence of adversaries who might want to tamper with the audit logs.,background,0
4966,"While it is important that auditors can inspect audit logs to assess past system activity, the content of an audit log may contain sensitive information, and should therefore be protected from unauthorized",background,0
4967,The Internet has become a rich and large repository of information about us as individuals.,background,0
4968,Anything from the links and text on a user's homepage to the mailing lists the user subscribes to are reflections of social interactions a user has in the real world.,background,0
4969,In this paper we devise techniques to mine this information in order to predict relationships between individuals.,method,2
4970,"Further we show that some pieces of information are better indicators of social connections than others, and that these indicators vary between user populations and provide a glimpse into the social lives of individuals in different communities.",method,2
4971,"Our techniques provide potential applications in automatically inferring real-world connections and discovering, labeling, and characterizing communities.",method,2
4972,Central to the development of computer vision systems is the collection and use of annotated images spanning our visual world.,background,0
4973,"Annotations may include information about the identity, spatial extent, and viewpoint of the objects present in a depicted scene.",background,0
4974,Such a database is useful for the training and evaluation of computer vision systems.,result,3
4975,"Motivated by the availability of images on the Internet, we introduced a web-based annotation tool that allows online users to label objects and their spatial extent in images.",method,2
4976,"To date, we have collected over 400 000 annotations that span a variety of different scene and object classes.",result,3
4977,"In this paper, we show the contents of the database, its growth over time, and statistics of its usage.",result,3
4978,"In addition, we explore and survey applications of the database in the areas of computer vision and computer graphics.",method,2
4979,"Particularly, we show how to extract the real-world 3-D coordinates of images in a variety of scenes using only the user-provided object annotations.",method,2
4980,The output 3-D information is comparable to the quality produced by a laser range scanner.,other,4
4981,We also characterize the space of the images in the database by analyzing 1) statistics of the co-occurrence of large objects in the images and 2) the spatial layout of the labeled images.,result,3
4982,"The class scheduling problem can be modeled by a graph where the vertices and edges represent the courses and the common students, respectively.",background,0
4983,"The problem is to assign the courses a given number of time slots (colors), where each time slot can be used for a given number of class rooms.",background,0
4984,The Vertex Coloring (VC) algorithm is a polynomial time algorithm which produces a conflict free solution using the least number of colors [9].,method,2
4985,"However, the VC solution may not be implementable because it uses a number of time slots that exceed the available ones with unbalanced use of class rooms.",method,2
4986,We propose a heuristic approach VC* to (1) promote uniform distribution of courses over the colors and to (2) balance course load for each time slot over the available class rooms.,method,2
4987,The performance function represents the percentage of students in all courses that could not be mapped to time slots or to class rooms.,result,3
4988,A randomized simulation of registration of four departments with up to 1200 students is used to evaluate the performance of proposed heuristic.,result,3
4989,"Super-deformed, SD, is a specific artistic style for Japanese manga and anime which exaggerates characters in the goal of appearing cute and funny.",background,0
4990,"The SD style characters are widely used, and can be seen in many anime, CG movies, or games.",background,0
4991,"However, to create an SD model often requires professional skills and considerable time and effort.",method,2
4992,"In this paper, we present a novel technique to generate an SD style counterpart of a normal 3D character model.",background,0
4993,Our approach uses an optimization guided by a number of constraints that can capture the properties of the SD style.,method,2
4994,Users can also customize the results by specifying a small set of parameters related to the body proportions and the emphasis of the signature characteristics.,result,3
4995,"With our technique, even a novel user can generate visually pleasing SD models in seconds.",result,3
4996,We use logical inference techniques for recognising textual entailment.,method,2
4997,"As the performance of theorem proving turns out to be highly dependent on not readily available background knowledge, we incorporate model building, a technique borrowed from automated reasoning, and show that it is a useful robust method to approximate entailment.",method,2
4998,"Finally, we use machine learning to combine these deep semantic analysis techniques with simple shallow word overlap; the resulting hybrid model achieves high accuracy on the RTE testset, given the state of the art.",method,2
4999,"Our results also show that the different techniques that we employ perform very differently on some of the subsets of the RTE corpus and as a result, it is useful to use the nature of the dataset as a feature.",result,3
5000,"Learning and then recognizing a route, whether travelled during the day or at night, in clear or inclement weather, and in summer or winter is a challenging task for state of the art algorithms in computer vision and robotics.",background,0
5001,"In this paper, we present a new approach to visual navigation under changing conditions dubbed SeqSLAM.",background,0
5002,"Instead of calculating the single location most likely given a current image, our approach calculates the best candidate matching location within every local navigation sequence.",background,0
5003,Localization is then achieved by recognizing coherent sequences of these “local best matches”.,method,2
5004,This approach removes the need for global matching performance by the vision front-end - instead it must only pick the best match within any short sequence of images.,method,2
5005,The approach is applicable over environment changes that render traditional feature-based techniques ineffective.,method,2
5006,"Using two car-mounted camera datasets we demonstrate the effectiveness of the algorithm and compare it to one of the most successful feature-based SLAM algorithms, FAB-MAP.",method,2
5007,"The perceptual change in the datasets is extreme; repeated traverses through environments during the day and then in the middle of the night, at times separated by months or years and in opposite seasons, and in clear weather and extremely heavy rain.",result,3
5008,"While the feature-based method fails, the sequence-based algorithm is able to match trajectory segments at 100% precision with recall rates of up to 60%.",result,3
5009,"Recent years have witnessed an exceptional research interest in cryptographic hash functions, especially after the popular attacks against MD5 and SHA-1 in 2005.",background,0
5010,"In 2007, the U.S. National Institute of Standards and Technology (NIST) has also significantly boosted this interest by announcing a public competition to select the next hash function standard, to be named SHA-3.",background,0
5011,"Not surprisingly, the hash function literature has since been rapidly growing in an extremely fast pace.",background,0
5012,"In this paper, we provide a comprehensive, up-to-date discussion of the current state of the art of cryptographic hash functions security and design.",objective,1
5013,"We first discuss the various hash functions security properties and notions, then proceed to give an overview of how (and why) hash functions evolved over the years giving raise to the current diverse hash functions design approaches.",method,2
5014,∗A short version of this paper is in [1].,other,4
5015,This version has been thoroughly extended.,other,4
5016,An identical version has been uploaded to the Cryptology ePrint Archive: eprint.iacr.org/2011/565,other,4
5017,"Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision.",background,0
5018,"Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation.",background,0
5019,"Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with.",objective,1
5020,"We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB.",method,2
5021,We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base.,method,2
5022,"When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.",result,3
5023,Plant Diseases and Pests are a major challenge in the agriculture sector.,background,0
5024,An accurate and a faster detection of diseases and pests in plants could help to develop an early treatment technique while substantially reducing economic losses.,result,3
5025,Recent developments in Deep Neural Networks have allowed researchers to drastically improve the accuracy of object detection and recognition systems.,result,3
5026,"In this paper, we present a deep-learning-based approach to detect diseases and pests in tomato plants using images captured in-place by camera devices with various resolutions.",method,2
5027,Our goal is to find the more suitable deep-learning architecture for our task.,objective,1
5028,"Therefore, we consider three main families of detectors:",other,4
5029,"Faster Region-based Convolutional Neural Network (Faster R-CNN), Region-based Fully Convolutional Network (R-FCN), and Single Shot Multibox Detector (SSD), which for the purpose of this work are called ""deep learning meta-architectures"".",result,3
5030,"We combine each of these meta-architectures with ""deep feature extractors"" such as VGG net and Residual Network (ResNet).",result,3
5031,"We demonstrate the performance of deep meta-architectures and feature extractors, and additionally propose a method for local and global class annotation and data augmentation to increase the accuracy and reduce the number of false positives during training.",method,2
5032,"We train and test our systems end-to-end on our large Tomato Diseases and Pests Dataset, which contains challenging images with diseases and pests, including several inter- and extra-class variations, such as infection status and location in the plant.",result,3
5033,"In this paper, we propose a large training dataset named Celeb-500K for face recognition, which contains 50M images from 500K persons.",objective,1
5034,"To better facilitate academic research, we clean Celeb-500K to obtain Celeb-500K-2R, which contains 25M aligned face images from 365K persons.",background,0
5035,"Based on the developed dataset, we achieve state-of-the-art face recognition performance and reveal two important observations on face recognition study.",background,0
5036,"First, metric learning methods have limited performance gain when the training dataset contains a large number of identities.",method,2
5037,"Second, in order to develop an efficient training dataset, the number of identities is more important than the average image number of each identity from the perspective of face recognition performance.",result,3
5038,Extensive experimental results show the superiority of Celeb-500K and provide a strong support to the two observations.,result,3
5039,A classical problem in the field of Multiple Criteria Decision Making (mcdm) is to build a preference relation on a set of multi-attributed alternatives on the basis of preferences expresses on each attribute and “inter-attribute” information such as weights.,background,0
5040,"Based on this preference relation (or, more generally, on various relations obtained following a robustness analysis) a recommendation is elaborated (e.g. exhibiting of a subset likely to contain the “best” alternatives).",background,0
5041,A common way [20] to do so is to attach a number v(x) to each alternative x ∈ X and to declare that x is at least as good as y if and only if v(x) ≥ v(y).,method,2
5042,"The number v(x) depends on the evaluations x1, x2, ...xn of x on the n attributes and we have v(x) = V (x1, x2, ..., xn).",background,0
5043,"The most common form for V is an additive value function in which V (x1, x2, ..., xn) = ∑n i=1 kivi(xi); in that case the task of the analyst reduces down to assessing the partial value functions vi and the scaling constants ki.",objective,1
5044,"The preference relation that is built using this value function approach is a weak order, i.e. a complete and transitive binary relation.",method,2
5045,"Using such information it is not difficult, in general, to elaborate a recommendation.",background,0
5046,The definition if the aggregation function V may not always be simple however.,background,0
5047,"Making all alternatives comparable in a “nice transitive way” requires much information and, in particular, a detailed analysis of trade-offs between attributes.",background,0
5048,Outranking Methods (OMs) were first developed in France in the late sixties following difficulties experienced with the value function approach in dealing with practical problems.,method,2
5049,Busy and no time to digest the news archive ....,other,4
5050,?,other,4
5051,"Ever since the Web wide-spreading, the amount of electronically available information online, especially news archive proliferates and threatens to overwhelm human attention.",background,0
5052,"Seeing this, we propose an information system that will extract the main topics in the news archive in a weekly basis.",objective,1
5053,"By getting a weekly report, user can know what were the main news events in the past week.",method,2
5054,Decades of research and numerous incidents have demonstrated the weaknesses of text passwords and prompted the need for more secure alternatives.,background,0
5055,"In recent years, two-factor authentication (2F) has emerged as the most used solution to strengthen passwords.",background,0
5056,"By requiring users to provide more than one authentication factor – e.g., a code generated by a security token, along with the password – 2F aims to enhance resilience against guessing attacks and breaches of password databases.",background,0
5057,"Alas, it also introduces non-negligible costs for service providers and requires users to carry out additional actions during the authentication process, nevertheless, little research has focused on its usability.",background,0
5058,This paper presents a comparative usability study of twofactor authentication.,objective,1
5059,"First, we report on a preliminary interview-based study involving 9 participants, identifying the most popular 2F technologies as well as the contexts and motivations in which they are used.",method,2
5060,"Then, we design and administer a survey to 219 Mechanical Turk users, aiming to explore the landscape of 2F technologies and measure the usability of three popular solutions: codes generated by security tokens, one-time PINs received via email or SMS, and dedicated smartphone apps (e.g., Google Authenticator).",method,2
5061,"We record contexts and motivations, and study their impact on perceived usability.",method,2
5062,We also present an exploratory factor analysis that captures some key factors affecting usability of 2F and highlight interesting findings that call for further research in the field.,method,2
5063,"Taxi ridesharing can be of significant social and environmental benefit, e.g. by saving energy consumption and satisfying people's commute needs.",background,0
5064,"Despite the great potential, taxi ridesharing, especially with dynamic queries, is not well studied.",background,0
5065,"In this paper, we formally define the dynamic ridesharing problem and propose a large-scale taxi ridesharing service.",objective,1
5066,It efficiently serves real-time requests sent by taxi users and generates ridesharing schedules that reduce the total travel distance significantly.,background,0
5067,"In our method, we first propose a taxi searching algorithm using a spatio-temporal index to quickly retrieve candidate taxis that are likely to satisfy a user query.",method,2
5068,A scheduling algorithm is then proposed.,method,2
5069,It checks each candidate taxi and inserts the query's trip into the schedule of the taxi which satisfies the query with minimum additional incurred travel distance.,background,0
5070,"To tackle the heavy computational load, a lazy shortest path calculation strategy is devised to speed up the scheduling algorithm.",method,2
5071,"We evaluated our service using a GPS trajectory dataset generated by over 33,000 taxis during a period of 3 months.",result,3
5072,"By learning the spatio-temporal distributions of real user queries from this dataset, we built an experimental platform that simulates user real behaviours in taking a taxi.",method,2
5073,L-BFGS-B is a limited-memory algorithm for solving large nonlinear optimization problems subject to simple bounds on the variables.,objective,1
5074,"It is intended for problems in which information on the Hessian matrix is difficult to obtain, or for large dense problems.",objective,1
5075,"L-BFGS-B can also be used for unconstrained problems and in this case performs similarly to its predessor, algorithm L-BFGS (Harwell routine VA15).",method,2
5076,The algorithm is implemented in Fortran 77.,method,2
5077,Information Technology Infra-structure Library (ITIL) is the most popular “best practices” framework for managing Information Technology (IT) services.,background,0
5078,"However, implementing ITIL not only is very difficult but there also are no best practices for implementing ITIL.",background,0
5079,"As a result, ITIL implementations are usually long, expensive, and risky.",background,0
5080,"In this paper, we propose a maturity model to assess an ITIL implementation and provide a roadmap for improvement based on priorities, dependencies, and guidelines.",objective,1
5081,We then demonstrate a practical application of the proposed model with a questionnaire to assess the ITIL Incident Management process that was evaluated in two real-world organizations.,result,3
5082,"Recent rapid advances in ICTs, specifically in Internet and mobile technologies, have highlighted the rising importance of the Business Model (BM) in Information Systems (IS).",background,0
5083,"Despite agreement on its importance to an organization’s success, the concept is still fuzzy and vague, and there is no consensus regarding its definition.",background,0
5084,"Furthermore, understanding the BM domain by identifying its meaning, fundamental pillars, and its relevance to other business concepts is by no means complete.",objective,1
5085,"In this paper we aim to provide further clarification by first presenting a classification of definitions found in the IS literature; second, proposing guidelines on which to develop a more comprehensive definition in order to reach consensus; and third, identifying the four main business model concepts and values and their interaction, and thus place the business model within the world of digital business.",objective,1
5086,"Based on this discussion, we propose a new definition for the business model that we argue is more appropriate to this new world.",method,2
5087,We study the use of kinematic and dynamic vehicle models for model-based control design used in autonomous driving.,background,0
5088,"In particular, we analyze the statistics of the forecast error of these two models by using experimental data.",objective,1
5089,"In addition, we study the effect of discretization on forecast error.",background,0
5090,We use the results of the first part to motivate the design of a controller for an autonomous vehicle using model predictive control (MPC) and a simple kinematic bicycle model.,method,2
5091,The proposed approach is less computationally expensive than existing methods which use vehicle tire models.,method,2
5092,Moreover it can be implemented at low vehicle speeds where tire models become singular.,method,2
5093,Experimental results show the effectiveness of the proposed approach at various speeds on windy roads.,result,3
5094,Most tasks in natural language processing can be cast into question answering (QA) problems over language input.,background,0
5095,"We introduce the dynamic memory network (DMN), a unified neural network framework which processes input sequences and questions, forms semantic and episodic memories, and generates relevant answers.",method,2
5096,Questions trigger an iterative attention process which allows the model to condition its attention on the result of previous iterations.,method,2
5097,These results are then reasoned over in a hierarchical recurrent sequence model to generate answers.,method,2
5098,"The DMN can be trained end-to-end and obtains state of the art results on several types of tasks and datasets: question answering (Facebook’s bAbI dataset), sequence modeling for part of speech tagging (WSJ-PTB), coreference resolution (Quizbowl dataset) and text classification for sentiment analysis (Stanford Sentiment Treebank).",result,3
5099,The model relies exclusively on trained word vector representations and requires no string matching or manually engineered features.,result,3
5100,Automatically recognizing entailment relations between pairs of natural language sentences has so far been the dominion of classifiers employing hand engineered features derived from natural language processing pipelines.,background,0
5101,End-to-end differentiable neural architectures have failed to approach state-of-the-art performance until very recently.,background,0
5102,"In this paper, we propose a neural model that reads two sentences to determine entailment using long short-term memory units.",objective,1
5103,We extend this model with a word-by-word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases.,method,2
5104,"Furthermore, we present a qualitative analysis of attention weights produced by this model, demonstrating such reasoning capabilities.",method,2
5105,On a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin.,result,3
5106,It is the first generic end-to-end differentiable system that achieves state-of-the-art accuracy on a textual entailment dataset.,method,2
5107,Impulse buying accounts for a large proportion of consumer shopping behavior in the bricks-and-mortar retail market.,background,0
5108,Online retailers also expect to profit from impulse buying.,background,0
5109,It is therefore interesting and beneficial to investigate the design elements of online stores and the sales promotion stimuli that eretailers can use to either arouse consumers’ desire or decrease their self-control to evoke their purchase impulses.,objective,1
5110,This study seeks to explicitly identify the factors associated with online store design and sales promotion stimuli that most affect online impulse buying behavior throughout the consumer decisionmaking process.,method,2
5111,"Drawing on the two-factor theory, it successfully identifies the hygiene and motivation factors that trigger online impulse buying.",method,2
5112,"The questionnaire responses of 239 valid respondents revealed that most of the hygiene factors are associated with the design of online stores, and all of the motivation factors are forms of sales promotion stimuli that effectively facilitate online impulse buying and present utilitarian or hedonic benefits to consumers.",method,2
5113,This study also identifies the most effective sales promotion stimuli and offers a comprehensive checklist for Web designers.,result,3
5114,"Moreover, the distribution of motivation and hygiene factors for each stage of the EKB model is uneven, and some stages include only hygiene factors.",result,3
5115,"The findings of this study demonstrate that the triggers of consumers’ online shopping behavior do not always apply to online impulse buying, and have important implications for impulse buying research",result,3
5116,"Purpose – Customer relationship management (CRM) is an information system that tracks customers’ interactions with the firm and allows employees to instantly pull up information about the customers such as past sales, service records, outstanding records and unresolved problem calls.",background,0
5117,This paper aims to put forward strategies for successful implementation of CRM and discusses barriers to CRM in e-business and m-business.,objective,1
5118,Design/methodology/approach – The paper combines narrative with argument and analysis.,method,2
5119,"Findings – CRM stores all information about its customers in a database and uses this data to coordinate sales, marketing, and customer service departments so as to work together smoothly to best serve their customers’ needs.",result,3
5120,"Originality/value – The paper demonstrates how CRM, if used properly, could enhance a company’s ability to achieve the ultimate goal of retaining customers and gain strategic advantage over its competitors.",result,3
5121,"Processing: A Programming Handbook for Visual Designers and Artists With this completely revised edition, Casey Reas and Ben Fry show readers how.",background,0
5122,"Processing: A Programming Handbook for Visual Designers and Artists by Ben Fry, Casey Reas, John Maeda download pdf book.",background,0
5123,"Jun 28, 2010 –",background,0
5124,"All right,.",other,4
5125,"With Ben Fry, Reas initiated Processing in 2001.",background,0
5126,"Reas and Fry published Processing: A Programming Handbook for Visual Designers and Artists, a comprehensive introduction to programming within the context of visual media (MIT Press.",result,3
5127,We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists.,objective,1
5128,"Our algorithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, currently the largest publicly available chest Xray dataset, containing over 100,000 frontalview X-ray images with 14 diseases.",background,0
5129,"Four practicing academic radiologists annotate a test set, on which we compare the performance of CheXNet to that of radiologists.",method,2
5130,We find that CheXNet exceeds average radiologist performance on the F1 metric.,result,3
5131,We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.,result,3
5132,It is important for researchers to efficiently conduct quality literature studies.,background,0
5133,"Hence, a structured and efficient approach is essential.",background,0
5134,We overview work that has demonstrated the potential for using software tools in literature reviews.,objective,1
5135,We highlight the untapped opportunities in using an end-to-end tool-supported literature review methodology.,objective,1
5136,"Qualitative data-analysis tools such as NVivo are immensely useful as a means to analyze, synthesize, and write up literature reviews.",method,2
5137,"In this paper, we describe how to organize and prepare papers for analysis and provide detailed guidelines for actually coding and analyzing papers, including detailed illustrative strategies to effectively write up and present the results.",method,2
5138,We present a detailed case study as an illustrative example of the proposed approach put into practice.,method,2
5139,"We discuss the means, value, and also pitfalls of applying tool-supported literature review approaches.",method,2
5140,We contribute to the literature by proposing a four-phased tool-supported methodology that serves as best practice in conducting literature reviews in IS.,method,2
5141,"By viewing the literature review process as a qualitative study and treating the literature as the “data set”, we address the complex puzzle of how best to extract relevant literature and justify its scope, relevance, and quality.",method,2
5142,"Organizations adopt sophisticated management information systems, which provide top managers with an ample range of information to achieve multiple strategic performances.",background,0
5143,"However, organizations differ in the extent to which they improve their performance.",background,0
5144,This paper analyzes the role of top management team in the relationship between management information systems and strategic performance.,objective,1
5145,"Using data collected from 92 top management teams, it analyses how different team compositions interact with a sophisticated management information system, and how this interaction affects strategic performances, which are focused on cost reduction and flexibility.",method,2
5146,The findings show how the effect of management information system on strategic performance (focused on flexibility) is moderated by top management,result,3
5147,Capturing the uncertain aspects in cyber security is important for security analysis in enterprise networks.,background,0
5148,"However, there has been insufficient effort in studying what modeling approaches correctly capture such uncertainty, and how to construct the models to make them useful in practice.",background,0
5149,"In this paper, we present our work on justifying uncertainty modeling for cyber security, and initial evidence indicating that it is a useful approach.",objective,1
5150,Our work is centered around near real-time security analysis such as intrusion response.,method,2
5151,"We need to know what is really happening, the scope and severity level, possible consequences, and potential countermeasures.",method,2
5152,We report our current efforts on identifying the important types of uncertainty and on using Bayesian networks to capture them for enhanced security analysis.,method,2
5153,"We build an example Bayesian network based on a current security graph model, justify our modeling approach through attack semantics and experimental study, and show that the resulting Bayesian network is not sensitive to parameter perturbation.",method,2
5154,"Machine learning and Data mining are becoming increasingly important in the recent years and have been successfully applied to solve a number of problems, especially in the areas of science and engineering.",background,0
5155,A variety of algorithms exist in the popular data mining tool ‘Weka’ to classify a given set of records into different classes.,background,0
5156,"However, choosing the right classifier among them is a tricky task as the performance of a particular algorithm depends on various factors such as the application domain and the data set.",background,0
5157,"In order to aid the researchers in comparing the performances of various classification algorithms in Weka, we have developed an online resource named Web-Weka using which one can compare a set of classification algorithms on a single data set on the fly and choose the right classifier for their study.",method,2
5158,The tool is available for free at www.mcr.org.in/webweka.,other,4
5159,"We present a unified model for face detection, pose estimation, and landmark estimation in real-world, cluttered images.",background,0
5160,Our model is based on a mixtures of trees with a shared pool of parts; we model every facial landmark as a part and use global mixtures to capture topological changes due to viewpoint.,objective,1
5161,"We show that tree-structured models are surprisingly effective at capturing global elastic deformation, while being easy to optimize unlike dense graph structures.",method,2
5162,"We present extensive results on standard face benchmarks, as well as a new “in the wild” annotated dataset, that suggests our system advances the state-of-the-art, sometimes considerably, for all three tasks.",result,3
5163,"Though our model is modestly trained with hundreds of faces, it compares favorably to commercial systems trained with billions of examples (such as Google Picasa and face.com).",background,0
5164,"Risk Management, according with the ISO Guide 73 is the set of ""coordinated activities to direct and control an organization with regard to risk"".",background,0
5165,"In a nutshell, Risk Management is the business process used to manage risk in organizations.",background,0
5166,ISO 31000 defines a framework and process for risk management.,background,0
5167,"However, implementing this standard without a detailed plan can become a burden on organizations.",background,0
5168,This paper presents a maturity model for the risk management process based on ISO 31000.,objective,1
5169,The purpose of this model is to provide an assessment tool for organizations to use in order to get their current risk management maturity level.,objective,1
5170,The results can then be used to create an improvement plan which will guide organizations to reach their target maturity level.,result,3
5171,This maturity model allows organizations to assess a risk management process according to the best practices defined in risk management references.,result,3
5172,The maturity model can also be used as a reference for improving this process since it sets a clear path of how a risk management process should be performed.,result,3
5173,This brief presents a time-domain model for the slew rate of CMOS two-stage Miller compensated operational transconductance amplifiers.,background,0
5174,"The effects of both the first- and second-stage currents are considered in this model and a simple analytical expression is given in terms of the compensation and load capacitors, output voltage change, and device sizes.",method,2
5175,HSPICE simulation results are provided to show the validity of the proposed model using a 0.25-/spl mu/m CMOS technology.,result,3
5176,Fake news detection is a critical yet challenging problem in Natural Language Processing (NLP).,background,0
5177,The rapid rise of social networking platforms has not only yielded a vast increase in information accessibility but has also accelerated the spread of fake news.,background,0
5178,"Given the massive amount of Web content, automatic fake news detection is a practical NLP problem required by all online content providers.",background,0
5179,This paper presents a survey on fake news detection.,objective,1
5180,Our survey introduces the challenges of automatic fake news detection.,method,2
5181,We systematically review the datasets and NLP solutions that have been developed for this task.,method,2
5182,"We also discuss the limits of these datasets and problem formulations, our insights, and recommended solutions.",result,3
5183,"We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total).",objective,1
5184,"The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text.",method,2
5185,"QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation.",result,3
5186,"We also report results for a number of reference models, including a recently state-ofthe-art reading comprehension architecture extended to model dialog context.",result,3
5187,"Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data.",result,3
5188,"Dataset, baseline, and leaderboard available at http://quac.ai.",result,3
5189,"With smart devices, particular smartphones, becoming our everyday companions, the ubiquitous mobile Internet and computing applications pervade people’s daily lives.",background,0
5190,"With the surge demand on high-quality mobile services at anywhere, how to address the ubiquitous user demand and accommodate the explosive growth of mobile traffics is the key issue of the next generation mobile networks.",background,0
5191,The Fog computing is a promising solution towards this goal.,objective,1
5192,Fog computing extends cloud computing by providing virtualized resources and engaged location-based services to the edge of the mobile networks so as to better serve mobile traffics.,objective,1
5193,"Therefore, Fog computing is a lubricant of the combination of cloud computing and mobile applications.",result,3
5194,"In this article, we outline the main features of Fog computing and describe its concept, architecture and design goals.",objective,1
5195,"Lastly, we discuss some of the future research issues from the networking perspective.",background,0
5196,"Data is nowadays an invaluable resource, indeed it guides all business decisions in most of the computer-aided human activities.",background,0
5197,"Threats to data integrity are thus of paramount relevance, as tampering with data may maliciously affect crucial business decisions.",background,0
5198,"This issue is especially true in cloud computing environments, where data owners cannot control fundamental data aspects, like the physical storage of data and the control of its accesses.",objective,1
5199,"Blockchain has recently emerged as a fascinating technology which, among others, provides compelling properties about data integrity.",method,2
5200,"Using the blockchain to face data integrity threats seems to be a natural choice, but its current limitations of low throughput, high latency, and weak stability hinder the practical feasibility of any blockchain-based solutions.",method,2
5201,"In this paper, by focusing on a case study from the European SUNFISH project, which concerns the design of a secure by-design cloud federation platform for the public sector, we precisely delineate the actual data integrity needs of cloud computing environments and the research questions to be tackled to adopt blockchain-based databases.",objective,1
5202,"First, we detail the open research questions and the difficulties inherent in addressing them.",result,3
5203,"Then, we outline a preliminary design of an effective blockchain-based database for cloud computing environments.",method,2
5204,"Compressed sensing is a novel research area, which was introduced in 2006, and since then has already become a key concept in various areas of applied mathematics, computer science, and electrical engineering.",background,0
5205,"It surprisingly predicts that high-dimensional signals, which allow a sparse representation by a suitable basis or, more generally, a frame, can be recovered from what was previously considered highly incomplete linear measurements by using efficient algorithms.",objective,1
5206,This article shall serve as an introduction to and a survey about compressed sensing.,objective,1
5207,This study explores teenage girls' narrations of the relationship between self-presentation and peer comparison on social media in the context of beauty.,objective,1
5208,Social media provide new platforms that manifest media and peer influences on teenage girls' understanding of beauty towards an idealized notion.,background,0
5209,"Through 24 in-depth interviews, this study examines secondary school girls' self-presentation and peer comparison behaviors on social network sites where the girls posted self-portrait photographs or “selfies” and collected peer feedback in the forms of “likes,” “followers,” and comments.",method,2
5210,Results of thematic analysis reveal a gap between teenage girls' self-beliefs and perceived peer standards of beauty.,result,3
5211,Feelings of low self-esteem and insecurity underpinned their efforts in edited self-presentation and quest for peer recognition.,result,3
5212,"Peers played multiple roles that included imaginary audiences, judges, vicarious learning sources, and comparison targets in shaping teenage girls' perceptions and presentation of beauty.",method,2
5213,Findings from this study reveal the struggles that teenage girls face today and provide insights for future investigations and interventions pertinent to teenage girls’ presentation and evaluation of self on,result,3
5214,"Starting from Shannon's celebrated 1948 channel coding theorem, we trace the evolution of channel coding from Hamming codes to capacity-approaching codes.",background,0
5215,"We focus on the contributions that have led to the most significant improvements in performance versus complexity for practical applications, particularly on the additive white Gaussian noise channel.",background,0
5216,"We discuss algebraic block codes, and why they did not prove to be the way to get to the Shannon limit.",method,2
5217,"We trace the antecedents of today's capacity-approaching codes: convolutional codes, concatenated codes, and other probabilistic coding schemes.",method,2
5218,"Finally, we sketch some of the practical applications of these codes.",result,3
5219,"We propose a simple, yet effective approach for spatiotemporal feature learning using deep 3-dimensional convolutional networks (3D ConvNets) trained on a large scale supervised video dataset.",background,0
5220,"Our findings are three-fold: 1) 3D ConvNets are more suitable for spatiotemporal feature learning compared to 2D ConvNets, 2) A homogeneous architecture with small 3x3x3 convolution kernels in all layers is among the best performing architectures for 3D ConvNets, and 3) Our learned features, namely C3D (Convolutional 3D), with a simple linear classifier outperform state-of-the-art methods on 4 different benchmarks and are comparable with current best methods on the other 2 benchmarks.",background,0
5221,"In addition, the features are compact: achieving 52.8% accuracy on UCF101 dataset with only 10 dimensions and also very efficient to compute due to the fast inference of ConvNets.",result,3
5222,"Finally, they are conceptually very simple and easy to train and use.",result,3
5223,"The use of virtual-reality technology in the areas of rehabilitation and therapy continues to grow, with encouraging results being reported for applications that address human physical, cognitive, and psychological functioning.",background,0
5224,"This article presents a SWOT (Strengths, Weaknesses, Opportunities, and Threats) analysis for the field of VR rehabilitation and therapy.",objective,1
5225,The SWOT analysis is a commonly employed framework in the business world for analyzing the factors that influence a company's competitive position in the marketplace with an eye to the future.,method,2
5226,"However, the SWOT framework can also be usefully applied outside of the pure business domain.",method,2
5227,"A quick check on the Internet will turn up SWOT analyses for urban-renewal projects, career planning, website design, youth sports programs, and evaluation of academic research centers, and it becomes obvious that it can be usefully applied to assess and guide any organized human endeavor designed to accomplish a mission.",method,2
5228,It is hoped that this structured examination of the factors relevant to the current and future status of VR rehabilitation will provide a good overview of the key issues and concerns that are relevant for understanding and advancing this vital application area.,result,3
5229,We have recently shown that deep Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform feed forward deep neural networks (DNNs) as acoustic models for speech recognition.,background,0
5230,"More recently, we have shown that the performance of sequence trained context dependent (CD) hidden Markov model (HMM) acoustic models using such LSTM RNNs can be equaled by sequence trained phone models initialized with connectionist temporal classification (CTC).",background,0
5231,"In this paper, we present techniques that further improve performance of LSTM RNN acoustic models for large vocabulary speech recognition.",method,2
5232,We show that frame stacking and reduced frame rate lead to more accurate models and faster decoding.,method,2
5233,CD phone modeling leads to further improvements.,method,2
5234,We also present initial results for LSTM RNN models outputting words directly.,result,3
5235,Designing a database system for both efficient data management and data services has been one of the enduring challenges in the healthcare domain.,background,0
5236,"In many healthcare systems, data services and data management are often viewed as two orthogonal tasks; data services refer to retrieval and analytic queries such as search, joins, statistical data extraction, and simple data mining algorithms, while data management refers to building error-tolerant and non-redundant database systems.",background,0
5237,The gap between service and management has resulted in rigid database systems and schemas that do not support effective analytics.,method,2
5238,We compose a rich graph structure from an abstracted healthcare RDBMS to illustrate how we can fill this gap in practice.,method,2
5239,We show how a healthcare graph can be automatically constructed from a normalized relational database using the proposed “3NF Equivalent Graph” (3EG) transformation.,method,2
5240,"We discuss a set of real world graph queries such as finding self-referrals, shared providers, and collaborative filtering, and evaluate their performance over a relational database and its 3EG-transformed graph.",method,2
5241,"Experimental results show that the graph representation serves as multiple de-normalized tables, thus reducing complexity in a database and enhancing data accessibility of users.",result,3
5242,"Based on this finding, we propose an ensemble framework of databases for healthcare applications.",result,3
5243,"We present a system for online handwritten signature verification, approaching the problem as a two-class pattern recognition problem.",objective,1
5244,"A test signature s authenticity is established by first aligning it with each reference signature for the claimed user, using dynamic time warping.",method,2
5245,"The distances of the test signature to the nearest, farthest and template reference signatures are normalized by the corresponding mean values obtained from the reference set, to form a threedimensional feature vector.",method,2
5246,This feature vector is then classified into one of the two classes (genuine or forgery).,method,2
5247,A linear classifier used in conjunction with the principal component analysis obtained a 1.4% error rate for a data set of 94 people and 619 test signatures (genuine signatures and skilled forgeries).,method,2
5248,Our method received the first place at SVC2004 with a 2.8% error rate.,method,2
5249,2005 Elsevier B.V. All rights reserved.,other,4
5250,"This work on GGS-NN is motivated by the program verification application, where we need to analyze dynamic data structures created in the heap.",background,0
5251,"On a very high level, in this application a machine learning model analyzes the heap states (a graph with memory nodes and pointers as edges) during the execution of a program and comes up with logical formulas that describes the heap.",background,0
5252,These logical formulas are then fed into a theorem prover to prove the correctness of the program.,method,2
5253,Problem-specific node annotations are used to initialize .,method,2
5254,Training classifiers with datasets which suffer of imbalanced class distributions is an important problem in data mining.,background,0
5255,This issue occurs when the number of examples representing the class of interest is much lower than the ones of the other classes.,background,0
5256,Its presence in many real-world applications has brought along a growth of attention from researchers.,background,0
5257,"We shortly review the many issues in machine learning and applications of this problem, by introducing the characteristics of the imbalanced dataset scenario in classification, presenting the specific metrics for evaluating performance in class imbalanced learning and enumerating the proposed solutions.",method,2
5258,"In particular, we will describe preprocessing, costsensitive learning and ensemble techniques, carrying out an experimental study to contrast these approaches in an intra and inter-family comparison.",method,2
5259,We will carry out a thorough discussion on the main issues related to using data intrinsic characteristics in this classification problem.,method,2
5260,"This will help to improve the current models with respect to: the presence of small disjuncts, the lack of density in the training data, the overlapping between classes, the identification of noisy data, the significance of the borderline instances, and the dataset shift between the training and the test distributions.",other,4
5261,"Finally, we introduce several approaches and recommendations to address these problems in conjunction with imbalanced data, and we will show some experimental examples on the behavior of the learning algorithms on data with such intrinsic characteristics.",result,3
5262,2013 Elsevier Inc. All rights reserved.,other,4
5263,"An in-depth analysis of the 80x86 processor families identi es architectural properties that may have unexpected, and undesirable, results in secure computer systems.",background,0
5264,"In addition, reported implementation errors in some processor versions render them undesirable for secure systems because of potential security and reliability problems.",background,0
5265,"In this paper, we discuss the imbalance in scrutiny for hardware protection mechanisms relative to software, and why this imbalance is increasingly di cult to justify as hardware complexity increases.",objective,1
5266,We illustrate this di culty with examples of architectural subtleties and reported implementation errors.,other,4
5267,Visual place recognition is a challenging problem due to the vast range of ways in which the appearance of real-world places can vary.,background,0
5268,"In recent years, improvements in visual sensing capabilities, an ever-increasing focus on long-term mobile robot autonomy, and the ability to draw on state-of-the-art research in other disciplines-particularly recognition in computer vision and animal navigation in neuroscience-have all contributed to significant advances in visual place recognition systems.",background,0
5269,This paper presents a survey of the visual place recognition research landscape.,objective,1
5270,"We start by introducing the concepts behind place recognition-the role of place recognition in the animal kingdom, how a “place” is defined in a robotics context, and the major components of a place recognition system.",method,2
5271,"Long-term robot operations have revealed that changing appearance can be a significant factor in visual place recognition failure; therefore, we discuss how place recognition solutions can implicitly or explicitly account for appearance change within the environment.",method,2
5272,"Finally, we close with a discussion on the future of visual place recognition, in particular with respect to the rapid advances being made in the related fields of deep learning, semantic scene understanding, and video description.",result,3
5273,Continuing growth of energy use by commercial buildings has created a need to develop innovative techniques to reduce and optimize building energy use.,background,0
5274,Recently Building Energy Management Systems (BEMS) have gained popularity because of increasing interest in building energy conservation and savings.,background,0
5275,"In this study, a conceptual framework for real-time weather responsive control systems combined with BEMS is proposed to achieve model simulation based Smart BEMS.",objective,1
5276,"The proposed control system is developed using building energy control patterns, which are generated from the combinations of weather data changes.",method,2
5277,"As a result, building energy use can be adjusted by, for example, using daylighting responsive controls for electrical lighting as well as by adjusting the HVAC operational schedule, in response to weather changes.",method,2
5278,"To create control logics for model based Smart systems, BIM and Computational Fluid Dynamic (CFD) simulation are used to obtain material properties and to develop air flow operational algorithms, respectively.",method,2
5279,Restricted Boltzmann machines were developed using binary stochastic hidden units.,background,0
5280,These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases.,method,2
5281,The learning and inference rules for these “Stepped Sigmoid Units” are unchanged.,method,2
5282,"They can be approximated efficiently by noisy, rectified linear units.",method,2
5283,"Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset.",result,3
5284,"Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.",method,2
5285,"The variety and complexity in cloud marketplaces is growing, making it difficult for cloud consumers to choose cloud services from multiple providers in an economic and suitable way by taking into account multiple objectives and constraints.",background,0
5286,"In this paper, we present an extension of CloudSim implementing cloud management functionality to enable the assessment of consumer-oriented brokering schemes.",objective,1
5287,The underlying discrete-event simulation framework allows evaluating their performance in more realistic operating conditions in a repeatable manner.,result,3
5288,We integrate brokering mechanisms to support a multi-criteria location-aware selection of virtual machines in multi-cloud environments by implementing a greedy heuristic and two large neighborhood search metaheuristics.,method,2
5289,"Based on microbenchmarks of real cloud offerings and a diverse set of scenarios and workloads, we conduct simulation experiments to assess the performance of our approaches.",method,2
5290,The results show that approximately 10 12 % of the total costs can be saved by using a large neighborhood search approach compared to the greedy heuristic.,method,2
5291,"Finally, we analyze and discuss the trade-off between costs and latency as well as the impact of region constraints, showing, e.g., that latency improvements often come at a high price and a greater regional flexibility can lead to latency improvements while solely optimizing costs.",result,3
5292,"Using real data of cloud marketplaces, we show that the proposed CloudSim extension can support decision makers as a tool for assessing cloud portfolios and market dynamics.",result,3
5293,Interleaving is an online evaluation method that compares two ranking functions by mixing their results and interpreting the users' click feedback.,method,2
5294,"An important property of an interleaving method is its sensitivity, i.e. the ability to obtain reliable comparison outcomes with few user interactions.",background,0
5295,"Several methods have been proposed so far to improve interleaving sensitivity, which can be roughly divided into two areas: (a) methods that optimize the credit assignment function (how the click feedback is interpreted), and (b) methods that achieve higher sensitivity by controlling the interleaving policy (how often a particular interleaved result page is shown).",method,2
5296,"In this paper, we propose an interleaving framework that generalizes the previously studied interleaving methods in two aspects.",method,2
5297,"First, it achieves a higher sensitivity by performing a joint data-driven optimization of the credit assignment function and the interleaving policy.",method,2
5298,"Second, we formulate the framework to be general w.r.t.",method,2
5299,"the search domain where the interleaving experiment is deployed, so that it can be applied in domains with grid-based presentation, such as image search.",method,2
5300,"In order to simplify the optimization, we additionally introduce a stratified estimate of the experiment outcome.",method,2
5301,"This stratification is also useful on its own, as it reduces the variance of the outcome and thus increases the interleaving sensitivity.",method,2
5302,We perform an extensive experimental study using large-scale document and image search datasets obtained from a commercial search engine.,method,2
5303,It is often important for designers and photographers to convey or enhance desired color themes in their work.,background,0
5304,A color theme is typically defined as a template of colors and an associated verbal description.,background,0
5305,This paper presents a data-driven method for enhancing a desired color theme in an image.,method,2
5306,"We formulate our goal as a unified optimization that simultaneously considers a desired color theme, texture-color relationships as well as automatic or user-specified color constraints.",other,4
5307,Quantifying the difference between an image and a color theme is made possible by color mood spaces and a generalization of an additivity relationship for two-color combinations.,method,2
5308,"We incorporate prior knowledge, such as texture-color relationships, extracted from a database of photographs to maintain a natural look of the edited images.",method,2
5309,Experiments and a user study have confirmed the effectiveness of our method.,result,3
5310,"Because of the properties such as transparency, decentralization, irreversibility, nonrepudiation, etc.",background,0
5311,", blockchain is not only a fundamental technology of great interest in its own right, but also has large potential when integrated into many other areas.",background,0
5312,"In this paper, based on the blockchain technology, we propose a decentralized e-voting protocol, without the existence of a trusted third party.",objective,1
5313,"Furthermore, we provide several possible extensions and improvements that meet the requirements in some specific voting scenarios.",objective,1
5314,"Current research has yet to examine the phenomenon of rape culture, particularly within social media forums.",background,0
5315,"The present study investigated the attitudes about rape, rapists, and gender-based violence within the comments section of newspaper articles reporting about rape and sexual assault.",background,0
5316,Naturalistic observation was used in order to gather statements within the comment sections following newspaper articles posted on either the periodical website or the periodical’s Facebook page.,method,2
5317,Four themes and various sub-themes emerged from the data.,background,0
5318,"The major themes include, Victim Blaming and Questioning, Survivor Support, Perpetrator Support, and Trolling Statements about Law and Society.",objective,1
5319,"Notable findings were found in the amount of victim blaming statements made in the comments responding to articles (25.8 percent) and perpetrator support comments were found responding to every article collected, except for one.",result,3
5320,The authors discuss the implications of rape culture within and outside social media and suggest future research to be conducted to further understand the impacts of rape culture within the online sphere.,result,3
5321,© 2016 Elsevier Ltd.,other,4
5323,This paper evaluates the four leading techniques proposed in the literature for construction of prediction intervals (PIs) for neural network point forecasts.,background,0
5324,"The delta, Bayesian, bootstrap, and mean-variance estimation (MVE) methods are reviewed and their performance for generating high-quality PIs is compared.",method,2
5325,PI-based measures are proposed and applied for the objective and quantitative assessment of each method's performance.,method,2
5326,A selection of 12 synthetic and real-world case studies is used to examine each method's performance for PI construction.,method,2
5327,"The comparison is performed on the basis of the quality of generated PIs, the repeatability of the results, the computational requirements and the PIs variability with regard to the data uncertainty.",method,2
5328,"The obtained results in this paper indicate that: 1) the delta and Bayesian methods are the best in terms of quality and repeatability, and 2) the MVE and bootstrap methods are the best in terms of low computational load and the width variability of PIs.",result,3
5329,"This paper also introduces the concept of combinations of PIs, and proposes a new method for generating combined PIs using the traditional PIs.",other,4
5330,Genetic algorithm is applied for adjusting the combiner parameters through minimization of a PI-based cost function subject to two sets of restrictions.,other,4
5331,It is shown that the quality of PIs produced by the combiners is dramatically better than the quality of PIs obtained from each individual method.,other,4
5332,One of the primary goals of computer architects is to design computers that are more costeffective than their predecessors.,objective,1
5333,"Cost-effectiveness includes the cost of hardware to manufacture the machine, the cost of programming, and costs incurred related to the architecture in debugging both the initial hardware and subsequent programs.",background,0
5334,If we review the history of computer families we find that the most common architectural change is the trend toward ever more complex machines.,background,0
5335,Presumably this additional complexity has a positive tradeoff with regard to the costeffectiveness of newer models.,background,0
5336,"In this paper we propose that this trend is not always cost-effective, and in fact, may even do more harm than good.",method,2
5337,We shall examine the case for a Reduced Instruction Set Computer (RISC) being as cost-effective as a Complex Instruction Set Computer (CISC).,result,3
5338,This paper will argue that the next generation of VLSI computers may be more effectively implemented as RISC's than CISC's.,result,3
5339,This paper documents a work on all-purpose discrete event simulation tools evaluation.,background,0
5340,Selected tools must be suitable for process design (e.g. manufacturing or services industries).,background,0
5341,"Rather than making specific judgments of the tools, authors tried to measure the intensity of usage or presence in different sources, which they called “popularity”.",background,0
5342,"It was performed in several different ways, including occurrences in the WWW and scientific publications with tool name and vendor name.",background,0
5343,"This work is an upgrade to the same study issued 5 years ago (2011), which in its turn was also an upgrade of 10 years ago (in 2006).",background,0
5344,"It is obvious that more popularity does not assure more quality, or being better to the purpose of a simulation tool; however, a positive correlation may exist between them.",method,2
5345,"The result of this work is a short list, of 19 commercial simulation tools, with probably the nowadays' most relevant ones.",result,3
5346,We develop a new edge detection algorithm that addresses two important issues in this long-standing vision problem: (1) holistic image training and prediction; and (2) multi-scale and multi-level feature learning.,objective,1
5347,"Our proposed method, holistically-nested edge detection (HED), performs image-to-image prediction by means of a deep learning model that leverages fully convolutional neural networks and deeply-supervised nets.",method,2
5348,HED automatically learns rich hierarchical representations (guided by deep supervision on side responses) that are important in order to resolve the challenging ambiguity in edge and object boundary detection.,method,2
5349,"We significantly advance the state-of-the-art on the BSDS500 dataset (ODS F-score of 0.790) and the NYU Depth dataset (ODS F-score of 0.746), and do so with an improved speed (0.4 s per image) that is orders of magnitude faster than some CNN-based edge detection algorithms developed before HED.",method,2
5350,We also observe encouraging results on other boundary detection benchmark datasets such as Multicue and PASCAL-Context.,result,3
5351,Describing clothing appearance with semantic attributes is an appealing technique for many important applications.,background,0
5352,"In this paper, we propose a fully automated system that is capable of generating a list of nameable attributes for clothes on human body in unconstrained images.",objective,1
5353,"We extract low-level features in a pose-adaptive manner, and combine complementary features for learning attribute classifiers.",method,2
5354,Mutual dependencies between the attributes are then explored by a Conditional Random Field to further improve the predictions from independent classifiers.,method,2
5355,"We validate the performance of our system on a challenging clothing attribute dataset, and introduce a novel application of dressing style analysis that utilizes the semantic attributes produced by our system.",result,3
5356,"The human forearm is composed of two long, thin bones called the radius and the ulna, and rotates using two axle joints.",background,0
5357,"We aimed to develop a forearm based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body in order to bring out its benefits.",objective,1
5358,"For this, we need to miniaturize the muscle modules.",method,2
5359,"To approach this task, we arranged two muscle motors inside one muscle module, and used the space effectively by utilizing common parts.",method,2
5360,"In addition, we enabled the muscle module to also be used as the bone structure.",method,2
5361,"Moreover, we used miniature motors and developed a way to dissipate the motor heat to the bone structure.",method,2
5362,"Through these approaches, we succeeded in developing a forearm with a radioulnar joint based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body, while keeping maintainability and reliability.",result,3
5363,"Also, we performed some motions such as soldering, opening a book, turning a screw, and badminton swinging using the benefits of the radioulnar structure, which have not been discussed before, and verified that Kengoro can realize skillful motions using the radioulnar joint like a human.",result,3
5364,We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction.,background,0
5365,"By analogy with auto-encoders, we propose Context Encoders - a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings.",background,0
5366,"In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s).",background,0
5367,"When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss.",background,0
5368,The latter produces much sharper results because it can better handle multiple modes in the output.,result,3
5369,We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures.,method,2
5370,"We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks.",result,3
5371,"Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.",method,2
5372,Customer relationship management is a popular and strategic topic in marketing and quality of service.,background,0
5373,The availability of big transactions data as well as computing systems have provided a great opportunity to model and predict customer behaviour.,background,0
5374,"However, there is a lack of modern modelling and analytical methods to perform analysis on such data.",objective,1
5375,Deep learning techniques can assist marketing decision makers to provide more reliable and practical marketing strategic plans.,method,2
5376,"In this paper, we propose a customer behaviour prediction model using recurrent neural networks (RNNs) based on the client loyalty number (CLN), recency, frequency, and monetary (RFM) variables.",method,2
5377,The experiment results show that RNNs can predict RFM values of customers efficiently.,result,3
5378,This model can be later used in recommender systems for exclusive promotional offers and loyalty programs management.,result,3
5379,And has been very often be produced.,other,4
5380,"I should be obtained from dynamic, models are introduced through the discipline on?",other,4
5381,Addendum simulations can easily be migrated from simple introductory text presents.,background,0
5382,"This is an articulated way a, virtual twin of models that shall.",other,4
5383,But they are well written easy to estimate the acpe as they.,other,4
5384,This is a special use of technical and simulation society secretary models that they.,other,4
5385,The digital workplace is widely acknowledged as an important organizational asset for optimizing knowledge worker productivity.,background,0
5386,"While there is no particular research stream on the digital workplace, scholars have conducted intensive research on related topics.",background,0
5387,This study aims to summarize the practical implications of the current academic body of knowledge on the digital workplace.,objective,1
5388,"For this purpose, a screening of academic-practitioner literature was conducted, followed by a systematic review of academic top journal literature.",objective,1
5389,"The screening revealed four main research topics on the digital workplace that are present in academic-practitioner literature: 1) Collaboration, 2) Compliance, 3) Mobility, and 4) Stress and overload.",method,2
5390,"Based on the four topics, this study categorizes practical implications on the digital workplace into 15 concepts.",method,2
5391,"Thereby, it provides two main contributions.",result,3
5392,"First, the study delivers condensed information for practitioners about digital workplace design.",result,3
5393,"Second, the results shed light on the relevance of IS research.",result,3
5394,"We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoderswhich are trained locally to denoise corrupted versions of t heir inputs.",background,0
5395,The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders.,background,0
5396,"It is however shown on a benchmark of classification problems to yield sign ificantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it.",background,0
5397,Higher level representations learnt in this purely u ns pervised fashion also help boost the performance of subsequent SVM classifiers.,method,2
5398,"Qualitative exp eriments show that, contrary to ordinary autoencoders, denoising autoencoders are able to lear n Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images .",result,3
5399,Thi work clearly establishes the value of using a denoising criterion as a tractable unsupervised o bjective to guide the learning of useful higher level representations.,result,3
5400,Cancer detection from gene expression data continues to pose a challenge due to the high dimensionality and complexity of these data.,background,0
5401,After decades of research there is still uncertainty in the clinical diagnosis of cancer and the identification of tumor-specific markers.,background,0
5402,"Here we present a deep learning approach to cancer detection, and to the identification of genes critical for the diagnosis of breast cancer.",method,2
5403,"First, we used Stacked Denoising Autoencoder (SDAE) to deeply extract functional features from high dimensional gene expression profiles.",method,2
5404,"Next, we evaluated the performance of the extracted representation through supervised classification models to verify the usefulness of the new features in cancer detection.",result,3
5405,"Lastly, we identified a set of highly interactive genes by analyzing the SDAE connectivity matrices.",method,2
5406,Our results and analysis illustrate that these highly interactive genes could be useful cancer biomarkers for the detection of breast cancer that deserve further studies.,result,3
5407,Along with the popularity of mobile social networks (MSNs) is the increasing danger of privacy breaches due to user location exposures.,background,0
5408,"In this work, we take an initial step towards quantifying location privacy leakage from MSNs by matching the users’ shared locations with their real mobility traces.",background,0
5409,"We conduct a three-week real-world experiment with 30 participants and discover that both direct location sharing (e.g., Weibo or Renren) and indirect location sharing (e.g., Wechat or Skout) can reveal a small percentage of users’ real points of interests (POIs).",method,2
5410,"We further propose a novel attack to allow an external adversary to infer the demographics (e.g., age, gender, education) after observing users’ exposed location profiles.",method,2
5411,"We implement such an attack in a large real-world dataset involving 22,843 mobile users.",method,2
5412,The experimental results show that the attacker can effectively predict demographic attributes about users with some shared locations.,method,2
5413,"To resist such attacks, we propose SmartMask, a context-based system-level privacy protection solution, designed to automatically learn users’ privacy preferences under different contexts and provide a transparent privacy control for MSN users.",method,2
5414,The effectiveness and efficiency of SmartMask have been well validated by extensive experiments.,result,3
5415,"Online feedback mechanisms harness the bidirectional communication capabilities of the Internet to engineer large-scale, word-of-mouth networks.",objective,1
5416,"Best known so far as a technology for building trust and fostering cooperation in online marketplaces, such as eBay, these mechanisms are poised to have a much wider impact on organizations.",objective,1
5417,"Their growing popularity has potentially important implications for a wide range of management activities such as brand building, customer acquisition and retention, product development, and quality assurance.",background,0
5418,This paper surveys our progress in understanding the new possibilities and challenges that these mechanisms represent.,objective,1
5419,"It discusses some important dimensions in which Internet-based feedback mechanisms differ from traditional word-of-mouth networks and surveys the most important issues related to their design, evaluation, and use.",objective,1
5420,It provides an overview of relevant work in game theory and economics on the topic of reputation.,objective,1
5421,"It discusses how this body of work is being extended and combined with insights from computer science, management science, sociology, and psychology to take into consideration the special properties of online environments.",method,2
5422,"Finally, it identifies opportunities that this new area presents for operations research/management science (OR/MS) research.",result,3
5423,(Reputation Mechanisms; Online Feedback; Electronic Markets; Trust; Internet; Game Theory ),other,4
5424,The visual recognition problem is central to computer vision research.,background,0
5425,"From robotics to information retrieval, many desired applications demand the ability to identify and localize categories, places, and objects.",objective,1
5426,This tutorial overviews computer vision algorithms for visual object recognition and image classification.,objective,1
5427,"We introduce primary representations and learning approaches, with an emphasis on recent advances in the field.",method,2
5428,"The target audience consists of researchers or students working in AI, robotics, or vision who would like to understand what methods and representations are available for these problems.",result,3
5429,"This lecture summarizes what is and isn’t possible to do reliably today, and overviews key concepts that could be employed in systems requiring visual categorization.",result,3
5430,In this paper we construct a Star Join Schema and show how this schema can be created using the basic tools delivered with SQL Server 7.0.,background,0
5431,Major objectives are to keep the operational database unchanged so that data loading can be done without disturbing the business logic of the operational database.,objective,1
5432,The operational database is an expanded version of the Pubs database [Sol96].,result,3
5433,"The dynamic Boltzmann machine (DyBM) has been proposed as a stochastic generative model of multi-dimensional time series, with an exact, learning rule that maximizes the log-likelihood of a given time series.",background,0
5434,"The DyBM, however, is defined only for binary valued data, without any nonlinear hidden units.",background,0
5435,"Here, in our first contribution, we extend the DyBM to deal with real valued data.",objective,1
5436,"We present a formulation called Gaussian DyBM, that can be seen as an extension of a vector autoregressive (VAR) model.",method,2
5437,"This uses, in addition to standard (explanatory) variables, components that captures long term dependencies in the time series.",method,2
5438,"In our second contribution, we extend the Gaussian DyBM model with a recurrent neural network (RNN) that controls the bias input to the DyBM units.",method,2
5439,"We derive a stochastic gradient update rule such that, the output weights from the RNN can also be trained online along with other DyBM parameters.",method,2
5440,"Furthermore, this acts as nonlinear hidden layer extending the capacity of DyBM and allows it to model nonlinear components in a given time-series.",method,2
5441,Numerical experiments with synthetic datasets show that the RNN-Gaussian DyBM improves predictive accuracy upon standard VAR by up to ≈ 35%.,result,3
5442,"On real multi-dimensional time-series prediction, consisting of high nonlinearity and non-stationarity, we demonstrate that this nonlinear DyBM model achieves significant improvement upon state of the art baseline methods like VAR and long short-term memory (LSTM) networks at a reduced com-",result,3
5443,Recognition techniques for printed and handwritten text in scanned documents are significantly different.,background,0
5444,In this paper we address the problem of identifying each type.,objective,1
5445,"We can list at least four steps: digitalization, preprocessing, feature extraction and decision or classification.",method,2
5446,A new aspect of our approach is the use of data mining techniques on the decision step.,method,2
5447,A new set of features extracted of each word is proposed as well.,method,2
5448,Classification rules are mining and used to discern printed text from handwritten.,method,2
5449,The proposed system was tested in two public image databases.,result,3
5450,All possible measures of efficiency were computed achieving on every occasion quantities above 80%.,result,3
5451,Data Centers (DCs) are experiencing a tremendous growth in the number of hosted servers.,background,0
5452,Aggregate bandwidth requirement is a major bottleneck to data center performance.,background,0
5453,New Data Center Network (DCN) architectures are proposed to handle different challenges faced by current DCN architecture.,background,0
5454,"In this paper we have implemented and simulated two promising DCN architectural models, namely switch-based and hybrid models, and compared their effectiveness by monitoring the network throughputs and average packet latencies.",method,2
5455,"The presented analysis may be a background for the further studies on the simulation and implementation of the DCN customized topologies, and customized addressing protocols in the large-scale data centers.",result,3
5456,The Port of Singapore Authority (PSA) used information technology (IT) extensively to create a high-tech port that has become the busiest port in the world.,objective,1
5457,"Now corporatised as a commercial port operator, PSA Corporation Ltd employs four key management success factors in managing IT to meet the demands and challenges facing port operators.",background,0
5458,They are: (1) having a business-driven IT investment; (2) aligning business and IT plans; (3) maintaining a ̄exible and extensible IT infrastructure; and (4) encouraging IT innovation and creativity.,method,2
5459,These management success factors are discussed and examples are given to illustrate how they help PSA more effectively leverage IT to streamline operations and sustain its competitive advantage.,method,2
5460,q 2000 Elsevier Science B.V.,other,4
5462,"As healthcare organizations continue to be asked to do more with less, access to information is essential for sound evidence-based decision making.",background,0
5463,Business intelligence (BI) systems are designed to deliver decision-support information and have been repeatedly shown to provide value to organizations.,background,0
5464,Many healthcare organizations have yet to implement BI systems and no existing research provides a healthcare-specific framework to guide implementation.,background,0
5465,"To address this research gap, we employ a case study in a Canadian Health Authority in order to address three questions: (1) what are the most significant adverse impacts to the organization’s decision processes and outcomes attributable to a lack of decision-support capabilities?",method,2
5466,"(2) what are the root causes of these impacts, and what workarounds do they necessitate?",method,2
5467,"and (3) in light of the issues identified, what are the key considerations for healthcare organizations in the early stages of BI implementation?",method,2
5468,Using the concept of co-agency as a guide we identified significant decision-related adverse impacts and their root causes.,result,3
5469,"We found strong management support, the right skill sets and an information-oriented culture to be key implementation considerations.",result,3
5470,Our major contribution is a framework for defining and prioritizing decision-support information needs in the context of healthcare-specific processes.,result,3
5471,© 2013 Elsevier Ltd.,other,4
5472,The Internet has become an indispensable tool in peoples' daily life.,background,0
5473,It also bring us serious computer security problem.,background,0
5474,One big security threat comes from malicious webpages.,background,0
5475,In this paper we study how to detect malicious pages.,result,3
5476,"Since malicious webpages are generated inconstantly, we use on line learning methods to detect malicious webpages.",method,2
5477,"To keep the client side as safe as possible, we do not download the webpages, and analysis webpages' content.",method,2
5478,We only use URL information to determine if the URL links to a malicious pages.,method,2
5479,"The feature selection methods for URL are discussed, and the performances of different on line learning methods are compared.",method,2
5480,"To improve the performance of on line learning classifiers, an improved on line learning method is proposed, experiments show that this method is effective.",result,3
5481,Small object segmentation is a common task in medical image analysis.,background,0
5482,Traditional feature-based methods require human intervention while methods based on deep learning train the neural network automatically.,background,0
5483,"However, it is still error prone when applying deep learning methods for small objects.",method,2
5484,"In this paper, Focal FCN was proposed for small object segmentation with limited training data.",method,2
5485,"Firstly, Fully-weighted FCN was proposed to apply an initialization for Focal FCN by adding weights to the background and foreground loss.",method,2
5486,"Secondly, focal loss was applied to make the training focus on wrongly-classified pixels and hence achieve good performance on small object segmentation.",method,2
5487,"Comparisons between FCN, Weighted FCN, Fully-weighted FCN and Focal FCN were tested on customized stent graft marker segmentation.",result,3
5488,"Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data.",background,0
5489,"In this paper, we provide a review of how such statistical models can be “trained” on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph).",objective,1
5490,"In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets.",objective,1
5491,The first is based on latent feature models such as tensor factorization and multiway neural networks.,method,2
5492,The second is based on mining observable patterns in the graph.,method,2
5493,We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost.,method,2
5494,"Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web.",method,2
5495,"To this end, we also discuss Google's knowledge vault project as an example of such combination.",result,3
5496,"Information technology (IT) has long been applied to support the exchange of goods, services and information between organizations.",background,0
5497,It is with the advent of Internet-based e-procurement systems and businessto-business (B2B) electronic markets that the real opportunities for online transactions have opened up across space and over time.,background,0
5498,"In this paper, we draw on IS and economics theory to investigate the motivation for the various online business models, and the adoption requirements of purchasing firms, through the examination of a set of mini-cases.",objective,1
5499,"Our exploratory study finds that private aggregating and negotiating mechanisms are being adopted for large quantity business supply purchases, while public market mechanisms are more often adopted when firms face uncertain and high variance demand.",objective,1
5500,"Moreover, market facilitation, expertise sharing and collaboration are gradually attracting more attention, and call for future investigation.",result,3
5501,"Since the early 1990s, there has been a significant research activity in efficient parallel algorithms and novel computer architectures for problems that have been already solved sequentially (sorting, maximum flow, searching, etc).",background,0
5502,"In this handout, we are interested in parallel algorithms and we avoid particular hardware details.",objective,1
5503,The primary architectural model for our algorithms is a simplified machine called Parallel RAM (or PRAM).,method,2
5504,"In essence, the PRAM model consists of a number p of processors that can read and/or write on a shared “global” memory in parallel (i.e., at the same time).",background,0
5505,The processors can also perform various arithmetic and logical operations in parallel.,background,0
5506,Using SQL has not been considered an efficient and feasible way to implement data mining algorithms.,background,0
5507,"Although this is true for many data mining, machine learning and statistical algorithms, this work shows it is feasible to get an efficient SQL implementation of the well-known K-means clustering algorithm that can work on top of a relational DBMS.",background,0
5508,The article emphasizes both correctness and performance.,background,0
5509,"From a correctness point of view the article explains how to compute Euclidean distance, nearest-cluster queries and updating clustering results in SQL.",objective,1
5510,"From a performance point of view it is explained how to cluster large data sets defining and indexing tables to store and retrieve intermediate and final results, optimizing and avoiding joins, optimizing and simplifying clustering aggregations, and taking advantage of sufficient statistics.",method,2
5511,Experiments evaluate scalability with synthetic data sets varying size and dimensionality.,result,3
5512,The proposed K-means implementation can cluster large data sets and exhibits linear scalability.,result,3
5513,"This paper examines and optimizes parameters that affect the air cooling of a Lithium-Ion (Li-Ion) battery, used in Electric Vehicles (EVs).",background,0
5514,A battery pack containing 150 cylindrical type Li-Ion battery cells in a PVC casing is investigated.,background,0
5515,An equal number of tubes are used in the pack as a medium to cool the battery by using a fan when the vehicle is stationary or with ambient air when in motion.,method,2
5516,The parameters affecting the air cooling of battery are studied and optimized by considering their practical constraints.,method,2
5517,The objective function and Number of Transfer Unit (NTU) are developed.,method,2
5518,"Finally, a genetic algorithm method is employed to optimize the decision variables.",method,2
5519,Analysing the results shows that NTU can be maximized by increasing the diameter of tubes on the battery and keeping the air velocity in a certain range.,result,3
5520,• Current neural network models.,background,0
5521,– They have drawbacks • Solution: – Deep reinforcement learning.,other,4
5522,CISC850 Cyber Analytics,other,4
5523,"Twitter, a 140-character microblogging social networking service, has garnered attention from researchers and practitioners due to its considerable potential for information diffusion.",background,0
5524,Prior studies on Twitter typically focused on how user traits or relationships in a network affect information diffusion.,background,0
5525,"However, few studies have been conducted on how posted messages in the service influence this phenomenon.",background,0
5526,"Thus, this paper focuses on posted messages (a.k.a.",result,3
5527,“tweets”) and how they affect individuals’ information sharing behaviors on Twitter.,method,2
5528,A model for investigating tweet sharing behavior on Twitter is proposed based on dual-process theory and on social cognitive theory.,method,2
5529,Results from a preliminary test show that individuals’ perceptions of the argument quality and source credibility of a received tweet play a major role in their information sharing behavior via the perceived level of usefulness of the information and self-efficacy in regard to the sharing of a received tweet.,result,3
5530,"Additionally, the existence of external links in a tweet moderates the impact of argument quality on users’ attitudes toward received tweets.",result,3
5531,"Embedded systems are the driving force for technological development in many domains such as automotive, healthcare, and industrial control in the emerging post-PC era.",background,0
5532,"As more and more computational and networked devices are integrated into all aspects of our lives in a pervasive and “invisible” way, security becomes critical for the dependability of all smart or intelligent systems built upon these embedded systems.",background,0
5533,"In this paper, we conduct a systematic review of the existing threats and vulnerabilities in embedded systems based on public available data.",objective,1
5534,"Moreover, based on the information, we derive an attack taxonomy for embedded systems.",method,2
5535,We envision that the findings in this paper provide a valuable insight of the threat landscape facing embedded systems.,result,3
5536,The knowledge can be used for a better understanding and the identification of security risks in system analysis and design.,result,3
5537,"Natural languages are full of collocations, recurrent combinations of words that co-occur more often than expected by chance and that correspond to arbitrary word usages.",background,0
5538,"Recent work in lexicography indicates that collocations are pervasive in English; apparently, they are common in all types of writing, including both technical and nontechnical genres.",background,0
5539,Several approaches have been proposed to retrieve various types of collocations from the analysis of large samples of textual data.,background,0
5540,These techniques automatically produce large numbers of collocations along with statistical figures intended to reflect the relevance of the associations.,background,0
5541,"However, noue of these techniques provides functional information along with the collocation.",background,0
5542,"Also, the results produced often contained improper word associations reflecting some spurious aspect of the training corpus that did not stand for true collocations.",background,0
5543,"In this paper, we describe a set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora.",method,2
5544,These techniques produce a wide range of collocations and are based on some original filtering methods that allow the production of richer and higher-precision output.,method,2
5545,"These techniques have been implemented and resulted in a lexicographic tool, Xtract.",method,2
5546,The techniques are described and some results are presented on a 10 million-word corpus of stock market news reports.,method,2
5547,This paper presents a 64-bit lightweight block cipherTWINE supporting 80 and 128-bit keys.,background,0
5548,"TWINE realizes quite small hardware implementation similar to the previous lightweight block cipher proposals, yet enables efficient software implementations on various CPUs, from micro-controllers to high-end CPUs.",method,2
5549,"This characteristic is obtained by the use of generalized Feistel combined with an improved block shuffle, introduced at FSE 2010.",method,2
5550,A Particle Swarm Optimization Toolbox (PSOt) for use with the Matlab scientific programming environment has been developed.,background,0
5551,PSO is introduced briefly and then the use of the toolbox is explained with some examples.,background,0
5552,A link to downloadable code is provided.,method,2
5553,"I. GENERAL INFORMATION A. Particle Swarm Optimization Toolbox (PSOt), Summary of Included Files Main files: 1) PSO – finds min/max of arbitrary MISO functions using PSO 2) trainPSO – Function to train neural nets using PSO 3) tpso1,2,3 – called by trainPSO for training 0 hidden layer, 1 hidden layer, and 2 hidden layer ANNs respectively.",result,3
5554,Support files: 4) wrapmat – convert vector(s) into matrix(ces) 5),result,3
5555,unwrapmat – convert any 2d matrix(ces) into a row vector(s) 6) normalize – takes a 2D matrix and reformats it to any specified range 7) goplotpso – called by trainpso for graphical display during training Demo and miscellaneous files: 8) DemoTrainPSO – shows an example of using PSO to train a neural net to the XOR function 9) f6 – Schaffer’s f6 function 10) hypara – 4 dimensional hyperbolic paraboloid function 11) hypara2 – 8 dimensional hyperbolic paraboloid function The toolbox may be downloaded freely as a self extracting zipfile from: http://www4.ncsu.edu/~bkbirge/PSO/PSOt.exe,result,3
5556,"In this paper, a novel approach for automatic segmentation and classification of skin lesions is proposed.",objective,1
5557,"Initially, skin images are filtered to remove unwanted hairs and noise and then the segmentation process is carried out to extract lesion areas.",method,2
5558,"For segmentation, a region growing method is applied by automatic initialization of seed points.",method,2
5559,The segmentation performance is measured with different well known measures and the results are appreciable.,method,2
5560,"Subsequently, the extracted lesion areas are represented by color and texture features.",method,2
5561,SVM and k-NN classifiers are used along with their fusion for the classification using the extracted features.,method,2
5562,The performance of the system is tested on our own dataset of 726 samples from 141 images consisting of 5 different classes of diseases.,result,3
5563,The results are very promising with 46.71% and 34% of F-measure using SVM and k-NN classifier respectively and with 61% of F-measure for fusion of SVM and k-NN.,result,3
5564,© 2015 The Authors.,other,4
5565,Published by Elsevier B.V. Peer-review under responsibility of scientific committee of International Conference on Advanced Computing Technologies and Applications (ICACTA-2015).,other,4
5566,Deep learning is at the heart of the current rise of artificial intelligence.,background,0
5567,"In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security.",background,0
5568,"Whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs.",background,0
5569,"For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models.",background,0
5570,Adversarial attacks pose a serious threat to the success of deep learning in practice.,background,0
5571,This fact has recently led to a large influx of contributions in this direction.,background,0
5572,This paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision.,objective,1
5573,"We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them.",method,2
5574,"To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios.",method,2
5575,"Finally, drawing on the reviewed literature, we provide a broader outlook of this research direction.",result,3
5576,"In the last two decades, we have witnessed that Interval Type-2 Fuzzy Logic Systems (IT2-FLSs) have been successfully implemented in various engineering areas.",background,0
5577,"In this paper, we will introduce a free open source Mat lab/Simulink toolbox for the development of IT2-FLSs for a wider accessibility to users beyond the type-2 fuzzy logic community.",background,0
5578,The presented IT2-FLS toolbox allows intuitive implementation of IT2-FLSs where it is capable to cover all the phases of its design.,objective,1
5579,"In order to allow users to easily construct IT2-FISs, a GUI is developed which is similar to that of Matlab® Fuzzy Logic Toolbox.",background,0
5580,We have embedded various Type Reduction (TR) methods in the toolbox since the TR method is the most important operation that must be taken into consideration.,method,2
5581,This gives the opportunity to the user to examine the performance of his/her IT2-FLS design with respect to the TR methods.,method,2
5582,We have also developed an IT2-FLS Simulink library so that the designer can perform various simulation analyses and can also investigate the effect of TR method on the performance of the IT2-FLS.,method,2
5583,"Moreover, the developed IT2-FLS Mat lab/Simulink toolbox contains an automatic connection between Matlab and Simulink environments.",method,2
5584,"Once the user has finished the design of the IT2-FLS via the GUI, it is possible to export his/her design directly to Simulink via an automatic Simulink file generation.",method,2
5585,We believe that the availability of the developed free and open-source IT2-FLS Mat lab/Simulink toolbox will be an important step for a wider deployment and development of IT2-FLSs.,result,3
5586,This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection.,background,0
5587,Short tutorial descriptions of each ML/DM method are provided.,method,2
5588,"Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized.",method,2
5589,"Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described.",result,3
5590,"The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.",result,3
5591,"It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall.",background,0
5592,"It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes.",background,0
5593,"In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy.",objective,1
5594,The optimization criterion used is that the average quantization noise power be a minimum.,method,2
5595,It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large.,result,3
5596,"The optimum quantization schemes for 26 quanta, b = 1,2, t ,7, are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.",result,3
5597,This paper focuses on a fleet management problem that arises in container trucking industry.,background,0
5598,"From the container transportation company perspective, the present and future operating costs to minimize can be divided in three components: the routing costs, the resource (i.e., driver and truck) assignment costs and the container repositioning costs (i.e., the costs of restoring a given container fleet distribution over the serviced territory, as requested by the shippers that own the containers).",objective,1
5599,This real-world problem has been modeled as an integer programming problem.,background,0
5600,The proposed solution approach is based on the decomposition of this problem in three simpler sub-problems associated to each of the costs considered above.,method,2
5601,"Numerical experiments on randomly generated instances, as well as on a real-world data set of an Italian container trucking company, are presented.",method,2
5602,2004 Elsevier B.V. All rights reserved.,other,4
5603,Transmission of IPv6 packets over Low-power Wireless Personal Area Networks (6LoWPAN) was considered nearly impractical once.,background,0
5604,The size of IPv6 packets is much larger than the packet size of the IEEE 802.15.4 data link layer.,background,0
5605,6LoWPAN implements an adaptation layer between network and data link layers.,background,0
5606,Main purpose of the adaptation layer is to fragment and reassemble IPv6 packets.,objective,1
5607,Implementation of the adaptation layer enhances the routing/forwarding decision of packets both network and adaptation layers.,result,3
5608,"We can divide the routing scheme in 6LoWPAN into two categories: the mesh-under and the route-over, based on the routing decision taken on adaptation layer or network layer respectively.",result,3
5609,"In this paper we perform an analytical comparison between these two schemes in terms of the packet/fragment arrival probability, the total number of transmissions and the total delay between source and destination.",method,2
5610,We also compare the selective fragment retransmission mechanism between mesh-under and route-over schemes.,method,2
5611,"Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations.",background,0
5612,"However, machine learning research in this area has been dramatically limited by the lack of large-scale resources.",background,0
5613,"To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning.",background,0
5614,"At 570K pairs, it is two orders of magnitude larger than all other resources of its type.",background,0
5615,"This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.",background,0
5616,Materials that possess a negative Poisson's ratio are called Auxetics.,background,0
5617,They are characterized by the counterintuitive behavior of expanding in tension and contracting in compression.,background,0
5618,"To justify this deformation behavior, there have been developed theoretical modelations like the reentrant and bowtie models.",objective,1
5619,"However, the most generalized models are based on geometries that possess rigid trusses and hinging nodes.",method,2
5620,This does not portrait the reality of the application of these models.,method,2
5621,"In this study, there have been performed simulations, using kinematic analysis to characterize the auxetic behavior of the theoretical rigid/hinging models and finite element analysis to characterize elastic models that represent real bodies.",result,3
5622,There were determined and compared the Poisson's ratios of the theoretical and elastic reentrant and bowtie.,method,2
5623,Additionally it was shown that there is a significant difference between the results.,result,3
5624,"In conclusion the theoretical models predict lower values of Poisson's ratio, while the elastic models that simulate a real body show less auxetic behavior.",result,3
5625,Researchers investigated the impact of podcasting on student motivation in the online environment during fall 2008 and spring 2009.,background,0
5626,Data were collected from students enrolled in fourteen online courses at a research university in the United States.,method,2
5627,"One hundred and ninety-one students completed a modified version of the Instructional Materials Motivation Survey (Keller, 2006); it has four subscales: attention, relevance, confidence, and satisfaction.",result,3
5628,Strong positive relationships between all subscales were detected.,background,0
5629,Results indicate students were moderately motivated by the use of podcasts in their online courses.,result,3
5630,"Statistically significant differences in student motivation based on gender, class standing, and prior online learning experience were found.",result,3
5631,Benefits of using podcasts and recommendations for improvement of the multimedia files were offered by users.,result,3
5632,2010 Elsevier Ltd. All rights reserved.,other,4
5633,Clustering nodes in a graph is a useful general technique in data mining of large network data sets.,background,0
5634,"In this context, Newman and Girvan [9] recently proposed an objective function for graph clustering called the Q function which allows automatic selection of the number of clusters.",objective,1
5635,"Empirically, higher values of the Q function have been shown to correlate well with good graph clusterings.",background,0
5636,In this paper we show how optimizing the Q function can be reformulated as a spectral relaxation problem and propose two new spectral clustering algorithms that seek to maximize Q. Experimental results indicate that the new algorithms are efficient and effective at finding both good clusterings and the appropriate number of clusters across a variety of real-world graph data sets.,result,3
5637,"In addition, the spectral algorithms are much faster for large sparse graphs, scaling roughly linearly with the number of nodes n in the graph, compared to O(n) for previous clustering algorithms using the Q function.",result,3
5638,"With the advent of new, low-cost 3D sensing hardware such as the Kinect, and continued efforts in advanced point cloud processing, 3D perception gains more and more importance in robotics, as well as other fields.",background,0
5639,In this paper we present one of our most recent initiatives in the areas of point cloud perception: PCL (Point Cloud Library - http://pointclouds.org).,objective,1
5640,"PCL presents an advanced and extensive approach to the subject of 3D perception, and it's meant to provide support for all the common 3D building blocks that applications need.",method,2
5641,"The library contains state-of-the art algorithms for: filtering, feature estimation, surface reconstruction, registration, model fitting and segmentation.",method,2
5642,PCL is supported by an international community of robotics and perception researchers.,result,3
5643,We provide a brief walkthrough of PCL including its algorithmic capabilities and implementation strategies.,result,3
5644,This contribution presents a novel approach for nonlinear time-optimal model predictive control (MPC) based on Timed-Elastic-Bands (TEB).,background,0
5645,"The TEB merges the states, control inputs and time intervals into a joint trajectory representation which enables planning of time-optimal trajectories in the context of model predictive control.",method,2
5646,Model predictive control integrates the planning of the optimal trajectory with state feedback in the control loop.,method,2
5647,The TEB approach formulates the fixed horizon optimal control problem for point-to-point transitions as a nonlinear program.,method,2
5648,The comparative analysis of the TEB approach with state-of-the-art approaches demonstrates its computational efficiency.,result,3
5649,The TEB approach generates a trajectory that approximates the analytical time-optimal trajectory in few iterations.,method,2
5650,This efficiency enables the refinement of the planned state and control sequence within the underlying closed-loop control during runtime.,result,3
5651,"We describe a number of applications of digital watermarking and the examine the common properties of robustness, tamper resistance, fidelity, computational cost and false positive rate.",background,0
5652,We observe that these properties vary greatly depending on the application.,result,3
5653,"Consequently, we conclude that evaluation of a watermarking algorithm is difficult without first indicating the context in which it is to",result,3
5654,"In this paper, we explore academic data center utilization rates from an energy management perspective with the broader goal of providing decision support for green computing.",objective,1
5655,The utilization rate is defined as the overall extent to which data center servers are being used and is usually recorded as a percentage.,result,3
5656,Recent literature states that utilization rates at many data centers are quite low resulting in poor usage of resources such as energy and labor.,method,2
5657,Based on our study we attribute these lower utilization rates to not fully taking advantage of virtualization and cloud technology.,method,2
5658,"This paper describes our research including energy data analysis with our proposed equations for performance measurement and forecasting, corroborated by evaluation with real data in a university setting.",result,3
5659,We suggest that future data centers will need to increase their utilization rates and thus shift more towards the cloud in order to lower costs and increase services despite current concerns for security of cloud technology.,result,3
5660,"A number of probabilistic methods such as LDA, hidden Markov models, Markov random fields have arisen in recent years for probabilistic analysis of text data.",background,0
5661,This chapter provides an overview of a variety of probabilistic models for text mining.,background,0
5662,"The chapter focuses more on the fundamental probabilistic techniques, and also covers their various applications to different text mining problems.",objective,1
5663,"Some examples of such applications include topic modeling, language modeling, document classification, document clustering, and information extraction.",background,0
5664,A process model of hypertext reading was used to generate predictions about the effects of hypertext features on cognitive processing during text navigation and comprehension.,background,0
5665,"We evaluated the predictions of the model with respect to the extant literature, focusing on studies in which versions of hypertexts were compared.",method,2
5666,"Consistent with our predictions, the increased demands of decisionmaking and visual processing in hypertext impaired reading performance.",background,0
5667,"Individual differences in readers, such as working memory capacity and prior knowledge, mediated the impact of hypertext features.",background,0
5668,"For example, readers with low working memory and low prior knowledge were usually disadvantaged in hypertext.",background,0
5669,"Some benefits were observed for learners with low prior knowledge, however, if the hypertext structure was hierarchical and consistent with that of the knowledge domain.",result,3
5670,"We also surveyed the effectiveness of structural features designed to reduce cognitive load, including graphical overviews, restricted access to links, and visible link types.",method,2
5671,"Complex graphical overviews did not reliably enable learning and navigation, whereas navigational support from restricted access and visible link types were helpful.",result,3
5672,We identified gaps in the empirical literature and suggested future studies to investigate cognitive processes in hypertext reading.,result,3
5673,2005 Elsevier Ltd.,other,4
5674,We present the design of a novel performance-oriented serverless computing platform implemented in.,background,0
5675,"NET, deployed in Microsoft Azure, and utilizing Windows containers as function execution environments.",objective,1
5676,"Implementation challenges such as function scaling and container discovery, lifecycle, and reuse are discussed in detail.",objective,1
5677,"We propose metrics to evaluate the execution performance of serverless platforms and conduct tests on our prototype as well as AWS Lambda, Azure Functions, Google Cloud Functions, and IBM's deployment of Apache OpenWhisk.",method,2
5678,"Our measurements show the prototype achieving greater throughput than other platforms at most concurrency levels, and we examine the scaling and instance expiration trends in the implementations.",method,2
5679,"Additionally, we discuss the gaps and limitations in our current design, propose possible solutions, and highlight future research.",result,3
5680,We have built and tested a decision tool which will help organisations properly select one business process maturity model (BPMM) over another.,objective,1
5681,"This prototype consists of a novel questionnaire with decision criteria for BPMM selection, linked to a unique data set of 69 BPMMs.",method,2
5682,"Fourteen criteria (questions) were elicited from an international Delphi study, and weighed by the analytical hierarchy process.",background,0
5683,Case studies have shown (non-)profit and academic applications.,result,3
5684,"Our purpose was to describe criteria that enable an informed BPMM choice (conform to decision-making theories, rather than ad hoc).",objective,1
5685,"Moreover, we propose a design process for building BPMM decision tools.",method,2
5686,2013 Elsevier B.V. All rights reserved.,other,4
5687,"From history to the present day, especially in the field of technology is provided a wide range of developments.",objective,1
5688,"The most important of these developments has achieved the realization of the industrial revolution, has led to play a leading role in the production is done by human beings.",method,2
5689,The effects on production of industry 4.0 emerging with this mind is very important.,background,0
5690,"The qualified employees should be trained to make the necessary preparations for the company in this period, it is experiencing the fourth industrial revolution.",background,0
5691,"Therefore, the impacts on higher education of industry 4.0 are examined in this paper.",background,0
5692,The importance in education of industry 4.0 has revealed with statistical data presented in this study.,result,3
5693,"In this paper, we survey the basic paradigms and notions of secure multiparty computation and discuss their relevance to the field of privacy-preserving data mining.",background,0
5694,"In addition to reviewing definitions and constructions for secure multiparty computation, we discuss the issue of efficiency and demonstrate the difficulties involved in constructing highly efficient protocols.",method,2
5695,We also present common errors that are prevalent in the literature when secure multiparty computation techniques are applied to privacy-preserving data mining.,method,2
5696,"Finally, we discuss the relationship between secure multiparty computation and privacy-preserving data mining, and show which problems it solves and which problems it does not.",method,2
5697,The Internet is evolving rapidly toward the future Internet of Things (IoT) which will potentially connect billions or even trillions of edge devices which could generate huge amount of data at a very high speed and some of the applications may require very low latency.,background,0
5698,"The traditional cloud infrastructure will run into a series of difficulties due to centralized computation, storage, and networking in a small number of datacenters, and due to the relative long distance between the edge devices and the remote datacenters.",background,0
5699,"To tackle this challenge, edge cloud and edge computing seem to be a promising possibility which provides resources closer to the resource-poor edge IoT devices and potentially can nurture a new IoT innovation ecosystem.",background,0
5700,"Such prospect is enabled by a series of emerging technologies, including network function virtualization and software defined networking.",background,0
5701,"In this survey paper, we investigate the key rationale, the state-of-the-art efforts, the key enabling technologies and research topics, and typical IoT applications benefiting from edge cloud.",objective,1
5702,We aim to draw an overall picture of both ongoing research efforts and future possible research directions through comprehensive discussions.,objective,1
5703,Genetic Algorithm is a search heuristic that mimics the process of evaluation.,background,0
5704,Genetic Algorithms can be applied to process controllers for their optimization using natural operators.,background,0
5705,This paper discusses the concept and design procedure of Genetic Algorithm as an optimization tool.,objective,1
5706,"Further, this paper explores the well established methodologies of the literature to realize the workability and applicability of genetic algorithms for process control applications.",method,2
5707,"Genetic Algorithms are applied to direct torque control of induction motor drive, speed control of gas turbine, speed control of DC servo motor for the optimization of control parameters in this work.",method,2
5708,The simulations were carried out in simulink package of MATLAB.,method,2
5709,The simulation results show better optimization of hybrid genetic algorithm controllers than fuzzy standalone and conventional controllers.,result,3
5710,Insufficient sleep is a known trigger of anxiety.,background,0
5711,"Nevertheless, not everyone experiences these effects to the same extent.",background,0
5712,"One determining factor is sex, wherein women experience a greater anxiogenic impact in response to sleep loss than men.",background,0
5713,"However, the underlying brain mechanism(s) governing this sleep-loss-induced anxiety increase, including the markedly different reaction in women and men, is unclear.",background,0
5714,"Here, we tested the hypothesis that structural brain morphology in a discrete network of emotion-relevant regions represents one such explanatory factor.",method,2
5715,"Healthy participants were assessed across sleep-rested and sleep-deprived conditions, with brain structure quantified using gray matter volume measures.",objective,1
5716,Sleep loss triggered greater levels of anxiety in women compared with men.,result,3
5717,"Reduced gray matter volume in the anterior insula and lateral orbitofrontal cortex predicted the anxiogenic impact of sleep loss in women, yet predicted resilience in men, and did so with high discrimination accuracy.",result,3
5718,"In contrast, gray matter volume in ventromedial prefrontal cortex predicted the anxiogenic impact of sleep loss in both men and women.",result,3
5719,Structural human brain morphology therefore appears to represent one mechanistic pathway (and possible biomarker) determining anxiety vulnerability to sleep loss—a discovery that may help explain the higher prevalence of sleep disruption and anxiety in women.,result,3
5720,In this paper we introduce a low-latency monaural source separation framework using a Convolutional Neural Network (CNN).,objective,1
5721,We use a CNN to estimate time-frequency soft masks which are applied for source separation.,method,2
5722,"We evaluate the performance of the neural network on a database comprising of musical mixtures of three instruments: voice, drums, bass as well as other instruments which vary from song to song.",result,3
5723,"The proposed architecture is compared to a Multilayer Perceptron (MLP), achieving on-par results and a significant improvement in processing time.",result,3
5724,"The algorithm was submitted to source separation evaluation campaigns to test efficiency, and achieved competitive results.",result,3
5725,Recent advances in clothes recognition have been driven by the construction of clothes datasets.,background,0
5726,Existing datasets are limited in the amount of annotations and are difficult to cope with the various challenges in real-world applications.,background,0
5727,"In this work, we introduce DeepFashion1, a large-scale clothes dataset with comprehensive annotations.",result,3
5728,"It contains over 800,000 images, which are richly annotated with massive attributes, clothing landmarks, and correspondence of images taken under different scenarios including store, street snapshot, and consumer.",method,2
5729,Such rich annotations enable the development of powerful algorithms in clothes recognition and facilitating future researches.,result,3
5730,"To demonstrate the advantages of DeepFashion, we propose a new deep model, namely FashionNet, which learns clothing features by jointly predicting clothing attributes and landmarks.",result,3
5731,The estimated landmarks are then employed to pool or gate the learned features.,method,2
5732,It is optimized in an iterative manner.,result,3
5733,Extensive experiments demonstrate the effectiveness of FashionNet and the usefulness of DeepFashion.,method,2
5734,This paper investigates two fundamental problems in computer vision: contour detection and image segmentation.,objective,1
5735,We present state-of-the-art algorithms for both of these tasks.,method,2
5736,Our contour detector combines multiple local cues into a globalization framework based on spectral clustering.,method,2
5737,Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree.,method,2
5738,"In this manner, we reduce the problem of image segmentation to that of contour detection.",method,2
5739,Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms.,method,2
5740,The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations.,method,2
5741,Computation at multiple image resolutions provides a means of coupling our system to recognition applications.,other,4
5742,"Despite their different perspectives, artificial intelligence (AI) and the disciplines of decision science have common roots and strive for similar goals.",objective,1
5743,"This paper surveys the potential for addressing problems in representation, inference, knowledge engineering, and explanation within the decision-theoretic framework.",method,2
5744,"Recent analyses of the restrictions of several traditional A I reasoning techniques, coupled with the development of more tractable and expressive decision-theoretic representation and inference strategies, have stimulated renewed interest in decision theory and decision analysis.",method,2
5745,"We describe early experience with simple probabilistic schemes for automated reasoning, review the dominant expert-system paradigm, and survey some recent research at the crossroads of A I and decision science.",method,2
5746,"In particular, we present the belief network and influence diagram representations.",method,2
5747,"Finally, we discuss issues that have not been studied in detail within the expert-systems setting, yet are crucial for developing theoretical methods and computational architectures for automated reasoners.",result,3
5748,"K E Y W O R D S : artificial intelligence, belief networks, decision analysis, decision theory, explanation, influence diagrams, knowledge engineering, operations research, probability, uncertainty",result,3
5749,Neural Networks are formally hard to train.,background,0
5750,How can we circumvent hardness results?,method,2
5751,"• Over specified networks: While over specification seems to speedup training , formally hardness results are valid in the improper model.",method,2
5752,"• Changing the activation function: While changing the activation function from sigmoid to ReLu has lead to faster convergence of SGD methods, formally these networks are still hard.",method,2
5753,The most exciting development in parallel computer architecture is the convergence of traditionally disparate approaches on a common machine structure.,background,0
5754,"This book explains the forces behind this convergence of shared-memory, message-passing, data parallel, and data-driven computing architectures.",objective,1
5755,"It then examines the design issues that are critical to all parallel architecture across the full range of modern design, covering data access, communication performance, coordination of cooperative work, and correct implementation of useful semantics.",objective,1
5756,It not only describes the hardware and software techniques for addressing each of these issues but also explores how these techniques interact in the same system.,method,2
5757,"Examining architecture from an application-driven perspective, it provides comprehensive discussions of parallel programming for high performance and of workload-driven evaluation, based on understanding hardware-software interactions.",result,3
5758,"Fall detection is a major challenge in the public health care domain, especially for the elderly, and reliable surveillance is a necessity to mitigate the effects of falls.",background,0
5759,The technology and products related to fall detection have always been in high demand within the security and the health-care industries.,background,0
5760,An effective fall detection system is required to provide urgent support and to significantly reduce the medical care costs associated with falls.,background,0
5761,"In this paper, we give a comprehensive survey of different systems for fall detection and their underlying algorithms.",objective,1
5762,"Fall detection approaches are divided into three main categories: wearable device based, ambience device based and vision based.",method,2
5763,These approaches are summarised and compared with each other and a conclusion is derived with some discussions on possible future work.,objective,1
5764,& 2012 Elsevier B.V. All rights reserved.,other,4
5765,Artificial neural networks (ANNs) are very popular as classification or regression mechanisms in medical decision support systems despite the fact that they are unstable predictors.,background,0
5766,This instability means that small changes in the training data used to build the model (i.e. train the ANN) may result in very different models.,background,0
5767,A central implication of this is that different sets of training data may produce models with very different generalisation accuracies.,objective,1
5768,"In this paper, we show in detail how this can happen in a prediction system for use in in-vitro fertilisation.",objective,1
5769,We argue that claims for the generalisation performance of ANNs used in such a scenario should only be based on k-fold cross-validation tests.,result,3
5770,We also show how the accuracy of such a predictor can be improved by aggregating the output of several predictors.,result,3
5771,"Deep Convolutional Neural Networks (DCNNs) have recently shown state of the art performance in high level vision tasks, such as image classification and object detection.",background,0
5772,This work brings together methods from DCNNs and probabilistic graphical models for addressing the task of pixel-level classification (also called ”semantic image segmentation”).,objective,1
5773,We show that responses at the final layer of DCNNs are not sufficiently localized for accurate object segmentation.,objective,1
5774,This is due to the very invariance properties that make DCNNs good for high level tasks.,objective,1
5775,We overcome this poor localization property of deep networks by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF).,method,2
5776,"Qualitatively, our “DeepLab” system is able to localize segment boundaries at a level of accuracy which is beyond previous methods.",method,2
5777,"Quantitatively, our method sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 71.6% IOU accuracy in the test set.",method,2
5778,We show how these results can be obtained efficiently: Careful network re-purposing and a novel application of the ’hole’ algorithm from the wavelet community allow dense computation of neural net responses at 8 frames per second on a modern GPU.,result,3
5779,Baseline wandering can mask some important features of the Electrocardiogram (ECG) signal hence it is desirable to remove this noise for proper analysis and display of the ECG signal.,background,0
5780,This paper presents the implementation and evaluation of different methods to remove this noise.,background,0
5781,"The parameters i. e. Power Spectral density (PSD), average Power & Signal to noise ratio (SNR) are calculated of signals to compare the performance of different filtering methods.",method,2
5782,IIR zero phase filtering has been proved efficient method for the removal of Baseline wander from ECG signal.,method,2
5783,The results have been concluded using Matlab software and MIT-BIH arrhythmia database.,result,3
5784,This paper re-examines the concept of ‘‘meme’’ in the context of digital culture.,objective,1
5785,"Defined as cultural units that spread from person to person, memes were debated long before the digital era.",background,0
5786,"Yet the Internet turned the spread of memes into a highly visible practice, and the term has become an integral part of the netizen vernacular.",background,0
5787,"After evaluating the promises and pitfalls of memes for understanding digital culture, I address the problem of defining memes by charting a communication-oriented typology of 3 memetic dimensions: content, form, and stance.",method,2
5788,"To illustrate the utility of the typology, I apply it to analyze the video meme ‘‘Leave Britney Alone.",result,3
5789,’’,other,4
5790,"Finally, I chart possible paths for further meme-oriented analysis of digital content.",result,3
5791,"In traditional customer service support of a manufacturing environment, a customer service database usually stores two types of service information: (1) unstructured customer service reports record machine problems and its remedial actions and (2) structured data on sales, employees, and customers for day-to-day management operations.",background,0
5792,This paper investigates how to apply data mining techniques to extract knowledge from the database to support two kinds of customer service activities: decision support and machine fault diagnosis.,objective,1
5793,"A data mining process, based on the data mining tool DBMiner, was investigated to provide structured management data for decision support.",method,2
5794,"In addition, a data mining technique that integrates neural network, case-based reasoning, and rule-based reasoning is proposed; it would search the unstructured customer service records for machine fault diagnosis.",method,2
5795,The proposed technique has been implemented to support intelligent fault diagnosis over the World Wide Web.,method,2
5796,# 2000 Elsevier Science B.V. All rights reserved.,other,4
5797,"We consider the problem of face swapping in images, where an input identity is transformed into a target identity while preserving pose, facial expression and lighting.",background,0
5798,"To perform this mapping, we use convolutional neural networks trained to capture the appearance of the target identity from an unstructured collection of his/her photographs.",method,2
5799,"This approach is enabled by framing the face swapping problem in terms of style transfer, where the goal is to render an image in the style of another one.",method,2
5800,"Building on recent advances in this area, we devise a new loss function that enables the network to produce highly photorealistic results.",result,3
5801,"By combining neural networks with simple pre- and post-processing steps, we aim at making face swap work in real-time with no input from the user.",objective,1
5802,Clustering is a division of data into groups of similar objects.,background,0
5803,"Representing the data by fewer clusters necessarily loses certain fine details, but achieves simplification.",background,0
5804,It models data by its clusters.,result,3
5805,"Data modeling puts clustering in a historical perspective rooted in mathematics, statistics, and numerical analysis.",method,2
5806,"From a machine learning perspective clusters correspond to hidden patterns, the search for clusters is unsupervised learning, and the resulting system represents a data concept.",result,3
5807,"From a practical perspective clustering plays an outstanding role in data mining applications such as scientific data exploration, information retrieval and text mining, spatial database applications, Web analysis, CRM, marketing, medical diagnostics, computational biology, and many others.",result,3
5808,Tic-Tac-Toe game can be played by two players where the square block (3 x 3) can be filled with a cross (X) or a circle (O).,background,0
5809,The game will toggle between the players by giving the chance for each player to mark their move.,background,0
5810,"When one of the players make a combination of 3 same markers in a horizontal, vertical or diagonal line the program will display which player has won, whether X or O. In this paper, we implement a 3x3 tic-tac-toe game in LabVIEW.",background,0
5811,The game is designed so that two players can play tic-tac-toe using LabVIEW software.,objective,1
5812,The program will contain a display function and a select function to place the symbol as well as toggle between the symbols allowing each player a turn to play the game.,method,2
5813,The program will update after each player makes their move and check for the conditions of game as it goes on.,method,2
5814,Overall program works without any bugs and is able to use,result,3
5815,"Neuromorphic computing has come to refer to a variety of brain-inspired computers, devices, and models that contrast the pervasive von Neumann computer architecture.",background,0
5816,This biologically inspired approach has created highly connected synthetic neurons and synapses that can be used to model neuroscience theories as well as solve challenging machine learning problems.,background,0
5817,"The promise of the technology is to create a brainlike ability to learn and adapt, but the technical challenges are significant, starting with an accurate neuroscience model of how the brain works, to finding materials and engineering breakthroughs to build devices to support these models, to creating a programming framework so the systems can learn, to creating applications with brain-like capabilities.",objective,1
5818,"In this work, we provide a comprehensive survey of the research and motivations for neuromorphic computing over its history.",method,2
5819,"We begin with a 35-year review of the motivations and drivers of neuromorphic computing, then look at the major research areas of the field, which we define as neuro-inspired models, algorithms and learning approaches, hardware and devices, supporting systems, and finally applications.",method,2
5820,We conclude with a broad discussion on the major research topics that need to be addressed in the coming years to see the promise of neuromorphic computing fulfilled.,result,3
5821,"The goals of this work are to provide an exhaustive review of the research conducted in neuromorphic computing since the inception of the term, and to motivate further work by illuminating gaps in the field where new research is needed.",objective,1
5822,"Technology adoption models specify a pathway of technology acceptance from external variables to beliefs, intentions, adoption and actual usage.",background,0
5823,"Mobile phone adoption has been studied from a variety of perspectives, including sociology, computer-supported cooperative work and human-computer interaction.",background,0
5824,What is lacking is a model integrating all these factors influencing mobile phone adoption.,objective,1
5825,This paper investigates technology adoption models as a strategy to match mobile phone design to user's technological needs and expectations.,objective,1
5826,Based on the literature study we integrate three existing technology adoption models and then evaluate the proposed model with interviews and a survey.,method,2
5827,The contribution of this paper is a model for representing the factors that influence mobile phone adoption.,result,3
5828,Web single sign-on (SSO) systems enable users to authenticate themselves to multiple online services with one authentication credential and mechanism offered by an identity provider.,background,0
5829,The topic is widely studied and many solutions exist.,background,0
5830,"However, logging out of a service using SSO has received less attention.",background,0
5831,"While previous studies note that users want single logout when using SSO, most of the existing services do not offer it, and the identity providers do not even keep track of the open sessions.",background,0
5832,This article describes challenges related to logout in federated identity management and analyzes unexpected behavior in logout situations.,background,0
5833,The examples are from the Shibboleth SSO system.,method,2
5834,"Based on the analysis, we give guidelines for implementing reliable logout and describe a polling-based solution for creating a system-wide logout mechanisms that only requires minor changes to the existing code and does not burden the identity provider excessively.",objective,1
5835,"In addition to the system-wide logout, our solution gives users the option to log out of only one service.",result,3
5836,A usability test was conducted to evaluate the solution.,result,3
5837,"The results show that the users liked the ability to choose between the two logout options, but they did not understand the words used to describe them.",result,3
5838,"To describe the log-likelihood computation in our model, let us consider a two scale pyramid for the moment.",objective,1
5839,"Given a (vectorized) j × j image I , denote by l = d(I) the coarsened image, and h = I − u(d(I)) to be the high pass.",method,2
5840,"In this section, to simplify the computations, we use a slightly different u operator than the one used to generate the images displayed in Figure 3 of the paper.",method,2
5841,"Namely, here we take d(I) to be the mean over each disjoint block of 2× 2 pixels, and take u to be the operator that removes the mean from each 2× 2 block.",method,2
5842,"Since u has rank 3d/4, in this section, we write h in an orthonormal basis of the range of u, then the (linear) mapping from I to (l, h) is unitary.",method,2
5843,"We now build a probability density p on Rd2 by p(I) = q0(l, h)q1(l) = q0(d(I), h(I))q1(d(I)); in a moment we will carefully define the functions qi.",method,2
5844,"For now, suppose that qi ≥ 0, ∫ q1(l) dl = 1, and for each fixed l, ∫ q0(l, h) dh = 1.",method,2
5845,Then we can check that p has unit integral: ∫,result,3
5846,Human activities are inherently translation invariant and hierarchical.,background,0
5847,"Human activity recognition (HAR), a field that has garnered a lot of attention in recent years due to its high demand in various application domains, makes use of time-series sensor data to infer activities.",background,0
5848,"In this paper, a deep convolutional neural network (convnet) is proposed to perform efficient and effective HAR using smartphone sensors by exploiting the inherent characteristics of activities and 1D time-series signals, at the same time providing a way to automatically and data-adaptively extract robust features from raw data.",objective,1
5849,"Experiments show that convnets indeed derive relevant and more complex features with every additional layer, although difference of feature complexity level decreases with every additional layer.",result,3
5850,A wider time span of temporal local correlation can be exploited (1x9~1x14) and a low pooling size (1x2~1x3) is shown to be beneficial.,method,2
5851,"Convnets also achieved an almost perfect classification on moving activities, especially very similar ones which were previously perceived to be very difficult to classify.",result,3
5852,"Lastly, convnets outperform other state-of-the-art data mining techniques in HAR for the benchmark dataset collected from 30 volunteer subjects, achieving an overall performance of 94.79% on the test set with raw sensor data, and 95.75% with additional information of temporal fast Fourier transform of the HAR data set.",result,3
5853,Recent advances in deep domain adaptation reveal that adversarial learning can be embedded into deep networks to learn transferable features that reduce distribution discrepancy between the source and target domains.,background,0
5854,Existing domain adversarial adaptation methods based on single domain discriminator only align the source and target data distributions without exploiting the complex multimode structures.,background,0
5855,"In this paper, we present a multi-adversarial domain adaptation (MADA) approach, which captures multimode structures to enable fine-grained alignment of different data distributions based on multiple domain discriminators.",method,2
5856,The adaptation can be achieved by stochastic gradient descent with the gradients computed by back-propagation in linear-time.,method,2
5857,Empirical evidence demonstrates that the proposed model outperforms state of the art methods on standard domain adaptation datasets.,result,3
5858,"Fake websites have become increasingly pervasive, generating billions of dollars in fraudulent revenue at the expense of unsuspecting Internet users.",background,0
5859,The design and appearance of these 5 websites makes it difficult for users to manually identify them as fake.,background,0
5860,"Automated detection systems have emerged as a mechanism for combating fake websites, however most are fairly simplistic in terms of their fraud cues and detection methods employed.",objective,1
5861,"Consequently, existing systems are susceptible to the myriad of obfuscation tactics used by fraudsters, resulting in highly ineffective fake website detection performance.",background,0
5862,"In light of these deficiencies, we propose 10 the development of a new class of fake website detection systems that are based on statistical learning theory (SLT).",method,2
5863,"Using a design science approach, a prototype system was developed to demonstrate the potential utility of this class of systems.",method,2
5864,"We conducted a series of experiments, comparing the proposed system against several existing fake website detection systems on a test bed encompassing 900 websites.",method,2
5865,The results indicate that systems grounded in SLT can more 15 accurately detect various categories of fake websites by utilizing richer sets of fraud cues in combination with problem-specific knowledge.,result,3
5866,"Given the hefty cost exacted by fake websites, the results have important implications for e-commerce and online security.",result,3
5867,"In this paper, we implement a reticle seeker missile simulator on MATLAB-SIMULINK to analyze the jamming effect of the spin-scan and conscan reticle seeker.",result,3
5868,The DIRCM (Directed Infrared Countermeasures) system uses the pulsing flashes of infrared (IR) energy and its frequency and intensity have influence on the missile guidance system.,method,2
5869,Our simulation results show that jamming effect is indicated significantly when jammer frequency and reticle frequency are similar and present a 3D trajectory of missile motions by jamming.,result,3
5870,Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields.,method,2
5871,"Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes.",background,0
5872,"In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network.",method,2
5873,"Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once.",method,2
5874,"We introduce a novel objective function, that we optimise during training, based on Dice coefficient.",method,2
5875,In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels.,method,2
5876,"To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching.",method,2
5877,We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.,result,3
5878,Let B(N) denote the set of all binary trees that have N nodes.,background,0
5879,"A procedure for randomly generating the trees in B(N) such that each tree is equally likely to occur, that is an unbiased random generator, is given which runs in O(N) time, requires very little storage, and uses a system of arithmetic no larger than is required to represent the number U itself.",method,2
5880,"Previous unbiased random binary tree generators, based on inverse rank functions, ran in O(N log N) time and required multiple precision arithmetic capable of handling numbers of the order of magnitude of the cardinality of B(N).",method,2
5881,"Although not commonly used, correlation filters can track complex objects through rotations, occlusions and other distractions at over 20 times the rate of current state-of-the-art techniques.",background,0
5882,The oldest and simplest correlation filters use simple templates and generally fail when applied to tracking.,background,0
5883,"More modern approaches such as ASEF and UMACE perform better, but their training needs are poorly suited to tracking.",result,3
5884,Visual tracking requires robust filters to be trained from a single frame and dynamically adapted as the appearance of the target object changes.,method,2
5885,"This paper presents a new type of correlation filter, a Minimum Output Sum of Squared Error (MOSSE) filter, which produces stable correlation filters when initialized using a single frame.",method,2
5886,"A tracker based upon MOSSE filters is robust to variations in lighting, scale, pose, and nonrigid deformations while operating at 669 frames per second.",method,2
5887,"Occlusion is detected based upon the peak-to-sidelobe ratio, which enables the tracker to pause and resume where it left off when the object reappears.",result,3
5888,Information communication technologies (ICTs) have significantly revolutionized travel industry in the last decade.,background,0
5889,"With an increasing number of travel companies participating in the Internet market, low price has become a minimum qualification to compete in the Internet market.",background,0
5890,"As a result, e-service quality is becoming even more critical for companies to retain and attract customers in the digital age.",background,0
5891,This study focuses on e-service quality dimensions in the Internet market with an empirical study on online travel service.,objective,1
5892,"The purpose of this study is to develop a scale to evaluate e-service quality from the perspectives of both online companies and customers, which provides fresh insight into the dimensions of e-service quality.",objective,1
5893,"The results in this study indicate that trust from the perspective of customer and ease of use from the perspective of online company are the most critical and important facets in customers’ perception of online travel service quality, while reliability, system availability and responsiveness have influence on customer’s perception of online travel service quality as well, but the influence is not so strong as that of trust and ease of use.",method,2
5894,"Online travel service companies should pay attention to the facets of reliability, system availability and responsiveness while focusing on the facets of ease of use and trust in order to improve their online travel service quality to customers.",result,3
5895,This article revisits the concept of autopoiesis and examines its relation to cognition and life.,background,0
5896,"We present a mathematical model of a 3D tesselation automaton, considered as a minimal example of autopoiesis.",background,0
5897,"This leads us to a thesis T1: An autopoietic system can be described as a random dynamical system, which is defined only within its organized autopoietic domain.",background,0
5898,"We propose a modified definition of autopoiesis: An autopoietic system is a network of processes that produces the components that reproduce the network, and that also regulates the boundary conditions necessary for its ongoing existence as a network.",background,0
5899,"We also propose a definition of cognition: A system is cognitive if and only if sensory inputs serve to trigger actions in a specific way, so as to satisfy a viability constraint.",method,2
5900,"It follows from these definitions that the concepts of autopoiesis and cognition, although deeply related in their connection with the regulation of the boundary conditions of the system, are not immediately identical: a system can be autopoietic without being cognitive, and cognitive without being autopoietic.",background,0
5901,"Finally, we propose a thesis T2: A system that is both autopoietic and cognitive is a living system.",objective,1
5902,"In today's society, social media have become an almost indispensable part of daily life, particularly among university students, who are generally heavy social media users.",background,0
5903,Social media multitasking has also been increasingly prevalent.,background,0
5904,"Little, however, is known about how social media usage and social media multitasking influence the academic performance of university students.",background,0
5905,This study examined whether and how these two behaviors predict academic performance among university students.,objective,1
5906,"From a sample of 348 undergraduate students at a comprehensive university in Hong Kong, this study found that using social media for academic purposes was not a significant predictor of academic performance as measured by cumulative grade point average, whereas using social media for nonacademic purposes (video gaming in particular) and social media multitasking significantly negatively predicted academic performance.",result,3
5907,© 2016 Elsevier Ltd.,other,4
5909,A new architecture for controlling mobile robots is described.,background,0
5910,Layers of control system are built to let the robot operate at increasing levels of competence.,background,0
5911,Layers are made up of asynchronous modules that communicate over low-bandwidth channels.,background,0
5912,Each module is an instance of a fairly simple computational machine.,background,0
5913,Higher-level layers can subsume the roles of lower levels by suppressing their outputs.,method,2
5914,"However, lower levels continue to function as higher levels are added.",method,2
5915,The result is a robust and flexible robot control system.,result,3
5916,The system has been used to control a mobile robot wandering around unconstrained laboratory areas and computer machine rooms.,method,2
5917,"Eventually it is intended to control a robot that wanders the office areas of our laboratory, building maps of its surroundings using an onboard arm to perform simple tasks.",method,2
5918,The time taken performing fitness calculations can dominate the total computational time when applying Particle Swarm Optimisation (PSO) to complex real life problems.,background,0
5919,"This paper describes a method of estimating fitness, and the reliability of that estimation, that can be used as an alternative to performing some true fitness calculations.",method,2
5920,"The fitness estimation is always made, but, should the reliability of this fitness estimation drop below a user specified threshold, the estimate is discarded and a true fitness evaluation performed.",background,0
5921,Results are presented for three problems that show that the number of true fitness evaluations can be significantly reduced by this method without degrading the performance of PSO.,result,3
5922,"Further the value used for the threshold, the only new parameter introduced, is shown not to be sensitive, at least on these test problems.",result,3
5923,"Provided that the time to perform a true fitness evaluation is far longer than the time for the fitness and reliability calculations, a substantial amount of computing time can be saved while still achieving the same end result.",result,3
5924,Effective training of neural networks requires much data.,background,0
5925,"In the low-data regime, parameters are underdetermined, and learnt networks generalise poorly.",background,0
5926,"Data Augmentation (Krizhevsky et al., 2012) alleviates this by using existing data more effectively.",background,0
5927,However standard data augmentation produces only limited plausible alternative data.,background,0
5928,"Given there is potential to generate a much broader set of augmentations, we design and train a generative model to do data augmentation.",method,2
5929,"The model, based on image conditional Generative Adversarial Networks, takes data from a source domain and learns to take any data item and generalise it to generate other within-class data items.",method,2
5930,"As this generative process does not depend on the classes themselves, it can be applied to novel unseen classes of data.",method,2
5931,We show that a Data Augmentation Generative Adversarial Network (DAGAN) augments standard vanilla classifiers well.,result,3
5932,We also show a DAGAN can enhance few-shot learning systems such as Matching Networks.,result,3
5933,"We demonstrate these approaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data.",result,3
5934,"We introduce a new model, the Recurrent Entity Network (EntNet).",objective,1
5935,It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data.,objective,1
5936,"For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015).",method,2
5937,"Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations.",method,2
5938,"However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously.",method,2
5939,"The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting.",method,2
5940,"We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon.",method,2
5941,"It can also be practically used on large scale datasets such as Children’s Book Test, where it obtains competitive performance, reading the story in a single pass.",result,3
5942,Learning based methods have shown very promising results for the task of depth estimation in single images.,background,0
5943,"However, most existing approaches treat depth prediction as a supervised regression problem and as a result, require vast quantities of corresponding ground truth depth data for training.",background,0
5944,Just recording quality depth data in a range of environments is a challenging problem.,background,0
5945,"In this paper, we innovate beyond existing approaches, replacing the use of explicit depth data during training with easier-to-obtain binocular stereo footage.",objective,1
5946,"We propose a novel training objective that enables our convolutional neural network to learn to perform single image depth estimation, despite the absence of ground truth depth data.",method,2
5947,"Ex-ploiting epipolar geometry constraints, we generate disparity images by training our network with an image reconstruction loss.",method,2
5948,We show that solving for image reconstruction alone results in poor quality depth images.,method,2
5949,"To overcome this problem, we propose a novel training loss that enforces consistency between the disparities produced relative to both the left and right images, leading to improved performance and robustness compared to existing approaches.",method,2
5950,"Our method produces state of the art results for monocular depth estimation on the KITTI driving dataset, even outperforming supervised methods that have been trained with ground truth depth.",result,3
5951,The vergence-accommodation conflict (VAC) remains a major problem in head-mounted displays for virtual and augmented reality (VR and AR).,background,0
5952,"In this review, I discuss why this problem is pivotal for nearby tasks in VR and AR, present a comprehensive taxonomy of potential solutions, address advantages and shortfalls of each design, and cover various ways to better evaluate the solutions.",objective,1
5953,"The review describes how VAC is addressed in monocular, stereoscopic, and multiscopic HMDs, including retinal scanning and accommodation-free displays.",method,2
5954,Eye-tracking-based approaches that do not provide natural focal cues-gaze-guided blur and dynamic stereoscopy-are also covered.,method,2
5955,Promising future research directions in this area are identified.,result,3
5956,Ninety organizations were surveyed in an exploratory investigation of the organizational impact of knowledge management (KM).,background,0
5957,A search of the literature revealed 12 KM practices.,method,2
5958,"Results indicated that these KM practices were directly related to organizational performance which, in turn, was directly related to financial performance.",result,3
5959,"In addition, a different set of KM practices were associated with specific value disciplines (i.e., customer intimacy, product development and operational excellence).",result,3
5960,"Interestingly, a significant gap exists between the KM practices that firms believe to be important and those that turned out to be directly related to organizational performance.",result,3
5961,The implications of this study are significant for both practitioners and academics.,result,3
5962,Suggestions are offered for future work in this area.,method,2
5963,"The three-inputTOFFOLI gate is the workhorse of circuit synthesis for classical log ic operations on quantum data, e.g., reversible arithmetic ci rcuits.",background,0
5964,"In physical implementations, however,TOFFOLI gates are decomposed into six CNOT gates and several one-qubit gates.",background,0
5965,"Though this decomposition has been known for at least 10 years, we provide here the first demonstration of its CNOT-optimality.",background,0
5966,"We study three-qubit circuits which contain less than six CNOT gates and implement a block-diagonal operator, then show that they implicitly d escribe the cosine-sine decomposition of a related operator.",method,2
5967,"Leveraging the canonicity o f such decompositions to limit one-qubit gates appearing in respective circuits, we prove that then-qubit analogue of the TOFFOLI requires at least 2 n CNOT gates.",method,2
5968,"Additionally, our results offer a complete classification of three-qubit diagonal operators by their CNOT-cost, which holds even if ancilla qubits are available.",result,3
5969,"∗Department of Mathematics, Princeton University, Princet on, NJ 08544.",other,4
5970,"†Department of EECS, University of Michigan, Ann Arbor, MI 48 109.",other,4
5971,"For more than a decade e-Commerce and e-Government applications have made major impacts in their respective sectors, private and public.",background,0
5972,"Some time ago, we presented early insights from a comparative study of the two phenomena.",background,0
5973,This paper reports on more robust findings from an ongoing empirical investigation and deepens our understanding of similarities and differences between e-Commerce and e-Government.,method,2
5974,The findings show that despite major similarities the two phenomena follow quite separate and distinct trajectories.,result,3
5975,Recurrent neural network architectures have been shown to efficiently model long term temporal dependencies between acoustic events.,background,0
5976,However the training time of recurrent networks is higher than feedforward networks due to the sequential nature of the learning algorithm.,background,0
5977,In this paper we propose a time delay neural network architecture which models long term temporal dependencies with training times comparable to standard feed-forward DNNs.,method,2
5978,The network uses sub-sampling to reduce computation during training.,method,2
5979,On the Switchboard task we show a relative improvement of 6% over the baseline DNN model.,method,2
5980,We present results on several LVCSR tasks with training data ranging from 3 to 1800 hours to show the effectiveness of the TDNN architecture in learning wider temporal dependencies in both small and large data scenarios.,result,3
5981,This paper describes a method of implementing two factor authentication using mobile phones.,objective,1
5982,"The proposed method guarantees that authenticating to services, such as online banking or ATM machines, is done in a very secure manner.",method,2
5983,The proposed system involves using a mobile phone as a software token for One Time Password generation.,method,2
5984,"The generated One Time Password is valid for only a short user-defined period of time and is generated by factors that are unique to both, the user and the mobile device itself.",method,2
5985,"Additionally, an SMS-based mechanism is implemented as both a backup mechanism for retrieving the password and as a possible mean of synchronization.",method,2
5986,The proposed method has been implemented and tested.,method,2
5987,Initial results show the success of the proposed method.,result,3
5988,The last few years have seen the emergence of several open access options in scholarly communication which can broadly be grouped into two areas referred to as ‘gold’ and ‘green’ open access (OA).,background,0
5989,In this article we review the literature examining the relationship between OA status and citation counts of scholarly articles.,objective,1
5990,"Early studies showed a correlation between the free online availability or OA status of articles and higher citation counts, and implied causality without due consideration of potential confounding factors.",method,2
5991,More recent investigations have dissected the nature of the relationship between article OA status and citations.,method,2
5992,"Three non-exclusive postulates have been proposed to account for the observed citation differences between OA and non-OA articles: an open access postulate, a selection bias postulate, and an early view postulate.",method,2
5993,"The most rigorous study to date (in condensed matter physics) showed that, after controlling for the early view postulate, the remaining difference in citation counts between OA and non-OA articles is explained by the selection bias postulate.",method,2
5994,No evidence was found to support the OA postulate per se; i.e. article OA status alone has little or no effect on citations.,result,3
5995,Further studies using a similarly rigorous approach are required to determine the generality of this finding.,result,3
5996,© 2007 Elsevier Ltd.,other,4
5998,"Developing hardware, algorithms and protocols, as well as collecting data in sensor networks are all important challenges in building good systems.",background,0
5999,We describe a vertical system integration of a sensor node and a toolkit of machine learning algorithms.,background,0
6000,Based on a dataset that combines sensor data with additional introduced data we predict the number of persons in a closed space.,method,2
6001,We analyze the dataset and evaluate the performance of two types of machine learning algorithms on this dataset: classification and regression.,result,3
6002,"Steganography is the art of hiding the fact that communication is taking place, by hiding information in other information.",background,0
6003,"Many different carrier file formats can be used, but digital images are the most popular because of their frequency on the Internet.",background,0
6004,"For hiding secret information in images, there exists a large variety of steganographic techniques some are more complex than others and all of them have respective strong and weak points.",background,0
6005,Different applications have different requirements of the steganography technique used.,background,0
6006,"For example, some applications may require absolute invisibility of the secret information, while others require a larger secret message to be hidden.",method,2
6007,"This paper intends to give an overview of image steganography, its uses and techniques.",objective,1
6008,It also attempts to identify the requirements of a good steganographic algorithm and briefly reflects on which steganographic techniques are more suitable for which applications.,result,3
6009,"Excerpted from:Boyan, Justin.",background,0
6010,Learning Evaluation Functions for Global Op timization.,background,0
6011,"Ph.D. thesis, Carnegie Mellon University, August 1998.",background,0
6012,(Available as Technical Report CMU-CS-98-152.,other,4
6013,) TD( ) is a popular family of algorithms for approximate policy eva luation in large MDPs.,method,2
6014,TD( ) works by incrementally updating the value function after each observed transition.,background,0
6015,"It has two major dr awbacks: it makes inefficient use of data, and it requires the user to manu ally tune a stepsize schedule for good performance.",background,0
6016,"For the case of lin ear value function approximations and = 0, the Least-Squares TD (LSTD) algorithm of Bradtke and Barto [5] eliminates all stepsize par ameters and improves data efficiency.",method,2
6017,This paper extends Bradtke and Barto’s work in three signific ant ways.,objective,1
6018,"First, it presents a simpler derivation of the LSTD algorith m. Second, it generalizes from = 0 to arbitrary values of ; at the extreme of = 1, the resulting algorithm is shown to be a practical formulati on of supervised linear regression.",method,2
6019,"Visualization: The use of computer-supported, interactive, visual representations of data to amplify cognition.",background,0
6020,(6) Cognition is the acquisition or use of knowledge.,method,2
6021,This definition has the virtue of focusing as much on the purpose of visualization as the means.,objective,1
6022,"Hamming (1973) saud, “the purpose of computation is insight, not numbers.",objective,1
6023,”,other,4
6024,"Likewise for visualization, “the purpose of visualization is insight not pictures.",result,3
6025,”,other,4
6026,"The main goals of this insight are discovery, decision making, and explanation.",result,3
6027,(6),other,4
6028,Emotion recognition is a challenging task because of the emotional gap between subjective emotion and the low-level audio-visual features.,background,0
6029,"Inspired by the recent success of deep learning in bridging the semantic gap, this paper proposes to bridge the emotional gap based on a multimodal Deep Convolution Neural Network (DCNN), which fuses the audio and visual cues in a deep model.",background,0
6030,This multimodal DCNN is trained with two stages.,method,2
6031,"First, two DCNN models pre-trained on large-scale image data are fine-tuned to perform audio and visual emotion recognition tasks respectively on the corresponding labeled speech and face data.",method,2
6032,"Second, the outputs of these two DCNNs are integrated in a fusion network constructed by a number of fully-connected layers.",objective,1
6033,The fusion network is trained to obtain a joint audio-visual feature representation for emotion recognition.,objective,1
6034,Experimental results on the RML audio-visual database demonstrates the promising performance of the proposed method.,objective,1
6035,"To the best of our knowledge, this is an early work fusing audio and visual cues in DCNN for emotion recognition.",result,3
6036,Its success guarantees further research in this direction.,result,3
6037,Authors present the stock price prediction algorithm by using Bayesian network.,background,0
6038,The present algorithm uses the network twice.,objective,1
6039,"First, the network is determined from the daily stock price and then, it is applied for predicting the daily stock price which was already observed.",background,0
6040,The prediction error is evaluated from the daily stock price and its prediction.,background,0
6041,"Second, the network is determined again from both the daily stock price and the daily prediction error and then, it is applied for the future stock price prediction.",result,3
6042,The present algorithm is applied for predicting NIKKEI stock average and Toyota motor corporation stock price.,result,3
6043,"Numerical results show that the maximum prediction error of the present algorithm is 30% in NIKKEI stock average and 20% in Toyota Motor Corporation below that of the time-series prediction algorithms such as AR, MA, ARMA and ARCH models.",result,3
6044,"There is considerable pressure to define the key requirements of 5G, develop 5G standards, and perform technology trials as quickly as possible.",background,0
6045,"Normally, these activities are best done in series but there is a desire to complete these tasks in parallel so that commercial deployments of 5G can begin by 2020.",background,0
6046,"5G will not be an incremental improvement over its predecessors; it aims to be a revolutionary leap forward in terms of data rates, latency, massive connectivity, network reliability, and energy efficiency.",method,2
6047,"These capabilities are targeted at realizing high-speed connectivity, the Internet of Things, augmented virtual reality, the tactile internet, and so on.",objective,1
6048,"The requirements of 5G are expected to be met by new spectrum in the microwave bands (3.3–4.2 GHz), and utilizing large bandwidths available in mm-wave bands, increasing spatial degrees of freedom via large antenna arrays and 3-D MIMO, network densification, and new waveforms that provide scalability and flexibility to meet the varying demands of 5G services.",method,2
6049,"Unlike the one size fits all 4G core networks, the 5G core network must be flexible and adaptable and is expected to simultaneously provide optimized support for the diverse 5G use case categories.",method,2
6050,"In this paper, we provide an overview of 5G research, standardization trials, and deployment challenges.",result,3
6051,"Due to the enormous scope of 5G systems, it is necessary to provide some direction in a tutorial article, and in this overview, the focus is largely user centric, rather than device centric.",background,0
6052,"In addition to surveying the state of play in the area, we identify leading technologies, evaluating their strengths and weaknesses, and outline the key challenges ahead, with research test beds delivering promising performance but pre-commercial trials lagging behind the desired 5G targets.",method,2
6053,This paper describes a user-friendly software for the calculation of general piping system networks composed of virtually any parallel and series pipe arrangement.,background,0
6054,Solution of the network is made with recourse to the iterative method of Hardy Cross.,method,2
6055,Solution is provided for pressure and flow-rate in each branch.,method,2
6056,"Dimensioning problems, where pump characteristics or a pipe diameter are sought for achieving a pre-specified flow-rate condition, may also be tackled.",result,3
6057,"2004 Wiley Periodicals, Inc. Comput Appl Eng Educ 12: 117 125, 2004; Published online in Wiley InterScience (www.interscience.wiley.com); DOI 10.1002/cae.20006",result,3
6058,Combination strategies are test case selection methods that identify test cases by combining values of the different test object input parameters based on some combinatorial strategy.,background,0
6059,"This survey presents 16 different combination strategies, covering more than 40 papers that focus on one or several combination strategies.",method,2
6060,This collection represents most of the existing work performed on combination strategies.,method,2
6061,This survey describes the basic algorithms used by the combination strategies.,method,2
6062,"Some properties of combination strategies, including coverage criteria and theoretical bounds on the size of test suites, are also included in this description.",method,2
6063,This survey paper also includes a subsumption hierarchy that attempts to relate the various coverage criteria associated with the identified combination strategies.,method,2
6064,Dengue is a life threatening disease prevalent in several developed as well as developing countries like India.,background,0
6065,This is a virus born disease caused by breeding of Aedes mosquito.,background,0
6066,"Datasets that are available for dengue describe information about the patients suffering with dengue disease and without dengue disease along with their symptoms like: Fever Temperature, WBC, Platelets, Severe Headache, Vomiting, Metallic Taste, Joint Pain, Appetite, Diarrhea, Hematocrit, Hemoglobin, and how many days suffer in different city.",result,3
6067,In this paper we discuss various algorithm approaches of data mining that have been utilized for dengue disease prediction.,objective,1
6068,"Data mining is a well known technique used by health organizations for classification of diseases such as dengue, diabetes and cancer in bioinformatics research.",method,2
6069,In the proposed approach we have used WEKA with 10 cross validation to evaluate data and compare results.,method,2
6070,Weka has an extensive collection of different machine learning and data mining algorithms.,method,2
6071,"In this paper we have firstly classified the dengue data set and then compared the different data mining techniques in weka through Explorer, knowledge flow and Experimenter interfaces.",method,2
6072,Furthermore in order to validate our approach we have used a dengue dataset with 108 instances but weka used 99 rows and 18 attributes to determine the prediction of disease and their accuracy using classifications of different algorithms to find out the best performance.,result,3
6073,The main objective of this paper is to classify data and assist the users in extracting useful information from data and easily identify a suitable algorithm for accurate predictive model from it.,objective,1
6074,The excessive level of construction business failures and their association with financial difficulties has placed financial management in the forefront of many business imperatives.,background,0
6075,This has highlighted the importance of cash flow forecasting and management which has given rise to the development of several forecasting models.,background,0
6076,The traditional approach to the use of project financial models has been largely project-oriented perspective.,background,0
6077,"However, the dominating role of ‘project economics’ in shaping ‘corporate economics’ tends to place the corporate strategy at the mercy of the projects.",background,0
6078,This paper approaches the concept of cash flow forecasting and management from a fresh perspective.,background,0
6079,"Here, the use of forecasting models is extended beyond their traditional role as a guideline for monitoring and control of progress.",objective,1
6080,They are regarded as tools for driving the project in the direction of corporate goals.,method,2
6081,The work is based on the premise that the main parties could negotiate the terms,result,3
6082,"Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions.",background,0
6083,Recent studies show that deep learning approaches can achieve impressive performance on these two tasks.,background,0
6084,"In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance.",method,2
6085,"In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner.",method,2
6086,"In addition, we propose a new online hard sample mining strategy that further improves the performance in practice.",method,2
6087,"Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.",result,3
6088,We present a new deep learning architecture Bi-CNN-MI for paraphrase identification (PI).,background,0
6089,"Based on the insight that PI requires comparing two sentences on multiple levels of granularity, we learn multigranular sentence representations using convolutional neural network (CNN) and model interaction features at each level.",method,2
6090,These features are then the input to a logistic classifier for PI.,method,2
6091,"All parameters of the model (for embeddings, convolution and classification) are directly optimized for PI.",result,3
6092,"To address the lack of training data, we pretrain the network in a novel way using a language modeling task.",method,2
6093,Results on the MSRP corpus surpass that of previous NN competitors.,result,3
6094,Video indexing is an important problem that has occupied recent research efforts.,background,0
6095,The text appearing in video can provide semantic information about the scene content.,background,0
6096,Detecting and recognizing text events can provide indices into the video for content-based querying.,background,0
6097,"We describe a system for detecting, tracking, and extracting artificial and scene text in MPEG–1 video.",method,2
6098,Preliminary results are presented.,result,3
6099,"For more than one decade, time series similarity search has been given a great deal of attention by data mining researchers.",background,0
6100,"As a result, many time series representations and distance measures have been proposed.",background,0
6101,"However, most existing work on time series similarity search focuses on finding shape-based similarity.",background,0
6102,"While some of the existing approaches work well for short time series data, they typically fail to produce satisfactory results when the sequence is long.",background,0
6103,"For long sequences, it is more appropriate to consider the similarity based on the higher-level structures.",background,0
6104,"In this work, we present a histogram-based representation for time series data, similar to the “bag of words” approach that is widely accepted by the text mining and information retrieval communities.",objective,1
6105,"We show that our approach outperforms the existing methods in clustering, classification, and anomaly detection on several real datasets.",result,3
6106,"A range of court cases and forensic investigations have involved thumbnail pictures contained within operating system files, such as thumbcache and thumbs.db.",background,0
6107,"In many of these cases, the thumbnail image has been the evidence presented to a court.",background,0
6108,"Further analysis may locate additional information relating to thumbnail pictures, such as being able to link a thumbnail to a picture file on storage media, or locating information relating to the original file used to create the thumbnail, such as the full path and original file name.",method,2
6109,"Using real-world law enforcement and test data, we demonstrate the application of our proposed operational methodology to conduct analysis of thumbcache files.",method,2
6110,"We also propose a reporting and visualisation methodology to present the evidence to investigators, legal counsel, and court, which then forms the basis of our software prototype.",result,3
6111,Insider threat cases which involve pictures of intellectual property can potentially benefit from our proposed method.,result,3
6112,Recurrent Neural Networks (RNNs) have the ability to retain memory and learn data sequences.,background,0
6113,"Due to the recurrent nature of RNNs, it is sometimes hard to parallelize all its computations on conventional hardware.",background,0
6114,"CPUs do not currently offer large parallelism, while GPUs offer limited parallelism due to sequential components of RNN models.",background,0
6115,In this paper we present a hardware implementation of Long-Short Term Memory (LSTM) recurrent network on the programmable logic Zynq 7020 FPGA from Xilinx.,objective,1
6116,We implemented a RNN with 2 layers and 128 hidden units in hardware and it has been tested using a character level language model.,method,2
6117,The implementation is more than 21× faster than the ARM Cortex-A9 CPU embedded on the Zynq 7020 FPGA.,method,2
6118,This work can potentially evolve to a RNN co-processor for future mobile devices.,objective,1
6119,Keywords-Recurrent Neural Network (RNN); Long Short Term Memory (LSTM); acceleration; FPGA;,result,3
6120,"The purpose of this experiment was to examine the effect of web page text/background colour combination on readability, retention, aesthetics, and behavioural intention.",objective,1
6121,"One hundred and thirty-six participants studied two Web pages, one with educational content and one with commercial content, in one of four colour-combination conditions.",background,0
6122,"Major findings were: (a) Colours with greater contrast ratio generally lead to greater readability; (b) colour combination did not significantly affect retention; (c) preferred colours (i.e., blues and chromatic colours) led to higher ratings of aesthetic quality and intention to purchase; and (d) ratings of aesthetic quality were significantly related to intention to purchase.",background,0
6123,Object recognition technology has matured to a point at which exciting applications are becoming possible.,background,0
6124,"Indeed, industry has created a variety of computer vision products and services from the traditional area of machine inspection to more recent applications such as video surveillance, or face recognition.",background,0
6125,"In this chapter, several representatives from industry present their views on the use of computer vision in industry.",objective,1
6126,Current research conducted in industry is summarized and prospects for future applications and developments in industry are discussed.,method,2
6127,"Bloom filter is effective, space-efficient data structure for concisely representing a data set and supporting approximate membership queries.",background,0
6128,"Traditionally, researchers often believe that it is possible that a Bloom filter returns a false positive, but it will never return a false negative under well-behaved operations.",background,0
6129,"By investigating the mainstream variants, however, we observe that a Bloom filter does return false negatives in many scenarios.",background,0
6130,"In this work, we show that the undetectable incorrect deletion of false positive items and detectable incorrect deletion of multiaddress items are two general causes of false negative in a Bloom filter.",method,2
6131,We then measure the potential and exposed false negatives theoretically and practically.,method,2
6132,"Inspired by the fact that the potential false negatives are usually not fully exposed, we propose a novel Bloom filter scheme, which increases the ratio of bits set to a value larger than one without decreasing the ratio of bits set to zero.",method,2
6133,Mathematical analysis and comprehensive experiments show that this design can reduce the number of exposed false negatives as well as decrease the likelihood of false positives.,result,3
6134,"To the best of our knowledge, this is the first work dealing with both the false positive and false negative problems of Bloom filter systematically when supporting standard usages of item insertion, query, and deletion operations.",result,3
6135,openair is an R package primarily developed for the analysis of air pollution measurement data but which is also of more general use in the atmospheric sciences.,background,0
6136,"The package consists of many tools for importing and manipulating data, and undertaking a wide range of analyses to enhance understanding of air pollution data.",background,0
6137,In this paper we consider the development of the package with the purpose of showing how air pollution data can be analysed in more insightful ways.,objective,1
6138,"Examples are provided of importing data from UK air pollution networks, source identiVcation and characterisation using bivariate polar plots, quantitative trend estimates and the use of functions for model evaluation purposes.",objective,1
6139,"We demonstrate how air pollution data can be analysed quickly and eXciently and in an interactive way, freeing time to consider the problem at hand.",result,3
6140,"One of the central themes of openair is the use of conditioning plots and analyses, which greatly enhance inference possibilities.",result,3
6141,"Finally, some consideration is given to future developments.",result,3
6142,Pedestrians follow different trajectories to avoid obstacles and accommodate fellow pedestrians.,background,0
6143,Any autonomous vehicle navigating such a scene should be able to foresee the future positions of pedestrians and accordingly adjust its path to avoid collisions.,background,0
6144,"This problem of trajectory prediction can be viewed as a sequence generation task, where we are interested in predicting the future trajectory of people based on their past positions.",objective,1
6145,"Following the recent success of Recurrent Neural Network (RNN) models for sequence prediction tasks, we propose an LSTM model which can learn general human movement and predict their future trajectories.",method,2
6146,This is in contrast to traditional approaches which use hand-crafted functions such as Social forces.,method,2
6147,We demonstrate the performance of our method on several public datasets.,result,3
6148,Our model outperforms state-of-the-art methods on some of these datasets.,result,3
6149,We also analyze the trajectories predicted by our model to demonstrate the motion behaviour learned by our model.,result,3
6150,"A fast fashion system combines quick response production capabilities with enhanced product design capabilities, to both design “hot”products that capture the latest consumer trends and exploit minimal production leadtimes to match supply with uncertain demand.",background,0
6151,"We develop a model of such a system, and compare its performance to three alternative systems: quick response-only systems, enhanced design-only systems, and traditional systems (which lack both enhanced design and quick response capabilities).",method,2
6152,"In particular, we focus on the impact of each of the four systems on “strategic”or forward-looking customer purchasing behavior, i.e., the intentional delay in purchasing an item at the full price to obtain it during an end-ofseason clearance.",method,2
6153,"We find that enhanced design helps to mitigate strategic behavior by offering consumers a product they value more, making them less willing to risk waiting for a clearance sale and possibly experiencing a stock-out.",method,2
6154,"Quick response mitigates strategic behavior through a different mechanism: by better matching supply to demand, it reduces the chance of a clearance sale.",method,2
6155,"Most importantly, we find that while it is possible for quick response and enhanced design to be either complements or substitutes, the complementarity effect tends to dominate.",result,3
6156,"Hence, when both quick response and enhanced design are combined in a fast fashion system, the firm typically enjoys a greater incremental increase in profit than the sum of the increases resulting from employing either system in isolation, roughly by a factor of two in our numerical experiments.",result,3
6157,"Furthermore, complementarity is strongest when customers are very strategic.",result,3
6158,"We conclude that fast fashion systems can be of significant value, particularly when consumers exhibit strategic behavior.",result,3
6159,The Request For Proposal (RFP) process can be agile and efficient.,background,0
6160,"At a high level, the key to achieving this is to specify requirements just in time and containing just enough detail.",background,0
6161,"This paper applies the following XP practices and concepts to the RFP process: acceptance tests, business value, iterative & incremental delivery, onsite customer, pair development, planning game, spike, story, velocity, and yesterday’s weather.",method,2
6162,"In addition, the following concepts are combined with those from XP to achieve maximal benefit: user-goal use case, context diagram, level of detail, and decision tree.",method,2
6163,The contributions of this paper to the agile community are two-fold: describing a practical application of XP concepts to a non-programming project; and making use case style requirements processes more agile.,method,2
6164,"The continuous developments in information and communication technology have recently led to the appearance of distributed computing environments, which comprise several, and different sources of large volumes of data and several computing units.",background,0
6165,"The most prominent example of a distributed environment is the Internet, where increasingly more databases and data streams appear that deal with several areas, such as meteorology, oceanography, economy and others.",background,0
6166,"In addition the Internet constitutes the communication medium for geographically distributed information systems, as for example the earth observing system of NASA (eos.gsfc. nasa.gov).",background,0
6167,Other examples of distributed environments that have been developed in the last few years are sensor networks for process monitoring and grids where a large number of computing and storage units are interconnected over a highspeed network.,background,0
6168,The application of the classical knowledge discovery process in distributed environments requires the collection of distributed data in a data warehouse for central processing.,result,3
6169,"However, this is usually either ineffective or infeasible for the following reasons:",result,3
6170,"As known, adventure and experience about lesson, entertainment, and knowledge can be gained by only reading a book.",background,0
6171,"Even it is not directly done, you can know more about this life, about the world.",background,0
6172,We offer you this proper and easy way to gain those all.,other,4
6173,We offer many book collections from fictions to science at all.,other,4
6174,One of them is this computer vision algorithms and applications that can be your partner.,method,2
6175,"This paper provides an energy-harvesting, shoe-mounted system for medical sensing using piezoelectric transducers for generating power.",background,0
6176,"The electronics are integrated inside a conventional consumer shoe, measuring the pressure of the wearer's foot exerted on the sole at six locations.",background,0
6177,"The electronics are completely powered by the harvested energy from walking or running, generating 10-20 μJ of energy per step that is then consumed by capturing and storing the force sensor data.",background,0
6178,The overall shoe system demonstrates that wearable sensor electronics can be adequately powered through piezoelectric energy-harvesting.,background,0
6179,"Reviews and other evaluations are used by consumers to decide what goods to buy and by firms to choose whom to trade with, hire, or promote.",background,0
6180,"However, because potential reviewers are not compensated for submitting reviews and may have reasons to omit relevant information in their reviews, reviews may be biased.",background,0
6181,"We use the setting of Airbnb to study the determinants of reviewing behavior, the extent to which reviews are biased, and whether changes in the design of reputation systems can reduce that bias.",method,2
6182,We find that reviews on Airbnb are generally informative and 97% of guests privately report having positive experiences.,result,3
6183,"Using two field experiments intended to reduce bias, we show that non-reviewers tend to have worse experiences than reviewers and that strategic reviewing behavior occurred on the site, although the aggregate effect of the strategic behavior was relatively small.",result,3
6184,We use a quantitative exercise to show that the mechanisms for bias that we document decrease the rate of reviews with negative text and a non-recommendation by just .86 percentage points.,result,3
6185,"Lastly, we discuss how online marketplaces can design more informative review systems.",result,3
6186,We propose two efficient approximations to standard convolutional neural networks: Binary-Weight-Networks and XNOR-Networks.,objective,1
6187,"In Binary-WeightNetworks, the filters are approximated with binary values resulting in 32× memory saving.",background,0
6188,"In XNOR-Networks, both the filters and the input to convolutional layers are binary.",method,2
6189,XNOR-Networks approximate convolutions using primarily binary operations.,method,2
6190,This results in 58× faster convolutional operations and 32× memory savings.,result,3
6191,XNOR-Nets offer the possibility of running state-of-the-art networks on CPUs (rather than GPUs) in real-time.,method,2
6192,"Our binary networks are simple, accurate, efficient, and work on challenging visual tasks.",result,3
6193,We evaluate our approach on the ImageNet classification task.,result,3
6194,The classification accuracy with a Binary-Weight-Network version of AlexNet is only 2.9% less than the full-precision AlexNet (in top-1 measure).,background,0
6195,"We compare our method with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than 16% in top-1 accuracy.",method,2
6196,The ultimate goal of an information provider is to satisfy the user information needs.,objective,1
6197,"That is, to provide the user with the right information, at the right time, through the right means.",background,0
6198,A prerequisite for developing personalised services is to rely on user profiles representing users’ information needs.,background,0
6199,In this paper we will first address the issue of presenting a general user profile model.,objective,1
6200,"Then, the general user profile model will be customised for digital libraries users.",result,3
6201,We believe that the field of organization theory is adrift.,background,0
6202,"In sailing jargon, we are “in irons”—stalled and making little headway toward understanding organizations and their place in our lives.",background,0
6203,"We first attempt to diagnose our maladies and then, in this light, offer three broad research questions that just might reinvigorate our work: First, how can we understand today’s changing organizations?",method,2
6204,"Second, how can we live in these organizations?",result,3
6205,"And third, how can we best live with them?",result,3
6206,We close by calling attention to how our familiar approaches to building and testing theory might hamper any attempt to revitalize our field.,result,3
6207,This paper presents an effective method to simulate the ink diffusion process in real time that yields realistic visual effects.,objective,1
6208,"Our algorithm updates the dynamic ink volume using a hybrid grid-particle method: the fluid velocity field is calculated with a low-resolution grid structure, whereas the highly detailed ink effects are controlled and visualized with the particles.",method,2
6209,"To facilitate user interaction and extend this method, we propose a particle-guided method that allows artists to design the overall states using the coarse-resolution particles and to preview the motion quickly.",method,2
6210,"To treat coupling with solids and other fluids, we update the grid-particle representation with no-penetration boundary conditions and implicit interaction conditions.",method,2
6211,"To treat moving ‘‘ink-emitting’’ objects, we introduce an extra drag-force model to enhance the particle motion effects; this force might not be physically accurate, but it proves effective for producing animations.",method,2
6212,We also propose an improved ink rendering method that uses particle sprites and motion blurring techniques.,method,2
6213,The simulation and the rendering processes are efficiently implemented on graphics hardware at interactive frame rates.,result,3
6214,"Compared to traditional fluid simulation methods that treat water and ink as two mixable fluids, our method is simple but effective: it captures various ink effects, such as pinned boundaries (Nelson, 2005 [1]) and filament patterns (Shiny et al., 2010 [2]), while still running in real time, it allows easy control of the animation, it includes basic solid–fluid interactions, and it can address multiple ink sources without complex interface tracking.",result,3
6215,Our method is attractive for animation production and art design.,result,3
6216,& 2012 Elsevier Ltd.,other,4
6217,cleverhans is a software library that provides standardized reference implementations of adversarial example construction techniques and adversarial training.,background,0
6218,The library may be used to develop more robust machine learning models and to provide standardized benchmarks of models’ performance in the adversarial setting.,method,2
6219,"Benchmarks constructed without a standardized implementation of adversarial example construction are not comparable to each other, because a good result may indicate a robust model or it may merely indicate a weak implementation of the adversarial example construction procedure.",background,0
6220,This technical report is structured as follows.,objective,1
6221,Section 1 provides an overview of adversarial examples in machine learning and of the cleverhans software.,method,2
6222,Section 2 presents the core functionalities of the library: namely the attacks based on adversarial examples and defenses to improve the robustness of machine learning models to these attacks.,method,2
6223,Section 3 describes how to report benchmark results using the library.,result,3
6224,Section 4 describes the versioning system.,result,3
6225,The field of cyber security is faced with ever-expanding amounts of data and a constant barrage of cyber attacks.,background,0
6226,"Within this space, we have designed BubbleNet as a cyber security dashboard to help network analysts identify and summarize patterns within the data.",objective,1
6227,"This design study faced a range of interesting constraints from limited time with various expert users and working with users beyond the network analyst, such as network managers.",method,2
6228,"To overcome these constraints, the design study employed a user-centered design process and a variety of methods to incorporate user feedback throughout the design of BubbleNet.",method,2
6229,This approach resulted in a successfully evaluated dashboard with users and further deployments of these ideas in both research and operational environments.,result,3
6230,"By explaining these methods and the process, it can benefit future visualization designers to help overcome similar challenges in cyber security or alternative domains.",result,3
6231,This research study proposes Hybrid Encryption System using new public key algorithm and private key algorithm.,background,0
6232,A hybrid cryptosystem is one which combines the convenience of a public-key cryptosystem with the efficiency of a symmetrickey cryptosystem.,background,0
6233,"Here, we propose a provably two way secured data encryption system, which addresses the concerns of user’s privacy, authentication and accuracy.",objective,1
6234,This system has two different encryption algorithms have been used both in the Encryption and decryption sequence.,method,2
6235,One is public key cryptography based on linear block cipher another one is private key cryptography based on simple symmetric algorithm.,method,2
6236,This cryptography algorithm provides more security as well as authentication comparing to other existing hybrid algorithm.,result,3
6237,"Trajectory planning for serial 6 degree of freedom (DOF) machinery systems is demanding due to complex kinematic structure which affects the machinery tool fame, position, orientation and singularity.",background,0
6238,These three characteristics represent the key elements for production planning and layout design of the manufacturing systems.,background,0
6239,"Both, simple and complex machine trajectory is defined as series of connected points in 3D space.",method,2
6240,Each point is defined with its position and orientation related to the machine's base frames.,background,0
6241,"To visualize the machine's reachable space, the work envelope is calculated and graphically presented as very well known machine's property.",method,2
6242,A methodology to predetermine regions of feasible tool orientation (work window) is analytically and graphically presented.,method,2
6243,"The work envelope boundary is generated using the filtering points algorithm, while work window is generated using either empirical or analytical methods.",method,2
6244,The singularity regions are calculated by finding the determinant of the reconfigurable Jacobian matrix.,method,2
6245,These three tool path characteristics represent three different spaces which are identified both analytically and graphically and plotted in Cartesian space using MATLAB tools.,method,2
6246,The singularity regions will be represented within the workspace and work window for a single machinery kinematic structure.,method,2
6247,Missing data is a well-recognized problem impacting all domains.,background,0
6248,"State-of-theart framework to minimize missing data bias is multiple imputation, for which the choice of an imputation model remains nontrivial.",background,0
6249,"We propose a multiple imputation model based on overcomplete deep denoising autoencoders, capable of handling different data types, missingness patterns, missingness proportions and distributions.",objective,1
6250,Evaluation on real life datasets shows our proposed model outperforms the state-of-the-art methods under varying conditions and improves the end of the line analytics.,result,3
6251,"In this article, we present a real-time 3D hybrid beamforming approach for 5G wireless networks.",background,0
6252,"One of the key concepts in 5G cellular systems is the small cell network, which settles the high mobile traffic demand and provides uniform user-experienced data rates.",objective,1
6253,The overall capacity of the small cell network can be enhanced with the enabling technology of 3D hybrid beamforming.,objective,1
6254,"This study validates the feasibility of 3D hybrid beamforming, mostly for link-level performance, through the implementation of a real-time testbed using a SDR platform and fabricated antenna array.",method,2
6255,"Based on the measured data, we also investigate system-level performance to verify the gain of the proposed smart small cell system over LTE systems by performing system-level simulations based on a 3D ray-tracing tool.",result,3
6256,Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs.,background,0
6257,"Our biologically plausible, wide and deep artificial neural network architectures can.",background,0
6258,"Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex.",background,0
6259,Only winner neurons are trained.,background,0
6260,Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged.,background,0
6261,Graphics cards allow for fast training.,result,3
6262,"On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance.",method,2
6263,On a traffic sign recognition benchmark it outperforms humans by a factor of two.,objective,1
6264,We also improve the state-of-the-art on a plethora of common image classification benchmarks.,result,3
6265,Twitter sentiment analysis has become widely popular.,background,0
6266,"However, stable Twitter sentiment classification performance remains elusive due to several issues: heavy class imbalance in a multi-class problem, representational richness issues for sentiment cues, and the use of diverse colloquial linguistic patterns.",background,0
6267,These issues are problematic since many forms of social media analytics rely on accurate underlying Twitter sentiments.,background,0
6268,"Accordingly, a text analytics framework is proposed for Twitter sentiment analysis.",method,2
6269,"The framework uses an elaborate bootstrapping ensemble to quell class imbalance, sparsity, and representational richness issues.",method,2
6270,"Experiment results reveal that the proposed approach is more accurate and balanced in its predictions across sentiment classes, as compared to various comparison tools and algorithms.",result,3
6271,"Consequently, the bootstrapping ensemble framework is able to build sentiment time series that are better able to reflect events eliciting strong positive and negative sentiments from users.",result,3
6272,"Considering the importance of Twitter as one of the premiere social media platforms, the results have important implications for social media analytics and social intelligence.",result,3
6273,This paper presents a survey on hate speech detection.,background,0
6274,"Given the steadily growing body of social media content, the amount of online hate speech is also increasing.",background,0
6275,"Due to the massive scale of the web, methods that automatically detect hate speech are required.",objective,1
6276,Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing.,method,2
6277,We also discuss limits of those approaches.,result,3
6278,"Reearch into virtual environments on the one hand and artificial intelligence and artificial life on the other has largely been carried out by two different groups of people with different preoccupations and interests, but some convergence is now apparent between the two fields.",background,0
6279,"Applications in which activity independent of the user takes place — involving crowds or other agents — are beginning to be tackled, while synthetic agents, virtual humans and computer pets are all areas in which techniqes from the two fields require strong integration.",background,0
6280,The two communities have much to learn from each other if wheels are not to be reinvented on both sides.,background,0
6281,This paper reviews the issues arising from combining artificial intelligence and artificial life techniques with those of virtual environments to produce just such intelligent virtual environments.,objective,1
6282,"The discussion is illustrated with examples that include environments providing knowledge to direct or assist the user rather than relying entirely on the user’s knowledge and skills, those in which the user is represented by a partially autonomous avatar, those containing intelligent agents separate from the user, and many others from both sides of the area.",result,3
6283,"In this paper, we use data augmentation to improve performance of deep neural network (DNN) embeddings for speaker recognition.",background,0
6284,"The DNN, which is trained to discriminate between speakers, maps variable-length utterances to fixed-dimensional embeddings that we call x-vectors.",background,0
6285,Prior studies have found that embeddings leverage large-scale training datasets better than i-vectors.,background,0
6286,"However, it can be challenging to collect substantial quantities of labeled data for training.",background,0
6287,"We use data augmentation, consisting of added noise and reverberation, as an inexpensive method to multiply the amount of training data and improve robustness.",method,2
6288,The x-vectors are compared with i-vector baselines on Speakers in the Wild and NIST SRE 2016 Cantonese.,objective,1
6289,"We find that while augmentation is beneficial in the PLDA classifier, it is not helpful in the i-vector extractor.",background,0
6290,"However, the x-vector DNN effectively exploits data augmentation, due to its supervised training.",objective,1
6291,"As a result, the x-vectors achieve superior performance on the evaluation datasets.",result,3
6292,Backpropagation and contrastive Hebbian learning are two methods of training networks with hidden neurons.,background,0
6293,Backpropagation computes an error signal for the output neurons and spreads it over the hidden neurons.,background,0
6294,Contrastive Hebbian learning involves clamping the output neurons at desired values and letting the effect spread through feedback connections over the entire network.,background,0
6295,"To investigate the relationship between these two forms of learning, we consider a special case in which they are identical: a multilayer perceptron with linear output units, to which weak feedback connections have been added.",method,2
6296,"In this case, the change in network state caused by clamping the output neurons turns out to be the same as the error signal spread by backpropagation, except for a scalar prefactor.",result,3
6297,"This suggests that the functionality of backpropagation can be realized alternatively by a Hebbian-type learning algorithm, which is suitable for implementation in biological networks.",result,3
6298,"We describe a parsing system based upon a language model for English that is, in turn, based upon assigning probabilities to possible parses for a sentence.",background,0
6299,This model is used in a parsing system by nding the parse for the sentence with the highest probability.,method,2
6300,This system outperforms previous schemes.,background,0
6301,"As this is the third in a series of parsers by di erent authors that are similar enough to invite detailed comparisons but di erent enough to give rise to di erent levels of performance, we also report on some experiments designed to identify what aspects of these systems best explain their relative performance.",result,3
6302,"The paper provides an overview of the development of intelligent data analysis in medicine from a machine learning perspective: a historical view, a state-of-the-art view, and a view on some future trends in this subfield of applied artificial intelligence.",objective,1
6303,The paper is not intended to provide a comprehensive overview but rather describes some subareas and directions which from my personal point of view seem to be important for applying machine learning in medical diagnosis.,objective,1
6304,"In the historical overview, I emphasize the naive Bayesian classifier, neural networks and decision trees.",objective,1
6305,"I present a comparison of some state-of-the-art systems, representatives from each branch of machine learning, when applied to several medical diagnostic tasks.",method,2
6306,The future trends are illustrated by two case studies.,method,2
6307,"The first describes a recently developed method for dealing with reliability of decisions of classifiers, which seems to be promising for intelligent data analysis in medicine.",method,2
6308,"The second describes an approach to using machine learning in order to verify some unexplained phenomena from complementary medicine, which is not (yet) approved by the orthodox medical community but could in the future play an important role in overall medical diagnosis and treatment.",result,3
6309,"With rapid progress and significant successes in a wide spectrum of applications, deep learning is being applied in many safety-critical environments.",background,0
6310,"However, deep neural networks (DNNs) have been recently found vulnerable to well-designed input samples called adversarial examples.",background,0
6311,Adversarial perturbations are imperceptible to human but can easily fool DNNs in the testing/deploying stage.,background,0
6312,The vulnerability to adversarial examples becomes one of the major risks for applying DNNs in safety-critical environments.,background,0
6313,"Therefore, attacks and defenses on adversarial examples draw great attention.",background,0
6314,"In this paper, we review recent findings on adversarial examples for DNNs, summarize the methods for generating adversarial examples, and propose a taxonomy of these methods.",objective,1
6315,"Under the taxonomy, applications for adversarial examples are investigated.",method,2
6316,We further elaborate on countermeasures for adversarial examples.,method,2
6317,"In addition, three major challenges in adversarial examples and the potential solutions are discussed.",method,2
6318,Spreadsheets are among the most widely used programming systems in the world.,background,0
6319,"Individuals and businesses use spreadsheets for a wide variety of applications, ranging from performing simple calculations to building complex financial models.",background,0
6320,"In this article, we first discuss how spreadsheet programs are actually functional programs.",method,2
6321,"We then describe concepts in spreadsheet programming, followed by a brief history of spreadsheet systems.",method,2
6322,"Widespread use of spreadsheets, coupled with their high error-proneness and the impact of spreadsheet errors, has motivated research into techniques aimed at the prevention, detection, and correction of errors in spreadsheets.",method,2
6323,We present an overview of research effort that seeks to rectify this problem.,method,2
6324,"In this study, we have assessed the validity and reliability of an automated labeling system that we have developed for subdividing the human cerebral cortex on magnetic resonance images into gyral based regions of interest (ROIs).",background,0
6325,Using a dataset of 40 MRI scans we manually identified 34 cortical ROIs in each of the individual hemispheres.,background,0
6326,This information was then encoded in the form of an atlas that was utilized to automatically label ROIs.,background,0
6327,"To examine the validity, as well as the intra- and inter-rater reliability of the automated system, we used both intraclass correlation coefficients (ICC), and a new method known as mean distance maps, to assess the degree of mismatch between the manual and the automated sets of ROIs.",method,2
6328,"When compared with the manual ROIs, the automated ROIs were highly accurate, with an average ICC of 0.835 across all of the ROIs, and a mean distance error of less than 1 mm.",method,2
6329,Intra- and inter-rater comparisons yielded little to no difference between the sets of ROIs.,method,2
6330,These findings suggest that the automated method we have developed for subdividing the human cerebral cortex into standard gyral-based neuroanatomical regions is both anatomically valid and reliable.,result,3
6331,"This method may be useful for both morphometric and functional studies of the cerebral cortex as well as for clinical investigations aimed at tracking the evolution of disease-induced changes over time, including clinical trials in which MRI-based measures are used to examine response to treatment.",result,3
6332,Automated classification of text into predefined categories has always been considered as a vital method to manage and process a vast amount of documents in digital forms that are widespread and continuously increasing.,background,0
6333,"This kind of web information, popularly known as the digital/electronic information is in the form of documents, conference material, publications, journals, editorials, web pages, e-mail etc.",background,0
6334,"People largely access information from these online sources rather than being limited to archaic paper sources like books, magazines, newspapers etc.",background,0
6335,But the main problem is that this enormous information lacks organization which makes it difficult to manage.,objective,1
6336,Text classification is recognized as one of the key techniques used for organizing such kind of digital data.,background,0
6337,In this paper we have studied the existing work in the area of text classification which will allow us to have a fair evaluation of the progress made in this field till date.,objective,1
6338,We have investigated the papers to the best of our knowledge and have tried to summarize all existing information in a comprehensive and succinct manner.,method,2
6339,The studies have been summarized in a tabular form according to the publication year considering numerous key,result,3
6340,"Departing from the comprehensive reviews carried out in the field, we identify the key challenges that agent-based methodology faces when modeling coupled socio-ecological systems.",background,0
6341,"Focusing primarily on the papers presented in this thematic issue, we review progress in spatial agent-based models along the lines of four methodological challenges: (1) design and parameterizing of agent decision models, (2) verification, validation and sensitivity analysis, (3) integration of socio-demographic, ecological, and biophysical models, and (4) spatial representation.",background,0
6342,Based on this we critically reflect on the future work that is required to make agent-based modeling widely accepted as a tool to support the real world policy.,method,2
6343,2013 Elsevier Ltd. All rights reserved.,other,4
6344,"Currently, Belgium is introducing an electronic version of its identity card.",background,0
6345,"In this article, we shortly describe the card, and give a brief introduction to its cryptographic features.",method,2
6346,"In particular, we focus on the Public-Key Infrastructure (PKI) associated with the card.",result,3
6347,"In this paper, we address the problems of contour detection, bottom-up grouping, object detection and semantic segmentation on RGB-D data.",objective,1
6348,"We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset (Silberman et al., ECCV, 2012).",method,2
6349,"We propose algorithms for object boundary detection and hierarchical segmentation that generalize the $$gPb-ucm$$ g P b - u c m approach of Arbelaez et al. (TPAMI, 2011) by making effective use of depth information.",method,2
6350,"We show that our system can label each contour with its type (depth, normal or albedo).",method,2
6351,We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping.,method,2
6352,"We train RGB-D object detectors by analyzing and computing histogram of oriented gradients on the depth image and using them with deformable part models (Felzenszwalb et al., TPAMI, 2010).",method,2
6353,We observe that this simple strategy for training object detectors significantly outperforms more complicated models in the literature.,method,2
6354,We then turn to the problem of semantic segmentation for which we propose an approach that classifies superpixels into the dominant object categories in the NYUD2 dataset.,method,2
6355,We design generic and class-specific features to encode the appearance and geometry of objects.,method,2
6356,We also show that additional features computed from RGB-D object detectors and scene classifiers further improves semantic segmentation accuracy.,method,2
6357,"A genetic algorithm, GENEsYs, is applied to an NP-complele problem, the 0/1 multiple knapsack problem.",background,0
6358,The partitioning of the search space resulting from this highly constrained problem may include substantially large infeasible regions.,background,0
6359,Our implementation allows for the breeding and participation of infeasible strings in the population.,objective,1
6360,"Unlike many other GA-based algorithms lhat are augmented with domainspecific knowledge, GENEsYs uses a simple fitness function that uses a graded penalty term to penalize infeasibly bred strings.",objective,1
6361,We apply our genetic algorithm to problem inslances trom the literature of well known test problems and report our experimental results.,method,2
6362,"These encouraging results, especially for relatively large test problems, indicate that genetic algorithms can be successfully used as heuristics for finding good solutions for highly constrained NP-complete problems.",result,3
6363,We develop a new approach that uses the ordered weighted averaging (OWA) operator in the selection of financial products.,objective,1
6364,"In doing so, we introduce the ordered weighted averaging distance (OWAD) operator and the ordered weighted averaging adequacy coefficient (OWAAC) operator.",method,2
6365,These aggregation operators are very useful for decision-making problems because they establish a comparison between an ideal alternative and available options in order to find the optimal choice.,method,2
6366,"The objective of this new model is to manipulate the attitudinal character of previous methods based on distance measures, so that the decision maker can select financial products according to his or her degree of optimism, which is also known as the orness measure.",objective,1
6367,The main advantage of using the OWA operator is that we can generate a parameterized family of aggregation operators between the maximum and the minimum.,result,3
6368,"Thus, the analysis developed in the decision process by the decision maker is much more complete, because he or she is able to select the particular case in accordance with his or her interests in the aggregation process.",result,3
6369,The paper ends with an illustrative example that shows results obtained by using different types of aggregation operators in the selection of financial products.,result,3
6370,2010 Elsevier Inc. All rights reserved.,other,4
6371,"The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations.",background,0
6372,"In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far.",background,0
6374,We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause.,result,3
6375,We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples.,objective,1
6378,"Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors.",result,3
6379,Code is at: https://github.com/facebookresearch/Detectron.,other,4
6380,The technology acceptance model proposes that perceived ease of use and perceived usefulness predict the acceptance of information technology.,background,0
6381,"Since its inception, the model has been tested with various applications in tens of studies and has become a most widely applied model of user acceptance and usage.",background,0
6382,"Nevertheless, the reported findings on the model are mixed in terms of statistical significance, direction, and magnitude.",background,0
6383,"In this study, we conducted a meta-analysis based on 26 selected empirical studies in order to synthesize the empirical evidence.",method,2
6384,The results suggest that both the correlation between usefulness and acceptance and between usefulness and ease of use are somewhat strong.,result,3
6385,"However, the relationship between ease of use and acceptance is weak, and its significance does not pass the fail-safe test.",result,3
6386,"IDEA GROUP PUBLISHING This chapter appears in the book, Advanced Topics in End User Computing, vol.",other,4
6387,"4 edited by M. Adam Mahmood © 2005, Idea Group Inc. 701 E. Chocolate Avenue, Suite 200, Hershey PA 17033-1240, USA Tel: 717/533-8845; Fax 717/533-8661; URL-http://www.idea-group.com ITB11300",other,4
6388,"We present an end-to-end system for augmented and virtual reality telepresence, called Holoportation.",background,0
6389,"Our system demonstrates high-quality, real-time 3D reconstructions of an entire space, including people, furniture and objects, using a set of new depth cameras.",background,0
6390,These 3D models can also be transmitted in real-time to remote users.,background,0
6391,"This allows users wearing virtual or augmented reality displays to see, hear and interact with remote participants in 3D, almost as if they were present in the same physical space.",method,2
6392,"From an audio-visual perspective, communicating and interacting with remote users edges closer to face-to-face communication.",method,2
6393,"This paper describes the Holoportation technical system in full, its key interactive capabilities, the application scenarios it enables, and an initial qualitative study of using this new communication medium.",result,3
6394,This paper explores a simple and efficient baseline for text classification.,background,0
6395,"Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation.",objective,1
6396,"We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU, and classify half a million sentences among 312K classes in less than a minute.",method,2
6397,"This paper presents a method for measuring the semantic similarity of texts, using corpus-based and knowledge-based measures of similarity.",method,2
6398,"Previous work on this problem has focused mainly on either large documents (e.g. text classification, information retrieval) or individual words (e.g. synonymy tests).",method,2
6399,"Given that a large fraction of the information available today, on the Web and elsewhere, consists of short text snippets (e.g. abstracts of scientific documents, imagine captions, product descriptions), in this paper we focus on measuring the semantic similarity of short texts.",method,2
6400,"Through experiments performed on a paraphrase data set, we show that the semantic similarity method outperforms methods based on simple lexical matching, resulting in up to 13% error rate reduction with respect to the traditional vector-based similarity metric.",result,3
6401,"In classification, it is often difficult or expensive to obtain completely accurate and reliable labels.",background,0
6402,"Indeed, labels may be polluted by label noise, due to e.g. insufficient information, expert mistakes, and encoding errors.",background,0
6403,"The problem is that errors in training labels that are not properly handled may deteriorate the accuracy of subsequent predictions, among other effects.",objective,1
6404,Many works have been devoted to label noise and this paper provides a concise and comprehensive introduction to this research topic.,method,2
6405,"In particular, it reviews the types of label noise, their consequences and a number of state of the art approaches to deal with label noise.",result,3
6406,This study involved developing a computer-aided diagnosis (CAD) system for discriminating the grades of breast cancer tumors in ultrasound (US) images.,background,0
6407,Histological tumor grades of breast cancer lesions are standard prognostic indicators.,background,0
6408,Tumor grade information enables physicians to determine appropriate treatments for their patients.,objective,1
6409,US imaging is a noninvasive approach to breast cancer examination.,background,0
6410,"In this study, 148 3-dimensional US images of malignant breast tumors were obtained.",result,3
6411,"Textural, morphological, ellipsoid fitting, and posterior acoustic features were quantified to characterize the tumor masses.",result,3
6412,A support vector machine was developed to classify breast tumor grades as either low or high.,method,2
6413,"The proposed CAD system achieved an accuracy of 85.14% (126/148), a sensitivity of 79.31% (23/29), a specificity of 86.55% (103/119), and an A Z of 0.7940.",objective,1
6414,"This paper describes an algorithm for Successive Approximation Register (SAR) ADCs with overlapping steps that allow comparison decision errors (due to, such as DAC incomplete settling) to be digitally corrected.",background,0
6415,"We generalize this non-binary search algorithm, and clarify which decision errors it can digitally correct.",method,2
6416,"This algorithm requires more SAR ADC conversion steps than a binary search algorithm, but we show that the sampling speed of an SAR ADC using this algorithm can be faster than that of a conventional binary-search SAR ADC — because the latter must wait for the settling time of the DAC inside the SAR ADC.",method,2
6417,"key words: SAR ADC, digital error correction, non-binary, redundancy",result,3
6418,"In this paper, we propose <italic>DeepCut</italic>, a method to obtain pixelwise object segmentations given an image dataset labelled weak annotations, in our case bounding boxes.",background,0
6419,"It extends the approach of the well-known <italic>GrabCut</italic> <xref ref-type=""bibr"" rid=""ref1"">[1]</xref> method to include machine learning by training a neural network classifier from bounding box annotations.",method,2
6420,We formulate the problem as an energy minimisation problem over a densely-connected conditional random field and iteratively update the training targets to obtain pixelwise object segmentations.,background,0
6421,"Additionally, we propose variants of the <italic>DeepCut</italic> method and compare those to a naïve approach to CNN training under weak supervision.",method,2
6422,We test its applicability to solve brain and lung segmentation problems on a challenging fetal magnetic resonance dataset and obtain encouraging results in terms of accuracy.,result,3
6423,"The enormous amount of information stored in unstructured texts cannot simply be used for further processing by computers, which typically handle text as simple sequences of character strings.",background,0
6424,"Therefore, specific (pre-)processing methods and algorithms are required in order to extract useful patterns.",background,0
6425,Text mining refers generally to the process of extracting interesting information and knowledge from unstructured text.,background,0
6426,"In this article, we discuss text mining as a young and interdisciplinary field in the intersection of the related areas information retrieval, machine learning, statistics, computational linguistics and especially data mining.",objective,1
6427,"We describe the main analysis tasks preprocessing, classification, clustering, information extraction and visualization.",background,0
6428,"In addition, we briefly discuss a number of successful applications of text mining.",objective,1
6429,A technique for software system behavior specification appropriate for use in designing systems with concurrency is presented.,background,0
6430,"The technique is based upon a generalized ability to define events, or significant occurrences in a software system, and then indicate whatever constraints the designer might wish to see imposed upon the ordering or simultaneity of those events.",background,0
6431,Constructs implementing this technique in the DREAM software design system are presented and illustrated.,method,2
6432,The relationship of this technique to other behavior specification techniques is also discussed.,result,3
6433,"Dynamic voltage (IR) drop, unlike the static voltage drop depends on the switching activity of the design, and hence it is vector dependent.",background,0
6434,"In this paper we have highlighted the pitfalls in the common design closure methodology that addresses static IR drop well, but often fails to bound the impact of dynamic voltage drops robustly.",background,0
6435,Factors that can affect the accuracy of dynamic IR analysis and the related metrics for design closure are discussed.,objective,1
6436,"A structured approach to planning the power distribution and grid for power managed designs is then presented, with an emphasis to cover realistic application scenarios, and how it can be done early in the design cycle.",method,2
6437,Care-about and solutions to avoid and fix the Dynamic voltage drop issues are also presented.,method,2
6438,Results are from industrial designs in 45nm process are presented related to the said topics.,result,3
6439,"This paper takes the stance that some cases of information systems development can be considered knowledge creating activities, and, in those cases, information systems development can be a legitimate research method.",background,0
6440,In these cases not only is knowledge created about the development process itself but also a deeper understanding emerges about the organisational problem that the system is designed to solve.,background,0
6441,"The paper begins with a brief overview of research in the design sciences and a comparison of research methods that are concerned with the design, and use, of information systems.",method,2
6442,"This is followed by an assessment of the way systems development as a research method deals with the scientific research processes of data collection, analysis, synthesis and display.",result,3
6443,"A case study, where the systems development research method was use, is described to illustrate the method and give the reader a better understanding of the approach.",result,3
6444,The increasing advances in hardware technology for sensor processing and mobile technology has resulted in greater access and availability of sensor data from a wide variety of applications.,background,0
6445,"For example, the commodity mobile devices contain a wide variety of sensors such as GPS, accelerometers, and other kinds of data.",background,0
6446,Many other kinds of technology such as RFID-enabled sensors also produce large volumes of data over time.,method,2
6447,This has lead to a need for principled methods for efficient sensor data processing.,method,2
6448,This chapter will provide an overview of the challenges of sensor data analytics and the different areas of research in this context.,result,3
6449,We will also present the organization of the chapters in this book in this context.,method,2
6450,Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system.,objective,1
6451,"Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information.",method,2
6452,"As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000.",method,2
6453,A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.,result,3
6454,The Recurrent Neural Network (RNN) is an extremely powerful sequence model that is often difficult to train.,background,0
6455,The Long Short-Term Memory (LSTM) is a specific RNN architecture whose design makes it much easier to train.,background,0
6456,"While wildly successful in practice, the LSTM’s architecture appears to be ad-hoc so it is not clear if it is optimal, and the significance of its individual components is unclear.",background,0
6457,"In this work, we aim to determine whether the LSTM architecture is optimal or whether much better architectures exist.",objective,1
6458,"We conducted a thorough architecture search where we evaluated over ten thousand different RNN architectures, and identified an architecture that outperforms both the LSTM and the recently-introduced Gated Recurrent Unit (GRU) on some but not all tasks.",method,2
6459,We found that adding a bias of 1 to the LSTM’s forget gate closes the gap between the LSTM and the GRU.,result,3
6460,"As the Internet becomes the critical information infrastructure for both personal and business applications, survivable routing protocols need to be designed that maintain the performance of those services in the presence of failures.",background,0
6461,"This paper examines the survivability of interdoamin routing protocols in the presence of routing failure events, and provides a backup route aware routing protocol that performs non-stop routing in the presence of failures.",background,0
6462,We demonstrate through simulation its effectiveness in preventing packet losses during transient routing failures.,result,3
6463,We describe a graphical system for automatically generating multiple 2D diagrams of ligand-protein interactions from 3D coordinates.,background,0
6464,The diagrams portray the hydrogen-bond interaction patterns and hydrophobic contacts between the ligand(s) and the main-chain or side-chain elements of the protein.,method,2
6465,"The system is able to plot, in the same orientation, related sets of ligand-protein interactions.",method,2
6466,"This facilitates popular research tasks, such as analyzing a series of small molecules binding to the same protein target, a single ligand binding to homologous proteins, or the completely general case where both protein and ligand change.",method,2
6467,Automated diagnosis of glaucoma disease has been studied for years.,background,0
6468,"A great amount of research work in this field has been focused on the analysis of retinal fundus images to localize, detect and evaluate the optic disc.",background,0
6469,An open fundus image database with accurate gold standards of the optic nerve head has been implemented.,method,2
6470,A variability measurement by zones of the optic disc is also proposed.,method,2
6471,The relevance of this work is to provide accurate ONH segmentations and a segmentation assessment procedure to allow the design of computerized methods for glaucoma detection.,result,3
6472,This study examines the effect of five factors on the adoption of electronic commerce among small and medium enterprises in Brunei Darussalam.,background,0
6473,"A review of the literature shows that owner characteristics such as lack of perceived relative advantage, lack of knowledge, and perceived lack of trust are significant inhibitors while environment characteristics such as competitive pressure and, government support are significant motivators of electronic commerce in Brunei Darussalam.",background,0
6474,A questionnaire survey was conducted in 360 small and medium enterprises.,method,2
6475,A total of 184 valid responses were obtained.,method,2
6476,Stratified random sampling was adopted over other techniques to enhance representativeness.,method,2
6477,Data analysis shows that significant relationship exists between each of the five variables and electronic commerce adoption among small and medium enterprises in Brunei Darussalam.,method,2
6478,This study concludes that the five factors explain more than fifty percent of the variation in small and medium enterprises adoption.,method,2
6479,Competitive pressure emerged as the most important factor in terms of relative importance.,result,3
6480,"This factor is followed by IT knowledge, relative advantage, security and government support.",result,3
6481,"Popcorn kernels are a natural, edible, and inexpensive material that has the potential to rapidly expand with high force upon application of heat.",background,0
6482,"Although this transition is irreversible, it carries potential for several robotic applications.",background,0
6483,"Here, we examine relevant characteristics of three types of kernels including expansion ratio, transition temperature, popping force, compression strength, and biodegradability.",method,2
6484,"We test the viability of popping by hot oil, hot air, microwaves, and direct contact with heated Nichrome wire.",method,2
6485,"As kernels can change from regular to (larger) irregular shapes, we examine the change in inter-granular friction and propose their use as granular fluids in jamming actuators, without the need for a vacuum pump.",method,2
6486,"Furthermore, as a proof-of-concept, we also demonstrate the use of popcorn-driven actuation in soft, compliant, and rigid-link grippers.",result,3
6487,"Serving as a first introduction of popcorn into robotics, we hope this paper will inspire novel mechanisms for multi-functional designs.",result,3
6488,Clustering is an unsupervised technique of Data Mining.,background,0
6489,It means grouping similar objects together and separating the dissimilar ones.,background,0
6490,Each object in the data set is assigned a class label in the clustering process using a distance measure.,background,0
6491,This paper has captured the problems that are faced in real when clustering algorithms are implemented .It,objective,1
6492,also considers the most extensively used tools which are readily available and support functions which ease the programming.,method,2
6493,"Once algorithms have been implemented, they also need to be tested for its validity.",method,2
6494,There exist several validation indexes for testing the performance and accuracy which have also been discussed here.,result,3
6495,"The recent increase in reported incidents of surveillance and security breaches compromising users' privacy call into question the current model, in which third-parties collect and control massive amounts of personal data.",background,0
6496,"Bit coin has demonstrated in the financial space that trusted, auditable computing is possible using a decentralized network of peers accompanied by a public ledger.",background,0
6497,"In this paper, we describe a decentralized personal data management system that ensures users own and control their data.",background,0
6498,We implement a protocol that turns a block chain into an automated access-control manager that does not require trust in a third party.,method,2
6499,"Unlike Bit coin, transactions in our system are not strictly financial -- they are used to carry instructions, such as storing, querying and sharing data.",result,3
6500,"Finally, we discuss possible future extensions to block chains that could harness them into a well-rounded solution for trusted computing problems in society.",result,3
6501,There has been a flowering of scholarly interest in the literature review as a research method in the information systems discipline.,background,0
6502,We feel privileged to contribute to this conversation and introduce the work of the authors represented in this special issue.,background,0
6503,"Some of the highlights include three new methods for conducting literature analysis and guidelines, tutorials, and approaches for coping with some of the challenges involved in carrying out a literature review.",background,0
6504,"Of the three “new method” papers, one (ontological meta-analysis and synthesis) is entirely new, and two (stylized facts and critical discourse analysis) are novel in the information systems context.",method,2
6505,"The other four paper address more general issues: the challenges of effective search strategies when confronted with the burgeoning volume of research available, a detailed tool-supported approach for conducting a rigorous review, a detailed tutorial for conducting a qualitative literature review, and a discussion of quality issues.",method,2
6506,"Collectively, the papers place emphasis beyond the traditional “narrative synthesis” on the importance of selecting the appropriate approach for the research context and the importance of attention to quality and transparency at all stages of the process, regardless of which approach is adopted.",result,3
6507,"A genetic algorithm-based clustering technique, called GA-clustering, is proposed in this article.",background,0
6508,The searching capability of genetic algorithms is exploited in order to search for appropriate cluster centres in the feature space such that a similarity metric of the resulting clusters is optimized.,background,0
6509,"The chromosomes, which are represented as strings of real numbers, encode the centres of a ""xed number of clusters.",background,0
6510,"The superiority of the GA-clustering algorithm over the commonly used K-means algorithm is extensively demonstrated for four arti""cial and three real-life data sets.",method,2
6511,( 2000 Pattern Recognition Society.,method,2
6512,Published by Elsevier Science Ltd.,method,2
6514,This paper presents a large-scale system for the recognition and semantic disambiguation of named entities based on information extracted from a large encyclopedic collection and Web search results.,method,2
6515,It describes in detail the disambiguation paradigm employed and the information extraction process from Wikipedia.,method,2
6516,"Through a process of maximizing the agreement between the contextual information extracted from Wikipedia and the context of a document, as well as the agreement among the category tags associated with the candidate entities, the implemented system shows high disambiguation accuracy on both news stories and Wikipedia articles.",method,2
6517,"This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding.",background,0
6518,"At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty.",background,0
6519,"MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation.",method,2
6520,"In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",result,3
6521,"In ATM cash replenishment banks want to use less resources (e.g., cash kept in ATMs, trucks for loading cash) for meeting fluctuated customer demands.",background,0
6522,"Traditionally, forecasting procedures such as exponentially weighted moving average are applied to daily cash withdraws for individual ATMs.",background,0
6523,"Then, the forecasted results are provided to optimization models for deciding the amount of cash and the trucking logistics schedules for replenishing cash to all ATMs.",background,0
6524,"For some situations where individual ATM withdraws have so much variations (e.g., data collected from Istanbul ATMs) the traditional approaches do not work well.",result,3
6525,"This article proposes grouping ATMs into nearby-location clusters and also optimizing the aggregates of daily cash withdraws (e.g., replenish every week instead of every day) in the forecasting process.",objective,1
6526,"Example studies show that this integrated forecasting and optimization procedure performs better for an objective in minimizing costs of replenishing cash, cash-interest charge and potential customer",result,3
6527,This paper gives a basic review and a summary of recent developments for leaky-wave antennas (LWAs).,background,0
6528,"An LWA uses a guiding structure that supports wave propagation along the length of the structure, with the wave radiating or “leaking” continuously along the structure.",background,0
6529,"Such antennas may be uniform, quasi-uniform, or periodic.",background,0
6530,"After reviewing the basic physics and operating principles, a summary of some recent advances for these types of structures is given.",method,2
6531,"Recent advances include structures that can scan to endfire, structures that can scan through broadside, structures that are conformal to surfaces, and structures that incorporate power recycling or include active elements.",method,2
6532,Some of these novel structures are inspired by recent advances in the metamaterials area.,method,2
6533,Model checking is an automatic verification technique for hardware and software systems that are finite state or have finite state abstractions.,background,0
6534,"It has been used successfully to verify computer hardware, and it is beginning to be used to verify computer software as well.",background,0
6535,"As the number of state variables in the system increases, the size of the system state space grows exponentially.",background,0
6536,This is called the “state explosion problem”.,background,0
6537,Much of the research in model checking over the past 30 years has involved developing techniques for dealing with this problem.,background,0
6538,"In these lecture notes, we will explain how the basic model checking algorithms work and describe some recent approaches to the state explosion problem, with an emphasis on Bounded Model Checking.",method,2
6539,"In this letter, we develop a gaussian process model for clustering.",background,0
6540,The variances of predictive values in gaussian processes learned from a training data are shown to comprise an estimate of the support of a probability density function.,method,2
6541,"The constructed variance function is then applied to construct a set of contours that enclose the data points, which correspond to cluster boundaries.",method,2
6542,"To perform clustering tasks of the data points, an associated dynamical system is built, and its topological invariant property is investigated.",method,2
6543,The experimental results show that the proposed method works successfully for clustering problems with arbitrary shapes.,result,3
6544,Distributed Denial of Service (DDoS) attacks grow rapidly and become one of the fatal threats to the Internet.,background,0
6545,Automatically detecting DDoS attack packets is one of the main defense mechanisms.,background,0
6546,Conventional solutions monitor network traffic and identify attack activities from legitimate network traffic based on statistical divergence.,background,0
6547,Machine learning is another method to improve identifying performance based on statistical features.,background,0
6548,"However, conventional machine learning techniques are limited by the shallow representation models.",method,2
6549,"In this paper, we propose a deep learning based DDoS attack detection approach (DeepDefense).",objective,1
6550,Deep learning approach can automatically extract high-level features from low-level ones and gain powerful representation and inference.,method,2
6551,We design a recurrent deep neural network to learn patterns from sequences of network traffic and trace network attack activities.,result,3
6552,The experimental results demonstrate a better performance of our model compared with conventional machine learning models.,result,3
6553,We reduce the error rate from 7.517% to 2.103% compared with conventional machine learning method in the larger data set.,result,3
6554,The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters.,background,0
6555,"Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes bruteforce search.",background,0
6556,There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand.,background,0
6557,"In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP).",objective,1
6558,"We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance.",method,2
6559,We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation.,result,3
6560,"We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.",result,3
6561,"In this paper, we examine and compare De Morgan-, Kleene-, and Boolean-disjunctive and conjunctive normal forms and consider their role in fuzzy settings.",background,0
6562,"In particular, we show that there are normal forms and truth tables for classical fuzzy propositional logic and interval-valued fuzzy propositional logic that are completely analogous to those for Boolean propositional logic.",background,0
6563,"Thus, determining logical equivalence of two expressions in fuzzy propositional logic is a <nite problem, and similarly for the interval-valued case.",objective,1
6564,Turksen’s work on interval-valued fuzzy sets is examined in light of these results.,result,3
6565,c © 2002 Elsevier B.V.,other,4
6567,"We present a system that complements virtual reality experiences with passive props, yet still allows modifying the virtual world at runtime.",background,0
6568,"The main contribution of our system is that it does not require any actuators; instead, our system employs the user to reconfigure and actuate otherwise passive props.",background,0
6569,"We demonstrate a foldable prop that users reconfigure to represent a suitcase, fuse cabinet, railing, and a seat.",result,3
6570,"A second prop, suspended from a long pendulum, not only stands in for inanimate objects, but also for objects that move and demonstrate proactive behavior, such as a group of flying droids that physically attack the user.",method,2
6571,"Our approach conveys a sense of a living, animate world, when in reality the user is the only animate entity present in the system, complemented with only one or two physical props.",method,2
6572,"In our study, participants rated their experience as more enjoyable and realistic than a corresponding no-haptics condition.",result,3
6573,The Internet of Things (IoT) paradigm comprises a heterogenous mix of connected devices connected to the Internet.,background,0
6574,This promises a a wealth of opportunity for a large collection of distributed applications and services.,background,0
6575,"However, the IoT introduces significant changes to the Internet model, largely in the form of billions to trillions of embedded devices that most likely will not be able to be managed centrally by cloud services due to lack of scalability.",background,0
6576,"We suggest that the natural direction for IoT devices is to manage themselves, both in terms of their software/hardware configuration and their resource utilization.",objective,1
6577,"In this work, we describe the underlying framework for self-managing devices, comprising measurement-based learning and adaptation to changing system context and application demands.",method,2
6578,"In addition, we describe several upcoming research challenges in order to realize this self-management vision.",method,2
6579,The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in mobile applications.,background,0
6580,Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability.,background,0
6581,"In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation.",method,2
6582,"ENet is up to 18× faster, requires 75× less FLOPs, has 79× less parameters, and provides similar or better accuracy to existing models.",method,2
6583,"We have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network.",result,3
6584,We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.,result,3
6585,This paper presents the development of several models of a deep convolutional auto-encoder in the Caffe deep learning framework and their experimental evaluation on the example of MNIST dataset.,objective,1
6586,We have created five models of a convolutional auto-encoder which differ architecturally by the presence or absence of pooling and unpooling layers in the auto-encoder’s encoder and decoder parts.,method,2
6587,"Our results show that the developed models provide very good results in dimensionality reduction and unsupervised clustering tasks, and small classification errors when we used the learned internal code as an input of a supervised linear classifier and multi-layer perceptron.",method,2
6588,"The best results were provided by a model where the encoder part contains convolutional and pooling layers, followed by an analogous decoder part with deconvolution and unpooling layers without the use of switch variables in the decoder part.",result,3
6589,The paper also discusses practical details of the creation of a deep convolutional auto-encoder in the very popular Caffe deep learning framework.,result,3
6590,We believe that our approach and results presented in this paper could help other researchers to build efficient deep neural network architectures in the future.,result,3
6591,"Data embedding is used in many machine learning applications to create low-dimensional feature representations, which preserves the structure of data points in their original space.",background,0
6592,"In this paper, we examine the scenario of a heterogeneous network with nodes and content of various types.",background,0
6593,Such networks are notoriously difficult to mine because of the bewildering combination of heterogeneous contents and structures.,background,0
6594,The creation of a multidimensional embedding of such data opens the door to the use of a wide variety of off-the-shelf mining techniques for multidimensional data.,background,0
6595,"Despite the importance of this problem, limited efforts have been made on embedding a network of scalable, dynamic and heterogeneous data.",background,0
6596,"In such cases, both the content and linkage structure provide important cues for creating a unified feature representation of the underlying network.",background,0
6597,"In this paper, we design a deep embedding algorithm for networked data.",method,2
6598,A highly nonlinear multi-layered embedding function is used to capture the complex interactions between the heterogeneous data in a network.,method,2
6599,"Our goal is to create a multi-resolution deep embedding function, that reflects both the local and global network structures, and makes the resulting embedding useful for a variety of data mining tasks.",objective,1
6600,"In particular, we demonstrate that the rich content and linkage information in a heterogeneous network can be captured by such an approach, so that similarities among cross-modal data can be measured directly in a common embedding space.",result,3
6601,"In this paper, a new type of 3D bin packing problem (BPP) is proposed, in which a number of cuboidshaped items must be put into a bin one by one orthogonally.",background,0
6602,The objective is to find a way to place these items that can minimize the surface area of the bin.,objective,1
6603,This problem is based on the fact that there is no fixed-sized bin in many real business scenarios and the cost of a bin is proportional to its surface area.,method,2
6604,Our research shows that this problem is NP-hard.,result,3
6605,"Based on previous research on 3D BPP, the surface area is determined by the sequence, spatial locations and orientations of items.",result,3
6606,"Among these factors, the sequence of items plays a key role in minimizing the surface area.",method,2
6607,"Inspired by recent achievements of deep reinforcement learning (DRL) techniques, especially Pointer Network, on combinatorial optimization problems such as TSP, a DRL-based method is applied to optimize the sequence of items to be packed into the bin.",result,3
6608,Numerical results show that the method proposed in this paper achieve about 5% improvement than heuristic method.,result,3
6609,"Two important classes of information systems, Workflow Management Systems (WfMSs) and Enterprise Resource Planning (ERP) systems, have been used to support e-business process redesign, integration, and management.",method,2
6610,"While both technologies can help with business process automation, data transfer, and information sharing, the technological approach and features of solutions provided by WfMS and ERP are different.",background,0
6611,"Currently, there is a lack of understanding of these two classes of information systems in the industry and academia, thus hindering their effective applications.",background,0
6612,"In this paper, we present a comprehensive comparison between these two classes of systems.",objective,1
6613,We discuss how the two types of systems can be used independently or together to develop intraand inter-organizational application solutions.,objective,1
6614,"In particular, we also explore the roles of WfMS and ERP in the next generation of IT architecture based on Web Services.",method,2
6615,Our findings should help businesses make better decisions in the adoption of both WfMS and ERP in their e-business strategies.,result,3
6616,"The purpose of this study was to explore the impact of Digital storytelling (DST) on the academic achievement, critical thinking, and learning motivation of senior high school students learning English as a foreign language.",background,0
6617,The one-year study adopted a pretest and posttest quasi-experimental design involving 110 10th grade students in two English classes.,method,2
6618,The independent variable was information technology-integrated instruction (ITII) on two different levels – lecture-type ITII (comparison group) and DST (experimental group).,method,2
6619,"Both quantitative and qualitative data were collected, including English achievement and critical thinking scores, questionnaire responses for learning motivation, as well as recordings of student and teacher interviews for evaluating the effectiveness of DST in learning.",method,2
6620,"Descriptive analysis, analysis of covariance (ANCOVA), multivariate analysis of covariance (MANCOVA), and qualitative content analysis was used for evaluating the obtained data.",method,2
6621,"Our findings indicate that DST participants performed significantly better than lecture-type ITII participants in terms of English achievement, critical thinking, and learning motivation.",method,2
6622,"Interview results highlight the important educational value of DST, as both the instructor and students reported that DST increased students’ understanding of course content, willingness to explore, and ability to think critically, factors which are important in preparing students for an ever-changing 21st century.",result,3
6623,2012 Elsevier Ltd. All rights reserved.,other,4
6624,"This work presents the use of click graphs in improving query intent classifiers, which are critical if vertical search and general-purpose search services are to be offered in a unified user interface.",objective,1
6625,"Previous works on query classification have primarily focused on improving feature representation of queries, e.g., by augmenting queries with search engine results.",objective,1
6626,"In this work, we investigate a completely orthogonal approach --- instead of enriching feature representation, we aim at drastically increasing the amounts of training data by semi-supervised learning with click graphs.",objective,1
6627,"Specifically, we infer class memberships of unlabeled queries from those of labeled ones according to their proximities in a click graph.",method,2
6628,"Moreover, we regularize the learning with click graphs by content-based classification to avoid propagating erroneous labels.",method,2
6629,"We demonstrate the effectiveness of our algorithms in two different applications, product intent and job intent classification.",result,3
6630,"In both cases, we expand the training data with automatically labeled queries by over two orders of magnitude, leading to significant improvements in classification performance.",result,3
6631,"An additional finding is that with a large amount of training data obtained in this fashion, classifiers using only query words/phrases as features can work remarkably well.",result,3
6632,We present a fractal technique for addressing geometric analogy problems from the Raven's Standard Progressive Matrices test of general intelligence.,background,0
6633,"In this method, an image is represented fractally, capturing its inherent selfsimilarity.",background,0
6634,"We apply these fractal representations to problems from the Raven's test, and show how these representations afford a new method for solving complex geometric analogy problems.",method,2
6635,We present results using the fractal algorithm on all 60 problems from the Standard Progressive Matrices version of the Raven's test.,method,2
6636,"A broad range of well-structured problems--embracing forms of diagnosis, catalog selection, and skeletal planning--are solved in 'expert systems"" by the methods of heuristic classification.",method,2
6637,"These programs have a characteristic inference structure that systematically relates data to a pre-enumerated set of solutions by abstraction, heuristic association, and refinement.",background,0
6638,"In contrast with previous descriptions of classification reasoning, particularly in psychology, this analysis emphasizes the role of a heuristic in routine problem solving as a non-hierarchical, direct association between concepts.",objective,1
6639,"In contrast with other descriptions of expert systems, this analysis specifies the knowledge needed to solve a problem, independent of its representation in a particular computer language.",result,3
6640,"The heuristic classification problem-solving model provides a useful framework for characterizing kinds of problems, for designing representation tools, and for understanding non-classification (constructive) problem-solving methods.",result,3
6641,To understand something as a specific instance of a more general case--which is what understanding a more fundamental principle or structure means-i s to have learned not only a specific thing but also a model for understanding other things like it that one may encounter.,result,3
6642,[13],other,4
6643,The next generation of music recommendation systems will be increasingly intelligent and likely take into account user behavior for more personalized recommendations.,background,0
6644,In this work we consider user behavior when making recommendations with features extracted from a user’s history of listening events.,objective,1
6645,"We investigate the impact of listener’s behavior by considering features such as play counts, “mainstreaminess”, and diversity in music taste on the performance of various music recommendation approaches.",method,2
6646,The underlying dataset has been collected by crawling social media (specifically Twitter) for listening events.,result,3
6647,"Each user’s listening behavior is characterized into a three dimensional feature space consisting of play count, “mainstreaminess” (i.e. the degree to which the observed user listens to currently popular artists), and diversity (i.e. the diversity of genres the observed user listens to).",method,2
6648,"Drawing subsets of the 28,000 users in our dataset, according to these three dimensions, we evaluate whether these dimensions influence figures of merit of various music recommendation approaches, in particular, collaborative filtering (CF) and CF enhanced by cultural information such as users located in the same city or country.",result,3
6649,"For Artificial Neural Networks (ANN) to become more widely used in power systems and the future smart grids, ANN based algorithms must be capable of scaling up as they try to identify and control larger and larger parts of a power system.",background,0
6650,This paper goes through the process of scaling up an ANN based identifier as it is driven to identify increasingly larger portions of a power system.,objective,1
6651,Distributed and centralized approaches for scaling up are taken and the pros and cons of each are presented.,method,2
6652,The New England/New York 68-bus power network is used as the test bed for the studies.,method,2
6653,"It is shown that while a fully-connected (centralized) ANNs is capable of identification of the system with appropriate accuracy, the increase in the training times required to obtain an acceptable set of weights becomes prohibitive as the system size is increased.",result,3
6654,Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services.,background,0
6655,"As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly.",background,0
6656,"For a popular product, the number of reviews can be in hundreds or even thousands.",background,0
6657,This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product.,background,0
6658,It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions.,background,0
6659,"For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products.",background,0
6660,"In this research, we aim to mine and to summarize all the customer reviews of a product.",objective,1
6661,This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative.,objective,1
6662,We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization.,method,2
6663,Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results.,method,2
6664,Hate speech in the form of racist and sexist remarks are a common occurrence on social media.,background,0
6665,"For that reason, many social media services address the problem of identifying hate speech, but the definition of hate speech varies markedly and is largely a manual effort (BBC, 2015; Lomas, 2015).",objective,1
6666,"We provide a list of criteria founded in critical race theory, and use them to annotate a publicly available corpus of more than 16k tweets.",objective,1
6667,We analyze the impact of various extra-linguistic features in conjunction with character n-grams for hatespeech detection.,result,3
6668,We also present a dictionary based the most indicative words in our data.,result,3
6669,This article presents results from a Delphi study on the future impact of Enterprise Resource Planning (ERP) systems on Supply Chain Management (SCM).,background,0
6670,The Delphi study was conducted with 23 Dutch supply chain executives of European multinationals.,background,0
6671,Findings from this exploratory study were threefold.,result,3
6672,"First, our executives have identified the following key SCM issues for the coming years: (1) further integration of activities between suppliers and customers across the entire supply chain; (2) on-going changes in supply chain needs and required flexibility from IT; (3) more mass customization of products and services leading to increasing assortments while decreasing cycle times and inventories; (4) the locus of the driver’s seat of the entire supply chain and (5) supply chains consisting of several independent enterprises.",result,3
6673,The second main finding is that the panel experts saw only a modest role for ERP in improving future supply chain effectiveness and a clear risk of ERP actually limiting progress in supply chain management.,result,3
6674,ERP was seen as offering a positive contribution to only four of the top 12 future supply chain issues: (1) more customization of products and services; (2) more standardized processes and information; (3) the need for worldwide IT systems; and (4) greater transparency of the marketplace.,method,2
6675,Implications for subsequent research and management practice are discussed.,background,0
6676,"The following key limitations of current ERP systems in providing effective SCM support emerge as the third finding from this exploratory study: (1) their insufficient extended enterprise functionality in crossing organizational boundaries; (2) their inflexibility to ever-changing supply chain needs, (3) their lack of functionality beyond managing transactions, and (4) their closed and non-modular system architecture.",result,3
6677,These limitations stem from the fact that the first generation of ERP products has been designed to integrate the various operations of an individual firm.,background,0
6678,"In modern supply chain management, however, the unit of analysis has become a network of organizations, rendering these ERP products inadequate in the new economy.",background,0
6679,"Since the rst shape-from-shading (SFS) technique was developed by Horn in the early 1970s, many di erent approaches have emerged.",background,0
6680,"In this paper, six well-known SFS algorithms are implemented and compared.",objective,1
6681,"The performance of the algorithms was analyzed on synthetic images using mean and standard deviation of depth (Z) error, mean of surface gradient (p, q) error and CPU timing.",method,2
6682,"Each algorithm works well for certain images, but performs poorly for others.",method,2
6683,"In general, minimization approaches are more robust, while the other approaches are faster.",result,3
6684,"The implementation of these algorithms in C, and images used in this paper, are available by anonymous ftp under the pub=tech paper=survey directory at eustis:cs:ucf:edu (132.170.108.42).",result,3
6685,These are also part of the electronic version of paper.,result,3
6686,0957-4174/$ see front matter 2011 Elsevier Ltd. A doi:10.1016/j.eswa.2011.09.058 ⇑ Tel.,background,0
6687,: +1 905 606 1175; fax: +1 905 286 4756.,other,4
6688,E-mail address: leo.guelman@rbc.com Gradient Boosting (GB) is an iterative algorithm that combines simple parameterized functions with ‘‘poor’’ performance (high prediction error) to produce a highly accurate prediction rule.,background,0
6689,"In contrast to other statistical learning methods usually providing comparable accuracy (e.g., neural networks and support vector machines), GB gives interpretable results, while requiring little data preprocessing and tuning of the parameters.",background,0
6690,"The method is highly robust to less than clean data and can be applied to classification or regression problems from a variety of response distributions (Gaussian, Bernoulli, Poisson, and Laplace).",other,4
6691,"Complex interactions are modeled simply, missing values in the predictors are managed almost without loss of information, and feature selection is performed as an integral part of the procedure.",objective,1
6692,These properties make GB a good candidate for insurance loss cost modeling.,other,4
6693,"However, to the best of our knowledge, the application of this method to insurance pricing has not been fully documented to date.",method,2
6694,This paper presents the theory of GB and its application to the problem of predicting auto ‘‘at-fault’’ accident loss cost using data from a major Canadian insurer.,method,2
6695,The predictive accuracy of the model is compared against the conventional Generalized Linear Model (GLM) approach.,result,3
6696,"Over one billion people live in the world’s 200,000 slums and informal settlements.",background,0
6697,"We used data generated from mobile phones to better understand one of the largest slums, Kibera located in Nairobi, Kenya.",result,3
6698,"Using call logs from June 2008 June 2009 and theories from human geography, economics, sociology, journalists, and anthropologists as a basis, we tested the validity of a few prominent theories.",method,2
6699,"In particular, we focused our research on migration patterns out of Kibera, inferring places of work, and tribal affiliations.",result,3
6700,Graph is an important data representation which appears in a wide diversity of real-world scenarios.,background,0
6701,"Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc.",background,0
6702,"However, most graph analytics methods suffer the high computation and space cost.",background,0
6703,Graph embedding is an effective yet efficient way to solve the graph analytics problem.,background,0
6704,It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved.,method,2
6705,"In this survey, we conduct a comprehensive review of the literature in graph embedding.",result,3
6706,We first introduce the formal definition of graph embedding as well as the related concepts.,result,3
6707,"After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work addresses these challenges in their solutions.",method,2
6708,"Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques, and application scenarios.",result,3
6709,An Automated Teller Machine (ATM) is a safety-critical and real-time system that is highly complicated in design and implementation.,background,0
6710,"This paper presents the formal design, specification, and modeling of the ATM system using a denotational mathematics known as Real-Time Process Algebra (RTPA).",objective,1
6711,The conceptual model of the ATM system is introduced as the initial requirements for the system.,method,2
6712,"The architectural model of the ATM system is created using RTPA architectural modeling methodologies and refined by a set of Unified Data Models (UDMs), which share a generic mathematical model of tuples.",method,2
6713,The static behaviors of the ATM system are specified and refined by a set of Unified Process Models (UPMs) for the ATM transition processing and system supporting processes.,method,2
6714,"The dynamic behaviors of the ATM system are specified and refined by process priority allocation, process deployment, and process dispatch models.",result,3
6715,"Based on the formal design models of the ATM system, code can be automatically generated using the RTPA Code Generator (RTPA-CG), or be seamlessly transformed into programs by programmers.",method,2
6716,"The formal models of ATM may not only serve as a formal design paradigm of realtime software systems, but also a test bench for the expressive power and modeling capability of exiting formal methods in software engineering.",method,2
6717,Data warehousing systems enable enterprise managers to acquire and integrate information from heterogeneous sources and to query very large databases efficiently.,background,0
6718,Building a data warehouse requires adopting design and implementation techniques completely different from those underlying information systems.,background,0
6719,"In this paper we present a graphical conceptual model for data warehouses, called Dimensional Fact model, and propose a semi-automated methodology to build it from the pre-existing Entity/Relationship schemes describing a database.",background,0
6720,"Our conceptual model consists of tree-structured fact schemes whose basic elements are facts, attributes, dimensions and hierarchies; other features which may be represented on fact schemes are the additivity of fact attributes along dimensions, the optionality of dimension attributes and the existence of non-dimension attributes.",method,2
6721,Compatible fact schemes may be overlapped in order to relate and compare data.,method,2
6722,"Fact schemes may be integrated with information of the conjectured workload, expressed in terms of query patterns, to be used as the input of a design phase whose output are the logical and physical schemes of the data warehouse.",result,3
6723,"A variety of simple graphical filters are available to camera phone users to enhance their photos on the fly; these filters often stylize, saturate or age a photo.",background,0
6724,"In this paper, we present a combination of large-scale data analysis and small scale in-depth interviews to understand filter-work.",background,0
6725,We look at producers’ practices of photo filtering and gain insights in the roles filters play in engaging photo consumers’ by driving their social interactions.,objective,1
6726,We first interviewed 15 Flickr mobile app users (photo producers) to understand their use and perception of filters.,method,2
6727,"Next, we analyzed how filters affect a photo’s engagement (consumers’ perspective) using a corpus of 7.6 million Flickr photos.",method,2
6728,We find two groups of serious and casual photographers among filter users.,method,2
6729,The serious see filters as correction tools and prefer milder effects.,result,3
6730,"Casual photographers, by contrast, use filters to significantly transform their photos with bolder effects.",result,3
6731,We also find that filtered photos are 21% more likely to be viewed and 45% more likely to be commented on by consumers of photographs.,result,3
6732,"Specifically, filters that increase warmth, exposure and contrast boost engagement the most.",result,3
6733,This paper proposes a person tracking framework using a scanning low-resolution thermal infrared (IR) sensor colocated with a wide-angle RGB camera.,objective,1
6734,The low temporal and spatial resolution of the low-cost IR sensor make it unable to track moving people and prone to false detections of stationary people.,method,2
6735,"Thus, IR-only tracking using only this sensor would be quite problematic.",method,2
6736,"We demonstrate that despite the limited capabilities of this low-cost IR sensor, it can be used effectively to correct the errors of a real-time RGB camera-based tracker.",method,2
6737,"We align the signals from the two sensors both spatially (by computing a pixel-to-pixel geometric correspondence between the two modalities) and temporally (by modeling the temporal dynamics of the scanning IR sensor), which enables multi-modal improvements based on judicious application of elementary reasoning.",method,2
6738,"Our combined RGB+IR system improves upon the RGB camera-only tracking by: rejecting false positives, improving segmentation of tracked objects, and correcting false negatives (starting new tracks for people that were missed by the camera-only tracker).",method,2
6739,"Since we combine RGB and thermal information at the level of RGB camera-based tracks, our method is not limited to the particular camera-based tracker that we used in our experiments.",method,2
6740,Our method could improve the results of any tracker that uses RGB camera input alone.,method,2
6741,We collect a new dataset and demonstrate the superiority of our method over RGB camera-only tracking.,result,3
6742,The debate about online privacy gives testimony of Web users’ concerns.,background,0
6743,"Privacy concerns make consumers adopt data protection features, guide their appreciation for existing features, and can steer their consumption choices amongst competing businesses.",background,0
6744,"However, approaches to measure privacy concern are fragmented and often ad-hoc, at the detriment of reliable results.",background,0
6745,The need for measurement instruments for privacy concern is twofold.,background,0
6746,"First, attitudes and opinions about data protection cannot be established and compared without reliable mechanisms.",method,2
6747,"Second, behavioural studies, notably in technology acceptance and the behavioural economics of privacy require measures for concern as a moderating factor.",method,2
6748,"In its first part, this paper provides a comprehensive review of existing survey instruments for measuring privacy concerns.",result,3
6749,The second part focuses on revealed preferences that can be used for opportunistically measuring privacy concerns in the wild or for scale validation.,result,3
6750,Recommendations for scale selection and reuse are provided.,result,3
6751,"Most word embedding models typically represent each word using a single vector, which makes these models indiscriminative for ubiquitous homonymy and polysemy.",background,0
6752,"In order to enhance discriminativeness, we employ latent topic models to assign topics for each word in the text corpus, and learn topical word embeddings (TWE) based on both words and their topics.",objective,1
6753,"In this way, contextual word embeddings can be flexibly obtained to measure contextual word similarity.",method,2
6754,"We can also build document representations, which are more expressive than some widely-used document models such as latent topic models.",method,2
6755,"In the experiments, we evaluate the TWE models on two tasks, contextual word similarity and text classification.",method,2
6756,"The experimental results show that our models outperform typical word embedding models including the multi-prototype version on contextual word similarity, and also exceed latent topic models and other representative document models on text classification.",result,3
6757,The source code of this paper can be obtained from https://github.com/largelymfs/ topical word embeddings.,result,3
6758,"The article addresses the well-known Capacitated Vehicle Routing Problem (CVRP), in the special case where the demand of a customer consists of a certain number of two-dimensional weighted items.",background,0
6759,"The problem calls for the minimization of the cost of transportation needed for the delivery of the goods demanded by the customers, and carried out by a fleet of vehicles based at a central depot.",background,0
6760,"In order to accommodate all items on the vehicles, a feasibility check of the two-dimensional packing (2L) must be executed on each vehicle.",background,0
6761,"The overall problem, denoted as 2L-CVRP, is NP-hard and particularly difficult to solve in practice.",method,2
6762,"We propose a Tabu Search algorithm, in which the loading component of the problem is solved through heuristics, lower bounds and a truncated branch-and-bound procedure.",method,2
6763,The effectiveness of the algorithm is demonstrated through extensive computational experiments.,result,3
6764,Currently there are many practical tools or theoretical methods to plan and dimension GSM or UMTS radio networks but overlooks the algorithms for core networks because of its complexity.,background,0
6765,"This paper introduces an algorithm for traffic and throughput dimensioning for Nb, Mc and Nc interfaces in UMTS core network.",objective,1
6766,The analysis is based on the traffic and throughput generated or absorbed in the interfaces of network entities in UMTS network.,method,2
6767,This paper is targeted at helping wireless carriers plan and dimensioning their UMTS core networks.,objective,1
6768,We present a library that provides optimized implementations for deep learning primitives.,background,0
6769,"Deep learning workloads are computationally intensive, and optimizing the kernels of deep learning workloads is difficult and time-consuming.",background,0
6770,"As parallel architectures evolve, kernels must be reoptimized for new processors, which makes maintaining codebases difficult over time.",background,0
6771,Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS) [2].,background,0
6772,"However, there is no analogous library for deep learning.",other,4
6773,"Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge.",background,0
6774,"To address this problem, we have created a library similar in intent to BLAS, with optimized routines for deep learning workloads.",objective,1
6775,"Our implementation contains routines for GPUs, and similarly to the BLAS library, could be implemented for other platforms.",method,2
6776,"The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage.",method,2
6777,"For example, integrating cuDNN into Caffe, a popular framework for convolutional networks, improves performance by 36% on a standard model while also reducing memory consumption.",result,3
6778,Market basket analysis (also known as association-rule mining) is a useful method of discovering customer purchasing patterns by extracting associations or co-occurrences from stores’ transactional databases.,background,0
6779,"Because the information obtained from the analysis can be used in forming marketing, sales, service, and operation strategies, it has drawn increased research interest.",background,0
6780,"The existing methods, however, may fail to discover important purchasing patterns in a multi-store environment, because of an implicit assumption that products under consideration are on shelf all the time across all stores.",background,0
6781,"In this paper, we propose a new method to overcome this weakness.",method,2
6782,"Our empirical evaluation shows that the proposed method is computationally efficient, and that it has advantage over the traditional method when stores are diverse in size, product mix changes rapidly over time, and larger numbers of stores and periods are considered.",result,3
6783,D 2004 Elsevier B.V. All rights reserved.,other,4
6784,OBJECTIVES To provide an overview and tutorial of natural language processing (NLP) and modern NLP-system design.,objective,1
6785,TARGET AUDIENCE,objective,1
6786,This tutorial targets the medical informatics generalist who has limited acquaintance with the principles behind NLP and/or limited knowledge of the current state of the art.,method,2
6787,"SCOPE We describe the historical evolution of NLP, and summarize common NLP sub-problems in this extensive field.",method,2
6788,We then provide a synopsis of selected highlights of medical NLP efforts.,method,2
6789,"After providing a brief description of common machine-learning approaches that are being used for diverse NLP sub-problems, we discuss how modern NLP architectures are designed, with a summary of the Apache Foundation's Unstructured Information Management Architecture.",result,3
6790,"We finally consider possible future directions for NLP, and reflect on the possible impact of IBM Watson on the medical field.",result,3
6791,Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s.,background,0
6792,"However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012.",background,0
6793,"In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems.",objective,1
6794,"Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications.",method,2
6795,We also introduce some of their current trends and remaining challenges.,method,2
6796,"Deep learning has allowed a paradigm shift in pattern recognition, from using hand-crafted features together with statistical classifiers to using general-purpose learning procedures for learning data-driven representations, features, and classifiers together.",background,0
6797,"The application of this new paradigm has been particularly successful in computer vision, in which the development of deep learning methods for vision applications has become a hot research topic.",method,2
6798,"Given that deep learning has already attracted the attention of the robot vision community, the main purpose of this survey is to address the use of deep learning in robot vision.",objective,1
6799,"To achieve this, a comprehensive overview of deep learning and its usage in computer vision is given, that includes a description of the most frequently used neural models and their main application areas.",method,2
6800,"Then, the standard methodology and tools used for designing deep-learning based vision systems are presented.",method,2
6801,"Afterwards, a review of the principal work using deep learning in robot vision is presented, as well as current and future trends related to the use of deep learning in robotics.",method,2
6802,This survey is intended to be a guide for the developers of robot vision systems.,result,3
6803,"The grocery industry evolved from mom-and-pop stores to mega-markets to online grocery buying, with many different forms along the way.",background,0
6804,The global market for groceries in 2000 is over $2 trillion.,background,0
6805,"The online grocery segment of the market is expected to reach $34 billion by 2002, a thirty-three fold increase from 1998.",background,0
6806,"This tutorial examines the issues surrounding online groceries and looks closely at fourteen examples from the Americas, Europe, and Australia.",method,2
6807,"The online market is currently one of growth, not profits.",method,2
6808,"Two key components of profitability for online vendors are the ability to generate sufficient volume, while keeping delivery costs low.",result,3
6809,The Internet also impacts business-tobusiness relations among grocers.,result,3
6810,"This tutorial describes key online grocery firms including Peapod, NetGrocer, Streamline, WebVan, Ruok@Net, Albert Heijn, Disco, Ykköshalli, Shoplink, Coles and Woolworths.",result,3
6811,"Each of these companies represents different business models, with differing organizational structure and scope of operations.",result,3
6812,Each has its own set of strengths and,result,3
6813,Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data.,background,0
6814,"In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data.",background,0
6815,RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator.,method,2
6816,"In the case of RCGANs, both of these RNNs are conditioned on auxiliary information.",background,0
6817,"We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series.",objective,1
6818,"We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa.",method,2
6819,"We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data.",method,2
6820,"This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit.",result,3
6821,"We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.",result,3
6822,"Recently, the quality and the diversity of transport services are more and more required.",background,0
6823,"Moreover, in case of a great deal of services and selling goods, a significant part of price is transport cost.",background,0
6824,"Thus, the design of models and applications which make possible efficient transport planning and scheduling becomes important.",background,0
6825,"A great deal of real transport problems may be modelled by using Pickup and Delivery Problem with Time Windows (PDPTW) and capacity constraints, which is based on the realization of a set of transport requests by a fleet of vehicles with given capacities.",method,2
6826,"Each request is described by pickup and delivery locations, time periods when pickup and delivery operations should be performed and needed load.",method,2
6827,"Application of evolutionary approach has brought good results in case of another, simpler transport problem – the Vehicle Routing Problem with Time Windows (VRPTW).",result,3
6828,This paper is aimed at proposing a straightforward extension of VRPTW based heuristics for the PDPTW.,objective,1
6829,This research surveys the current state-of-the-art technologies that are instrumental in the adoption and development of fake news detection.,objective,1
6830,"“Fake news detection” is defined as the task of categorizing news along a continuum of veracity, with an associated measure of certainty.",background,0
6831,Veracity is compromised by the occurrence of intentional deceptions.,objective,1
6832,"The nature of online news publication has changed, such that traditional fact checking and vetting from potential deception is impossible against the flood arising from content generators, as well as various formats and genres.",objective,1
6833,"The paper provides a typology of several varieties of veracity assessment methods emerging from two major categories – linguistic cue approaches (with machine learning), and network analysis approaches.",objective,1
6834,"We see promise in an innovative hybrid approach that combines linguistic cue and machine learning, with network-based behavioral data.",method,2
6835,"Although designing a fake news detector is not a straightforward problem, we propose operational guidelines for a feasible fake news detecting system.",result,3
6836,Nearest-neighbor collaborative filtering provides a successful means of generating recommendations for web users.,background,0
6837,"However, this approach suffers from several shortcomings, including data sparsity and noise, the cold-start problem, and scalability.",background,0
6838,"In this work, we present a novel method for recommending items to users based on expert opinions.",method,2
6839,"Our method is a variation of traditional collaborative filtering: rather than applying a nearest neighbor algorithm to the user-rating data, predictions are computed using a set of expert neighbors from an independent dataset, whose opinions are weighted according to their similarity to the user.",method,2
6840,"This method promises to address some of the weaknesses in traditional collaborative filtering, while maintaining comparable accuracy.",method,2
6841,We validate our approach by predicting a subset of the Netflix data set.,method,2
6842,"We use ratings crawled from a web portal of expert reviews, measuring results both in terms of prediction accuracy and recommendation list precision.",method,2
6843,"Finally, we explore the ability of our method to generate useful recommendations, by reporting the results of a user-study where users prefer the recommendations generated by our approach.",result,3
6844,The Java™ programming language contains built-in synchronization primitives for use in constructing multithreaded programs.,background,0
6845,Efficient implementation of these synchronization primitives is necessary in order to achieve high performance.,background,0
6846,"Recent research [9, 12, 10, 3, 7] has focused on the run-time elimination of the atomic operations required to implement object monitor synchronization primitives.",background,0
6847,This paper describes a novel technique called store-free biased locking which eliminates all synchronization-related atomic operations on uncontended object monitors.,background,0
6848,"The technique supports the bulk transfer of object ownership from one thread to another, and the selective disabling of the optimization where unprofitable, using epoch-based bulk rebiasing and revocation.",method,2
6849,It has been implemented in the production version of the Java HotSpot™VM and has yielded significant performance improvements on a range of benchmarks and applications.,method,2
6850,The technique is applicable to any virtual machine-based programming language implementation with mostly block-structured locking primitives.,method,2
6851,"In this paper, we train a semantic parser that scales up to Freebase.",background,0
6852,"Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs.",background,0
6853,The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question.,objective,1
6854,"We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus.",method,2
6855,"Second, we use a bridging operation to generate additional predicates based on neighboring predicates.",method,2
6856,"On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser.",result,3
6857,"Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.",result,3
6858,Preserving details in restoring images highly corrupted by impulse noise remains a challenging problem.,background,0
6859,We proposed an algorithm based on radial basis functions (RBF) interpolation which estimates the intensities of corrupted pixels by their neighbors.,method,2
6860,"In this algorithm, first intensity values of noisy pixels in the corrupted image are estimated using RBFs.",method,2
6861,"Next, the image is smoothed.",method,2
6862,The proposed algorithm can effectively remove the highly dense impulse noise.,method,2
6863,Experimental results show the superiority of the proposed algorithm in comparison to the recent similar methods both in noise suppression and detail preservation.,result,3
6864,"Extensive simulations show better results in measure of peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM), especially when the image is corrupted by very highly dense impulse noise.",result,3
6865,"The cloud computing exhibits, remarkable potential to provide cost effective, easy to manage, elastic, and powerful resources on the fly, over the Internet.",background,0
6866,"The cloud computing, upsurges the capabilities of the hardware resources by optimal and shared utilization.",background,0
6867,The above mentioned features encourage the organizations and individual users to shift their applications and services to the cloud.,background,0
6868,"Even the critical infrastructure, for example, power generation and distribution plants are being migrated to the cloud computing paradigm.",background,0
6869,"However, the services provided by third-party cloud service providers entail additional security threats.",background,0
6870,"The migration of user’s assets (data, applications, etc.) outside the administrative control in a shared environment where numerous users are collocated escalates the security concerns.",background,0
6871,This survey details the security issues that arise due to the very nature of cloud computing.,objective,1
6872,"Moreover, the survey presents the recent solutions presented in the literature to counter the security issues.",method,2
6873,"Furthermore, a brief view of security vulnerabilities in the mobile cloud computing are also highlighted.",result,3
6874,"In the end, the discussion on the open issues and future research directions is also presented.",result,3
6875,Data management workloads are increasingly write-intensive and subject to strict latency SLAs.,background,0
6876,This presents a dilemma: Update in place systems have unmatched latency but poor write throughput.,background,0
6877,"In contrast, existing log structured techniques improve write throughput but sacrifice read performance and exhibit unacceptable latency spikes.",background,0
6878,"We begin by presenting a new performance metric: read fanout, and argue that, with read and write amplification, it better characterizes real-world indexes than approaches such as asymptotic analysis and price/performance.",method,2
6879,"We then present bLSM, a Log Structured Merge (LSM) tree with the advantages of B-Trees and log structured approaches: (1) Unlike existing log structured trees, bLSM has near-optimal read and scan performance, and (2) its new ""spring and gear"" merge scheduler bounds write latency without impacting throughput or allowing merges to block writes for extended periods of time.",background,0
6880,It does this by ensuring merges at each level of the tree make steady progress without resorting to techniques that degrade read performance.,method,2
6881,"We use Bloom filters to improve index performance, and find a number of subtleties arise.",method,2
6882,"First, we ensure reads can stop after finding one version of a record.",method,2
6883,"Otherwise, frequently written items would incur multiple B-Tree lookups.",result,3
6884,"Second, many applications check for existing values at insert.",method,2
6885,Recurrent neural networks (RNN) are a widely used tool for the prediction of time series.,background,0
6886,In this paper we use the dynamic behaviour of the RNN to categorize input sequences into different specified classes.,method,2
6887,These two tasks do not seem to have much in common.,background,0
6888,"However, the prediction task strongly supports the development of a suitable internal structure, representing the main features of the input sequence, to solve the classification problem.",method,2
6889,"Therefore, the speed and success of the training as well as the generalization ability of the trained RNN are significantly improved.",result,3
6890,The trained RNN provides good classification performance and enables the user to assess efficiently the degree of reliability of the classification result.,result,3
6891,"Recently, with the obvious increasing number of cardiovascular disease, the automatic classification research of Electrocardiogram signals (ECG) has been playing a significantly important part in the clinical diagnosis of cardiovascular disease.",background,0
6892,"In this paper, a 1D convolution neural network (CNN) based method is proposed to classify ECG signals.",method,2
6893,"The proposed CNN model consists of five layers in addition to the input layer and the output layer, i.e., two convolution layers, two down sampling layers and one full connection layer, extracting the effective features from the original data and classifying the features automatically.",method,2
6894,"This model realizes the classification of 5 typical kinds of arrhythmia signals, i.e., normal, left bundle branch block, right bundle branch block, atrial premature contraction and ventricular premature contraction.",method,2
6895,"The experimental results on the public MIT-BIH arrhythmia database show that the proposed method achieves a promising classification accuracy of 97.5%, significantly outperforming several typical ECG classification methods.",result,3
6896,"As Cloud Computing becomes prevalent, more and more sensitive information are being centralized into the cloud.",background,0
6897,"For the protection of data privacy, sensitive data usually have to be encrypted before outsourcing, which makes effective data utilization a very challenging task.",background,0
6898,"Although traditional searchable encryption schemes allow a user to securely search over encrypted data through keywords and selectively retrieve files of interest, these techniques support only exact keyword search.",background,0
6899,"That is, there is no tolerance of minor typos and format inconsistencies which, on the other hand, are typical user searching behavior and happen very frequently.",objective,1
6900,"This significant drawback makes existing techniques unsuitable in Cloud Computing as it greatly affects system usability, rendering user searching experiences very frustrating and system efficacy very low.",objective,1
6901,"In this paper, for the first time we formalize and solve the problem of effective fuzzy keyword search over encrypted cloud data while maintaining keyword privacy.",background,0
6902,"Fuzzy keyword search greatly enhances system usability by returning the matching files when users' searching inputs exactly match the predefined keywords or the closest possible matching files based on keyword similarity semantics, when exact match fails.",method,2
6903,"In our solution, we exploit edit distance to quantify keywords similarity and develop an advanced technique on constructing fuzzy keyword sets, which greatly reduces the storage and representation overheads.",method,2
6904,"Through rigorous security analysis, we show that our proposed solution is secure and privacy-preserving, while correctly realizing the goal of fuzzy keyword search.",result,3
6905,In this paper we present a design framework to analyze person-product interaction.,background,0
6906,Its focus is on how the user's action and the product's function are coupled through different types of feedback and feedforward: inherent and augmented information.,background,0
6907,"Instead of using the notion of 'coupling' in an abstract sense, our framework tries to give six practical characteristics for coupling action and information, i.e., time, location, direction, dynamics, modality and expression.",method,2
6908,Unifying action and information on each of these aspects makes the interaction intuitive.,method,2
6909,The framework invites and challenges designers to explore couplings leading towards embodied freedom of interaction.,method,2
6910,"Deep convolutional neural networks have recently achieved state-of-the-art performance on a number of image recognition benchmarks, including the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC-2012).",background,0
6911,The winning model on the localization sub-task was a network that predicts a single bounding box and a confidence score for each object category in the image.,background,0
6912,Such a model captures the whole-image context around the objects but cannot handle multiple instances of the same object in the image without naively replicating the number of outputs for each instance.,background,0
6913,"In this work, we propose a saliency-inspired neural network model for detection, which predicts a set of class-agnostic bounding boxes along with a single score for each box, corresponding to its likelihood of containing any object of interest.",method,2
6914,The model naturally handles a variable number of instances for each class and allows for cross-class generalization at the highest levels of the network.,method,2
6915,"We are able to obtain competitive recognition performance on VOC2007 and ILSVRC2012, while using only the top few predicted locations in each image and a small number of neural network evaluations.",result,3
6916,This paper describes a novel strategy to enhance underwater videos and images.,background,0
6917,"Built on the fusion principles, our strategy derives the inputs and the weight measures only from the degraded version of the image.",objective,1
6918,"In order to overcome the limitations of the underwater medium we define two inputs that represent color corrected and contrast enhanced versions of the original underwater image/frame, but also four weight maps that aim to increase the visibility of the distant objects degraded due to the medium scattering and absorption.",objective,1
6919,Our strategy is a single image approach that does not require specialized hardware or knowledge about the underwater conditions or scene structure.,method,2
6920,Our fusion framework also supports temporal coherence between adjacent frames by performing an effective edge preserving noise reduction strategy.,method,2
6921,"The enhanced images and videos are characterized by reduced noise level, better exposed-ness of the dark regions, improved global contrast while the finest details and edges are enhanced significantly.",method,2
6922,"In addition, the utility of our enhancing technique is proved for several challenging applications.",result,3
6923,Cyber situational awareness is attracting much attention.,background,0
6924,"It features prominently in the national cyber strategies of many countries, and there is a considerable body of research dealing with it.",background,0
6925,"However, until now, there has been no systematic and up-to-date review of the scientific literature on cyber situational awareness.",background,0
6926,"This article presents a review of cyber situational awareness, based on systematic queries in four leading scientific databases.",objective,1
6927,"102 articles were read, clustered, and are succinctly described in the paper.",method,2
6928,"The findings are discussed from the perspective of both national cyber strategies and science, and some directions for future research are examined.",result,3
6929,Ensemble analysis is a widely used meta-algorithm for many data mining problems such as classification and clustering.,background,0
6930,Numerous ensemble-based algorithms have been proposed in the literature for these problems.,background,0
6931,"Compared to the clustering and classification problems, ensemble analysis has been studied in a limited way in the outlier detection literature.",background,0
6932,"In some cases, ensemble analysis techniques have been implicitly used by many outlier analysis algorithms, but the approach is often buried deep into the algorithm and not formally recognized as a general-purpose meta-algorithm.",background,0
6933,This is in spite of the fact that this problem is rather important in the context of outlier analysis.,result,3
6934,This paper discusses the various methods which are used in the literature for outlier ensembles and the general principles by which such analysis can be made more effective.,objective,1
6935,A discussion is also provided on how outlier ensembles relate to the ensemble-techniques used commonly for other data mining problems.,result,3
6936,"The User Requirements Notation (URN), standardized by the International Telecommunication Union in 2008, is used to model and analyze requirements with goals and scenarios.",background,0
6937,"This paper describes the first ten years of development of URN, and discusses ongoing efforts targeting the next ten years.",background,0
6938,"We did a study inspired by the systematic literature review approach, querying five major search engines and using the existing URN Virtual Library.",method,2
6939,"Based on the 281 scientific publications related to URN we collected and analyzed, we observe a shift from a more conventional use of URN for telecommunications and reactive systems to business process management and aspect-oriented modeling, with relevant extensions to the language being proposed.",result,3
6940,"URN also benefits from a global and active research community, although industrial contributions are still sparse.",result,3
6941,URN is now a leading language for goal-driven and scenario-oriented modeling with a promising future for many application domains.,result,3
6942,"The mobile phone landscape changed last year with the introduction of smart phones running Android, a platform marketed by Google.",background,0
6943,Android phones are the first credible threat to the iPhone market.,background,0
6944,"Not only did Google target the same consumers as iPhone, it also aimed to win the hearts and minds of mobile application developers.",objective,1
6945,"On the basis of market share and the number of available apps, Android is a success.",result,3
6946,"With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading.",background,0
6947,Intelligence comes from data.,background,0
6948,Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing.,background,0
6949,"Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing.",objective,1
6950,"In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance.",method,2
6951,"On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives.",method,2
6952,"Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed.",result,3
6953,Single-Gaussian and Gaussian-Mixture Models are utilized in various pattern recognition tasks.,background,0
6954,The model parameters are estimated usually via Maximum Likelihood Estimation (MLE) with respect to available training data.,background,0
6955,"However, if only small amount of training data is available, the resulting model will not generalize well.",background,0
6956,"Loosely speaking, classification performance given an unseen test set may be poor.",background,0
6957,"In this paper, we propose a novel estimation technique of the model variances.",objective,1
6958,"Once the variances were estimated using MLE, they are multiplied by a scaling factor, which reflects the amount of uncertainty present in the limited sample set.",method,2
6959,The optimal value of the scaling factor is based on the Kullback-Leibler criterion and on the assumption that the training and test sets are sampled from the same source distribution.,method,2
6960,"In addition, in the case of GMM, the proper number of components can be determined.",result,3
6961,Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact.,background,0
6962,Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object.,objective,1
6963,"In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench.",method,2
6964,"To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches.",method,2
6965,"We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels.",method,2
6966,We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify robust suction targets in point clouds containing a single object.,result,3
6967,We evaluate the resulting system in 350 physical trials on an ABB YuMi fitted with a pneumatic suction gripper.,result,3
6968,"When evaluated on novel objects that we categorize as Basic (prismatic or cylindrical), Typical (more complex geometry), and Adversarial (with few available suction-grasp points) Dex-Net 3.0 achieves success rates of 98%, 82%, and 58% respectively, improving to 81% in the latter case when the training set includes only adversarial objects.",result,3
6969,"Code, datasets, and supplemental material can be found at http://berkeleyautomation.github.io/dex-net.",other,4
6970,"Speech comprehension includes both bottom-up and top-down processes, and imaging studies have isolated a frontal-temporal network of brain areas active during speech perception.",background,0
6971,"However, the precise role of the various areas in this network during normal speech comprehension is not yet fully understood.",background,0
6972,"In the present fMRI study, the signal-to-noise ratio (SNR) of spoken sentences was varied in 144 steps, and speech intelligibility was measured independently in order to study in detail its effect on the activation of brain areas involved in speech perception.",objective,1
6973,"Relative to noise alone, intelligible speech in noise evoked spatially extended activation in left frontal, bilateral temporal, and medial occipital brain regions.",method,2
6974,Increasing SNR led to a sigmoid-shaped increase of activation in all areas of the frontal-temporal network.,method,2
6975,"The onset of the activation with respect to SNR was similar in temporal and frontal regions, but frontal activation was found to be smaller than temporal activation at the highest SNRs.",method,2
6976,"Finally, only Broca's area (BA44) showed activation to unintelligible speech presented at low SNRs.",result,3
6977,"These findings demonstrate distinct roles of frontal and temporal areas in speech comprehension in that temporal regions subserve bottom-up processing of speech, whereas frontal areas are more involved in top-down supplementary mechanisms.",result,3
6978,"Rank structures provide an opportunity to develop new efficient numerical methods for practical problems, when the off-diagonal blocks of certain dense intermediate matrices have small (numerical) ranks.",background,0
6979,"In this work, we present a framework of structured direct factorizations for general sparse matrices, including discretized PDEs on general meshes, based on the multifrontal method and hierarchically semiseparable (HSS) matrices.",objective,1
6980,We prove the idea of replacing certain complex structured operations by fast simple ones performed on compact reduced matrix forms.,method,2
6981,"Such forms result from the hierarchical factorization of a tree-structured HSS matrix in a ULV-type scheme, so that the tree structure is reduced into a single node, the root of the original tree.",objective,1
6982,This idea is shown to be very useful in the partial ULV factorization of an HSS matrix (for quickly computing Schur complements) as well as the solution stage.,method,2
6983,"These techniques are then built into the multifrontal method for sparse factorizations after nested dissection, so as to convert the intermediate dense factorizations into fast structured ones.",method,2
6984,"This method keeps certain Schur complements dense so as to avoid complicated data assembly, and is much simpler and more general than some existing methods.",method,2
6985,"In particular, if the matrix arises from the discretization of certain PDEs, the factorization costs roughly O(n) flops in two dimensions, and roughly O(n4/3) flops or less in three dimensions.",method,2
6986,The solution cost and memory are nearly O(n) in both cases.,result,3
6987,"These counts are obtained with an idea of rank relaxation, so that this method is more generally applicable to problems where the intermediate off-diagonal ranks are not small.",method,2
6988,"Object detector with region proposal networks such as Fast/Faster R-CNN [1, 2] have shown the state-of-the art performance on several benchmarks.",background,0
6989,"However, they have limited success for detecting small objects.",background,0
6990,We argue the limitation is related to insufficient performance of Fast R-CNN block in Faster R-CNN.,background,0
6991,"In this paper, we propose a refining block for Fast R-CNN.",method,2
6992,We further merge the block and Faster R-CNN into a single network (RF-RCNN).,method,2
6993,The RF-RCNN was applied on plate and human detection in RoadView image that consists of high resolution street images (over 30M pixels).,method,2
6994,"As a result, the RF-RCNN showed great improvement over the Faster-RCNN.",result,3
6995,Predicting the results of football matches poses an interesting challenge due to the fact that the sport is so popular and widespread.,background,0
6996,"However, predicting the outcomes is also a difficult problem because of the number of factors which must be taken into account that cannot be quantitatively valued or modeled.",background,0
6997,"As part of this work, a software solution has been developed in order to try and solve this problem.",method,2
6998,"During the development of the system, a number of tests have been carried out in order to determine the optimal combination of features and classifiers.",method,2
6999,The results of the presented system show a satisfactory capability of prediction which is superior to the one of the reference method (most likely a priori outcome).,result,3
7000,Null hypothesis statistical significance tests (NHST) are widely used in quantitative research in the empirical sciences including scientometrics.,background,0
7001,"Nevertheless, since their introduction nearly a century ago significance tests have been controversial.",background,0
7002,Many researchers are not aware of the numerous criticisms raised against NHST.,background,0
7003,"As practiced, NHST has been characterized as a ‘null ritual’ that is overused and too often misapplied and misinterpreted.",background,0
7004,"NHST is in fact a patchwork of two fundamentally different classical statistical testing models, often blended with some wishful quasi-Bayesian interpretations.",method,2
7005,This is undoubtedly a major reason why NHST is very often misunderstood.,background,0
7006,But NHST also has intrinsic logical problems and the epistemic range of the information provided by such tests is much more limited than most researchers recognize.,method,2
7007,"In this article we introduce to the scientometric community the theoretical origins of NHST, which is mostly absent from standard statistical textbooks, and we discuss some of the most prevalent problems relating to the practice of NHST and trace these problems back to the mix-up of the two different theoretical origins.",method,2
7008,"Finally, we illustrate some of the misunderstandings with examples from the scientometric literature and bring forward some modest recommendations for a more sound practice in quantitative data analysis.",result,3
7009,Hyperspectral imaging is a widely used technique in remote sensing in which an imaging spectrometer collects hundreds of images (at different wavelength channels) for the same area on the surface of the earth.,background,0
7010,"In the last two decades, several methods (unsupervised, supervised, and semisupervised) have been proposed to deal with the hyperspectral image classification problem.",background,0
7011,"Supervised techniques have been generally more popular, despite the fact that it is difficult to collect labeled samples in real scenarios.",background,0
7012,"In particular, deep neural networks, such as convolutional neural networks (CNNs), have recently shown a great potential to yield high performance in the hyperspectral image classification.",background,0
7013,"However, these techniques require sufficient labeled samples in order to perform properly and generalize well.",background,0
7014,"Obtaining labeled data is expensive and time consuming, and the high dimensionality of hyperspectral data makes it difficult to design classifiers based on limited samples (for instance, CNNs overfit quickly with small training sets).",background,0
7015,Active learning (AL) can deal with this problem by training the model with a small set of labeled samples that is reinforced by the acquisition of new unlabeled samples.,background,0
7016,"In this paper, we develop a new AL-guided classification model that exploits both the spectral information and the spatial-contextual information in the hyperspectral data.",method,2
7017,The proposed model makes use of recently developed Bayesian CNNs.,background,0
7018,Our newly developed technique provides robust classification results when compared with other state-of-the-art techniques for hyperspectral image classification.,result,3
7019,"In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions.",background,0
7020,"VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent.",objective,1
7021,"VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits [1, 2], faces [1, 3, 4], house numbers [5, 6], CIFAR images [6], physical models of scenes [4], segmentation [7], and predicting the future from static images [8].",method,2
7022,"This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior.",method,2
7023,No prior knowledge of variational Bayesian methods is assumed.,result,3
7024,"In this paper we investigate the performance of different types of rectified activation functions in convolutional neural network: standard rectified linear unit (ReLU), leaky rectified linear unit (Leaky ReLU), parametric rectified linear unit (PReLU) and a new randomized leaky rectified linear units (RReLU).",objective,1
7025,We evaluate these activation function on standard image classification task.,background,0
7026,Our experiments suggest that incorporating a nonzero slope for negative part in rectified activation units could consistently improve the results.,result,3
7027,Thus our findings are negative on the common belief that sparsity is the key of good performance in ReLU.,result,3
7028,"Moreover, on small scale dataset, using deterministic negative slope or learning it are both prone to overfitting.",result,3
7029,They are not as effective as using their randomized counterpart.,result,3
7030,"By using RReLU, we achieved 75.68% accuracy on CIFAR-100 test set without multiple test or ensemble.",method,2
7031,Haptic interaction is an increasingly common form of interaction in virtual environment (VE) simulations.,background,0
7032,This medium introduces some new challenges.,background,0
7033,In this paper we study the problem arising from the difference between the sampling rate requirements of haptic interfaces and the significantly lower update rates of the physical models being manipulated.,objective,1
7034,We propose a multirate simulation approach which uses a local linear approximation.,method,2
7035,The treatment includes a detailed analysis and experimental verification of the approach.,method,2
7036,The proposed method is also shown to improve the stability of the haptic interaction.,method,2
7037,Our objective with this study is to compare three distinct periods of CPR development.,objective,1
7038,We contrast the original concerns regarding computer/information systems personnel from the early days of computing with emergent concerns reflecting the accumulation of evolution of both computing technology and IS management in the subsequent years.,method,2
7039,"In order to accomplish our goal, we review the proceedings of the Computer Personnel Research (CPR) group analyzing the very first proceedings (1962), the next five proceedings (1964 to 1969), and the most recent five proceedings (2006 to 2011).",method,2
7040,Our intention is to present and analyze a broad picture of trends illustrating them with vignettes from practice and observations derived from particular studies.,objective,1
7041,"Finally, we identify and comment on the array of themes and topics that the CPR conferences have addressed in the most recent five years.",result,3
7042,In this paper we consider a class of optimal control problems that have continuous-time nonlinear dynamics and nonconvex control constraints.,background,0
7043,"We propose a convex relaxation of the nonconvex control constraints, and prove that the optimal solution to the relaxed problem is the globally optimal solution to the original problem with nonconvex control constraints.",objective,1
7044,This lossless convexification enables a computationally simpler problem to be solved instead of the original problem.,method,2
7045,We demonstrate the approach in simulation with a planetary soft landing problem involving a nonlinear gravity field.,result,3
7046,"The widespread use of Internet of Things (IoT), especially smart wearables, will play an important role in improving the quality of medical care, bringing convenience for patients and improving the management level of hospitals.",background,0
7047,"However, due to the limitation of communication protocols, there exists non unified architecture that can connect all intelligent things in smart hospitals, which is made possible by the emergence of the Narrowband IoT (NB-IoT).",background,0
7048,"In light of this, we propose an architecture to connect intelligent things in smart hospitals based on NB-IoT, and introduce edge computing to deal with the requirement of latency in medical process.",objective,1
7049,"As a case study, we develop an infusion monitoring system to monitor the real-time drop rate and the volume of remaining drug during the intravenous infusion.",method,2
7050,"Finally, we discuss the challenges and future directions for building a smart hospital by connecting intelligent things.",result,3
7051,"Microprocessors and their applications course is considered as a significant core course for electrical engineering students due to its potential impact into several real life applications such as complex calculations, interfacing, control and automation technology.",background,0
7052,"In this paper, we propose an eight bit scientific calculator based Intel 8086 assembly language programming.",method,2
7053,The calculator were designed over the virtual machine for Intel 8086 microprocessor using EMU8086 emulator software.,method,2
7054,Several arithmetic and logic operations as well as trigonometric functions were implemented in this paper.,method,2
7055,"Also, a plot function and integration of function tools are to be implemented and added as a separate modules for this design.",method,2
7056,"This work was very beneficial in enhancing the student' skills in mathematics, engineering and computer programming which can be employed in designing a useful applications for users as well as the ability to apply numerical techniques and programming algorithms to design a small microprocessor-based system.",result,3
7057,© 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of [name organizer],result,3
7058,"In this paper, we describe Whirlpool, which is a block-cipher-based secure hash function.",background,0
7059,Whirlpool produces a hash code of 512 bits for an input message of maximum length less than 2 bits.,objective,1
7060,"The underlying block cipher, based on the Advanced Encryption Standard (AES), takes a 512-bit key and operates on 512-bit blocks of plaintext.",objective,1
7061,"Whirlpool has been endorsed by NESSIE (New European Schemes for Signatures, Integrity, and Encryption), which is a European Union-sponsored effort to put forward a portfolio of strong cryptographic primitives of various types.",objective,1
7062,"As a side effect of increasingly popular social media, cyberbullying has emerged as a serious problem afflicting children, adolescents and young adults.",background,0
7063,"Machine learning techniques make automatic detection of bullying messages in social media possible, and this could help to construct a healthy and safe social media environment.",background,0
7064,"In this meaningful research area, one critical issue is robust and discriminative numerical representation learning of text messages.",background,0
7065,"In this paper, we propose a new representation learning method to tackle this problem.",method,2
7066,Our method named semantic-enhanced marginalized denoising auto-encoder (smSDA) is developed via semantic extension of the popular deep learning model stacked denoising autoencoder (SDA).,method,2
7067,"The semantic extension consists of semantic dropout noise and sparsity constraints, where the semantic dropout noise is designed based on domain knowledge and the word embedding technique.",method,2
7068,Our proposed method is able to exploit the hidden feature structure of bullying information and learn a robust and discriminative representation of text.,method,2
7069,"Comprehensive experiments on two public cyberbullying corpora ( Twitter and MySpace) are conducted, and the results show that our proposed approaches outperform other baseline text representation learning methods.",result,3
7070,The boxplot is a very popular graphical tool for visualizing the distribution of continuous unimodal data.,background,0
7071,"It shows information about the location, spread, skewness as well as the tails of the data.",background,0
7072,"However, when the data are skewed, usually many points exceed the whiskers and are often erroneously declared as outliers.",background,0
7073,An adjustment of the boxplot is presented that includes a robust measure of skewness in the determination of the whiskers.,objective,1
7074,This results in a more accurate representation of the data and of possible outliers.,result,3
7075,"Consequently, this adjusted boxplot can also be used as a fast and automatic outlier detection tool without making any parametric assumption about the distribution of the bulk of the data.",result,3
7076,Several examples and simulation results show the advantages of this new procedure.,result,3
7077,c © 2007 Elsevier B.V.,other,4
7079,We propose a simple method for improving the security of hashed passwords: the maintenance of additional ``honeywords'' (false passwords) associated with each user's account.,background,0
7080,An adversary who steals a file of hashed passwords and inverts the hash function cannot tell if he has found the password or a honeyword.,background,0
7081,The attempted use of a honeyword for login sets off an alarm.,method,2
7082,"An auxiliary server (the ``honeychecker'') can distinguish the user password from honeywords for the login routine, and will set off an alarm if a honeyword is submitted.",method,2
7083,"Under direction of medical professionals associated with the National Child Traumatic Stress Network, a mobile game was developed for children ages 10-12 to teach the Cognitive Triangle concept of feelings, thoughts, and behaviors.",objective,1
7084,This triangle is an essential component of Trauma-Focused Cognitive Behavioral Therapy (TF-CBT).,background,0
7085,"A storybook experience with minigames was quickly prototyped, but first playtests showed a lack of engagement with children.",result,3
7086,The game was revised to emphasize side-scroller platform advancement where success in a level was tied intrinsically to cognitive triangle classification.,result,3
7087,Children rated the game highly across a series of playtests.,result,3
7088,The game has potential to be used by clinicians delivering TF-CBT as an appealing exercise for children.,method,2
7089,SWOT analysis is an established method for assisting the formulation of strategy.,background,0
7090,An application to strategy formulation and its incorporation into the strategic development process at the University of Warwick is described.,method,2
7091,"The application links SWOT analysis to resource-based planning, illustrates it as an iterative rather than a linear process and embeds it within the overall planning process.",method,2
7092,Lessons are drawn both for the University and for the strategy formulation process itself.,method,2
7093,2003 Elsevier B.V. All rights reserved.,other,4
7094,We introduce UCF101 which is currently the largest dataset of human actions.,background,0
7095,"It consists of 101 action classes, over 13k clips and 27 hours of video data.",background,0
7096,The database consists of realistic user-uploaded videos containing camera motion and cluttered background.,result,3
7097,"Additionally, we provide baseline action recognition results on this new dataset using standard bag of words approach with overall performance of 43.9%.",result,3
7098,"To the best of our knowledge, UCF101 is currently the most challenging dataset of actions due to its large number of classes, large number of clips and also unconstrained nature of such clips.",result,3
7099,"This paper presents a highly efficient, very accurate regression approach for face alignment.",background,0
7100,"Our approach has two novel components: a set of local binary features, and a locality principle for learning those features.",objective,1
7101,The locality principle guides us to learn a set of highly discriminative local binary features for each facial landmark independently.,objective,1
7102,The obtained local binary features are used to jointly learn a linear regression for the final output.,objective,1
7103,Our approach achieves the state-of-the-art results when tested on the current most challenging benchmarks.,objective,1
7104,"Furthermore, because extracting and regressing local binary features is computationally very cheap, our system is much faster than previous methods.",method,2
7105,"It achieves over 3, 000 fps on a desktop or 300 fps on a mobile phone for locating a few dozens of landmarks.",result,3
7106,Modern economic theory ignores the influence of emotions on decision-making.,background,0
7107,"Emerging science evidence suggests that sound and rational decision making, in fact, depends on prior emotional processing.",background,0
7108,The somatic marker hypothesis provides a systems-level neuroanatom cognitive framework for decision-making and its influence by emotion.,background,0
7109,"The key idea of this hyp sis is that decision-making is a process that is influenced by marker signals that arise in bioreg processes, including those that express themselves in emotions and feelings.",background,0
7110,"This influence cur at multiple levels of operation, some of which occur consciously, and some of which non-consciously.",background,0
7111,"Here we review studies that confirm various predictions from the hypothes propose a neural model for economic decision, in which emotions are a major factor in the in tion between environmental conditions and human decision processes, with these emotional providing valuable implicit or explicit knowledge for making fast and advantageous decisions.",method,2
7112, 2004 Elsevier Inc. All rights reserved.,other,4
7113,Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people.,background,0
7114,"Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects.",background,0
7115,"Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways.",background,0
7116,We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it.,background,0
7117,"Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations.",method,2
7118,We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.,method,2
7119,☆ Editor's Choice Articles are invited and handled by Editorial Board committee.,other,4
7120,This paper has been reco Philippos Mordohai.,other,4
7121,"☆☆ This work was carried out while both authors Group, Toshiba Cambridge Research Laboratory, Cambri The research was fully funded by Toshiba Research Eur ⁎ Corresponding author.",method,2
7123,: +44 7900023260.,other,4
7124,E-mail addresses: g.vogiatzis@aston.ac.uk (G. Vogiat carloshernandez@google.com (C. Hernández).,other,4
7125,Social media based brand communities are communities initiated on the platform of social media.,background,0
7126,"In this article, we explore whether brand communities based on social media (a special type of online brand communities) have positive effects on the main community elements and value creation practices in the communities as well as on brand trust and brand loyalty.",objective,1
7127,A survey based empirical study with 441 respondents was conducted.,method,2
7128,"The results of structural equation modeling show that brand communities established on social media have positive effects on community markers (i.e., shared consciousness, shared rituals and traditions, and obligations to society), which have positive effects on value creation practices (i.e., social networking, community engagement, impressions management, and brand use).",result,3
7129,Such communities could enhance brand loyalty through brand use and impression management practices.,result,3
7130,We show that brand trust has a full mediating role in converting value creation practices into brand loyalty.,result,3
7131,Implications for practice and future research opportunities are discussed.,result,3
7132,The contemporary idea for interaction has embraced new understandings of the content of experience and the structure of space.,background,0
7133,New electronic technologies and advanced digital media have separated realities from the realm of the body and transformed experiences into ubiquitous events.,background,0
7134,"The architectural discourse, once largely a discourse of form and style, has overcome these limitations and encountered, in territories of information, the product of a new way of thinking.",background,0
7135,"Marcos Novak emerges in this context of multimedia as an innovative creator whose ""liquid architectures"" represent a break with the traditional discourse of physicality.",background,0
7136,"His creations are meant for a virtual domain, and information is what structures this new territory for architectural practice.",method,2
7137,"With respect to Novak's structures, the approaches to virtual spaces posited by scholars of new media culture over the past few decades, either through phenomenological aspects of the bodily existence and modes of experience or through the poststructural metaphoric manifestation of codes and symbols, do not suffice.",method,2
7138,"While Novak's work does embrace both philosophies, it also transcends them by crossbreeding the reality of the individual with the virtuality of the structure.",background,0
7139,"Indeed, his architectures require a new concept of space to come forward, where the manifestation of the mind in the realm of the body calls for what is to be perceived as real.",background,0
7140,"Architecture is now characterized by the fusion of information, art, and technology",background,0
7141,"We propose Prototypical Networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class.",objective,1
7142,Prototypical Networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class.,background,0
7143,"Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results.",background,0
7144,We provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning.,method,2
7145,We further extend Prototypical Networks to zero-shot learning and achieve state-ofthe-art results on the CU-Birds dataset.,result,3
7146,Owning a SOC is an important status symbol for many organizations.,background,0
7147,"Although the concept of a 'SOC' can be considered a hype, only a few of them are actually effective in counteracting cybercrime and IT abuse.",background,0
7148,A literature review reveals that there is no standard framework available and no clear scope or vision on SOCs.,background,0
7149,"In most of the papers, specific implementations are described, although often with a commercial purpose.",background,0
7150,"Our research was focused on identifying and defining the generic building blocks for a SOC, to draft a design framework.",objective,1
7151,"In addition, a measurement method has been developed to assess the effectiveness of the protection provided by a SOC.",method,2
7152,"The performance of existing image dehazing methods is limited by hand-designed features, such as the dark channel, color disparity and maximum contrast, with complex fusion schemes.",background,0
7153,"In this paper, we propose a multi-scale deep neural network for single-image dehazing by learning the mapping between hazy images and their corresponding transmission maps.",background,0
7154,"The proposed algorithm consists of a coarse-scale net which predicts a holistic transmission map based on the entire image, and a fine-scale net which refines results locally.",method,2
7155,"To train the multiscale deep network, we synthesize a dataset comprised of hazy images and corresponding transmission maps based on the NYU Depth dataset.",result,3
7156,Extensive experiments demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods on both synthetic and real-world images in terms of quality and speed.,result,3
7157,This paper considers the question of using a nonlinear complementary filter for attitude estimation of fixed-wing unmanned aerial vehicle (UAV) given only measurements from a low-cost inertial measurement unit.,objective,1
7158,A nonlinear complementary filter is proposed that combines accelerometer output for low frequency attitude estimation with integrated gyrometer output for high frequency estimation.,method,2
7159,"The raw accelerometer output includes a component corresponding to airframe acceleration, occurring primarily when the aircraft turns, as well as the gravitational acceleration that is required for the filter.",method,2
7160,"The airframe acceleration is estimated using a simple centripetal force model (based on additional airspeed measurements), augmented by a first order dynamic model for angle-of-attack, and used to obtain estimates of the gravitational direction independent of the airplane manoeuvres.",method,2
7161,Experimental results are provided on a real-world data set and the performance of the filter is evaluated against the output from a full GPS/INS that was available for the data set.,result,3
7162,Recurrent neural networks (RNNs) stand at the forefront of many recent developments in deep learning.,background,0
7163,"Yet a major difficulty with these models is their tendency to overfit, with dropout shown to fail when applied to recurrent layers.",background,0
7164,Recent results at the intersection of Bayesian modelling and deep learning offer a Bayesian interpretation of common deep learning techniques such as dropout.,background,0
7165,"This grounding of dropout in approximate Bayesian inference suggests an extension of the theoretical results, offering insights into the use of dropout with RNN models.",method,2
7166,"We apply this new variational inference based dropout technique in LSTM and GRU models, assessing it on language modelling and sentiment analysis tasks.",method,2
7167,"The new approach outperforms existing techniques, and to the best of our knowledge improves on the single model state-of-the-art in language modelling with the Penn Treebank (73.4 test perplexity).",result,3
7168,This extends our arsenal of variational tools in deep learning.,result,3
7169,"Due to the Web expansion, the prediction of online news popularity is becoming a trendy research topic.",background,0
7170,"In this paper, we propose a novel and proactive Intelligent Decision Support System (IDSS) that analyzes articles prior to their publication.",objective,1
7171,"Using a broad set of extracted features (e.g., keywords, digital media content, earlier popularity of news referenced in the article) the IDSS first predicts if an article will become popular.",method,2
7172,"Then, it optimizes a subset of the articles features that can more easily be changed by authors, searching for an enhancement of the predicted popularity probability.",method,2
7173,"Using a large and recently collected dataset, with 39,000 articles from the Mashable website, we performed a robust rolling windows evaluation of five state of the art models.",result,3
7174,The best result was provided by a Random Forest with a discrimination power of 73%.,result,3
7175,"Moreover, several stochastic hill climbing local searches were explored.",result,3
7176,"When optimizing 1000 articles, the best optimization method obtained a mean gain improvement of 15 percentage points in terms of the estimated popularity probability.",result,3
7177,These results attest the proposed IDSS as a valuable tool for online news authors.,result,3
7178,"A wide range of research areas, from telemanipulation in robotics to limb regeneration in tissue engineering, could benefit from an anthropomorphic robotic hand that mimics the salient features of the human hand.",background,0
7179,The challenges of designing such a robotic hand are mainly resulted from our limited understanding of the human hand from engineering point of view and our ability to replicate the important biomechanical features with conventional mechanical design.,background,0
7180,We believe that the biomechanics of human hand is an essential component of the hand dexterity and can be replicated with highly biomimetic design.,background,0
7181,"To this end, we reinterpret the important biomechanical advantages of the human hand from roboticist's perspective and design a biomimetic robotic hand that closely mimics its human counterpart with artificial joint capsules, crocheted ligaments and tendons, laser-cut extensor hood, and elastic pulley mechanisms.",objective,1
7182,We experimentally identify the workspaces of the fingertips and successfully demonstrate that our proofof- concept design can be teleoperated to grasp and manipulate daily objects with a variety of natural hand postures based on hand taxonomy.,background,0
7183,"In this paper, we prove the complexity bounds for methods of Convex Optimization based only on computation of the function value.",method,2
7184,The search directions of our schemes are normally distributed random Gaussian vectors.,method,2
7185,"It appears that such methods usually need at most n times more iterations than the standard gradient methods, where n is the dimension of the space of variables.",method,2
7186,This conclusion is true both for nonsmooth and smooth problems.,method,2
7187,"For the later class, we present also an accelerated scheme with the expected rate of convergence O(n/k), where k is the iteration counter.",method,2
7188,"For Stochastic Optimization, we propose a zero-order scheme and justify its expected rate of convergence O(n/k).",method,2
7189,"We give also some bounds for the rate of convergence of the random gradient-free methods to stationary points of nonconvex functions, both for smooth and nonsmooth cases.",result,3
7190,Our theoretical results are supported by preliminary computational experiments.,result,3
7191,Optimisation problems in Healthcare have received considerable attention for more than three decades.,background,0
7192,"More recently, however, with decreasing birth rates in nearly all of the developed countries and increasing average longevity globally, optimisation issues in Healthcare have become noticeably important and attract keen interest from the Operations Research community.",background,0
7193,"Over the years, attention has gradually expanded from resource allocation and strategic planning to include operational issues such as resource scheduling and treatment planning.",background,0
7194,This paper surveys several applications of Operations Research in the domain of Healthcare.,result,3
7195,"In particular, the paper reviews key contributions addressing contemporary optimisation issues in this area.",background,0
7196,"It highlights current research activities, focusing on a variety of optimisation problems as well as solution techniques used for solving the optimisation problems.",background,0
7197,Recommender systems have developed in parallel with the web.,background,0
7198,"They were initially based on demographic, content-based and collaborative filtering.",background,0
7199,"Currently, these systems are incorporating social information.",background,0
7200,"In the future, they will use implicit, local and personal information from the Internet of things.",background,0
7201,"This article provides an overview of recommender systems as well as collaborative filtering methods and algorithms; it also explains their evolution, provides an original classification for these systems, identifies areas of future implementation and develops certain areas selected for past, present or future",result,3
7202,Trilateration is a common operation to find the object location using its distances or range measurements to three other known points or stations.,background,0
7203,"Traditionally, this problem has been solved either by algebraic or numerical methods.",method,2
7204,These methods involve long and complex geometric computations which are usually implemented in software.,method,2
7205,An approach that avoids this complexity is proposed here.,method,2
7206,Simulation results show improvements of the proposed approach in terms of computational cost and implementation simplicity over the conventional methods used.,result,3
7207,"In addition, the proposed approach is based on vector rotations and uses only simple add and shift operations and therefore can be easily implemented in the hardware (or firmware) of the mobile object.",result,3
7209,IT governance is one of the central areas of IS research.,background,0
7210,"This study examines research on Control Objectives for Information and Related Technology (COBIT), a popular governance framework.",background,0
7211,COBIT is a comprehensive IT governance framework that provides guidelines to IT managers in managing and governing enterprise IT.,method,2
7212,This paper compiles and analyses extant research on COBIT.,result,3
7213,"Our findings suggest that researchers have examined COBIT through multiple perspectives and that most papers either concentrate on overall framework development/comparison or certain pockets of interest within COBIT such as security, risk management, systems development, effectiveness and internal control.",result,3
7214,Our survey also indicates that many of the published papers are in the accounting domain.,method,2
7215,COBIT’s scope has increased over the years and now it encompasses many of the mainstream IS related areas.,method,2
7216,"Hence, suggestions for future research in IS with regard to COBIT is also articulated in this study.",result,3
7217,We propose several means for improving the performance and training of neural networks for classification.,background,0
7218,We use crossvalidation as a tool for optimizing network parameters and architecture.,objective,1
7219,We show further that the remaining residual “generalization” error can be reduced by invoking ensembles of similar networks.,objective,1
7220,"Zndex Terms-Crossvalidation, fault tolerant computing, neural networks, N-version programming.",other,4
7221,When is an argument to be called one-sided?,background,0
7222,When is putting forward such an argument fallacious?,other,4
7223,"How can we develop a model for critical discussion, such that a fallaciously one-sided argument corresponds to a violation of a discussion rule?",objective,1
7224,These issues are dealt with within ‘the limits of the dialogue model of argument’ by specifying a type of persuasion dialogue in which an arguer can offer complex arguments to anticipate particular responses by a critic.,objective,1
7225,The large number of potential applications from bridging web data with knowledge bases have led to an increase in the entity linking research.,background,0
7226,Entity linking is the task to link entity mentions in text with their corresponding entities in a knowledge base.,background,0
7227,"Potential applications include information extraction, information retrieval, and knowledge base population.",background,0
7228,"However, this task is challenging due to name variations and entity ambiguity.",background,0
7229,"In this survey, we present a thorough overview and analysis of the main approaches to entity linking, and discuss various applications, the evaluation of entity linking systems, and future directions.",result,3
7230,"A t the 1996 and 1997 International Conferences on Software Engineering, three of the six keynote addresses identified negotiation techniques as the most critical success factor in improving the outcome of software projects.",background,0
7231,"At the USC Center for Software Engineering, we have been developing a negotiationbased approach to software system requirements engineering, architecture, development, and management.",method,2
7232,Our approach has three primary elements:,objective,1
7233,House sales are determined based on the Standard & Poor’s Case-Shiller home price indices and the housing price index of the Office of Federal Housing Enterprise Oversight (OFHEO).,background,0
7234,These reflect the trends of the US housing market.,background,0
7235,"In addition to these housing price indices, the development of a housing price prediction model can greatly assist in the prediction of future housing prices and the establishment of real estate policies.",method,2
7236,This study uses machine learning algorithms as a research methodology to develop a housing price prediction model.,method,2
7237,"To improve the accuracy of housing price prediction, this paper analyzes the housing data of 5359 townhouses in Fairfax County, Virginia, gathered by the Multiple Listing Service (MLS) of the Metropolitan Regional Information Systems (MRIS).",method,2
7238,"We develop a housing price prediction model based on machine learning algorithms such as C4.5, RIPPER, Naïve Bayesian, and AdaBoost and compare their classification accuracy performance.",method,2
7239,We then propose an improved housing price prediction model to assist a house seller or a real estate agent make better informed decisions based on house price valuation.,method,2
7240,"The experiments demonstrate that the RIPPER algorithm, based on accuracy, consistently outperforms the other models in the performance of housing price prediction.",method,2
7241,2014 Elsevier Ltd.,other,4
7243,"Eye tracking technology is becoming easier and cheaper to use, resulting in its increasing application to numerous fields of research.",background,0
7244,The data collected during an eye tracking experiment can be analyzed by statistical methods and/or with visualization techniques.,background,0
7245,"Visualizations can reveal characteristics of fixations, saccades, and scanpath structures.",background,0
7246,"In this survey, we present an overview of visualization techniques for eye tracking data and describe their functionality.",background,0
7247,We classify the visualization techniques using nine categories.,background,0
7248,"The categories are based on properties of eye tracking data, including aspects of the stimuli and the viewer, and on properties of the visualization techniques.",method,2
7249,The classification of about 90 publications including technical as well as application papers with modifications of common visualization techniques are described in more detail.,method,2
7250,We finally present possible directions for further research in the field of eye tracking data visualization.,result,3
7251,"This paper presents carry-lookahead adder (CLA) based design of the contemporary inexact-speculative adder (ISA) which is fine grain pipelined to include few logic gates along its critical path and thereby, enhancing the frequency of operation.",objective,1
7252,"Additionally, various stages of the proposed ISA architecture has been clock gated to reduce the power consumed by this design.",objective,1
7253,Functional verification and hardware implementation for various configurations of the suggested ISA is carried out on field-programmable gate-array (FPGA) platform.,objective,1
7254,It could operate at a maximum clock frequency of 324 MHz which is 52% better then the conventional ISA.,method,2
7255,"Thereafter, the synthesis and post-layout simulation of 32-bit proposed ISA is carried out using 90 nm complementary metal-oxide semiconductors (CMOS) technology node for power and area analysis.",method,2
7256,Our design occupied 5.11 mm2 of chip area and consumed 9.68 mW of total power at 400 MHz clock frequency.,result,3
7257,The proposed ISA burns 52.8% lesser power than the state-of-the-art work.,result,3
7258,This paper features a Spatial Augmented Reality system for rehabilitation of hand and arm movement.,objective,1
7259,"The table-top home-based system tracks a subject's hand and creates a virtual audio-visual interface for performing rehabilitation-related tasks that involve wrist, elbow, and shoulder movements.",objective,1
7260,"It measures range, speed, and smoothness of movements locally and can send the real-time photos and data to the clinic for further assessment.",objective,1
7261,"To evaluate the system, it was tested on two normal subjects and proved functional.",result,3
7262,"We propose a deep Convolutional Neural Network (CNN) for land cover mapping in remote sensing images, with a focus on urban areas.",background,0
7263,"In remote sensing, class imbalance represents often a problem for tasks like land cover mapping, as small objects get less prioritised in an effort to achieve the best overall accuracy.",background,0
7264,"We propose a novel approach to achieve high overall accuracy, while still achieving good accuracy for small objects.",objective,1
7265,"Quantifying the uncertainty on a pixel scale is another challenge in remote sensing, especially when using CNNs.",method,2
7266,In this paper we use recent advances in measuring uncertainty for CNNs and evaluate their quality both qualitatively and quantitatively in a remote sensing context.,method,2
7267,"We demonstrate our ideas on different deep architectures including patch-based and so-called pixel-to-pixel approaches, as well as their combination, by classifying each pixel in a set of aerial images covering Vaihingen, Germany.",method,2
7268,The results show that we obtain an overall classification accuracy of 87%.,result,3
7269,"The corresponding F1- score for the small object class ""car"" is 80.6%, which is higher than state-of-the art for this dataset.",result,3
7270,"In this paper, a model predictive control (MPC) approach for controlling an active front steering system in an autonomous vehicle is presented.",objective,1
7271,"At each time step, a trajectory is assumed to be known over a finite horizon, and an MPC controller computes the front steering angle in order to follow the trajectory on slippery roads at the highest possible entry speed.",background,0
7272,We present two approaches with different computational complexities.,method,2
7273,"In the first approach, we formulate the MPC problem by using a nonlinear vehicle model.",method,2
7274,The second approach is based on successive online linearization of the vehicle model.,method,2
7275,Discussions on computational complexity and performance of the two schemes are presented.,method,2
7276,The effectiveness of the proposed MPC formulation is demonstrated by simulation and experimental tests up to 21 m/s on icy roads,result,3
7277,"Cryptocurrencies, based on and led by Bitcoin, have shown promise as infrastructure for pseudonymous online payments, cheap remittance, trustless digital asset exchange, and smart contracts.",background,0
7278,"However, Bitcoin-derived blockchain protocols have inherent scalability limits that trade-off between throughput and latency and withhold the realization of this potential.",background,0
7279,"This paper presents Bitcoin-NG, a new blockchain protocol designed to scale.",objective,1
7280,"Based on Bitcoin’s blockchain protocol, Bitcoin-NG is Byzantine fault tolerant, is robust to extreme churn, and shares the same trust model obviating qualitative changes to the ecosystem.",method,2
7281,"In addition to Bitcoin-NG, we introduce several novel metrics of interest in quantifying the security and efficiency of Bitcoin-like blockchain protocols.",method,2
7282,"We implement Bitcoin-NG and perform large-scale experiments at 15% the size of the operational Bitcoin system, using unchanged clients of both protocols.",method,2
7283,"These experiments demonstrate that Bitcoin-NG scales optimally, with bandwidth limited only by the capacity of the individual nodes and latency limited only by the propagation time of the network.",result,3
7284,Twitter is among the fastest-growing microblogging and online social networking services.,background,0
7285,Messages posted on Twitter (tweets) have been reporting everything from daily life stories to the latest local and global news and events.,background,0
7286,"Monitoring and analyzing this rich and continuous user-generated content can yield unprecedentedly valuable information, enabling users and organizations to acquire actionable knowledge.",background,0
7287,This article provides a survey of techniques for event detection from Twitter streams.,objective,1
7288,These techniques aim at finding real-world occurrences that unfold over space and time.,method,2
7289,"In contrast to conventional media, event detection from Twitter streams poses new challenges.",method,2
7290,"Twitter streams contain large amounts of meaningless messages and polluted content, which negatively affect the detection performance.",method,2
7291,"In addition, traditional text mining techniques are not suitable, because of the short length of tweets, the large number of spelling and grammatical errors, and the frequent use of informal and mixed language.",method,2
7292,Event detection techniques presented in literature address these issues by adapting techniques from various fields to the uniqueness of Twitter.,method,2
7293,"This article classifies these techniques according to the event type, detection task, and detection method and discusses commonly used features.",method,2
7294,"Data deduplication is one of important data compression techniques for eliminating duplicate copies of repeating data, and has been widely used in cloud storage to reduce the amount of storage space and save bandwidth.",background,0
7295,"To protect the confidentiality of sensitive data while supporting deduplication, the convergent encryption technique has been proposed to encrypt the data before outsourcing.",method,2
7296,"To better protect data security, this paper makes the first attempt to formally address the problem of authorized data deduplication.",method,2
7297,"Different from traditional deduplication systems, the differential privileges of users are further considered in duplicate check besides the data itself.",method,2
7298,We also present several new deduplication constructions supporting authorized duplicate check in a hybrid cloud architecture.,method,2
7299,Security analysis demonstrates that our scheme is secure in terms of the definitions specified in the proposed security model.,result,3
7300,"As a proof of concept, we implement a prototype of our proposed authorized duplicate check scheme and conduct testbed experiments using our prototype.",method,2
7301,We show that our proposed authorized duplicate check scheme incurs minimal overhead compared to normal operations.,result,3
7302,The k-Nearest-Neighbours (kNN) is a simple but effective method for classification.,method,2
7303,"The major drawbacks with respect to kNN are (1) its low efficiency being a lazy learning method prohibits it in many applications such as dynamic web mining for a large repository, and (2) its dependency on the selection of a “good value” for k. In this paper, we propose a novel kNN type method for classification that is aimed at overcoming these shortcomings.",result,3
7304,"Our method constructs a kNN model for the data, which replaces the data to serve as the basis of classification.",method,2
7305,"The value of k is automatically determined, is varied for different data, and is optimal in terms of classification accuracy.",method,2
7306,The construction of the model reduces the dependency on k and makes classification faster.,result,3
7307,Experiments were carried out on some public datasets collected from the UCI machine learning repository in order to test our method.,result,3
7308,"The experimental results show that the kNN based model compares well with C5.0 and kNN in terms of classification accuracy, but is more efficient than the standard kNN.",result,3
7309,"Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains.",objective,1
7310,They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance.,method,2
7311,"However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts.",method,2
7312,"On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss.",background,0
7313,"In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches.",method,2
7314,"We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA).",method,2
7315,"We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",method,2
7316,"Article history: Received 23 September 2009 Accepted 3 September 2010 The purpose of this commentary is to initiate discussion on the status of research on the interface between management control, especially management accounting, and information technology, and on howwe could proceed to understand this relationship and changes in it.",objective,1
7317,"The commentary also points to the need for expanding the sphere of theories and methodologies applied in the accounting information systems field, if we want to explain and understand the complex and mutually constitutive nature of the relationship, especially how new technologies are actually designed and adapted to work in practice.",objective,1
7318,The mainstream tradition tends to largely ignore the design and implementation processes and especially the struggles therein.,background,0
7319,© 2010 Elsevier Inc.,other,4
7321,Object-oriented concepts are crucial in software design because they address fundamental issues of adaptation and evolution.,background,0
7322,"With the proliferation of object-oriented notations and methods, the Unified Modeling Language (UML) has emerged to provide a standardized notation for describing object-oriented models.",background,0
7323,"However, for the UML notation to be effectively applied, it needs to be used with an object-oriented analysis and design method.",background,0
7324,"This tutorial describes the COMET method for designing real-time and distributed applications, which integrates object-oriented and concurrency concepts and uses the UML notation.",method,2
7325,The goal of this study was to examine the mediating role of negative emotions in the link between academic stress and Internet addiction among Korean adolescents.,objective,1
7326,We attempted to extend the general strain theory to Internet addiction by exploring psychological pathways from academic stress to Internet addiction using a national and longitudinal panel study.,objective,1
7327,"A total of 512 adolescents completed self-reported scales for academic stress, negative emotions, and Internet addiction.",method,2
7328,"We found that academic stress was positively associated with negative emotions and Internet addiction, and negative emotions were positively associated with Internet addiction.",result,3
7329,"Further, the results of structural equation modeling revealed that adolescents’ academic stress had indirectly influenced Internet addiction through negative emotions.",result,3
7330,"The results of this study suggest that adolescents who experience academic stress might be at risk for Internet addiction, particularly when accompanied with negative emotions.",result,3
7331,"These findings provided significant implications for counselors and policymakers to prevent adolescents’ Internet addiction, and extended the general strain theory to Internet addiction which is typically applicable to deviant behavior.",result,3
7332,2015 Elsevier Ltd. All rights reserved.,other,4
7333,"Gamification has drawn the attention of academics, practitioners and business professionals in domains as diverse as education, information studies, human–computer interaction, and health.",background,0
7334,"As yet, the term remains mired in diverse meanings and contradictory uses, while the concept faces division on its academic worth, underdeveloped theoretical foundations, and a dearth of standardized guidelines for application.",background,0
7335,"Despite widespread commentary on its merits and shortcomings, little empirical work has sought to validate gamification as a meaningful concept and provide evidence of its effectiveness as a tool for motivating and engaging users in non-entertainment contexts.",background,0
7336,"Moreover, no work to date has surveyed gamification as a field of study from a human–computer studies perspective.",background,0
7337,"In this paper, we present a systematic survey on the use of gamification in published theoretical reviews and research papers involving interactive systems and human participants.",objective,1
7338,"We outline current theoretical understandings of gamification and draw comparisons to related approaches, including alternate reality games (ARGs), games with a purpose (GWAPs), and gameful design.",method,2
7339,"We present a multidisciplinary review of gamification in action, focusing on empirical findings related to purpose and context, design of systems, approaches and techniques, and user impact.",method,2
7340,Findings from the survey show that a standard conceptualization of gamification is emerging against a growing backdrop of empirical participantsbased research.,result,3
7341,"However, definitional subjectivity, diverse or unstated theoretical foundations, incongruities among empirical findings, and inadequate experimental design remain matters of concern.",result,3
7342,We discuss how gamification may to be more usefully presented as a subset of a larger effort to improve the user experience of interactive systems through gameful design.,result,3
7343,Research on financial decision-making shows that traders and investors with high emotion regulation capabilities perform better in trading.,background,0
7344,But how can the others learn to regulate their emotions?,background,0
7345,‘Learning by doing’ sounds like a straightforward approach.,background,0
7346,But how can one perform ‘learning by doing’ when there is no feedback?,background,0
7347,"This problem particularly applies to learning emotion regulation, because learners can get practically no feedback on their level of emotion regulation.",method,2
7348,Our research aims at providing a learning environment that can help decision-makers to improve their emotion regulation.,objective,1
7349,The approach is based on a serious game with real-time biofeedback.,method,2
7350,The game is settled in a financial context and the decision scenario is directly linked to the individual biofeedback of the learner’s heart rate data.,method,2
7351,"More specifically, depending on the learner’s ability to regulate emotions, the decision scenario of the game continuously adjusts and thereby becomes more (or less) difficult.",method,2
7352,The learner wears an electrocardiogram sensor that transfers the data via Bluetooth to the game.,method,2
7353,"Although promising results have been achieved in the areas of traffic-sign detection and classification, few works have provided simultaneous solutions to these two tasks for realistic real world images.",background,0
7354,We make two contributions to this problem.,background,0
7355,"Firstly, we have created a large traffic-sign benchmark from 100000 Tencent Street View panoramas, going beyond previous benchmarks.",method,2
7356,It provides 100000 images containing 30000 traffic-sign instances.,method,2
7357,These images cover large variations in illuminance and weather conditions.,objective,1
7358,"Each traffic-sign in the benchmark is annotated with a class label, its bounding box and pixel mask.",method,2
7359,We call this benchmark Tsinghua-Tencent 100K.,method,2
7360,"Secondly, we demonstrate how a robust end-to-end convolutional neural network (CNN) can simultaneously detect and classify trafficsigns.",result,3
7361,"Most previous CNN image processing solutions target objects that occupy a large proportion of an image, and such networks do not work well for target objects occupying only a small fraction of an image like the traffic-signs here.",result,3
7362,Experimental results show the robustness of our network and its superiority to alternatives.,result,3
7363,Machine learning is a useful technology for decision support systems and assumes greater importance in research and practice.,background,0
7364,"Whilst much of the work focuses technical implementations and the adaption of machine learning algorithms to application domains, the factors of machine learning design affecting the usefulness of decision support are still understudied.",background,0
7365,"To enhance the understanding of machine learning and its use in decision support systems, we report the results of our content analysis of design-oriented research published between 1994 and 2013 in major Information Systems outlets.",objective,1
7366,"The findings suggest that the usefulness of machine learning for supporting decision-makers is dependent on the task, the phase of decision-making, and the applied technologies.",method,2
7367,"We also report about the advantages and limitations of prior research, the applied evaluation methods and implications for future decision support research.",method,2
7368,Our findings suggest that future decision support research should shed more light on organizational and people-related evaluation criteria.,result,3
7369,"The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution.",background,0
7370,"Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant.",background,0
7371,"However, in their existing form, GANs have no means of learning the inverse mapping – projecting data back into the latent space.",objective,1
7372,"We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.",objective,1
7373,Many Natural Language Processing (NLP) techniques have been used in Information Retrieval.,background,0
7374,The results are not encouraging.,background,0
7375,"Simple methods (stopwording, porter-style stemming, etc.) usually yield significant improvements, while higher-level processing (chunking, parsing, word sense disambiguation, etc.)",background,0
7376,only yield very small improvements or even a decrease in accuracy.,method,2
7377,"At the same time, higher-level methods increase the processing and storage cost dramatically.",method,2
7378,This makes them hard to use on large collections.,method,2
7379,"We review NLP techniques and come to the conclusion that (a) NLP needs to be optimized for IR in order to be effective and (b) document retrieval is not an ideal application for NLP, at least given the current state-of-the-art in NLP.",result,3
7380,"Other IR-related tasks, e.g., question answering and information extraction, seem to be better suited.",result,3
7381,"As an envisaged future of transportation, self-driving cars are being discussed from various perspectives, including social, economical, engineering, computer science, design, and ethics.",background,0
7382,"On the one hand, self-driving cars present new engineering problems that are being gradually successfully solved.",background,0
7383,"On the other hand, social and ethical problems are typically being presented in the form of an idealized unsolvable decision-making problem, the so-called trolley problem, which is grossly misleading.",background,0
7384,"We argue that an applied engineering ethical approach for the development of new technology is what is needed; the approach should be applied, meaning that it should focus on the analysis of complex real-world engineering problems.",method,2
7385,"Software plays a crucial role for the control of self-driving cars; therefore, software engineering solutions should seriously handle ethical and social considerations.",method,2
7386,"In this paper we take a closer look at the regulative instruments, standards, design, and implementations of components, systems, and services and we present practical social and ethical challenges that have to be met, as well as novel expectations for software engineering.",result,3
7387,"In this paper, a fast and flexible algorithm for computing watersheds in digital grayscale images is introduced.",background,0
7388,"A review of watersheds and related notion is first presented, and the major methods to determine watersheds are discussed.",background,0
7389,"The present algorithm is based on an immersion process analogy, in which the flooding of the water in the picture is efficiently simulated using a queue of pixels.",method,2
7390,It is described in detail and provided in a pseudo C language.,method,2
7391,We prove the accuracy of this algorithm is superior to that of the existing implementations.,objective,1
7392,"Furthermore, it is shown that its adaptation to any kind of digital grid and its generalization to n-dimensional images and even to graphs are straightforward.",objective,1
7393,"In addition, its strongest point is that it is faster than any other watershed algorithm.",background,0
7394,Applications of this algorithm with regard to picture segmentation are presented for MR imagery and for digital elevation models.,method,2
7395,An example of 3-D watershed is also provided.,method,2
7396,"Lastly, some ideas are given on how to solve complex segmentation tasks using watersheds on graphs.",method,2
7397,"Malicious software, or malware, continues to be a problem for computer users, corporations, and governments.",background,0
7398,"Previous research [1] has explored training file-based, malware classifiers using a two-stage approach.",background,0
7399,"In the first stage, a malware language model is used to learn the feature representation which is then input to a second stage malware classifier.",method,2
7400,"In Pascanu et al. [1], the language model is either a standard recurrent neural network (RNN) or an echo state network (ESN).",method,2
7401,"In this work, we propose several new malware classification architectures which include a long short-term memory (LSTM) language model and a gated recurrent unit (GRU) language model.",method,2
7402,"We also propose using an attention mechanism similar to [12] from the machine translation literature, in addition to temporal max pooling used in [1], as an alternative way to construct the file representation from neural features.",method,2
7403,"Finally, we propose a new single-stage malware classifier based on a character-level convolutional neural network (CNN).",method,2
7404,Results show that the LSTM with temporal max pooling and logistic regression offers a 31.3% improvement in the true positive rate compared to the best system in [1] at a false positive rate of 1%.,result,3
7405,"We propose a new isotropic remeshing method, based on Centroidal Voronoi Tessellation (CVT).",background,0
7406,"Constructing CVT requires to repeatedly compute Restricted Voronoi Diagram (RVD), defined as the intersection between a 3D Voronoi diagram and an input mesh surface.",method,2
7407,Existing methods use some approximations of RVD.,method,2
7408,"In this paper, we introduce an efficient algorithm that computes RVD exactly and robustly.",method,2
7409,"As a consequence, we achieve better remeshing quality than approximation-based approaches, without sacrificing efficiency.",result,3
7410,Our method for RVD computation uses a simple procedure and a kd-tree to quickly identify and compute the intersection of each triangle face with its incident Voronoi cells.,method,2
7411,"Its time complexity is O(m logn), where n is the number of seed points and m is the number of triangles of the input mesh.",method,2
7412,"Fast convergence of CVT is achieved using a quasi-Newton method, which proved much faster than Lloyd’s iteration.",method,2
7413,Examples are presented to demonstrate the better quality of remeshing results with our method than with the state-of-art approaches.,result,3
7414,We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units.,objective,1
7415,"Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs.",method,2
7416,"In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks.",method,2
7417,"These tasks include language modeling, speech recognition, and machine translation.",result,3
7418,Liver cancer is one of the leading causes of cancer death.,background,0
7419,"To assist doctors in hepatocellular carcinoma diagnosis and treatment planning, an accurate and automatic liver and tumor segmentation method is highly demanded in the clinical practice.",background,0
7420,"Recently, fully convolutional neural networks (FCNs), including 2D and 3D FCNs, serve as the back-bone in many volumetric image segmentation.",background,0
7421,"However, 2D convolutions can not fully leverage the spatial information along the third dimension while 3D convolutions suffer from high computational cost and GPU memory consumption.",objective,1
7422,"To address these issues, we propose a novel hybrid densely connected UNet (H-DenseUNet), which consists of a 2D DenseUNet for efficiently extracting intra-slice features and a 3D counterpart for hierarchically aggregating volumetric contexts under the spirit of the auto-context algorithm for liver and tumor segmentation.",objective,1
7423,"We formulate the learning process of H-DenseUNet in an end-to-end manner, where the intra-slice representations and inter-slice features can be jointly optimized through a hybrid feature fusion (HFF) layer.",method,2
7424,We extensively evaluated our method on the dataset of MICCAI 2017 Liver Tumor Segmentation (LiTS) Challenge.,result,3
7425,Our method outperformed other state-of-the-arts on the segmentation results of tumors and achieved very competitive performance for liver segmentation even with a single model.,result,3
7426,Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995.,background,0
7427,"In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems.",background,0
7428,This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants.,objective,1
7429,"In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling.",result,3
7430,"The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework.",method,2
7431,"In total, we summarize the results of 5400 experimental runs ( $\approx 15$ years of CPU time), which makes our study the largest of its kind on LSTM networks.",result,3
7432,"Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components.",result,3
7433,We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.,result,3
7434,Tree boosting is a highly effective and widely used machine learning method.,background,0
7435,"In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges.",background,0
7436,We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning.,method,2
7437,"More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system.",objective,1
7438,"By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.",result,3
7439,"Fog/edge computing has been proposed to be integrated with Internet of Things (IoT) to enable computing services devices deployed at network edge, aiming to improve the user’s experience and resilience of the services in case of failures.",objective,1
7440,"With the advantage of distributed architecture and close to end-users, fog/edge computing can provide faster response and greater quality of service for IoT applications.",objective,1
7441,"Thus, fog/edge computing-based IoT becomes future infrastructure on IoT development.",method,2
7442,"To develop fog/edge computing-based IoT infrastructure, the architecture, enabling techniques, and issues related to IoT should be investigated first, and then the integration of fog/edge computing and IoT should be explored.",method,2
7443,"To this end, this paper conducts a comprehensive overview of IoT with respect to system architecture, enabling technologies, security and privacy issues, and present the integration of fog/edge computing and IoT, and applications.",method,2
7444,"Particularly, this paper first explores the relationship between cyber-physical systems and IoT, both of which play important roles in realizing an intelligent cyber-physical world.",result,3
7445,"Then, existing architectures, enabling technologies, and security and privacy issues in IoT are presented to enhance the understanding of the state of the art IoT development.",result,3
7446,"To investigate the fog/edge computing-based IoT, this paper also investigate the relationship between IoT and fog/edge computing, and discuss issues in fog/edge computing-based IoT. Finally, several applications, including the smart grid, smart transportation, and smart cities, are presented to demonstrate how fog/edge computing-based IoT to be implemented in real-world applications.",result,3
7447,In this paper we apply a heuristic method based on artificial neural networks (NN) in order to trace out the efficient frontier associated to the portfolio selection problem.,method,2
7448,We consider a generalization of the standard Markowitz meanvariance model which includes cardinality and bounding constraints.,method,2
7449,These constraints ensure the investment in a given number of different assets and limit the amount of capital to be invested in each asset.,method,2
7450,We present some experimental results obtained with the NN heuristic and we compare them to those obtained with three previous heuristic methods.,result,3
7451,The portfolio selection problem is an instance from the family of quadratic programming problems when the standard Markowitz mean-variance model is considered.,result,3
7452,"But if this model is generalized to include cardinality and bounding constraints, then the portfolio selection problem becomes a mixed quadratic and integer programming problem.",result,3
7453,"When considering the latter model, there is not any exact algorithm able to solve the portfolio selection problem in an efficient way.",result,3
7454,The use of heuristic algorithms in this case is imperative.,result,3
7455,"In the past some heuristic methods based mainly on evolutionary algorithms, tabu search and simulated annealing have been developed.",result,3
7456,"The purpose of this paper is to consider a particular neural network (NN) model, the Hopfield network, which has been used to solve some other optimisation problems and apply it here to the portfolio selection problem, comparing the new results to those obtained with previous heuristic algorithms.",result,3
7457,Mobile Cloud Computing is a new technology which refers to an infrastructure where both data storage and data processing operate outside of the mobile device.,background,0
7458,Another recent technology is Internet of Things.,background,0
7459,Internet of Things is a new technology which is growing rapidly in the field of telecommunications.,background,0
7460,"More specifically, IoT related with wireless telecommunications.",background,0
7461,The main goal of the interaction and cooperation between things and objects which sent through the wireless networks is to fulfill the objective set to them as a combined entity.,objective,1
7462,"In addition, there is a rapid development of both technologies, Cloud Computing and Internet of Things, regard the field of wireless communications.",background,0
7463,"In this paper, we present a survey of IoT and Cloud Computing with a focus on the security issues of both technologies.",method,2
7464,"Specifically, we combine the two aforementioned technologies (i.e Cloud Computing and IoT) in order to examine the common features, and in order tο discover the benefits of their integration.",method,2
7465,"Concluding, we present the contribution of Cloud Computing to the IoT technology.",method,2
7466,"Thus, it shows how the Cloud Computing technology improves the function of the IoT. Finally, we survey the security challenges of the integration of IoT and Cloud Computing.",result,3
7467,"This is a short introduction to information visualisation, which is increasingly important in many fields as information expands faster than our ability to comprehend it.",background,0
7468,"Visualisation makes data easier to understand through direct sensory experience (usually visual), as opposed to more linguistic/logical reasoning.",background,0
7469,This chapter examines reasons for using information visualisation both for professional data analysts and also end-users.,objective,1
7470,"It will also look at some of the history of visualisation (going back 4,500 years), classic examples of information visualisations, and some current challenges for visualisation research and practice.",method,2
7471,"Design of effective visualisation requires an appreciation of human perceptual, cognitive and also organisational and social factors, and the chapter discusses some of these factors and the design issues and principles arising from them.",method,2
7472,Solving software evaluation problems is a particularly difficult software engineering process and many contradictory criteria must be considered to reach a decision.,background,0
7473,"Nowadays, the way that decision support techniques are applied suffers from a number of severe problems, such as naive interpretation of sophisticated methods and generation of counter-intuitive, and therefore most probably erroneous, results.",method,2
7474,In this paper we identify some common flaws in decision support for software evaluations.,objective,1
7475,"Subsequently, we discuss an integrated solution through which significant improvement may be achieved, based on the Multiple Criteria Decision Aid methodology and the exploitation of packaged software evaluation expertise in the form of an intelligent system.",method,2
7476,Both common mistakes and the way they are overcome are explained through a real world example.,other,4
7477,q 2000 Elsevier Science B.V. All rights reserved.,other,4
7478,"In this paper, drawing intuition from the Turing test, we propose using adversarial training for open-domain dialogue generation: the system is trained to produce sequences that are indistinguishable from human-generated dialogue utterances.",background,0
7479,"We cast the task as a reinforcement learning (RL) problem where we jointly train two systems, a generative model to produce response sequences, and a discriminator—analagous to the human evaluator in the Turing test— to distinguish between the human-generated dialogues and the machine-generated ones.",method,2
7480,"The outputs from the discriminator are then used as rewards for the generative model, pushing the system to generate dialogues that mostly resemble human dialogues.",method,2
7481,"In addition to adversarial training we describe a model for adversarial evaluation that uses success in fooling an adversary as a dialogue evaluation metric, while avoiding a number of potential pitfalls.",result,3
7482,"Experimental results on several metrics, including adversarial evaluation, demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines.",result,3
7483,Telecommunication companies generate a tremendous amount of data.,background,0
7484,"These data include call detail data, which describes the calls that traverse the telecommunication networks, network data, which describes the state of the hardware and software components in the network, and customer data, which describes the telecommunication customers.",background,0
7485,This chapter describes how data mining can be used to uncover useful information buried within these data sets.,method,2
7486,"Several data mining applications are described and together they demonstrate that data mining can be used to identify telecommunication fraud, improve marketing effectiveness, and identify network faults.",method,2
7487,Objective of the current work is to develop an Optical Character Recognition (OCR) engine for information Just In Time (iJIT) system that can be used for recognition of handwritten textual annotations of lower case Roman script.,objective,1
7488,"Tesseract open source OCR engine under Apache License 2.0 is used to develop user-specific handwriting recognition models, viz.",background,0
7489,", the language sets, for the said system, where each user is identified by a unique identification tag associated with the digital pen.",method,2
7490,"To generate the language set for any user, Tesseract is trained with labeled handwritten data samples of isolated and free-flow texts of Roman script, collected exclusively from that user.",method,2
7491,The designed system is tested on five different language sets with freeflow handwritten annotations as test samples.,result,3
7492,"The system could successfully segment and subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80% handwritten characters in the test samples of five different users.",result,3
7493,"This tutorial brings together perspectives on ER from a variety of fields, including databases, machine learning, natural language processing and information retrieval, to provide, in one setting, a survey of a large body of work.",background,0
7494,We discuss both the practical aspects and theoretical underpinnings of ER.,background,0
7495,"We describe existing solutions, current challenges, and open research problems.",result,3
7496,We describe a new physics engine tailored to model-based control.,background,0
7497,Multi-joint dynamics are represented in generalized coordinates and computed via recursive algorithms.,background,0
7498,"Contact responses are computed via efficient new algorithms we have developed, based on the modern velocity-stepping approach which avoids the difficulties with spring-dampers.",background,0
7499,Models are specified using either a high-level C++ API or an intuitive XML file format.,method,2
7500,A built-in compiler transforms the user model into an optimized data structure used for runtime computation.,method,2
7501,The engine can compute both forward and inverse dynamics.,method,2
7502,The latter are well-defined even in the presence of contacts and equality constraints.,result,3
7503,The model can include tendon wrapping as well as actuator activation states (e.g. pneumatic cylinders or muscles).,method,2
7504,"To facilitate optimal control applications and in particular sampling and finite differencing, the dynamics can be evaluated for different states and controls in parallel.",result,3
7505,"Around 400,000 dynamics evaluations per second are possible on a 12-core machine, for a 3D homanoid with 18 dofs and 6 active contacts.",result,3
7506,The notion of a shared mental model is well known in the literature regarding team work among humans.,background,0
7507,It has been used to explain team functioning.,method,2
7508,The idea is that team performance improves if team members have a shared understanding of the task that is to be performed and of the involved team work.,method,2
7509,"We maintain that the notion of shared mental model is not only highly relevant in the context of human teams, but also for teams of agents and for human-agent teams.",method,2
7510,"However, before we can start investigating how to engineer agents on the basis of the notion of shared mental model, we first have to get a better understanding of the notion, which is the aim of this paper.",method,2
7511,"We do this by investigating which concepts are relevant for shared mental models, and modeling how they are related by means of UML.",result,3
7512,"Through this, we obtain a mental model ontology.",result,3
7513,"Then, we formally define the notion of shared mental model and related notions.",result,3
7514,We illustrate our definitions by means of an example.,result,3
7515,"Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device.",background,0
7516,"For example, language models can improve speech recognition and text entry, and image models can automatically select good photos.",background,0
7517,"However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data-center and training there using conventional approaches.",background,0
7519,We term this decentralized approach Federated Learning.,method,2
7520,We present a practical method for the federated learning of deep networks that proves robust to the unbalanced and non-IID data distributions that naturally arise.,method,2
7521,"This method allows high-quality models to be trained in relatively few rounds of communication, the principal constraint for federated learning.",method,2
7522,"The key insight is that despite the non-convex loss functions we optimize, parameter averaging over updates from multiple clients produces surprisingly good results, for example decreasing the communication needed to train an LSTM language model by two orders of magnitude.",result,3
7523,Purpose – Aims to review the key concepts of competency management (CM) and to propose method for developing competency method.,objective,1
7524,Design/methodology/approach – Examines the CM features of 22 CM systems and 18 learning management systems.,method,2
7525,"Findings – Finds that the areas of open standard (XML, web services, RDF), semantic technologies (ontologies and the semantic web) and portals with self-service technologies are going to play a significant part in the evolution of CM systems.",method,2
7526,Originality/value – Emphasizes the beneficial attributes of CM for private and public organizations.,result,3
7527,"In this work, we cast text summarization as a sequence-to-sequence problem and apply the attentional encoder-decoder RNN that has been shown to be successful for Machine Translation (Bahdanau et al. (2014)).",background,0
7528,Our experiments show that the proposed architecture significantly outperforms the state-of-the art model of Rush et al. (2015) on the Gigaword dataset without any additional tuning.,background,0
7529,"We also propose additional extensions to the standard architecture, which we show contribute to further improvement in performance.",objective,1
7530,This paper presents an approach to the description and analysis of complex Man-Machine Systems (MMSs) called Cognitive Systems Engineering (CSE).,objective,1
7531,"In contrast to traditional approaches to the study of man-machine systems which mainly operate on the physical and physiological level, CSE operates on the level of cognitive functions.",method,2
7532,"Instead of viewing an MMS as decomposable by mechanistic principles, CSE introduces the concept of a cognitive system: an adaptive system which functions using knowledge about itself and the environment in the planning and modification of actions.",method,2
7533,Operators are generally acknowledged to use a model of the system (machine) with which they work.,method,2
7534,"Similarly, the machine has an image of the operator.",method,2
7535,"The designer of an MMS must recognize this, and strive to obtain a match between the machine's image and the user characteristics on a cognitive level, rather than just on the level of physical functions.",method,2
7536,"This article gives a presentation of what cognitive systems are, and of how CSE can contribute to the design of an MMS, from cognitive task analysis to final evaluation.",result,3
7537,We present the MULTOVL application suite that detects and statistically analyses multiple overlaps of genomic regions in a fast and efficient manner.,background,0
7538,"The package supports the detection of multiple region intersections, unions and 'solitary' genomic regions.",background,0
7539,The significance of actually observed overlaps is estimated by comparing them with empirical null distributions generated by random shuffling of the input regions.,background,0
7540,An access control model describes at a high level of abstraction a mechanism for governing access to shared resources.,background,0
7541,"In this paper, we view an access control model as a design pattern providing a general solution for ensuring confidentiality, integrity and availability of information resources.",objective,1
7542,"We present three widely used access control models, DAC, MAC and RBAC as design patterns using the POSA template.",method,2
7543,We use an extension of the UML to represent the structure and behavior of the patterns.,method,2
7544,The extension enables capturing variations of pattern instances.,method,2
7545,We also attempt to give more details on the problem domain of the patterns to help pattern selection.,method,2
7546,On-line learning in domains where the target concept depends on some hidden context poses serious problems.,background,0
7547,"A changing context can induce changes in the target concepts, producing what is known as concept drift.",background,0
7548,We describe a family of learning algorithms that flexibly react to concept drift and can take advantage of situations where contexts reappear.,objective,1
7549,The general approach underlying all these algorithms consists of (1) keeping only a window of currently trusted examples and hypotheses; (2) storing concept descriptions and reusing them when a previous context re-appears; and (3) controlling both of these functions by a heuristic that constantly monitors the system's behavior.,method,2
7550,The paper reports on experiments that test the systems' perfomance under various conditions such as different levels of noise and different extent and rate of concept drift.,result,3
7551,"Face recognition presents a challenging problem in the field of image analysis and computer vision, and as such has received a great deal of attention over the last few years because of its many applications in various domains.",background,0
7552,Face recognition techniques can be broadly divided into three categories based on the face data acquisition methodology: methods that operate on intensity images; those that deal with video sequences; and those that require other sensory data such as 3D information or infra-red imagery.,background,0
7553,"In this paper, an overview of some of the well-known methods in each of these categories is provided and some of the benefits and drawbacks of the schemes mentioned therein are examined.",objective,1
7554,"Furthermore, a discussion outlining the incentive for using face recognition, the applications of this technology, and some of the difficulties plaguing current systems with regard to this task has also been provided.",background,0
7555,This paper also mentions some of the most recent algorithms developed for this purpose and attempts to give an idea of the state of the art of face recognition technology.,objective,1
7556,The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging.,background,0
7557,"This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field.",background,0
7558,The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features.,method,2
7559,"We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration.",method,2
7560,"We conclude by discussing research obstacles, emerging trends, and possible future directions.",result,3
7561,"We study, for the first time, automated inference on criminality based solely on still face images.",background,0
7562,"Via supervised machine learning, we build four classifiers (logistic regression, KNN, SVM, CNN) using facial images of 1856 real persons controlled for race, gender, age and facial expressions, nearly half of whom were convicted criminals, for discriminating between criminals and non-criminals.",method,2
7563,"All four classifiers perform consistently well and produce evidence for the validity of automated face-induced inference on criminality, despite the historical controversy surrounding the topic.",background,0
7564,"Also, we find some discriminating structural features for predicting criminality, such as lip curvature, eye inner corner distance, and the so-called nose-mouth angle.",result,3
7565,"Above all, the most important discovery of this research is that criminal and non-criminal face images populate two quite distinctive manifolds.",result,3
7566,The variation among criminal faces is significantly greater than that of the non-criminal faces.,method,2
7567,"The two manifolds consisting of criminal and non-criminal faces appear to be concentric, with the non-criminal manifold lying in the kernel with a smaller span, exhibiting a law of normality for faces of non-criminals.",result,3
7568,"In other words, the faces of general law-biding public have a greater degree of resemblance compared with the faces of criminals, or criminals have a higher degree of dissimilarity in facial appearance than normal people.",result,3
7569,This paper presents the design of a lightweight robot arm intended for safe physical human-robot interaction.,background,0
7570,The robot arm design combines tendon actuation with elasticity in the tendons to achieve a significant reduction in mass and passive compliant behavior.,background,0
7571,"The use of elastic tendons in all joints in order to gain maximum safety and performance properties, however, results in a significant increase of the model complexity with oscillatory behavior and kinematic coupling of the joint equilibrium positions.",method,2
7572,"Therefore, special effort needs to be made to model the robot arm dynamics, which is an essential basis for model-based algorithms utilizing and fully exploiting the particular properties of the robot arm.",method,2
7573,"This paper therefore derives the full dynamics model of the robot arm with focus on the nonlinear elastic tendon actuators, the kinematic tendon coupling, and modeling complexity reduction by reflecting all model parameters to the joint space.",method,2
7574,The resulting model is validated by comparing the identified simulation model with experimental data of an application-related pick-and-place trajectory and a trajectory with undamped oscillating motions of the robot arm.,result,3
7575,Linear algebra algorithms are fundamental to many computing applications.,background,0
7576,Modern GPUs are suited for many general purpose processing tasks and have emerged as inexpensive high performance co-processors due to their tremendous computing power.,background,0
7577,"In this paper, we present the implementation of singular value decomposition (SVD) of a dense matrix on GPU using the CUDA programming model.",method,2
7578,SVD is implemented using the twin steps of bidiagonalization followed by diagonalization.,method,2
7579,It has not been implemented on the GPU before.,method,2
7580,Bidiagonalization is implemented using a series of Householder transformations which map well to BLAS operations.,method,2
7581,Diagonalization is performed by applying the implicitly shifted QR algorithm.,method,2
7582,Our complete SVD implementation outperforms the MATLAB and Intel ®Math Kernel Library (MKL) LAPACK implementation significantly on the CPU.,method,2
7583,We show a speedup of upto 60 over the MATLAB implementation and upto 8 over the Intel MKL implementation on a Intel Dual Core 2.66GHz PC on NVIDIA GTX 280 for large matrices.,result,3
7584,We also give results for very large matrices on NVIDIA Tesla S1070.,result,3
7585,The presence of gender stereotypes in many aspects of society is a well-known phenomenon.,background,0
7586,"In this paper, we focus on studying such stereotypes and bias in Hindi movie industry (Bollywood).",objective,1
7587,We analyze movie plots and posters for all movies released since 1970.,method,2
7588,The gender bias is detected by semantic modeling of plots at inter-sentence and intrasentence level.,method,2
7589,"Different features like occupation, introduction of cast in text, associated actions and descriptions are captured to show the pervasiveness of gender bias and stereotype in movies.",method,2
7590,We derive a semantic graph and compute centrality of each character and observe similar bias there.,method,2
7591,We also show that such bias is not applicable for movie posters where females get equal importance even though their character has little or no impact on the movie plot.,method,2
7592,"Furthermore, we explore the movie trailers to estimate on-screen time for males and females and also study the portrayal of emotions by gender in them.",method,2
7593,The silver lining is that our system was able to identify 30 movies over last 3 years where such stereotypes were broken.,result,3
7594,Herewe propose a real-timemethod for low-drift odometry andmapping using rangemeasurements from a 3D laser scanner moving in 6-DOF.,background,0
7595,"The problem is hard because the range measurements are received at different times, and errors in motion estimation (especially without an external reference such asGPS) causemis-registration of the resulting point cloud.",background,0
7596,"To date, coherent 3D maps have been built by off-line batch methods, often using loop closure to correct for drift over time.",background,0
7597,Our method achieves both low-drift in motion estimation and low-computational complexity.,method,2
7598,"The key idea that makes this level of performance possible is the division of the complex problem of Simultaneous Localization andMapping, which seeks to optimize a large number of variables simultaneously, into two algorithms.",method,2
7599,One algorithm performs odometry at a high-frequency but at low fidelity to estimate velocity of the laser scanner.,result,3
7600,"Although not necessary, if an IMU is available, it can provide a motion prior and mitigate for gross, high-frequency motion.",method,2
7601,A second algorithm runs at an order of magnitude lower frequency for fine matching and registration of the point cloud.,result,3
7602,Combination of the two algorithms allows map creation in real-time.,result,3
7603,Our method has been evaluated by indoor and outdoor experiments as well as the KITTI odometry benchmark.,result,3
7604,Streaming music services represent the music industry’s greatest prospective source of revenue and are well established among consumers.,background,0
7605,This paper presents a theory of a streaming music business model consisting of two types of services provided by a monopolist.,background,0
7606,"The first service, which offers access free of charge, is of low quality and financed by advertising.",method,2
7607,The second service charges its users and is of high quality.,method,2
7608,"The analysis demonstrates that if users are highly tolerant of commercials, the monopolist benefits from advertising funding and hence charges a high price to users of the fee-based service to boost demand for the advertising supported service.",result,3
7609,The analysis addresses the welfare consequences of such a business model and shows it is an effective policy for combating digital piracy.,result,3
7610,2013 Elsevier B.V. All rights reserved.,other,4
7611,"In this paper, we present an algorithm to estimate a signal from its modified short-time Fourier transform (STFT).",method,2
7612,This algorithm is computationally simple and is obtained by minimizing the mean squared error between the STFT of the estimated signal and the modified STFT.,method,2
7613,"Using this algorithm, we also develop an iterative algorithm to estimate a signal from its modified STFT magnitude.",method,2
7614,"The iterative algorithm is shown to decrease, in each iteration, the mean squared error between the STFT magnitude of the estimated signal and the modified STFT magnitude.",result,3
7615,"The major computation involved in the iterative algorithm is the discrete Fourier transform (DFT) computation, and the algorithm appears to be real-time implementable with current hardware technology.",background,0
7616,The algorithm developed in this paper has been applied to the time-scale modification of speech.,background,0
7617,"The resulting system generates very high-quality speech, and appears to be better in performancc than any existing method.",result,3
7618,Behavioral economics tells us that emotions can profoundly affect individual behavior and decision-making.,background,0
7619,"Does this also apply to societies at large, i.e. can societies experience mood states that affect their collective decision making?",background,0
7620,By extension is the public mood correlated or even predictive of economic indicators?,background,0
7621,Here we investigate whether measurements of collective mood states derived from large-scale Twitter feeds are correlated to the value of the Dow Jones Industrial Average (DJIA) over time.,objective,1
7622,"We analyze the text content of daily Twitter feeds by two mood tracking tools, namely OpinionFinder that measures positive vs. negative mood and Google-Profile of Mood States (GPOMS) that measures mood in terms of 6 dimensions (Calm, Alert, Sure, Vital, Kind, and Happy).",method,2
7623,We cross-validate the resulting mood time series by comparing their ability to detect the public’s response to the presidential election and Thanksgiving day in 2008.,method,2
7624,"A Granger causality analysis and a Self-Organizing Fuzzy Neural Network are then used to investigate the hypothesis that public mood states, as measured by the OpinionFinder and GPOMS mood time series, are predictive of changes in DJIA closing values.",method,2
7625,Our results indicate that the accuracy of DJIA predictions can be significantly improved by the inclusion of specific public mood dimensions but not others.,result,3
7626,We find an accuracy of 87.6% in predicting the daily up and down changes in the closing values of the DJIA and a reduction of the Mean Average Percentage Error by more than 6%.,result,3
7627,Graphical interface use involves schemata operations that range from transfer to induction.,background,0
7628,"The former apply existing knowledge, such as prior schemata, and are effortless, preconscious and intuitive.",background,0
7629,"The latter, which consist in constructing new schemata, are resource-consuming and thus detrimental to intuitive use (IV).",objective,1
7630,A quantitative method is proposed to manipulate and screen schemata operations at the level of an interface's states and features.,method,2
7631,"Relevance for the design cycle of innovative interfaces is critically reviewed, and integration with existing intuitive-use design frameworks is proposed.",method,2
7632,These considerations are built upon instructional design studies suggesting that assessment should precede and inform the application of design techniques geared toward IV.,result,3
7633,We present a new state-of-the-art approach for face detection.,background,0
7634,"The key idea is to combine face alignment with detection, observing that aligned face shapes provide better features for face classification.",objective,1
7635,"To make this combination more effective, our approach learns the two tasks jointly in the same cascade framework, by exploiting recent advances in face alignment.",method,2
7636,Such joint learning greatly enhances the capability of cascade detection and still retains its realtime performance.,method,2
7637,"Extensive experiments show that our approach achieves the best accuracy on challenging datasets, where all existing solutions are either inaccurate or too slow.",result,3
7638,Image forensics has now raised the anxiety of justice as increasing cases of abusing tampered images in newspapers and court for evidence are reported recently.,background,0
7639,"With the goal of verifying image content authenticity, passive-blind image tampering detection is called for.",background,0
7640,More realistic open benchmark databases are also needed to assist the techniques.,background,0
7641,"Recently, we collect a natural color image database with realistic tampering operations.",method,2
7642,The database is made publicly available for researchers to compare and evaluate their proposed tampering detection techniques.,method,2
7643,We call this database CASI-A Image Tampering Detection Evaluation Database.,result,3
7644,"We describe the purpose, the design criterion, the organization and self-evaluation of this database in this paper.",result,3
7645,This edition is a translation of the book formerly published in French in 1995 (Les systèmes multi-agents:,background,0
7646,"Vers une intelligence collective, Inter Editions, Paris.)",background,0
7647,"Even now, it is still the main reference for the French research community in multi-agent systems (MAS).",background,0
7648,The book is intended to be both a state of the art text and an introduction for people who are interested in capturing the main ideas of MAS.,background,0
7649,"It deals mainly with the theoretical background, antecedents and applications.",method,2
7650,I will present a summary of the main ideas and the points that the author highlights as novel features arising from the multi-agent approach to computer science.,objective,1
7651,"When some details are very well developed in the book, I will just refer to them, since they are mainly useful for people who actually want to apply the techniques.",method,2
7652,"Fog Computing extends the Cloud Computing paradigm to the edge of the network, thus enabling a new breed of applications and services.",background,0
7653,"Defining characteristics of the Fog are: a) Low latency and location awareness; b) Wide-spread geographical distribution; c) Mobility; d) Very large number of nodes, e) Predominant role of wireless access, f) Strong presence of streaming and real time applications, g) Heterogeneity.",result,3
7654,"In this paper we argue that the above characteristics make the Fog the appropriate platform for a number of critical Internet of Things (IoT) services and applications, namely, Connected Vehicle, Smart Grid, Smart Cities, and, in general, Wireless Sensors and Actuators Networks (WSANs).",result,3
7655,We study the phenomenon of business ecosystems in which a platform firm orchestrates the functioning of the ecosystem by providing a platform and setting the rules for other complementor firms to participate in it.,background,0
7656,We develop a theoretical framework to explain how the structural and evolutionary features of the ecosystem may shape the extent to which participating complementor firms can sustain their superior performance.,method,2
7657,"The structural feature, which we refer to as ecosystem complexity, is a function of the number of unique components or subsystems that interact with the complementor’s product.",background,0
7658,We incorporate the evolutionary features by considering the role of generational transitions initiated by platform firms over time as well as the role of complementors’ ecosystem-specific experience.,method,2
7659,"Evidence from Apple’s iOS and Google’s Android smartphone ecosystems supports our arguments that higher ecosystem complexity helps app developers sustain their superior performance, and that this effect is stronger for more experienced firms.",objective,1
7660,"In contrast, platform transitions initiated by Apple and Google make it more difficult for app developers to sustain their performance superiority, and that this effect is exacerbated by the extent of ecosystem complexity.",result,3
7661,The study offers a novel perspective on how the performance of complementor firms in business ecosystems may be shaped by the rules and actions of the central platform firms.,result,3
7662,"Since emotions play an important role in the daily life of human beings, the need and importance of automatic emotion recognition has grown with increasing role of human computer interface applications.",background,0
7663,"Emotion recognition could be done from the text, speech, facial expression or gesture.",background,0
7664,"In this paper, we concentrate on recognition of “inner” emotions from electroencephalogram (EEG) signals.",objective,1
7665,We propose real-time fractal dimension based algorithm of quantification of basic emotions using Arousal-Valence emotion model.,method,2
7666,Two emotion induction experiments with music stimuli and sound stimuli from International Affective Digitized Sounds (IADS) database were proposed and implemented.,method,2
7667,"Finally, the real-time algorithm was proposed, implemented and tested to recognize six emotions such as fear, frustrated, sad, happy, pleasant and satisfied.",method,2
7668,Real-time applications were proposed and implemented in 3D virtual environments.,method,2
7669,The user emotions are recognized and visualized in real time on his/her avatar adding one more so-called “emotion dimension” to human computer interfaces.,result,3
7670,An EEGenabled music therapy site was proposed and implemented.,method,2
7671,The music played to the patients helps them deal with problems such as pain and depression.,method,2
7672,Question classification is very important for question answering.,background,0
7673,This paper presents our research work on automatic question classification through machine learning approaches.,background,0
7674,"We have experimented with five machine learning algorithms: Nearest Neighbors (NN), Naive Bayes (NB), Decision Tree (DT), Sparse Network of Winnows (SNoW), and Support Vector Machines (SVM) using two kinds of features: bag-of-words and bag-of-ngrams.",background,0
7675,The experiment results show that with only surface text features the SVM outperforms the other four methods for this task.,objective,1
7676,"Further, we propose to use a special kernel function called the tree kernel to enable the SVM to take advantage of the syntactic structures of questions.",objective,1
7677,We describe how the tree kernel can be computed efficiently by dynamic programming.,method,2
7678,"The performance of our approach is promising, when tested on the questions from the TREC QA track.",result,3
7679,"In real-world face detection, large visual variations, such as those due to pose, expression, and lighting, demand an advanced discriminative model to accurately differentiate faces from the backgrounds.",background,0
7680,"Consequently, effective models for the problem tend to be computationally prohibitive.",background,0
7681,"To address these two conflicting challenges, we propose a cascade architecture built on convolutional neural networks (CNNs) with very powerful discriminative capability, while maintaining high performance.",background,0
7682,"The proposed CNN cascade operates at multiple resolutions, quickly rejects the background regions in the fast low resolution stages, and carefully evaluates a small number of challenging candidates in the last high resolution stage.",method,2
7683,"To improve localization effectiveness, and reduce the number of candidates at later stages, we introduce a CNN-based calibration stage after each of the detection stages in the cascade.",method,2
7684,The output of each calibration stage is used to adjust the detection window position for input to the subsequent stage.,method,2
7685,"The proposed method runs at 14 FPS on a single CPU core for VGA-resolution images and 100 FPS using a GPU, and achieves state-of-the-art detection performance on two public face detection benchmarks.",result,3
7686,"Gender classification is a fundamental and important application in computer vision, and it has become a research hotspot.",background,0
7687,Real-world applications require gender classification in unconstrained conditions where traditional methods are not appropriate.,background,0
7688,This paper proposes a Deep Convolutional Neural Network for feature extraction together with fully-connected layers for metric learning.,objective,1
7689,A Siamese network is built for similarity measuring to promote the performance of classification.,objective,1
7690,Extensive experiments on several databases demonstrate that a significant improvement can be obtained for gender classification tasks in both constrained and unconstrained conditions.,result,3
7691,"Children and adolescents now communicate online to form and/or maintain relationships with friends, family, and strangers.",background,0
7692,"Relationships in ""real life"" are important for children's and adolescents' psychosocial development; however, they can be difficult for those who experience feelings of loneliness and/or social anxiety.",background,0
7693,The aim of this study was to investigate differences in usage of online communication patterns between children and adolescents with and without self-reported loneliness and social anxiety.,objective,1
7694,"Six hundred twenty-six students ages 10 to 16 years completed a survey on the amount of time they spent communicating online, the topics they discussed, the partners they engaged with, and their purposes for communicating over the Internet.",method,2
7695,Participants were administered a shortened version of the UCLA Loneliness Scale and an abbreviated subscale of the Social Anxiety Scale for Adolescents (SAS-A).,method,2
7696,"Additionally, age and gender differences in usage of the online communication patterns were examined across the entire sample.",method,2
7697,Findings revealed that children and adolescents who self-reported being lonely communicated online significantly more frequently about personal and intimate topics than did those who did not self-report being lonely.,result,3
7698,The former were motivated to use online communication significantly more frequently to compensate for their weaker social skills to meet new people.,result,3
7699,"Results suggest that Internet usage allows them to fulfill critical needs of social interactions, self-disclosure, and identity exploration.",result,3
7700,"Future research, however, should explore whether or not the benefits derived from online communication may also facilitate lonely children's and adolescents' offline social relationships.",result,3
7701,"Qualitative research is often associated with interpretivism, but alternatives do exist.",background,0
7702,"Besides critical research and sometimes positivism, qualitative research in information systems can be performed following a paradigm of pragmatism.",background,0
7703,"This paradigm is associated with action, intervention and constructive knowledge.",background,0
7704,This paper has picked out interpretivism and pragmatism as two possible and important research paradigms for qualitative research in information systems.,objective,1
7705,It clarifies each paradigm in an ideal-typical fashion and then conducts a comparison revealing commonalities and differences.,method,2
7706,The possibilities of combining pragmatism and interpretivism in qualitative research in information systems are analysed.,method,2
7707,A research case that combines interpretivism and pragmatism is used for illustration.,method,2
7708,The paper thus contributes to a discussion about different paradigms and methods for qualitative research in information systems.,result,3
7709,"Within the past three years, several new AI textbooks have been published, all written by well-known researchers (Dean, Allen, and Aloiminos 1995; Russell and Norvig 1995; Shoham 1994; Ginsberg 1993).",background,0
7710,"Thus, it is not surprising that the authors of each of these textbooks have sought a way to distinguish their own book from the rest.",method,2
7711,"The hook for Stuart Russell and Peter Norvig's new textbook, Artificial Intelligence: A Modern Approach, is indicated on the book's jacket, which proclaims it to be 'the intelligent agent book.'",method,2
7712,"Throughout the book, attention is given to the question of how individual AI algorithms might be incorporated into a larger agent that interacts with its environment.",method,2
7713,"I've been teaching from the Russell and Norvig textbook for the past two years, and I think it's a terrific book; however, I think its merit is more or less independent of its identity as the intelligent-agent book.",result,3
7714,In this work we describe a Convolutional Neural Network (CNN) to accurately predict image quality without a reference image.,background,0
7715,"Taking image patches as input, the CNN works in the spatial domain without using hand-crafted features that are employed by most previous methods.",background,0
7716,"The network consists of one convolutional layer with max and min pooling, two fully connected layers and an output node.",objective,1
7717,"Within the network structure, feature learning and regression are integrated into one optimization process, which leads to a more effective model for estimating image quality.",objective,1
7718,This approach achieves state of the art performance on the LIVE dataset and shows excellent generalization ability in cross dataset experiments.,method,2
7719,"Further experiments on images with local distortions demonstrate the local quality estimation ability of our CNN, which is rarely reported in previous literature.",result,3
7720,In this paper we explore the topic of using metaphors and analogies in teaching algorithms.,background,0
7721,We argue their importance in the teaching process.,background,0
7722,We present a selection of metaphors we successfully used when teaching algorithms to secondary school students.,method,2
7723,"We also discuss the suitability of several commonly used metaphors, and in several cases we show significant weaknesses of these metaphors.",method,2
7724,"Mobile communication technologies such as Bluetooth are becoming ubiquitous, but they must provide satisfactory levels of security and privacy.",background,0
7725,"Concerns about Bluetooth device security have led the specification of the “non-discoverable” mode, which prevents devices from being listed during a Bluetooth device search process.",background,0
7726,"However, a nondiscoverable Bluetooth device is visible to devices that know its address or can discover its address.",background,0
7727,This paper discusses the detection of non-discoverable Bluetooth devices using an enhanced brute force search attack.,objective,1
7728,Our results indicate that the average time to attack a non-discoverable Bluetooth device using multiple search devices and condensed packet timing can be reduced to well under 24 hours.,result,3
7729,The design of software has been a focus of software engineering research since the field's beginning.,background,0
7730,This paper explores key aspects of this research focus and shows why design will remain a principal focus.,objective,1
7731,"The intrinsic elements of software design, both process and product, are discussed: concept formation, use of experience, and means for representation, reasoning, and directing the design activity.",objective,1
7732,"Design is presented as being an activity engaged by a wide range of stakeholders, acting throughout most of a system's lifecycle, making a set of key choices which constitute the application's architecture.",method,2
7733,"Directions for design research are outlined, including: (a) drawing lessons, inspiration, and techniques from design fields outside of computer science, (b) emphasizing the design of application ""character"" (functionality and style) as well as the application's structure, and (c) expanding the notion of software to encompass the design of additional kinds of intangible complex artifacts.",method,2
7734,Automatic access control systems (ACS) based on the human biometrics or physical tokens are widely employed in public and private areas.,background,0
7735,"Yet these systems, in their conventional forms, are restricted to active interaction from the users.",background,0
7736,"In scenarios where users are not cooperating with the system, these systems are challenged.",background,0
7737,"Failure in cooperation with the biometric systems might be intentional or because the users are incapable of handling the interaction procedure with the biometric system or simply forget to cooperate with it, due to for example, illness like dementia.",background,0
7738,"This work introduces a challenging bimodal database, including face and hand information of the users when they approach a door to open it by its handle in a noncooperative context.",objective,1
7739,We have defined two (an easy and a challenging) protocols on how to use the database.,method,2
7740,"We have reported results on many baseline methods, including deep learning techniques as well as conventional methods on the database.",result,3
7741,The obtained results show the merit of the proposed database and the challenging nature of access control with non-cooperative users.,result,3
7742,Organizations today face shortages of IT personnel.,background,0
7743,We investigated workplace factors in one state government in hope of identifying factors that influence perceived organizational support (POS) within an IT work environment.,objective,1
7744,"A combination of job characteristics (challenging job and perceived workload), job stressors (work exhaustion, role conflict, and role ambiguity), and the organization’s discretionary actions (pay-for-performance and mentoring opportunities) were measured and hierarchical regression was used to determine the relationships.",method,2
7745,"Four control variables were also included (age, gender, organizational tenure, and professional versus administrator status).",method,2
7746,"Role ambiguity, role conflict, work exhaustion, career mentoring, and pay-for-performance together explained 62% of the variance in the IT employees’ POS.",result,3
7747,Career mentoring and role ambiguity explained most of the variance.,result,3
7749,"We introduce new online and batch algorithms that are robust to data with missing features, a situation that arises in many practical applications.",method,2
7750,"In the online setup, we allow for the comparison hypothesis to change as a function of the subset of features that is observed on any given round, extending the standard setting where the comparison hypothesis is fixed throughout.",objective,1
7751,"In the batch setup, we present a convex relaxation of a non-convex problem to jointly estimate an imputation function, used to fill in the values of missing features, along with the classification hypothesis.",method,2
7752,We prove regret bounds in the online setting and Rademacher complexity bounds for the batch i.i.d.,method,2
7753,setting.,other,4
7754,"The algorithms are tested on several UCI datasets, showing superior performance over baseline imputation methods.",method,2
7755,Automatic citation recommendation can be very useful for authoring a paper and is an AI-complete problem due to the challenge of bridging the semantic gap between citation context and the cited paper.,background,0
7756,It is not always easy for knowledgeable researchers to give an accurate citation context for a cited paper or to find the right paper to cite given context.,background,0
7757,"To help with this problem, we propose a novel neural probabilistic model that jointly learns the semantic representations of citation contexts and cited papers.",objective,1
7758,The probability of citing a paper given a citation context is estimated by training a multi-layer neural network.,objective,1
7759,"We implement and evaluate our model on the entire CiteSeer dataset, which at the time of this work consists of 10,760,318 citation contexts from 1,017,457 papers.",method,2
7760,"We show that the proposed model significantly outperforms other stateof-the-art models in recall, MAP, MRR, and nDCG.",result,3
7761,Recent results in monocular visual-inertial navigation (VIN) have shown that optimization-based approaches outperform filtering methods in terms of accuracy due to their capability to relinearize past states.,background,0
7762,"However, the improvement comes at the cost of increased computational complexity.",background,0
7763,"In this paper, we address this issue by preintegrating inertial measurements between selected keyframes.",method,2
7764,The preintegration allows us to accurately summarize hundreds of inertial measurements into a single relative motion constraint.,method,2
7765,Our first contribution is a preintegration theory that properly addresses the manifold structure of the rotation group and carefully deals with uncertainty propagation.,method,2
7766,"The measurements are integrated in a local frame, which eliminates the need to repeat the integration when the linearization point changes while leaving the opportunity for belated bias corrections.",method,2
7767,The second contribution is to show that the preintegrated IMU model can be seamlessly integrated in a visual-inertial pipeline under the unifying framework of factor graphs.,method,2
7768,"This enables the use of a structureless model for visual measurements, further accelerating the computation.",method,2
7769,"The third contribution is an extensive evaluation of our monocular VIN pipeline: experimental results confirm that our system is very fast and demonstrates superior accuracy with respect to competitive state-of-the-art filtering and optimization algorithms, including off-the-shelf systems such as Google Tango [1].",result,3
7770,How could the body influence our thinking when it seems obvious that the brain controls the body?,background,0
7771,"In How the Body Shapes the Way We Think, Rolf Pfeifer and Josh Bongard demonstrate that thought is not independent of the body but is tightly constrained, and at the same time enabled, by it.",background,0
7772,They argue that the kinds of thoughts we are capable of have their foundation in our embodiment—in our morphology and the material properties of our bodies.,background,0
7773,"This crucial notion of embodiment underlies fundamental changes in the field of artificial intelligence over the past two decades, and Pfeifer and Bongard use the basic methodology of artificial intelligence—“understanding by building”—to describe their insights.",method,2
7774,"If we understand how to design and build intelligent systems, they reason, we will better understand intelligence in general.",objective,1
7775,"In accessible, nontechnical language, and using many examples, they introduce the basic concepts by building on recent developments in robotics, biology, neuroscience, and psychology to outline a possible theory of intelligence.",objective,1
7776,"They illustrate applications of such a theory in ubiquitous computing, business and management, and the psychology of human memory.",method,2
7777,"Embodied intelligence, as described by Pfeifer and Bongard, has important implications for our understanding of both natural and artificial intelligence.",method,2
7778,Rolf Pfeifer is Professor of Computer Science and Director of the Artificial Intelligence Laboratory in the Department of Informatics at the University of Zurich.,result,3
7779,"He is the author of Understanding Intelligence (MIT Press, 1999).",result,3
7780,This paper integrates and extends research on e-commerce in the developing world.,objective,1
7781,"We use three categories of feedback systems–economic, sociopolitical and cognitive—to offer a simple model of e-commerce barriers in the developing world.",method,2
7782,We also examine characteristics of e-business models that can be successfully employed in developing countries.,method,2
7783,"Then, we provide the case of an e-business model followed by a Nepal-based multiple international award winning online provider.",method,2
7784,This paper‘s theoretical contribution is to explain the ̳hows‘ and ̳whys‘ of e-commerce in developing countries and to identify clear contexts and attendant mechanism.,result,3
7785,"This paper proposes a novel nature-inspired meta-heuristic optimization algorithm, called Whale Optimization Algorithm (WOA), which mimics the social behavior of humpback whales.",objective,1
7786,The algorithm is inspired by the bubble-net hunting strategy.,method,2
7787,WOA is tested with 29 mathematical optimization problems and 6 structural design problems.,method,2
7788,Optimization results prove that the WOA algorithm is very competitive compared to the state-of-art meta-heuristic algorithms as well as conventional methods.,result,3
7789,The source codes of the WOA algorithm are publicly available at http://www.alimirjalili.com/WOA.html © 2016 Elsevier Ltd.,result,3
7791,A new coded modulation scheme is proposed.,objective,1
7792,"At the transmitter, the concatenation of a distribution matcher and a systematic binary encoder performs probabilistic signal shaping and channel coding.",method,2
7793,"At the receiver, the output of a bitwise demapper is fed to a binary decoder.",method,2
7794,No iterative demapping is performed.,method,2
7795,Rate adaption is achieved by adjusting the input distribution and the transmission power.,method,2
7796,The scheme is applied to bipolar amplitudeshift keying (ASK) constellations with equidistant signal points and it is directly applicable to two-dimensional quadrature amplitude modulation (QAM).,method,2
7797,The scheme is implemented by using the DVB-S2 low-density parity-check (LDPC) codes.,method,2
7798,"At a frame error rate of 10-3, the new scheme operates within less than 1.1 dB of the AWGN capacity 1/2 log2(1 + SNR) at any spectral efficiency between 1 and 5 bits/s/Hz by using only 5 modes, i.e., 4-ASK with code rate 2/3, 8-ASK with 3/4, 16-ASK and 32-ASK with 5/6, and 64-ASK with 9/10.",result,3
7799,"Since the effective and efficient system of water quality monitoring (WQM) are critical implementation for the issue of polluted water globally, with increasing in the development of Wireless Sensor Network (WSN) technology in the Internet of Things (IoT) environment, real time water quality monitoring is remotely monitored by means of real-time data acquisition, transmission and processing.",background,0
7800,This paper presents a reconfigurable smart sensor interface device for water quality monitoring system in an IoT environment.,objective,1
7801,"The smart WQM system consists of Field Programmable Gate Array (FPGA) design board, sensors, Zigbee based wireless communication module and personal computer (PC).",method,2
7802,The FPGA board is the core component of the proposed system and it is programmed in very high speed integrated circuit hardware description language (VHDL) and C programming language using Quartus II software and Qsys tool.,method,2
7803,"The proposed WQM system collects the five parameters of water data such as water pH, water level, turbidity, carbon dioxide (CO2) on the surface of water and water temperature in parallel and in real time basis with high speed from multiple different sensor nodes.",method,2
7804,The usual recursive summation technique is just one of several ways of computing the sum of n floating point numbers.,background,0
7805,Five summation methods and their variations are analyzed here.,background,0
7806,The accuracy of the methods is compared using rounding error analysis and numerical experiments.,method,2
7807,"Four of the methods are shown to be special cases of a general class of methods, and an error analysis is given for this class.",method,2
7808,"No one method is uniformly more accurate than the others, but some guidelines are given on the choice of method in particular cases.",result,3
7809,"Recently, convolutional neural networks (CNNs) have been shown to outperform the standard fully connected deep neural networks within the hybrid deep neural network / hidden Markov model (DNN/HMM) framework on the phone recognition task.",background,0
7810,"In this paper, we extend the earlier basic form of the CNN and explore it in multiple ways.",background,0
7811,"We first investigate several CNN architectures, including full and limited weight sharing, convolution along frequency and time axes, and stacking of several convolution layers.",method,2
7812,We then develop a novel weighted softmax pooling layer so that the size in the pooling layer can be automatically learned.,method,2
7813,"Further, we evaluate the effect of CNN pretraining, which is achieved by using a convolutional version of the RBM.",result,3
7814,We show that all CNN architectures we have investigated outperform the earlier basic form of the DNN on both the phone recognition and large vocabulary speech recognition tasks.,objective,1
7815,The architecture with limited weight sharing provides additional gains over the full weight sharing architecture.,result,3
7816,"The softmax pooling layer performs as well as the best CNN with the manually tuned fixed-pooling size, and has a potential for further improvement.",result,3
7817,"Finally, we show that CNN pretraining produces significantly better results on a large vocabulary speech recognition task.",result,3
7818,"We propose a normative model of transactional negotiation in which cooperative and competitive behaviors wax and wane across four stages: relational positioning, identifying the problem, generating solutions, and reaching agreement.",background,0
7819,"Based on a classic proposition of communicative flexibility in high-context cultures, we propose culture-specific dyadic movements within and across these stages.",background,0
7820,"Our sample included 102 high-context dyads from Russia, Japan, Hong Kong, and Thailand; 89 low-context dyads from Germany, Israel, Sweden, and the United States; and 45 United States–Hong Kong and United States–Japan mixed-context dyads.",method,2
7821,"Dyads negotiated a complex, 90-minute transaction with integrative potential.",method,2
7822,"We audiotaped, transcribed, and coded their negotiations for sequences of information and influence behaviors.",background,0
7823,The unit of analysis was the action-response sequence.,method,2
7824,Results confirmed that the pattern of sequences varied across the four stages and the frequency of particular sequences varied with culture.,result,3
7825,"We suggest that negotiators can use this model to manage the evolution and strategic focus of their negotiation, especially during the first two stages, when the use of influence-information sequences and reciprocal-information sequences generate the groundwork for joint gains.",result,3
7826,"In the last years, the spread of computers and the Internet caused a significant amount of documents to be available in digital format.",background,0
7827,"Collecting them in digital repositories raised problems that go beyond simple acquisition issues, and cause the need to organize and classify them in order to improve the effectiveness and efficiency of the retrieval procedure.",background,0
7828,The success of such a process is tightly related to the ability of understanding the semantics of the document components and content.,background,0
7829,"Since the obvious solution of manually creating and maintaining an updated index is clearly infeasible, due to the huge amount of data under consideration, there is a strong interest in methods that can provide solutions for automatically acquiring such a knowledge.",background,0
7830,"This work presents a framework that intensively exploits intelligent techniques to support different tasks of automatic document processing from acquisition to indexing, from categorization to storing and retrieval.",method,2
7831,"The prototypical version of the system DOMINUS is presented, whose main characteristic is the use of a Machine Learning Server, a suite of different inductive learning methods and systems, among which the more suitable for each specific document processing phase is chosen and applied.",method,2
7832,The core system is the incremental first-order logic learner INTHELEX.,method,2
7833,"Thanks to incrementality, it can continuously update and refine the learned theories, dynamically extending its knowledge to handle even completely new classes of documents.",method,2
7834,"Since DOMINUS is general and flexible, it can be embedded as a document management engine into many different Digital Library systems.",method,2
7835,"Experiments in a real-world domain scenario, scientific conference management, confirmed the good performance of the proposed prototype.",result,3
7836,Purpose –,other,4
7837,This article seeks to provide a conceptual model that explains the complexity of an enterprise resource planning (ERP) system to general and project managers in a non-technical manner that is easily understood.,objective,1
7838,Design/methodology/approach – The 4Ps business model serves as a starting-point to derive the ERP model because most managers are familiar with it and can therefore relate to it with ease.,method,2
7839,"An ERP system is divided into four major components, namely, the software, the customer mindset, change management, and the flow of processes within it.",method,2
7840,"A fifth component, methodology, encircles these four components to ensure that they are integrated and implemented in an organised manner.",method,2
7841,Findings – ERP is more than just software.,result,3
7842,"Unless a clear understanding exists of the different components and their integration, ERP projects will continue to be plagued by failure.",result,3
7843,This model is applicable to any ERP system as it is generic and vendor-independent and helps in determining the scope of an ERP project.,result,3
7844,Research limitations/implications – The suggested model is conceptual in nature and provides a holistic view of ERP.,result,3
7845,"It does not attempt to provide a detailed, step-by-step approach for implementing an ERP system.",result,3
7846,"While commoditization is creating opportunities for customers of information technology services, it is creating new challenges for the service providers.",background,0
7847,Pricing strategies are one of the most important challenges and decisions for today's IT service providers.,background,0
7848,"Pricing strategies for IT services have traditionally focused on covering costs, achieving desired margins and meeting the competition.",background,0
7849,"These pricing schemes range from simple approaches, easily copied by competitors, to complex models with high management costs.",background,0
7850,"In order to be successful in today's competitive business world, the service providers need to define their pricing strategies by considering the customer's perceived value from the service they receive rather than using traditional cost-based pricing strategies.",background,0
7851,This paper surveys literature on IT services pricing and presents a value-based approach to effectively price IT services.,result,3
7852,We consider the problem of finding the best arm in a stochastic multi-armed bandit game.,background,0
7853,The regret of a forecaster is here defined by the gap between the mean reward of the optimal arm and the mean reward of the ultimately chosen arm.,background,0
7854,We propose a highly exploring UCB policy and a new algorithm based on successive rejects.,objective,1
7855,"We show that these algorithms are essentially optimal since their regret decreases exponentially at a rate which is, up to a logarithmic factor, the best possible.",method,2
7856,"However, while the UCB policy needs the tuning of a parameter depending on the unobservable hardness of the task, the successive rejects policy benefits from being parameter-free, and also independent of the scaling of the rewards.",result,3
7857,"As a by-product of our analysis, we show that identifying the best arm (when it is unique) requires a number of samples of order (up to a log(K) factor) ∑ i 1/∆ 2 i , where the sum is on the suboptimal arms and ∆i represents the difference between the mean reward of the best arm and the one of arm i. This generalizes the well-known fact that one needs of order of 1/∆ samples to differentiate the means of two distributions with gap ∆.",result,3
7858,Natural language sentence matching is a fundamental technology for a variety of tasks.,background,0
7859,Previous approaches either match sentences from a single direction or only apply single granular (wordby-word or sentence-by-sentence) matching.,background,0
7860,"In this work, we propose a bilateral multi-perspective matching (BiMPM) model.",objective,1
7861,"Given two sentences P and Q, our model first encodes them with a BiLSTM encoder.",method,2
7862,"Next, we match the two encoded sentences in two directions P against Q and Q against P .",method,2
7863,"In each matching direction, each time step of one sentence is matched against all timesteps of the other sentence from multiple perspectives.",method,2
7864,"Then, another BiLSTM layer is utilized to aggregate the matching results into a fixed-length matching vector.",method,2
7865,"Finally, based on the matching vector, a decision is made through a fully connected layer.",method,2
7866,"We evaluate our model on three tasks: paraphrase identification, natural language inference and answer sentence selection.",result,3
7867,Experimental results on standard benchmark datasets show that our model achieves the state-of-the-art performance on all tasks.,result,3
7868,Learning Convolutional Neural Networks (CNN) is commonly carried out by plain supervised gradient descent.,background,0
7869,"With sufficient training data, this leads to very competitive results for visual recognition tasks when starting from a random initialization.",background,0
7870,"When the amount of labeled data is limited, CNNs reveal their strong dependence on large amounts of training data.",background,0
7871,"However, recent results have shown that a well chosen optimization starting point can be beneficial for convergence to a good generalizing minimum.",result,3
7872,This starting point was mostly found using unsupervised feature learning techniques such as sparse coding or transfer learning from related recognition tasks.,method,2
7873,"In this work, we compare these two approaches against a simple patch based initialization scheme and a random initialization of the weights.",method,2
7874,We show that pre-training helps to train CNNs from few samples and that the correct choice of the initialization scheme can push the network's performance by up to 41% compared to random initialization.,result,3
7875,"Novel data-driven and demand-driven computer architectures are under development in a large number of laboratories in the United States, Japan, and Europe.",background,0
7876,"These computers are not based on the tradlUonal von Neumann organization; instead, they are attempts to identify the next generation of computer.",objective,1
7877,"Basmally, m data-driven (e.g., data-flow) computers the availability of operands triggers the execution of the operation to be performed on them, whereas in demand-driven (e.g, reduction) computers the reqmrement for a result triggers the operation that will generate it.",method,2
7878,"Although there are these two distinct areas of research, each laboratory has developed its own mdlvxdual model of computation, stored program representation, and machine organization.",method,2
7879,"Across this spectrum of designs there m, however, a significant sharing of concepts.",method,2
7880,The aim of this palaer m to identify the concepts and relationships that exist both within and between the two areas of research.,objective,1
7881,"It does thin by examlmng data-driven and demand-driven architecture at three levels, computation organizatmn, (stored) program organization, and machine organLzation.",result,3
7882,"Finally, a survey of various novel computer architectures under development is given.",result,3
7883,Metric learning algorithms produce distance metrics that capture the important relationships among data.,background,0
7884,In this work we study the connection between metric learning and collaborative filtering.,objective,1
7885,We propose Collaborative Metric Learning (CML) which learns a joint metric space to encode not only users’ preferences but also the user-user and itemitem similarity.,objective,1
7886,The proposed algorithm outperforms stateof-the-art collaborative filtering algorithms on a wide range of recommendation tasks and uncovers the underlying spectrum of users’ fine-grained preferences.,method,2
7887,"CML also achieves significant speedup for Top-K recommendation tasks using off-the-shelf, approximate nearest-neighbor search, with negligible accuracy reduction.",result,3
7888,"Facebook, as one of the most popular social networking sites among college students, provides a platform for people to manage others' impressions of them.",background,0
7889,People tend to present themselves in a favorable way on their Facebook profile.,background,0
7890,This research examines the impact of using Facebook on people's perceptions of others' lives.,background,0
7891,It is argued that those with deeper involvement with Facebook will have different perceptions of others than those less involved due to two reasons.,objective,1
7892,"First, Facebook users tend to base judgment on examples easily recalled (the availability heuristic).",background,0
7893,"Second, Facebook users tend to attribute the positive content presented on Facebook to others' personality, rather than situational factors (correspondence bias), especially for those they do not know personally.",result,3
7894,"Questionnaires, including items measuring years of using Facebook, time spent on Facebook each week, number of people listed as their Facebook ""friends,"" and perceptions about others' lives, were completed by 425 undergraduate students taking classes across various academic disciplines at a state university in Utah.",method,2
7895,"Surveys were collected during regular class period, except for two online classes where surveys were submitted online.",method,2
7896,"The multivariate analysis indicated that those who have used Facebook longer agreed more that others were happier, and agreed less that life is fair, and those spending more time on Facebook each week agreed more that others were happier and had better lives.",result,3
7897,"Furthermore, those that included more people whom they did not personally know as their Facebook ""friends"" agreed more that others had better lives.",result,3
7898,"This article presents a model for describing the architecture of software-intensive systems, based on the use of multiple, concurrent views.",method,2
7899,"This use of multiple views allows to address separately the concerns of the various ‘stakeholders’ of the architecture: end-user, developers, systems engineers, project managers, etc., and to handle separately the functional and non functional requirements.",method,2
7900,"Each of the five views is described, together with a notation to capture it.",method,2
7901,"The views are designed using an architecture-centered, scenariodriven, iterative development process.",method,2
7902,We use Reinforcement Learning (RL) to learn question-answering dialogue policies for a real-world application.,background,0
7903,"We analyze a corpus of interactions of museum visitors with two virtual characters that serve as guides at the Museum of Science in Boston, in order to build a realistic model of user behavior when interacting with these characters.",background,0
7904,A simulated user is built based on this model and used for learning the dialogue policy of the virtual characters using RL.,method,2
7905,Our learned policy outperforms two baselines (including the original dialogue policy that was used for collecting the corpus) in a simulation setting.,result,3
7906,"Audio event recognition, the human-like ability to identify and relate sounds from audio, is a nascent problem in machine perception.",background,0
7907,Comparable problems such as object detection in images have reaped enormous benefits from comprehensive datasets - principally ImageNet.,background,0
7908,"This paper describes the creation of Audio Set, a large-scale dataset of manually-annotated audio events that endeavors to bridge the gap in data availability between image and audio research.",method,2
7909,"Using a carefully structured hierarchical ontology of 632 audio classes guided by the literature and manual curation, we collect data from human labelers to probe the presence of specific audio classes in 10 second segments of YouTube videos.",method,2
7910,"Segments are proposed for labeling using searches based on metadata, context (e.g., links), and content analysis.",method,2
7911,"The result is a dataset of unprecedented breadth and size that will, we hope, substantially stimulate the development of high-performance audio event recognizers.",result,3
7912,This paper proposes an efficient active noise cancelling (ANC) circuit design for the in-ear headphones.,background,0
7913,"We develop a hardware oriented Least Mean Square (LMS) adaptive algorithm, and design a modified high-performance feed-forward ANC architecture which only uses one microphone to effectively cancel broadband noise for the in-ear headphones.",method,2
7914,The proposed ANC circuit design has been successfully implemented through adopting the standard cell-based design flow based on the TSMC 90nm CMOS technology.,method,2
7915,"Besides, the proposed design has been verified under versatile noisy scenarios for its real-time ANC performance by using a Field Programmable Gate Array (FPGA) platform.",method,2
7916,"Experimental results show that the proposed high-performance circuit design can reduce disturbing noise of various frequency bands very well, and outperforms the existing works.",result,3
7917,"The proposed design can attenuate the broadband pink noise between 300 Hz to 900 Hz, with a maximum performance of 18 dB. Moreover, the proposed design can achieve 406.5 k samples/sec data throughput rate at operating frequency of 50 MHz, at the costs of 111.7 k gates and power consumption of 4.47 mW.",result,3
7918,"While Instagram, the rising photo-sharing social networking service, has received increasing attention from scholars and practitioners, little is known about the social and psychological factors that lead consumers to become fanatics of this app.",background,0
7919,"To provide a baseline understanding of Instagram users, the current study aims to uncover the structural dimensions of consumers' motives for using Instagram and to explore the relationships between identified motivations and key attitudinal and behavioral intention variables.",objective,1
7920,"A comprehensive survey was developed in which a total of 212 Instagram users evaluated their motivation, primary activities, use intention, and attitude regarding Instagram.",method,2
7921,"The results suggest that Instagram users have five primary social and psychological motives: social interaction, archiving, self-expression, escapism, and peeking.",result,3
7922,The implications of this study's findings are discussed.,result,3
7923,"In order to characterize the transient dynamics of steam turbines subsections, in this paper, nonlinear mathematical models are first developed based on the energy balance, thermodynamic principles and semi-empirical equations.",objective,1
7924,"Then, the related parameters of developed models are either determined by empirical relations or they are adjusted by applying genetic algorithms (GA) based on experimental data obtained from a complete set of field experiments.",method,2
7925,"In the intermediate and low-pressure turbines where, in the sub-cooled regions, steam variables deviate from prefect gas behavior, the thermodynamic characteristics are highly dependent on pressure and temperature of each region.",background,0
7926,"Thus, nonlinear functions are developed to evaluate specific enthalpy and specific entropy at these stages of turbines.",method,2
7927,The parameters of proposed functions are individually adjusted for the operational range of each subsection by using genetic algorithms.,method,2
7928,Comparison between the responses of the overall turbine-generator model and the response of real plant indicates the accuracy and performance of the proposed models over wide range of operations.,result,3
7929,The simulation results show the validation of the developed model in term of more accurate and less deviation between the responses of the models and real system where errors of the proposed functions are less than 0.1% and the modeling error is less than 0.3%.,result,3
7931,The Internet has favored the growth of collaborative platforms where marketers and consumers interact to develop more engaging products and services.,background,0
7932,These platforms are usually centered in a specific brand/product and their members are linked by a shared admiration to that brand.,background,0
7933,"This paper analyzes one of the most powerful online collaborative platforms, the free software (FS) case, which involves a lot of virtual communities developed around products such as Linux or Android, the new Google’s mobile operating system.",result,3
7934,Our purpose is to determine some of the main antecedents and consequences of the consumer involvement in this type of communities.,objective,1
7935,Results have shown that satisfaction with a virtual community may increase the level of consumer participation in that community.,result,3
7936,"At the same time, a greater identification with the virtual community may increase indirectly the consumer participation thanks to the enhancement of his/her satisfaction with the community.",result,3
7937,We have also found positive and significant effects of consumer identification and participation on the level of community promotion.,result,3
7938,"Finally, positive and significant effects of consumer participation and satisfaction with the community on loyalty to the FS were also found.",result,3
7939,These findings allow us to conclude some interesting managerial implications.,result,3
7940,© 2010 Elsevier Ltd.,other,4
7941,"We present DeepWalk, a novel approach for learning latent representations of vertices in a network.",background,0
7942,"These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models.",background,0
7943,DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs.,method,2
7944,DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences.,method,2
7945,"We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube.",method,2
7946,"Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information.",method,2
7947,DeepWalk's representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse.,method,2
7948,"In some experiments, DeepWalk's representations are able to outperform all baseline methods while using 60% less training data.",method,2
7949,DeepWalk is also scalable.,method,2
7950,"It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable.",result,3
7951,Sketch-based modeling strives to bring the ease and immediacy of drawing to the 3D world.,background,0
7952,"However, while drawings are easy for humans to create, they are very challenging for computers to interpret due to their sparsity and ambiguity.",background,0
7953,We propose a data-driven approach that tackles this challenge by learning to reconstruct 3D shapes from one or more drawings.,method,2
7954,At the core of our approach is a deep convolutional neural network (CNN) that predicts occupancy of a voxel grid from a line drawing.,method,2
7955,This CNN provides an initial 3D reconstruction as soon as the user completes a single drawing of the desired shape.,method,2
7956,We complement this single-view network with an updater CNN that refines an existing prediction given a new drawing of the shape created from a novel viewpoint.,method,2
7957,"A key advantage of our approach is that we can apply the updater iteratively to fuse information from an arbitrary number of viewpoints, without requiring explicit stroke correspondences between the drawings.",method,2
7958,We train both CNNs by rendering synthetic contour drawings from hand-modeled shape collections as well as from procedurally-generated abstract shapes.,method,2
7959,"Finally, we integrate our CNNs in an interactive modeling system that allows users to seamlessly draw an object, rotate it to see its 3D reconstruction, and refine it by re-drawing from another vantage point using the 3D reconstruction as guidance.",result,3
7960,The use of Social Network Sites (SNS) is increasing nowadays especially by the younger generations.,background,0
7961,"The availability of SNS allows users to express their interests, feelings and share daily routine.",background,0
7962,Many researchers prove that using user-generated content (UGC) in a correct way may help determine people's mental health levels.,objective,1
7963,Mining the UGC could help to predict the mental health levels and depression.,objective,1
7964,"Depression is a serious medical illness, which interferes most with the ability to work, study, eat, sleep and having fun.",method,2
7965,"However, from the user profile in SNS, we can collect all the information that relates to person's mood, and negativism.",result,3
7966,"In this research, our aim is to investigate how SNS user's posts can help classify users according to mental health levels.",objective,1
7967,We propose a system that uses SNS as a source of data and screening tool to classify the user using artificial intelligence according to the UGC on SNS.,result,3
7968,"We created a model that classify the UGC using two different classifiers: Support Vector Machine (SVM), and Naïve Bayes.",result,3
7969,Understanding the behavior of source code written in an unfamiliar programming language is difficult.,background,0
7970,"One way to aid understanding of difficult code is to add corresponding pseudo-code, which describes in detail the workings of the code in a natural language such as English.",method,2
7971,"In spite of its usefulness, most source code does not have corresponding pseudo-code because it is tedious to create.",background,0
7972,This paper demonstrates a tool Pseudogen that makes it possible to automatically generate pseudo-code from source code using statistical machine translation (SMT).,method,2
7973,"Pseudogen currently supports generation of English or Japanese pseudo-code from Python source code, and the SMT framework makes it easy for users to create new generators for their preferred source code/pseudo-code pairs.",result,3
7974,We have designed and presented a wireless sensor network monitoring and control system for aquaculture.,result,3
7975,"The system can detect and control water quality parameters of temperature, dissolved oxygen content, pH value, and water level in real-time.",background,0
7976,The sensor nodes collect the water quality parameters and transmit them to the base station host computer through ZigBee wireless communication standard.,result,3
7977,"The host computer is used for data analysis, processing and presentation using LabVIEW software platform.",method,2
7978,The water quality parameters will be sent to owners through short messages from the base station via the Global System for Mobile (GSM) module for notification.,method,2
7979,"The experimental evaluation of the network performance metrics of quality of communication link, battery performance and data aggregation was presented.",result,3
7980,The experimental results show that the system has great prospect and can be used to operate in real world environment for optimum control of aquaculture,result,3
7981,"While the importance of customer loyalty has been recognized in marketing literature for at least three decades, the development and empirical validation of a customer loyalty model in a mobile commerce (m-commerce) context had not been addressed.",background,0
7982,The purpose of our study was to develop and validate such a customer loyalty model.,objective,1
7983,"Based on IS and marketing literature, a comprehensive set of constructs and hypotheses were compiled with a methodology for testing them.",method,2
7984,A questionnaire was constructed and data were collected from 255 users of m-commerce systems in Taiwan.,method,2
7985,Structural modeling techniques were then applied to analyze the data.,method,2
7986,"The results indicated that customer loyalty was affected by perceived value, trust, habit, and customer satisfaction, with customer satisfaction playing a crucial intervening role in the relationship of perceived value and trust to loyalty.",result,3
7987,"Based on the findings, its implications and limitations are discussed.",result,3
7988,# 2005 Elsevier B.V. All rights reserved.,other,4
7989,This paper introduces an Intelligent agent for the vacuum cleaner named as VROBO.,background,0
7990,Objectives of this work are to prepare a pedagogical device for Artificial Intelligence students and to practically implement the Artificial Intelligent Technology in real world problems to enhance the physical capabilities of human being.,objective,1
7991,"Most of the significant Intelligent Agent’s attributes like; Goals, Perception, Autonomy and Action, may be found in this agent.",objective,1
7992,Two options are given for the implementation of proposed setup i.e. Screen oriented simulation developed in java and Java API for “real” robotic simulation using LEGO Mindstorms robots developed by Frank and Scott.,method,2
7993,"Home location is represented by blue color, while yellow color is used to represent dirt.",method,2
7994,When robot sees dirt it emits beep.,method,2
7995,"This Intelligent Agent is just like a prototype system and conceptual in nature, which can be extended for enhancements to be implemented physically.",background,0
7996,"While direct social ties have been intensely studied in the context of computer-mediated social networks, indirect ties (e.g., friends of friends) have seen little attention.",background,0
7997,"Yet in real life, we often rely on friends of our friends for recommendations (of good doctors, good schools, or good babysitters), for introduction to a new job opportunity, and for many other occasional needs.",background,0
7998,"In this work we attempt to 1) quantify the strength of indirect social ties, 2) validate the quantification, and 3) empirically demonstrate its usefulness for applications on two examples.",objective,1
7999,We quantify social strength of indirect ties using a measure of the strength of the direct ties that connect two people and the intuition provided by the sociology literature.,background,0
8000,We evaluate the proposed metric by framing it as a link prediction problem and experimentally demonstrate that our metric accurately (up to 87.2%) predicts link’s formation.,method,2
8001,We show via data-driven experiments that the proposed metric for social strength can be used successfully for social applications.,method,2
8002,"Specifically, we show that it can be used for predicting the effects of information diffusion with an accuracy of up to 0.753.",method,2
8003,We also show that it alleviates known problems in friend-to-friend storage systems by addressing two previously documented shortcomings: reduced set of storage candidates and data availability correlations.,method,2
8006,RAID triple parity (RTP) is a new algorithm for protecting against three-disk failures.,method,2
8007,It is an extension of the double failure correction Row-Diagonal Parity code.,method,2
8008,"For any number of data disks, RTP uses only three parity disks.",background,0
8009,This is optimal with respect to the amount of redundant information required and accessed.,background,0
8010,RTP uses XOR operations and stores all data un-encoded.,method,2
8011,The algorithm's parity computation complexity is provably optimal.,result,3
8012,The decoding complexity is also much lower than that of existing comparable codes.,result,3
8013,This paper also describes a symmetric variant of the algorithm where parity computation is identical to triple reconstruction.,objective,1
8014,"We introduce a new approach for exploration based on the concept of frontiers, regions on the boundary between open space and unexplored space.",background,0
8015,"By moving to new frontiers, a mobile robot can extend its map into new territory until the entire environment has been explored.",objective,1
8016,We describe a method for detecting frontiers in evidence grids and navigating to these frontiers.,objective,1
8017,We also introduce a technique for minimizing specular reflections in evidence grids using laser-limited sonar.,method,2
8018,"We have tested this approach with a real mobile robot, exploring real-world office environments cluttered with a variety of obstacles.",result,3
8019,"An advantage of our approach is its ability to explore both large open spaces and narrow cluttered spaces, with walls and obstacles in arbitrary orientations.",objective,1
8020,"Service innovations, enabled by the confluence of big data, mobile solutions, cloud, social, and cognitive computing, and the Internet of Things, have gained a lot of attention among many enterprises in the past few years because they represent promising ways for companies to effectively and rapidly deliver new services.",background,0
8021,But one of today's most pervasive and bedeviling challenges is how to start this journey and stay on course.,background,0
8022,"In this paper, we review some of the important developments in this area and reports the views voiced by five industry leaders from IBM, Cisco, HP, and ISSIP at a panel session at the 24th Annual Compete through Service Symposium in 2013.",objective,1
8023,Panelists provided an extensive list of recommendations to academicians and professionals.,objective,1
8024,The biggest conclusion is that all of the information and communications technology (ICT)-enabled service innovations need to be human-centered and focused on co-creating value.,result,3
8025,Controllable generation of emphasis in speech is desirable for expressive TTS systems utilized in various dialog applications.,background,0
8026,Usually such models remain voice-specific and the strength of emphasis can't be readily controlled.,background,0
8027,In this work we present a flexible emphatic prosody generation model based on Deep Recurrent Neural Networks (DRNN) for controllable word-level emphasis realization.,objective,1
8028,The word emphasis DRNN model was trained on syllable-level piecewise linear prosodic trajectory parameters.,method,2
8029,"A special data preprocessing technique was introduced to enable emphasis strength control, allowing to generate emphatic prosody trajectories of various strength.",method,2
8030,"Additionally, we trained a DRNN model generating a sentence-level emphasis, i.e. producing whole sentences in forceful, decisive manner.",method,2
8031,Both models preserve quality and naturalness of the baseline TTS output.,method,2
8032,"A large set of email messages, the Enron corpus, was made public during the legal investigation concerning the Enron corporation.",background,0
8033,"This dataset, along with a thorough explanation of its origin, is available at http://www-2.cs.cmu.edu/~enron/. This paper provides a brief introduction and analysis of the dataset.",background,0
8034,"The raw Enron corpus contains 619,446 messages belonging to 158 users.",background,0
8035,"We cleaned the corpus before this analysis by removing certain folders from each user, such as “discussion_threads”.",method,2
8036,"These folders were present for most users, and did not appear to be used directly by the users, but rather were computer generated.",result,3
8037,"Many, such as “all_documents”, also contained large numbers of duplicate emails, which were already present in the users’ other folders.",result,3
8038,"Our goal in this paper is to analyze the suitability of this corpus for exploring how to classify messages as organized by a human, so these folders would have likely been misleading.",objective,1
8039,Ontology alignment is the task of identifying semantically equivalent entities from two given ontologies.,background,0
8040,"Different ontologies have different representations of the same entity, resulting in a need to de-duplicate entities when merging ontologies.",background,0
8041,"We propose a method for enriching entities in an ontology with external definition and context information, and use this additional information for ontology alignment.",method,2
8042,"We develop a neural architecture capable of encoding the additional information when available, and show that the addition of external data results in an F1-score of 0.69 on the Ontology Alignment Evaluation Initiative (OAEI) largebio SNOMEDNCI subtask, comparable with the entitylevel matchers in a SOTA system.",method,2
8043,Most object detectors contain two important components: a feature extractor and an object classifier.,background,0
8044,The feature extractor has rapidly evolved with significant research efforts leading to better deep convolutional architectures.,background,0
8045,"The object classifier, however, has not received much attention and many recent systems (like SPPnet and Fast/Faster R-CNN) use simple multi-layer perceptrons.",background,0
8046,This paper demonstrates that carefully designing deep networks for object classification is just as important.,objective,1
8047,"We experiment with region-wise classifier networks that use shared, region-independent convolutional features.",method,2
8048,We call them “Networks on Convolutional feature maps” (NoCs).,other,4
8049,"We discover that aside from deep feature maps, a deep and convolutional per-region classifier is of particular importance for object detection, whereas latest superior image classification models (such as ResNets and GoogLeNets) do not directly lead to good detection accuracy without using such a per-region classifier.",result,3
8050,"We show by experiments that despite the effective ResNets and Faster R-CNN systems, the design of NoCs is an essential element for the 1st-place winning entries in ImageNet and MS COCO challenges 2015.",result,3
8051,"Semantic matching is of central importance to many natural language tasks [2, 28].",background,0
8052,A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them.,background,0
8053,"As a step toward this goal, we propose convolutional neural network models for matching two sentences, by adapting the convolutional strategy in vision and speech.",method,2
8054,"The proposed models not only nicely represent the hierarchical structures of sentences with their layerby-layer composition and pooling, but also capture the rich matching patterns at different levels.",method,2
8055,"Our models are rather generic, requiring no prior knowledge on language, and can hence be applied to matching tasks of different nature and in different languages.",method,2
8056,The empirical study on a variety of matching tasks demonstrates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models.,result,3
8057,"Lazy learning algorithms, exemplified by nearestneighbor algorithms, do not induce a concise hypothesis from a given training set; the inductive process is delayed until a test instance is given.",background,0
8058,"Algorithms for constructing decision trees, such as C4.5, ID3, and CART create a single “best” decision tree during the training phase, and this tree is then used to classify test instances.",background,0
8059,"The tests at the nodes of the constructed tree are good on average, but there may be better tests for classifying a specific instance.",background,0
8060,We propose a lazy decision tree algorithm-LAzuDT-that conceptually constructs the “best” decision tree for each test instance.,method,2
8061,"In practice, only a path needs to be constructed, and a caching scheme makes the algorithm fast.",result,3
8062,The algorithm is robust with respect to missing values without resorting to the complicated methods usually seen in induction of decision trees.,result,3
8063,Experiments on real and artificial problems are presented.,result,3
8064,One of the main building blocks and major challenges for 5G cellular systems is the design of flexible network architectures which can be realized by the software defined networking paradigm.,background,0
8065,Existing commercial cellular systems rely on closed and inflexible hardware-based architectures both at the radio frontend and in the core network.,background,0
8066,"These problems significantly delay the adoption and deployment of new standards, impose significant challenges in implementing and innovation of new techniques to maximize the network capacity and accordingly the coverage, and prevent provisioning of trulydifferentiated services which are able to adapt to growing and uneven and highly variable traffic patterns.",background,0
8067,"In this paper, a new softwaredefined architecture, called SoftAir, for next generation (5G) wireless systems, is introduced.",objective,1
8068,"Specifically, the novel ideas of network function cloudification and network virtualization are exploited to provide a scalable, flexible and resilient network architecture.",method,2
8069,"Moreover, the essential enabling technologies to support and manage the proposed architecture are discussed in details, including fine-grained base station decomposition, seamless incorporation of Openflow, mobilityaware control traffic balancing, resource-efficient network virtualization, and distributed and collaborative traffic classification.",objective,1
8070,"Furthermore, the major benefits of SoftAir architecture with its enabling technologies are showcased by introducing softwaredefined traffic engineering solutions.",objective,1
8071,The challenging issues for realizing SoftAir are also discussed in details.,result,3
8074,"The mining process in blockchain requires solving a proof-of-work puzzle, which is resource expensive to implement in mobile devices due to the high computing power and energy needed.",background,0
8075,"In this paper, we, for the first time, consider edge computing as an enabler for mobile blockchain.",background,0
8076,"In particular, we study edge computing resource management and pricing to support mobile blockchain applications in which the mining process of miners can be offloaded to an edge computing service provider.",objective,1
8077,We formulate a two-stage Stackelberg game to jointly maximize the profit of the edge computing service provider and the individual utilities of the miners.,method,2
8078,"In the first stage, the service provider sets the price of edge computing nodes.",method,2
8079,"In the second stage, the miners decide on the service demand to purchase based on the observed prices.",method,2
8080,We apply the backward induction to analyze the sub-game perfect equilibrium in each stage for both uniform and discriminatory pricing schemes.,method,2
8081,"For the uniform pricing where the same price is applied to all miners, the existence and uniqueness of Stackelberg equilibrium are validated by identifying the best response strategies of the miners.",method,2
8082,"For the discriminatory pricing where the different prices are applied to different miners, the Stackelberg equilibrium is proved to exist and be unique by capitalizing on the Variational Inequality theory.",result,3
8083,"Further, the real experimental results are employed to justify our proposed model.",result,3
8084,"We present an algorithm for simultaneous face detection, landmarks localization, pose estimation and gender recognition using deep convolutional neural networks (CNN).",background,0
8085,"The proposed method called, HyperFace, fuses the intermediate layers of a deep CNN using a separate CNN followed by a multi-task learning algorithm that operates on the fused features.",method,2
8086,It exploits the synergy among the tasks which boosts up their individual performances.,method,2
8087,"Additionally, we propose two variants of HyperFace: (1) HyperFace-ResNet that builds on the ResNet-101 model and achieves significant improvement in performance, and (2) Fast-HyperFace that uses a high recall fast face detector for generating region proposals to improve the speed of the algorithm.",method,2
8088,Extensive experiments show that the proposed models are able to capture both global and local information in faces and performs significantly better than many competitive algorithms for each of these four tasks.,result,3
8089,This paper describes the five development stages of the rope human parasite.,background,0
8090,Rope parasites have been discovered as a result of cleansing enemas.,background,0
8091,Parasite adult stages live in human gastrointestinal tract and are anaerobic.,background,0
8092,They move inside the body by releasing gas bubbles utilizing jet propulsion.,background,0
8093,"Rope parasites look like a rope, and can be over a meter long.",background,0
8094,It takes tens of years for them to fully develop into mature species (fifth stage).,result,3
8095,"The fourth stage looks similar, but the parasite is shorter and has softer slimier body.",result,3
8096,The third stage looks like branched jellyfish.,result,3
8097,"The second stage is viscous snot, or mucus with visible gas bubbles that act as suction cups.",background,0
8098,"The first stage is slimier mucus with fewer bubbles, which can reside almost anywhere in the body.",background,0
8099,"We give an overview of the scripting languages used in existing cryptocurrencies, and in particular we review in some detail the scripting languages of Bitcoin, Nxt and Ethereum, in the context of a high-level overview of Distributed Ledger Technology and cryptocurrencies.",background,0
8100,"We survey different approaches, and give an overview of critiques of existing languages.",method,2
8101,"We also cover technologies that might be used to underpin extensions and innovations in scripting and contracts, including technologies for verification, such as zero knowledge proofs, proof-carrying code and static analysis, as well as approaches to making systems more efficient, e.g. Merkelized Abstract Syntax Trees.",method,2
8102,"Digital divide research has benefitted from theories that account for unevenness between individuals, households, and geographic units in access to, and uses of information and communications technologies (ICTs).",background,0
8103,"The objective of this paper is to explain and examine important digital divide theories, compare and contrast their major features, and identify appropriate methodologies to test them.",objective,1
8104,"Four theories examined are Adoption-Diffusion Theory (ADT), van Dijk's Theory of Digital Technology Access and Societal Impacts, Unified Theory of Acceptance and Use of Technology (UTAUT), and Spatially Aware Technology Utilization Model (SATUM).",objective,1
8105,"The theories are compared based on their independent and outcome factors, units of analysis, spatial components, and amount of scholarly literature.",result,3
8106,"The methodologies utilized depend on sample size and range from varied regression and multinominal logit models to structured equation modeling, event history, and spatial analyses.",method,2
8107,The strengths and weaknesses of the digital divide theories are compared and can inform investigators on appropriate theoretical choice for particular settings.,result,3
8108,Facial sketches are widely used by law enforcement agencies to assist in the identification and apprehension of suspects involved in criminal activities.,background,0
8109,Sketches used in forensic investigations are either drawn by forensic artists (forensic sketches) or created with computer software (composite sketches) following the verbal description provided by an eyewitness or the victim.,background,0
8110,These sketches are posted in public places and in media in hopes that some viewers will provide tips about the identity of the suspect.,background,0
8111,This method of identifying suspects is slow and tedious and may not lead to apprehension of the suspect.,background,0
8112,"Hence, there is a need for a method that can automatically and quickly match facial sketches to large police mugshot databases.",background,0
8113,"We address the problem of automatic facial sketch to mugshot matching and, for the first time, compare the effectiveness of forensic sketches and composite sketches.",method,2
8114,"The contributions of this paper include: (i) a database containing mugshots and corresponding forensic and composite sketches that will be made available to interested researchers; (ii) a comparison of holistic facial representations versus component based representations for sketch to mugshot matching; and (iii) an analysis of the effect of filtering a mugshot gallery using three sources of demographic information (age, gender and race/ethnicity).",method,2
8115,Our experimental results show that composite sketches are matched with higher accuracy than forensic sketches to the corresponding mugshots.,result,3
8116,Both of the face representations studied here yield higher sketch to photo matching accuracy compared to a commercial face matcher.,result,3
8117,The segmentation of cursive and mixed scripts persists to be a difficult problem in the area of handwriting recognition.,background,0
8118,This research details advances for segmenting characters in off-line cursive script.,objective,1
8119,"Specifically, a heuristic algorithm and a neural network-based technique, which uses a structural feature vector representation, are proposed and combined for identifying incorrect segmentation points.",objective,1
8120,"Following the location of appropriate anchorage points, a character extraction technique, using segmentation paths, is employed to complete the segmentation process.",objective,1
8121,"Results are presented for neural-based heuristic segmentation, segmentation point validation, character recognition, segmentation path detection and overall segmentation accuracy.",result,3
8122,Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging.,background,0
8123,Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection.,background,0
8124,High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches.,background,0
8125,"Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers.",objective,1
8126,"We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space.",method,2
8127,"Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution.",method,2
8128,"Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.",result,3
8129,This paper motivates a comprehensive academic study of metadata and the roles that metadata plays in organizational information systems.,background,0
8130,"While the benefits of metadata and challenges in implementing metadata solutions are widely addressed in practitioner publications, explicit discussion of metadata in academic literature is rare.",background,0
8131,"Metadata, when discussed, is perceived primarily as a technology solution.",background,0
8132,Integrated management of metadata and its business value are not well addressed.,background,0
8133,This paper discusses both the benefits offered by and the challenges associated with integrating metadata.,objective,1
8134,It also describes solutions for addressing some of these challenges.,objective,1
8135,The inherent complexity of an integrated metadata repository is demonstrated by reviewing the metadata functionality required in a data warehouse: a decision support environment where its importance is acknowledged.,method,2
8136,Comparing this required functionality with metadata management functionalities offered by data warehousing software products identifies crucial gaps.,method,2
8137,"Based on these analyses, topics for further research on metadata are proposed.",result,3
8138,Received: 31 August 2009 Revised: 25 September 2011 Accepted: 16 October 2011 Abstract This paper offers guidance to conducting a rigorous literature review.,background,0
8139,We present this in the form of a five-stage process in which we use Grounded Theory as a method.,method,2
8140,"We first probe the guidelines explicated by Webster and Watson, and then we show the added value of Grounded Theory for rigorously analyzing a carefully chosen set of studies; it assures solidly legitimized, indepth analyses of empirical facts and related insights.",method,2
8141,"This includes, the emergence of new themes, issues and opportunities; interrelationships and dependencies in or beyond a particular area; as well as inconsistencies.",objective,1
8142,"If carried out meticulously, reviewing a well-carved out piece of literature by following this guide is likely to lead to more integrated and fruitful theory emergence, something that would enrich many fields in the social sciences.",result,3
8143,"European Journal of Information Systems advance online publication, 29 November 2011; doi:10.1057/ejis.2011.51",other,4
8144,State-of-the-art sequence labeling systems traditionally require large amounts of taskspecific knowledge in the form of handcrafted features and data pre-processing.,background,0
8145,"In this paper, we introduce a novel neutral network architecture that benefits from both wordand character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF.",background,0
8146,"Our system is truly end-to-end, requiring no feature engineering or data preprocessing, thus making it applicable to a wide range of sequence labeling tasks on different languages.",background,0
8147,We evaluate our system on two data sets for two sequence labeling tasks — Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER).,method,2
8148,We obtain stateof-the-art performance on both datasets — 97.55% accuracy for POS tagging and 91.21% F1 for NER.,result,3
8149,"We propose Meta-Prod2vec, a novel method to compute item similarities for recommendation that leverages existing item metadata.",background,0
8150,"Such scenarios are frequently encountered in applications such as content recommendation, ad targeting and web search.",background,0
8151,Our method leverages past user interactions with items and their attributes to compute low-dimensional embeddings of items.,method,2
8152,"Specifically, the item metadata is injected into the model as side information to regularize the item embeddings.",method,2
8153,We show that the new item representations lead to better performance on recommendation tasks on an open music dataset.,result,3
8154,"This paper has always been one of my favorite “children,” combining as it does elements of the duality of linear programming and combinatorial tools from graph theory.",background,0
8155,It may be of some interest to tell the story of its origin.,background,0
8156,I spent the summer of 1953 at the Institute for Numerical Analysis which was housed on the U.C.L.A. campus.,background,0
8157,"I was supported by the National Bureau of Standards and shared an office with Ted Motzkin, a pioneer in the theory of inequalities and one of the most scholarly mathematicians I have ever known.",background,0
8158,"I had no fixed duties and spent the summer working on subjects that were of interest to me at the time, such as the traveling salesman problem and the assignment problem.",background,0
8159,"The Institute for Numerical Analysis was the home of the SWAC (Standards Western Automatic Computer), which had been designed by Harry Huskey and had a memory of 256 words of 40 bits each on 40 Williamson tubes.",background,0
8160,"The formulation of the assignment problem as a linear program was well known, but a 10 by 10 assignment problem has 100 variables in its primal statement and 100 constraints in the dual and so was too large for the SWAC to solve as a linear program.",method,2
8161,"The SEAC (Standard Eastern Automatic Computer), housed in the National Bureau of Standards in Washington, could solve linear programs with about 25 variables and 25 constraints.",method,2
8162,The SEAC had a liquid mercury memory system which was extremely limiting.,method,2
8163,"During that summer, I was reading König’s book on graph theory.",method,2
8164,"In this paper, we propose an approximate multiplier that is high speed yet energy efficient.",objective,1
8165,The approach is to round the operands to the nearest exponent of two.,objective,1
8166,This way the computational intensive part of the multiplication is omitted improving speed and energy consumption at the price of a small error.,method,2
8167,The proposed approach is applicable to both signed and unsigned multiplications.,objective,1
8168,We propose three hardware implementations of the approximate multiplier that includes one for the unsigned and two for the signed operations.,method,2
8169,The efficiency of the proposed multiplier is evaluated by comparing its performance with those of some approximate and accurate multipliers using different design parameters.,result,3
8170,"In addition, the efficacy of the proposed approximate multiplier is studied in two image processing applications, i.e., image sharpening and smoothing.",result,3
8171,"STORM, presented in this paper, is a UML-based software engineering tool designed for the purpose of automating as much of the requirements specification phase as possible.",background,0
8172,The main idea of the STORM approach is to combine adequate requirements writing with robust use case modelling in order to expedite the process leading up to the actual design of the software.,background,0
8173,"This paper presents a description of our approach to software requirements specification as well as an overview of STORM’s design concepts, organizing principles, and modes of operation.",method,2
8174,"Also included are examples of the tool’s use, a comparison between STORM and similar CASE tools, and a discussion of needed features for software environments that support text aspects of requirements and use case modelling.",method,2
8175,We propose to train trading systems by optimizing financial objective functions via reinforcement learning.,objective,1
8176,"The performance functions that we consider are profit or wealth, the Sharpe ratio and our recently proposed differential Sharpe ratio for online learning.",background,0
8177,"In Moody & Wu (1997), we presented empirical results that demonstrate the advantages of reinforcement learning relative to supervised learning.",method,2
8178,Here we extend our previous work to compare Q-Learning to our Recurrent Reinforcement Learning (RRL) algorithm.,method,2
8179,"We provide new simulation results that demonstrate the presence of predictability in the monthly S&P 500 Stock Index for the 25 year period 1970 through 1994, as well as a sensitivity analysis that provides economic insight into the trader's structure.",result,3
8180,Social media provides a platform for seeking information from a large user base.,background,0
8181,"Information seeking in social media, however, occurs simultaneously with users expressing their viewpoints by making statements.",background,0
8182,Rhetorical questions have the form of a question but serve the function of a statement and might mislead platforms assisting information seeking in social media.,background,0
8183,It becomes difficult to identify rhetorical questions as they are not syntactically different from other questions.,background,0
8184,"In this paper, we develop a framework to identify rhetorical questions by modeling the motivations of the users to post them.",objective,1
8185,"We focus on one motivation of the users drawing from linguistic theories, to implicitly convey a message.",method,2
8186,We develop a framework from this motivation to identify rhetorical questions in social media and evaluate the framework using questions posted on Twitter.,method,2
8187,This is the first framework to model the motivations for posting rhetorical questions to identify them on social,method,2
8188,"The objective of the tutorial is to introduce attendees to Activity Theory, a general theoretical framework for the analysis of human and communal action in the world.",objective,1
8189,"After an overview of the theory, focus shifts to how this framework can be utilized in practice.",method,2
8190,Some examples are shown of how this framework can provide a fresh perspective on certain extant problems in the fields of HCI and CSCW.,method,2
8191,"Hopefully, participants become more aware of the nature and complexity of current controversies concerning the role of theory in the design of computer artifacts.",method,2
8192,"By the end of the tutorial, participants should be able to understand the basic principles of the approach, and to describe their work activities in ways illuminated by this framework",result,3
8193,The increasing integration of the Internet of Everything into the industrial value chain has built the foundation for the next industrial revolution called Industrie 4.0.,background,0
8194,"Although Industrie 4.0 is currently a top priority for many companies, research centers, and universities, a generally accepted understanding of the term does not exist.",background,0
8195,"As a result, discussing the topic on an academic level is difficult, and so is implementing Industrie 4.0 scenarios.",background,0
8196,"Based on a quantitative text analysis and a qualitative literature review, the paper identifies design principles of Industrie 4.0.",objective,1
8197,"Taking into account these principles, academics may be enabled to further investigate on the topic, while practitioners may find assistance in identifying appropriate scenarios.",method,2
8198,A case study illustrates how the identified design principles support practitioners in identifying Industrie 4.0 scenarios.,result,3
8199,Optimization problems involving the eigenvalues of symmetric and nonsymmetric matrices present a fascinating mathematical challenge.,background,0
8200,"Such problems arise often in theory and practice, particularly in engineering design, and are amenable to a rich blend of classical mathematical techniques and contemporary optimization theory.",background,0
8201,"This essay presents a personal choice of some central mathematical ideas, outlined for the broad optimization community.",objective,1
8202,"I discuss the convex analysis of spectral functions and invariant matrix norms, touching briefly on semidefinite representability, and then outlining two broader algebraic viewpoints based on hyperbolic polynomials and Lie algebra.",method,2
8203,Analogous nonconvex notions lead into eigenvalue perturbation theory.,method,2
8204,"The last third of the article concerns stability, for polynomials, matrices, and associated dynamical systems, ending with a section on robustness.",method,2
8205,"The powerful and elegant language of nonsmooth analysis appears throughout, as a unifying narrative thread.",result,3
8206,We present a hierarchical model that learns image decompositions via alternating layers of convolutional sparse coding and max pooling.,objective,1
8207,"When trained on natural images, the layers of our model capture image information in a variety of forms: low-level edges, mid-level edge junctions, high-level object parts and complete objects.",background,0
8208,"To build our model we rely on a novel inference scheme that ensures each layer reconstructs the input, rather than just the output of the layer directly beneath, as is common with existing hierarchical approaches.",method,2
8209,"This makes it possible to learn multiple layers of representation and we show models with 4 layers, trained on images from the Caltech-101 and 256 datasets.",objective,1
8210,"When combined with a standard classifier, features extracted from these models outperform SIFT, as well as representations from other feature learning methods.",method,2
8211,"We built a research model based on a benefit–risk paradigm, and tested the moderating effects of trust propensity and gender in relationship to the impacts of perceived benefits and risks on user online behavior.",background,0
8212,Results showed that gender moderated the impact of perceived benefit on one’s intention to purchase.,result,3
8213,Trust propensity was found to moderate the relationship between perceived risk and overall satisfaction.,result,3
8214,"In addition, we found that the interaction of trust propensity and gender played a significant joint moderating role in affecting the impact of perceived benefit on intention to purchase.",result,3
8215,Men with high trust propensity belief are the most benefit oriented consumer group.,result,3
8216,Implications for both research and practice are discussed.,result,3
8217,2014 Elsevier Ltd.,other,4
8219,"In any competitive business, success is based on the ability to make an item more appealing to customers than the competition.",background,0
8220,A number of questions arise in the context of this task: how do we formalize and quantify the competitiveness between two items?,background,0
8221,Who are the main competitors of a given item?,background,0
8222,What are the features of an item that most affect its competitiveness?,background,0
8223,"Despite the impact and relevance of this problem to many domains, only a limited amount of work has been devoted toward an effective solution.",background,0
8224,"In this paper, we present a formal definition of the competitiveness between two items, based on the market segments that they can both cover.",method,2
8225,"Our evaluation of competitiveness utilizes customer reviews, an abundant source of information that is available in a wide range of domains.",method,2
8226,We present efficient methods for evaluating competitiveness in large review datasets and address the natural problem of finding the top-k competitors of a given item.,method,2
8227,"Finally, we evaluate the quality of our results and the scalability of our approach using multiple datasets from different domains.",result,3
8228,The main contribution of this paper is a simple semisupervised pipeline that only uses the original training set without collecting extra data.,objective,1
8229,It is challenging in 1) how to obtain more training data only from the training set and 2) how to use the newly generated data.,objective,1
8230,"In this work, the generative adversarial network (GAN) is used to generate unlabeled samples.",method,2
8231,We propose the label smoothing regularization for outliers (LSRO).,objective,1
8232,"This method assigns a uniform label distribution to the unlabeled images, which regularizes the supervised model and improves the baseline.",method,2
8233,We verify the proposed method on a practical problem: person re-identification (re-ID).,method,2
8234,This task aims to retrieve a query person from other cameras.,objective,1
8235,"We adopt the deep convolutional generative adversarial network (DCGAN) for sample generation, and a baseline convolutional neural network (CNN) for representation learning.",method,2
8236,Experiments show that adding the GAN-generated data effectively improves the discriminative ability of learned CNN embeddings.,result,3
8237,"On three large-scale datasets, Market- 1501, CUHK03 and DukeMTMC-reID, we obtain +4.37%, +1.6% and +2.46% improvement in rank-1 precision over the baseline CNN, respectively.",result,3
8238,"Chatbots are one class of intelligent, conversational software agents activated by natural language input (which can be in the form of text, voice, or both).",background,0
8239,"They provide conversational output in response, and if commanded, can sometimes also execute tasks.",objective,1
8240,"Although chatbot technologies have existed since the 1960’s and have influenced user interface development in games since the early 1980’s, chatbots are now easier to train and implement.",background,0
8241,"This is due to plentiful open source code, widely available development platforms, and implementation options via Software as a Service (SaaS).",objective,1
8242,"In addition to enhancing customer experiences and supporting learning, chatbots can also be used to engineer social harm that is, to spread rumors and misinformation, or attack people for posting their thoughts and opinions online.",objective,1
8243,This paper presents a literature review of quality issues and attributes as they relate to the contemporary issue of chatbot development and implementation.,result,3
8244,"Finally, quality assessment approaches are reviewed, and a quality assessment method based on these attributes and the Analytic Hierarchy Process (AHP) is proposed and examined.",result,3
8245,"Next month, you will have your final examinations.",background,0
8246,"After calculating your average scores for each course, you are sure that you can get high distinctions in almost all courses.",method,2
8247,"You have finished reviewing all lecture materials, all tutorial materials, and all textbooks.",method,2
8248,"However, there are still four weeks before the examination.",method,2
8249,"Since you have extra time available, you plan to buy a book about your major to do some extra preparation.",method,2
8250,The first needs a lot of data and suffers from covariate shift.,method,2
8251,It’s a supervised learning method when we fit the state-action pair mapping.,method,2
8252,The latter finds a cost function under which the expert is uniquely optimal.,method,2
8253,"Compounding error is not a problem here, but IRL is super data inefficiend and requires RL in the inner loop.",result,3
8254,"Since we only interested in the final policy, why do we learn the cost function?",result,3
8255,"So, GAIL was born.",other,4
8256,"The goal of this paper is not to introduce a single algorithm or method, but to make theoretical steps towards fully understanding the training dynamics of generative adversarial networks.",objective,1
8257,"In order to substantiate our theoretical analysis, we perform targeted experiments to verify our assumptions, illustrate our claims, and quantify the phenomena.",method,2
8258,This paper is divided into three sections.,background,0
8259,The first section introduces the problem at hand.,method,2
8260,The second section is dedicated to studying and proving rigorously the problems including instability and saturation that arize when training generative adversarial networks.,method,2
8261,"The third section examines a practical and theoretically grounded direction towards solving these problems, while introducing new tools to study them.",method,2
8262,Interest in multimodal optimization function is expanding rapidly since real-world optimization problems often require the location of multiple optima in the search space.,background,0
8263,"In this context, fitness sharing has been used widely to maintain population diversity and permit the investigation of many peaks in the feasible domain.",background,0
8264,This paper reviews various strategies of sharing and proposes new recombination schemes to improve its efficiency.,objective,1
8265,Some empirical results are presented for high and a limited number of fitness function evaluations.,result,3
8266,"Finally, the study compares the sharing method with other niching techniques.",result,3
8267,The ability to verify the integrity of video files is important for consumer and business applications alike.,background,0
8268,"Especially if video files are to be used as evidence in court, the ability to prove that a file existed in a certain state at a specific time and was not altered since is crucial.",background,0
8269,This paper proposes the use of blockchain technology to secure and verify the integrity of video files.,objective,1
8270,"To demonstrate a specific use case for this concept, we present an application that converts a videocamera enabled smartphone into a cost-effective tamperproof dashboard camera (dash cam).",method,2
8271,"If the phone’s built-in sensors detect a collision, the application automatically creates a hash of the relevant video recording.",method,2
8272,"This video file’s hash is immediately transmitted to the OriginStamp service, which includes the hash in a transaction made to the Bitcoin network.",background,0
8273,"Once the Bitcoin network confirms the transaction, the video file’s hash is permanently secured in the tamperproof decentralized public ledger that is the blockchain.",method,2
8274,"Any subsequent attempt to manipulate the video is futile, because the hash of the manipulated footage will not match the hash that was secured in the blockchain.",method,2
8275,"Using this approach, the integrity of video evidence cannot be contested.",background,0
8276,The footage of dashboard cameras could become a valid form of evidence in court.,background,0
8277,Run-time reconfiguration of FPGAs has been around in academia for more than two decades but it is still applied very seldom in industrial applications.,background,0
8278,This has two main reasons: a lack of killer applications that substantially benefit from run-time reconfiguration and design tools that permit to quickly implement corresponding reconfigurable systems.,background,0
8279,"This tutorial gives a survey on state-of-the-art trends on reconfigurable architectures and devices, application specific requirements, and design techniques and tools that are essential for implementing partial run-time reconfiguration on FPGAs.",objective,1
8280,This is followed by a demonstration of the floorplanning and constraint generation tool GoAhead.,method,2
8281,"Furthermore, the tutorial will reveal several applications that benefit from partial reconfiguration, including network data processing, digital signal processing, cognitive radio, and systems on a reconfigurable chip.",method,2
8282,"For these applications, the individual challenges and implementation issues are presented together with the achieved results.",background,0
8283,This tutorial demonstrates that partial FPGA reconfiguration is beneficial and applicable in industrial systems.,result,3
8284,This paper presents a wearable Internet of Things (IoT) sensor node aimed at monitoring harmful environmental conditions for safety applications via LoRa wireless technology.,background,0
8285,The proposed sensor node is low-power and supports multiple environmental sensors.,background,0
8286,A LoRa based gateway is used to connect sensors to the Internet.,method,2
8287,"We mainly focus on monitoring carbon monoxide, carbon dioxide, ultraviolet, and some general environmental parameters.",method,2
8288,Poor environment quality could cause severe health problems to individuals.,method,2
8289,"Therefore, surrounding environmental data is gathered by the wearable node in a real-time manner and then transmitted to a remote cloud server.",method,2
8290,The data can then be displayed to authorized users through a web-based application located in the cloud server and the device will give alert to the user via mobile application when an emergency condition occurs.,method,2
8291,The experimental results indicate that our safety monitoring network can work reliably with low power consumption.,result,3
8292,We present a novel method for detecting 3D model instances and estimating their 6D poses from RGB data in a single shot.,background,0
8293,"To this end, we extend the popular SSD paradigm to cover the full 6D pose space and train on synthetic model data only.",objective,1
8294,Our approach competes or surpasses current state-of-the-art methods that leverage RGBD data on multiple challenging datasets.,method,2
8295,"Furthermore, our method produces these results at around 10Hz, which is many times faster than the related methods.",method,2
8296,"For the sake of reproducibility, we make our trained networks and detection code publicly available.",result,3
8297,"In this paper we present a novel dataset for a critical aspect of autonomous driving, the joint attention that must occur between drivers and of pedestrians, cyclists or other drivers.",background,0
8298,This dataset is produced with the intention of demonstrating the behavioral variability of traffic participants.,objective,1
8299,"We also show how visual complexity of the behaviors and scene understanding is affected by various factors such as different weather conditions, geographical locations, traffic and demographics of the people involved.",objective,1
8300,"The ground truth data conveys information regarding the location of participants (bounding boxes), the physical conditions (e.g. lighting and speed) and the behavior of the parties involved.",method,2
8301,"We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model which is trained and evaluated based on information theoretic constraints.",result,3
8302,"Using the selective exchange of information between a user’s device and a service provider, DPFE enables the user to prevent certain sensitive information from being shared with a service provider, while allowing them to extract approved information using their model.",method,2
8303,"We introduce and utilize the log-rank privacy, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy tradeoff.",result,3
8304,"We then implement and evaluate the performance of DPFE on smartphones to understand its complexity, resource demands, and efficiency tradeoffs.",result,3
8305,"Our results on benchmark image datasets demonstrate that under moderate resource utilization, DPFE can achieve high accuracy for primary tasks while preserving the privacy of sensitive information.",result,3
8306,Hydrogen sulfide (H₂S) has attracted attention in biochemical research because it plays an important role in biosystems and has emerged as the third endogenous gaseous signaling compound along with nitric oxide (NO) and carbon monoxide (CO).,background,0
8307,"Since H₂S is a kind of gaseous molecule, conventional approaches for H₂S detection are mostly based on the detection of sulfide (S2-) for indirectly reflecting H₂S levels.",background,0
8308,"Hence, there is a need for an accurate and reliable assay capable of determining sulfide in physiological systems.",objective,1
8309,"We report here a colorimetric, economic, and green method for sulfide anion detection using in situ formation of silver nanoparticles (AgNPs) using dopamine as a reducing and protecting agent.",method,2
8310,"The changes in the AgNPs absorption response depend linearly on the concentration of Na₂S in the range from 2 to 15 μM, with a detection limit of 0.03 μM. Meanwhile, the morphological changes in AgNPs in the presence of S2- and thiol compounds were characterized by transmission electron microscopy (TEM).",method,2
8311,"The as-synthetized AgNPs demonstrate high selectivity, free from interference, especially by other thiol compounds such as cysteine and glutathione.",method,2
8312,"Furthermore, the colorimetric sensor developed was applied to the analysis of sulfide in fetal bovine serum and spiked serum samples with good recovery.",result,3
8313,The aptamer database is designed to contain comprehensive sequence information on aptamers and unnatural ribozymes that have been generated by in vitro selection methods.,background,0
8314,"Such data are not normally collected in 'natural' sequence databases, such as GenBank.",background,0
8315,"Besides serving as a storehouse of sequences that may have diagnostic or therapeutic utility, the database serves as a valuable resource for theoretical biologists who describe and explore fitness landscapes.",background,0
8316,The database is updated monthly and is publicly available at http://aptamer.,other,4
8317,icmb.utexas.edu/.,other,4
8318,Modern natural language processing (NLP) research requires writing code.,background,0
8319,"Ideally this code would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the research.",background,0
8320,"However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten.",background,0
8321,"This paper describes AllenNLP, a library for applying deep learning methods to NLP research, which addresses these issues with easyto-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions.",method,2
8322,"AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field.",result,3
8323,"Buildings account for nearly 40% of the total energy consumption in the United States, about half of which is used by the HVAC (heating, ventilation, and air conditioning) system.",background,0
8324,Intelligent scheduling of building HVAC systems has the potential to significantly reduce the energy cost.,background,0
8325,"However, the traditional rule-based and model-based strategies are often inefficient in practice, due to the complexity in building thermal dynamics and heterogeneous environment disturbances.",background,0
8326,"In this work, we develop a data-driven approach that leverages the deep reinforcement learning (DRL) technique, to intelligently learn the effective strategy for operating the building HVAC systems.",objective,1
8327,We evaluate the performance of our DRL algorithm through simulations using the widely-adopted EnergyPlus tool.,method,2
8328,"Experiments demonstrate that our DRL-based algorithm is more effective in energy cost reduction compared with the traditional rule-based approach, while maintaining the room temperature within desired range.",result,3
8329,"3D shape models are becoming widely available and easier to capture, making available 3D information crucial for progress in object classification.",background,0
8330,Current state-of-theart methods rely on CNNs to address this problem.,method,2
8331,"Recently, we witness two types of CNNs being developed: CNNs based upon volumetric representations versus CNNs based upon multi-view representations.",background,0
8332,"Empirical results from these two types of CNNs exhibit a large gap, indicating that existing volumetric CNN architectures and approaches are unable to fully exploit the power of 3D representations.",result,3
8333,"In this paper, we aim to improve both volumetric CNNs and multi-view CNNs according to extensive analysis of existing approaches.",result,3
8334,"To this end, we introduce two distinct network architectures of volumetric CNNs.",method,2
8335,"In addition, we examine multi-view CNNs, where we introduce multiresolution filtering in 3D.",method,2
8336,"Overall, we are able to outperform current state-of-the-art methods for both volumetric CNNs and multi-view CNNs.",method,2
8337,"We provide extensive experiments designed to evaluate underlying design choices, thus providing a better understanding of the space of methods available for object classification on 3D data.",result,3
8338,This paper discusses a method for obtaining accurate 3D measurements using a temporally encoded structured light system.,background,0
8339,An objective of the work was to have a balance in the accuracy of all components in the system.,objective,1
8340,This was achieved by including lens distortion in the models for both the camera and projector which comprise the structured light system.,method,2
8341,"In addition, substripe estimation was used to estimate projector stripe values as a complement to subpixel estimators used for locating image features.",result,3
8342,Experimental evaluation shows that it is important to use substripe estimation and incorporate lens distortion in the projector model.,result,3
8343,Aspects of the role of information in strategic decision-making by executives in industry are hardly ever mentioned in management research publications.,background,0
8344,"We therefore investigate in this paper the way information is obtained, analysed, judged and applied by executives in industry that have to take strategic decisions.",objective,1
8345,We interviewed executives from thirteen companies in The Netherlands and in Germany about the stages in the decision process that they followed in thirty two recent decisions they had to make.,method,2
8346,We found that executives that follow a rational approach collect and use ample information in a structured decision-making process passing through a number of distinct phases in time.,background,0
8347,"In this process, information plays a crucial role in reducing uncertainty.",background,0
8348,"Over all discussions held, the aspect of the quality of the information used by the board was stressed.",method,2
8349,We could only obtain circumstantial evidence of changes in the decision making process caused by developments in new information acquisition and analysis methods such as use of the Internet becoming common practice.,result,3
8350,"But we can affirm that with more relevant information available, discussions in the boardroom on issues affecting the choices and etter alternatives can now be b",result,3
8351,"Spin-transfer torque magnetic random access memory (STT-MRAM) is a novel, magnetic memory technology that leverages the base platform established by an existing 100+nm node memory product called MRAM to enable a scalable nonvolatile memory solution for advanced process nodes.",background,0
8352,"STT-MRAM features fast read and write times, small cell sizes of 6F2 and potentially even smaller, and compatibility with existing DRAM and SRAM architecture with relatively small associated cost added.",background,0
8353,STT-MRAM is essentially a magnetic multilayer resistive element cell that is fabricated as an additional metal layer on top of conventional CMOS access transistors.,background,0
8354,"In this review we give an overview of the existing STT-MRAM technologies currently in research and development across the world, as well as some specific discussion of results obtained at Grandis and with our foundry partners.",method,2
8355,"We will show that in-plane STT-MRAM technology, particularly the DMTJ design, is a mature technology that meets all conventional requirements for an STT-MRAM cell to be a nonvolatile solution matching DRAM and/or SRAM drive circuitry.",method,2
8356,"Exciting recent developments in perpendicular STT-MRAM also indicate that this type of STT-MRAM technology may reach maturity faster than expected, allowing even smaller cell size and product introduction at smaller nodes.",result,3
8357,Teenagers are among the most prolific users of social network sites (SNS).,background,0
8358,Emerging studies find that youth spend a considerable portion of their daily life interacting through social media.,background,0
8359,"Subsequently, questions and controversies emerge about the effects SNS have on adolescent development.",background,0
8360,This review outlines the theoretical frameworks researchers have used to understand adolescents and SNS.,objective,1
8361,"It brings together work from disparate fields that examine the relationship between SNS and social capital, privacy, youth safety, psychological well-being, and educational achievement.",objective,1
8362,"These research strands speak to high-profile concerns and controversies that surround youth participation in these online communities, and offer ripe areas for future research.",result,3
8363,"This research essay outlines a set of guidelines for conducting functional Magnetic Resonance Imaging (fMRI) studies in social science research in general and also, accordingly, in Information Systems research.",background,0
8364,"Given the increased interest in using neuroimaging tools across the social sciences, this study aims at specifying the key steps needed to conduct an fMRI study while ensuring that enough detail is provided to evaluate the methods and results.",objective,1
8365,"The outline of an fMRI study consists of four key steps: (1) formulating the research question, (2) designing the fMRI protocol, (3) analyzing fMRI data, and (4) interpreting and reporting fMRI results.",method,2
8366,These steps are described with an illustrative example of a published fMRI study on trust and distrust in this journal (Dimoka 2010).,method,2
8367,"The paper contributes to the methodological literature by (1) providing a set of guidelines for designing and conducting fMRI studies, (2) specifying methodological details that should be included in fMRI studies in academic venues, and (3) illustrating these practices with an exemplar fMRI study.",method,2
8368,Future directions for conducting high-quality fMRI studies in the social sciences are discussed.,result,3
8369,This paper suggests that it may be easier to learn several hard tasks at one time than to learn these same tasks separately.,objective,1
8370,"In effect, the information provided by the training signal for each task serves as a domain-specific inductive bias for the other tasks.",background,0
8371,Frequently the world gives us clusters of related tasks to learn.,background,0
8372,"When it does not, it is often straightforward to create additional tasks.",method,2
8373,"For many domains, acquiring inductive bias by collecting additional teaching signal may be more practical than the traditional approach of codifying domain-specific biases acquired from human expertise.",background,0
8374,We call this approach Multitask Learning (MTL).,method,2
8375,"Since much of the power of an inductive learner follows directly from its inductive bias, multitask learning may yield more powerful learning.",method,2
8376,An empirical example of multitask connectionist learning is presented where learning improves by training one network on several related tasks at the same time.,method,2
8377,Multitask decision tree induction is also outlined.,method,2
8378,The benefits of the flipped classroom (FC) model in students’ learning are claimed in many recent studies.,background,0
8379,These benefits are typically accounted to the pedagogically efficient use of classroom time for engaging students in active learning.,objective,1
8380,"Although there are several relevant studies for the deployment of the FC model in Science, Technology, Engineering and Maths (STEM) subjects, and at Higher Education and/or High School, there are very few works studying FC in social studies and at primary school level.",background,0
8381,This paper presents an action research focused on the implementation of the FC model in teaching social studies in primary school.,objective,1
8382,"The main scope of this action research, conducted over an entire school year with two different History classes (one representing the experimental group that followed the FC model and the other representing the control group following the traditional lecture based approach) was to compare the use of classroom time for student-centered learning activities and the resulted learning outcomes related to both traditional learning goals of a history course (that is, memorization of historical content) and more ambitious ones such as the cultivation of historical thinking skills (HTS).",method,2
8383,"The study revealed that indeed, the classroom based sessions of the experimental group were used for engaging student-centered activities and that this resulted into better learning outcomes in terms of demonstrating critical HTS.",result,3
8384,"Thus, this initial action research provides encouraging evidences for the potential benefits of the FC model in primary school social studies courses.",result,3
8385,We present a lexicon-based approach to extracting sentiment from text.,objective,1
8386,"The Semantic Orientation CALculator (SO-CAL) uses dictionaries of words annotated with their semantic orientation (polarity and strength), and incorporates intensification and negation.",background,0
8387,"SO-CAL is applied to the polarity classification task, the process of assigning a positive or negative label to a text that captures the text's opinion towards its main subject matter.",method,2
8388,We show that SO-CAL's performance is consistent across domains and in completely unseen data.,method,2
8389,"Additionally, we describe the process of dictionary creation, and our use of Mechanical Turk to check dictionaries for consistency and reliability.",method,2
8390,"A new software reliability model is developed that predicts expected failures (and hence related reliability quantities) as well or better than existing software reliability models, and is simpler than any of the models that approach it in predictive validity.",background,0
8391,"The model incorporates both execution time and calendar time components, each of which is derived.",background,0
8392,"The model is evaluated, using actual data, and compared with other models.",background,0
8393,"Soccer is one of the most successful sports of our times, and for various reasons.",background,0
8394,"One such reason is its level of unpredictability: surprising results can occur, and it is still unclear what are the secrets that make a team winning or losing within a single game.",background,0
8395,"In this paper we tackle the problem of soccer analysis from a different perspective: we transform every team, together with the playfield, into a network structure (the Team Brain), and we shift perspective, turning soccer games into battles of minds.",objective,1
8396,"We show how this approach proves to be successful, allowing to better understand what the recipes for the success of a team can be, and also getting a new, somehow surprising, view of what are the really important critical areas of a soccer field.",result,3
8397,"Deep Learning’s recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions.",background,0
8398,"However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities.",background,0
8399,"In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data.",objective,1
8400,"In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.",method,2
8401,Recent studies have confirmed the importance of understanding the cognition of users and information systems (IS) professionals.,background,0
8402,These works agree that organizational cognition is far too critical to be ignored as it can impact on IS outcomes.,background,0
8403,"While cognition has been considered in a variety of IS contexts, no specific methodology has dominated.",background,0
8404,A theory and method suitable to the study of cognition defined as personal constructs that individuals use to understand IT in organizations is Kelly's (1955) Personal Construct Theory and its cognitive mapping tool known as the repertory grid (RepGrid).,method,2
8405,This article expounds on the potential of this technique to IS researchers by considering the variety of ways the RepGrid may be employed.,method,2
8406,The flexibility of the RepGrid is illustrated by examining published studies in IS.,background,0
8407,The diagnostic qualities of the RepGrid and its mapping outcomes can be used for practical intervention at the individual and organizational levels.,result,3
8408,"When answering a question, people often draw upon their rich world knowledge in addition to some task-specific context.",background,0
8409,"Recent work has focused primarily on answering questions based on some relevant document or content, and required very little general background.",background,0
8410,"To investigate question answering with prior knowledge, we present COMMONSENSEQA: a difficult new dataset for commonsense question answering.",objective,1
8411,"To capture common sense beyond associations, each question discriminates between three target concepts that all share the same relationship to a single source drawn from CONCEPTNET (Speer et al., 2017).",method,2
8412,"This constraint encourages crowd workers to author multiple-choice questions with complex semantics, in which all candidates relate to the subject in a similar way.",result,3
8413,"We create 9,500 questions through this procedure and demonstrate the dataset’s difficulty with a large number of strong baselines.",result,3
8414,"Our best baseline, the OpenAI GPT (Radford et al., 2018), obtains 54.8% accuracy, well below human performance, which is 95.3%.",result,3
8415,The Personalization of information has taken recommender systems at a very high level.,background,0
8416,With personalization these systems can generate user specific recommendations accurately and efficiently.,background,0
8417,"User profiling helps personalization, where information retrieval is done to personalize a scenario which maintains a separate user profile for individual user.",background,0
8418,"The main objective of this paper is to explore this field of personalization in context of user profiling, to help researchers make aware of the user profiling.",objective,1
8419,"Various trends, techniques and Applications have been discussed in paper which will fulfill this motto.",method,2
8420,"Index Terms : Personalization, Profiling, User Profiling, Machine Learning, Information Retrieval, Recommender Systems",method,2
8421,Transportation is a necessary infrastructure for our modern society.,background,0
8422,"The performance of transportation systems is of crucial importance for individual mobility, commerce, and for the economic growth of all nations.",background,0
8423,"In recent years modern society has been facing more traffic jams, higher fuel prices, and an increase in CO2 emissions.",background,0
8424,It is imperative to improve the safety and efficiency of transportation.,background,0
8425,"Developing a sustainable intelligent transportation system requires the seamless integration and interoperability with emerging technologies such as connected vehicles, cloud computing, and the Internet of Things.",background,0
8426,"In this article we present and discuss some of the integration challenges that must be addressed to enable an intelligent transportation system to address issues facing the transportation sector such as high fuel prices, high levels of CO2 emissions, increasing traffic congestion, and improved road safety.",objective,1
8427,This paper gives a review of the recent developments in deep learning and unsupervised feature learning for time-series problems.,objective,1
8428,"While these techniques have shown promise for modeling static data, such as computer vision, applying them to time-series data is gaining increasing attention.",background,0
8429,This paper overviews the particular challenges present in time-series data and provides a review of the works that have either applied time-series data to unsupervised feature learning algorithms or alternatively have contributed to modi cations of feature learning algorithms to take into account the challenges present in time-series data.,background,0
8430,"The present research seeks to extend existing theory on self-disclosure to the online arena in higher educational institutions and contribute to the knowledge base and understanding about the use of a popular social networking site (SNS), Facebook, by college students.",objective,1
8431,"We conducted a non-experimental study to investigate how university students (N = 463) use Facebook, and examined the roles that personality and culture play in disclosure of information in online SNS-based environments.",objective,1
8432,"Results showed that individuals do disclose differently online vs. in-person, and that both culture and personality matter.",result,3
8433,"Specifically, it was found that collectivistic individuals low on extraversion and interacting in an online environment disclosed the least honest and the most audience-relevant information, as compared to others.",method,2
8434,Exploratory analyses also indicate that students use sites such as Facebook primarily to maintain existing personal relationships and selectively used privacy settings to control their self-presentation on SNSs.,method,2
8435,"The findings of this study offer insight into understanding college students’ self-disclosure on SNS, add to the literature on personality and self-disclosure, and shape future directions for research and practice on online self-presentation.",result,3
8436,Published by Elsevier Ltd.,other,4
8437,Convolutional neural networks (CNNs) achieved impressive recognition rates in image classification tasks recently.,background,0
8438,"In order to exploit those capabilities, we trained CNNs on a database of photometric stereo images of metal surface defects, i.e. rail defects.",background,0
8439,Those defects are cavities in the rail surface and are indication for further surface degradation right up to rail break.,background,0
8440,"Due to security issues, defects have to be recognized early in order to take countermeasures in time.",background,0
8441,"By means of differently colored light-sources illuminating the rail surfaces from different and constant directions, those cavities are made visible in a photometric dark-field setup.",background,0
8442,"So far, a model-based approach has been used for image classification, which expressed the expected reflection properties of surface defects in contrast to non-defects.",objective,1
8443,"In this work, we experimented with classical CNNs trained in pure supervised manner and also explored the impact of regularization methods such as unsupervised layer-wise pre-training and training data-set augmentation.",method,2
8444,The classical CNN already distinctly outperforms the model-based approach.,method,2
8445,"Moreover, regularization methods yet yield further improvements.",result,3
8446,"Requirements analysis and general management issues within the development process of new software components are addressed in this paper, focusing on factors that result from requirements elicitation and significantly affect management decisions and development activities.",background,0
8447,"A new methodology performing a certain form of requirements identification and collection prior to developing new software components is proposed and demonstrated, the essence of which lays on a three-entity model that describes the relationship between different types of component stakeholders: Developers, reusers and end-users.",method,2
8448,"The model is supported by a set of critical factors analysed in the context of three main directions that orient the production of a new component, that is, the generality of the services offered, the management approach and the characteristics of the targeted market.",method,2
8449,The investigation of the three directions produces critical success factors that are closely connected and interdependent.,result,3
8450,Further analysis of the significance of each factor according to the priorities set by component developers can provide a detail picture of potential management implications during the development process and more importantly can support management decisions related to if and how development should proceed.,result,3
8451,We present some new results on the nonparametric estimation of entropy and mutual information.,objective,1
8452,"First, we use an exact local expansion of the entropy function to prove almost sure consistency and central limit theorems for three of the most commonly used discretized information estimators.",method,2
8453,The setup is related to Grenander's method of sieves and places no assumptions on the underlying probability measure generating the data.,method,2
8454,"Second, we prove a converse to these consistency theorems, demonstrating that a misapplication of the most common estimation techniques leads to an arbitrarily poor estimate of the true information, even given unlimited data.",method,2
8455,"This inconsistency theorem leads to an analytical approximation of the bias, valid in surprisingly small sample regimes and more accurate than the usual formula of Miller and Madow over a large region of parameter space.",result,3
8456,"The two most practical implications of these results are negative: (1) information estimates in a certain data regime are likely contaminated by bias, even if bias-corrected estimators are used, and (2) confidence intervals calculated by standard techniques drastically underestimate the error of the most common estimation methods.",result,3
8457,"Finally, we note a very useful connection between the bias of entropy estimators and a certain polynomial approximation problem.",result,3
8458,"By casting bias calculation problems in this approximation theory framework, we obtain the best possible generalization of known asymptotic bias results.",method,2
8459,"More interesting, this framework leads to an estimator with some nice properties: the estimator comes equipped with rigorous bounds on the maximum error over all possible underlying probability distributions, and this maximum error turns out to be surprisingly small.",result,3
8460,We demonstrate the application of this new estimator on both real and simulated data.,result,3
8461,Sorting has been a profound area for the algorithmic researchers and many resources are invested to suggest more works for sorting algorithms.,background,0
8462,"For this purpose, many existing sorting algorithms were observed in terms of the efficiency of the algorithmic complexity.",background,0
8463,In this paper we implemented the bubble sort algorithm using multithreading (OpenMP).,method,2
8464,The proposed work tested on two standard datasets (text file) with different size .,method,2
8465,The main idea of the proposed algorithm is distributing the elements of the input datasets into many additional temporary subarrays according to a number of characters in each word.,objective,1
8466,The sizes of each of these sub-arrays are decided depending on a number of elements with the same number of characters in the input array.,method,2
8467,"We implemented OpenMP using Intel core i7-3610QM ,(8 CPUs),using two approaches (vectores of string and array 3D) .",method,2
8468,"Finally, we get the data structure effects on the performance of the algorithm for that we choice the second approach.",result,3
8469,"Keywords— Bubble sort, OpemMP, sorting algorithms, parallel computing, Parallelize Bubble algorithm",result,3
8470,The two fundamental problems in machine learning (ML) are statistical analysis and algorithm design.,background,0
8471,The former tells us the principles of the mathematical models that we establish from the observation data.,background,0
8472,The latter defines the conditions on which implementation of data models and data sets rely.,background,0
8473,"A newly discovered challenge to ML is the Rashomon effect, which means that data are possibly generated from a mixture of heterogeneous sources.",result,3
8474,A simple classification standard can shed light on emerging forms of ML.,method,2
8475,This article is part of a special issue on AI in China.,other,4
8476,"To help the blind people walk to the destination efficiently and safely in indoor environment, a novel wearable navigation device is presented in this paper.",background,0
8477,"The locating, way-finding, route following, and obstacle avoiding modules are the essential components in a navigation system, while it remains a challenging task to consider obstacle avoiding during route following, as the indoor environment is complex, changeable, and possibly with dynamic objects.",background,0
8478,"To address this issue, we propose a novel scheme which utilizes a dynamic subgoal selecting strategy to guide the users to the destination and help them bypass obstacles at the same time.",method,2
8479,This scheme serves as the key component of a complete navigation system deployed on a pair of wearable optical see-through glasses for the ease of use of blind people’s daily walks.,method,2
8480,The proposed navigation device has been tested on a collection of individuals and proved to be effective on indoor navigation tasks.,result,3
8481,"The sensors embedded are of low cost, small volume, and easy integration, making it possible for the glasses to be widely used as a wearable consumer device.",result,3
8482,Experience replay lets online reinforcement learning agents remember and reuse experiences from the past.,background,0
8483,"In prior work, experience transitions were uniformly sampled from a replay memory.",background,0
8484,"However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance.",background,0
8485,"In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently.",objective,1
8486,"We use prioritized experience replay in the Deep Q-Network (DQN) algorithm, which achieved human-level performance in Atari games.",method,2
8487,"DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 42 out of 57 games.",method,2
8488,Process capability indices CPU and CPL have been widely used in the microelectronics manufacturing industry as capability measures for processes with one-sided specification limits.,background,0
8489,"In this paper, the theory of statistical hypothesis testing is implemented for normal processes, using the uniformly minimum variance unbiased estimators of CPU and CPL.",method,2
8490,Efficient SAS computer programs are provided to calculate the critical values and the p-values required for making decisions.,method,2
8491,Useful critical values for some commonly used capability requirements are tabulated.,method,2
8492,Based on the test a simple but practical step-by-step procedure is developed for in-plant applications.,method,2
8493,An example on the voltage level translator manufacturing process is given to illustrate how the proposed procedure may be applied to test whether the process meets the preset capability requirement.,result,3
8494,2002 Elsevier Science Ltd.,other,4
8496,Collaborative filtering has been extensively studied in the context of ratings prediction.,background,0
8497,"However, industrial recommender systems often aim at predicting a few items of immediate interest to the user, typically products that (s)he is likely to buy in the near future.",background,0
8498,"In a collaborative filtering setting, the prediction may be based on the user's purchase history rather than rating information, which may be unreliable or unavailable.",background,0
8499,"In this paper, we present an experimental evaluation of various collaborative filtering algorithms on a real-world dataset of purchase history from customers in a store of a French home improvement and building supplies chain.",objective,1
8500,These experiments are part of the development of a prototype recommender system for salespeople in the store.,method,2
8501,"We show how different settings for training and applying the models, as well as the introduction of domain knowledge may dramatically influence both the absolute and the relative performances of the different algorithms.",method,2
8502,"To the best of our knowledge, the influence of these parameters on the quality of the predictions of recommender systems has rarely been reported in the literature.",result,3
8503,A 125 KHz wake-up receiver to receive wake-up signal and a 433MHz data transmitter to transmit temperature and pressure data of the tire to central control module for battery-less TPMS (Tire Pressure Monitoring System) are presented in this paper.,background,0
8504,The receiver adopts dual-channel to improve reliability and logarithmic amplifier to achieve ASK demodulation and dynamic range compression.,background,0
8505,The receiver is implemented in 0.35μm BCD process.,background,0
8506,Maximum data rate is 35Kbps with 0.5mVpp sensitivity and 5μA typical power consumption.,background,0
8507,The transmitter is implemented in 0.18μm process.,background,0
8508,"The typical power consumption is 7.3mA with a transmit power of −10 dBm@433.9 MHz, and phase noise of the PLL is − 103dBc/Hz@ 300 KHz with 30Kbps data rate.",result,3
8509,"Computational neuroscience has produced a diversity of software for simulations of networks of spiking neurons, with both negative and positive consequences.",background,0
8510,"On the one hand, each simulator uses its own programming or configuration language, leading to considerable difficulty in porting models from one simulator to another.",background,0
8511,This impedes communication between investigators and makes it harder to reproduce and build on the work of others.,background,0
8512,"On the other hand, simulation results can be cross-checked between different simulators, giving greater confidence in their correctness, and each simulator has different optimizations, so the most appropriate simulator can be chosen for a given modelling task.",objective,1
8513,A common programming interface to multiple simulators would reduce or eliminate the problems of simulator diversity while retaining the benefits.,objective,1
8514,"PyNN is such an interface, making it possible to write a simulation script once, using the Python programming language, and run it without modification on any supported simulator (currently NEURON, NEST, PCSIM, Brian and the Heidelberg VLSI neuromorphic hardware).",method,2
8515,"PyNN increases the productivity of neuronal network modelling by providing high-level abstraction, by promoting code sharing and reuse, and by providing a foundation for simulator-agnostic analysis, visualization and data-management tools.",result,3
8516,PyNN increases the reliability of modelling studies by making it much easier to check results on multiple simulators.,objective,1
8517,PyNN is open-source software and is available from http://neuralensemble.org/PyNN.,objective,1
8518,"We present a large-scale dataset, ReCoRD, for machine reading comprehension requiring commonsense reasoning.",background,0
8519,Experiments on this dataset demonstrate that the performance of state-of-the-art MRC systems fall far behind human performance.,background,0
8520,ReCoRD represents a challenge for future research to bridge the gap between human and machine commonsense reading comprehension.,objective,1
8521,ReCoRD is available at http://nlp.jhu.edu/record.,other,4
8522,Convolutional neural networks (CNNs) have been successfully applied to many recognition and learning tasks using a universal recipe; training a deep model on a very large dataset of supervised examples.,background,0
8523,"However, this approach is rather restrictive in practice since collecting a large set of labeled images is very expensive.",background,0
8524,One way to ease this problem is coming up with smart ways for choosing images to be labelled from a very large collection (i.e. active learning).,background,0
8525,Our empirical study suggests that many of the active learning heuristics in the literature are not effective when applied to CNNs in batch setting.,objective,1
8526,"Inspired by these limitations, we define the problem of active learning as core-set selection, i.e. choosing set of points such that a model learned over the selected subset is competitive for the remaining data points.",background,0
8527,We further present a theoretical result characterizing the performance of any selected subset using the geometry of the datapoints.,background,0
8528,"As an active learning algorithm, we choose the subset which is expected to yield best result according to our characterization.",background,0
8529,Our experiments show that the proposed method significantly outperforms existing approaches in image classification experiments by a large margin.,method,2
8530,We report a simulation program for indoor visible light communication environment based on MATLAB and Simulink.,background,0
8531,The program considers the positions of the transmitters and the reflections at each wall.,objective,1
8532,"For visible light communication environment, the illumination light-emitting diode is used not only as a lighting device, but also as a communication device.",method,2
8533,"Using the simulation program, the distributions of illuminance and root-mean-square delay spread are analyzed at bottom surface.",method,2
8534,"In many real-world reinforcement learning problems, an agent needs to control multiple actions simultaneously.",background,0
8535,"To learn under this circumstance, previously, each action was commonly treated independently with other.",background,0
8536,"However, these multiple actions are rarely independent in applications, and it could be helpful to accelerate the learning if the underlying relationship among the actions is utilized.",background,0
8537,This paper explores multi-action relationship in reinforcement learning.,objective,1
8538,We propose to learn the multi-action relationship by enforcing a regularization term capturing the relationship.,method,2
8539,"We incorporate the regularization term into the least-square policy-iteration and the temporal-difference methods, which result efficiently solvable convex learning objectives.",method,2
8540,The proposed methods are validated empirically in several domains.,method,2
8541,Experiment results show that incorporating multi-action relationship can effectively improve the learning performance.,result,3
8542,"Simultaneous tracking of multiple persons in real-world environments is an active research field and several approaches have been proposed, based on a variety of features and algorithms.",background,0
8543,"Recently, there has been a growing interest in organizing systematic evaluations to compare the various techniques.",background,0
8544,"Unfortunately, the lack of common metrics for measuring the performance of multiple object trackers still makes it hard to compare their results.",objective,1
8545,"In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time.",objective,1
8546,"These metrics have been extensively used in two large-scale international evaluations, the 2006 and 2007 CLEAR evaluations, to measure and compare the performance of multiple object trackers for a wide variety of tracking tasks.",method,2
8547,Selected performance results are presented and the advantages and drawbacks of the presented metrics are discussed based on the experience gained during the evaluations.,result,3
8548,"Positive identification (ID) verification of a large number of people (possibly thousands) in a short time, such as when people enter the gates of a manufacturing plant in the morning, can be a daunting task for the security guards.",background,0
8549,"Current methods that use a password, card swipe system, proximity card reader system, or combination are slow and vulnerable.",method,2
8550,"For example a card can be stolen or a password forgotten, copied or given to an unauthorized person.",result,3
8551,Hence the need for biometric-based access control systems (ACS).,result,3
8552,"Many biometric systems address the ID verification problem; however, none provide quick and convenient positive (reliable) ID.",objective,1
8553,"Fingerprinting is unreliable and requires too much cooperation, face recognition systems (FRS) are unacceptable in a one-to-many application, and iris scan is slow and cumbersome.",result,3
8554,"In this paper, we describe a fast access control technology solution (FACTS) system we developed and demonstrated at Honeywell Labs that enables many motorists to enter a secured parking lot without coming to a complete stop.",method,2
8555,"The FACTS solution combines radio frequency identification (RFID) tags with FRS, reducing the one-to-many FRS problem by using a one-to-one match for facial verification (FV).",method,2
8556,"This solution is dynamic, secure, positive, and hands-free for fast gate access control.",result,3
8557,At the heart of the Honeywell FV system is a unique tri-band imaging (TBI) camera that reliably locates and records the face of an individual or driver in motion while entering a gate.,result,3
8558,A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models.,background,0
8559,"We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality.",background,0
8560,"In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible.",background,0
8561,We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems.,method,2
8562,We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution.,result,3
8563,"Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.",result,3
8564,This paper utilizes agent-based simulation to compare different market making strategies for high frequency traders (HFTs).,background,0
8565,"After proposing a model representing HFTs' activities in financial market when they act as market makers, we carry out simulations to explore how different quoting strategies affect their profit.",objective,1
8566,"The results show that combination of (i) offering prices based on the latest trading price, and (ii) using the information about market volatility and order imbalance, increase market makers' daily returns.",result,3
8567,"In addition, other scenarios including the competition environment of increased competitors and decreased latencies are incorporated in the model, in order to find out how these factors change the performance of market making strategy.",result,3
8568,"The Internet of Things (IoT) is defined as a paradigm in which objects equipped with sensors, actuators, and processors communicate with each other to serve a meaningful purpose.",background,0
8569,"In this paper, we survey state-of-the-art methods, protocols, and applications in this new emerging area.",method,2
8570,"This survey paper proposes a novel taxonomy for IoT technologies, highlights some of the most important technologies, and profiles some applications that have the potential to make a striking difference in human life, especially for the differently abled and the elderly.",method,2
8571,"As compared to similar survey papers in the area, this paper is far more comprehensive in its coverage and exhaustively covers most major technologies spanning from sensors to applications.",result,3
8572,Speech activity detection (SAD) is an important first step in speech processing.,background,0
8573,"Commonly used methods (e.g., frame-level classification using gaussian mixture models (GMMs)) work well under stationary noise conditions, but do not generalize well to domains such as YouTube, where videos may exhibit a diverse range of environmental conditions.",method,2
8574,"One solution is to augment the conventional cepstral features with additional, hand-engineered features (e.g., spectral flux, spectral centroid, multiband spectral entropies) which are robust to changes in environment and recording condition.",objective,1
8575,"An alternative approach, explored here, is to learn robust features during the course of training using an appropriate architecture such as deep neural networks (DNNs).",objective,1
8576,In this paper we demonstrate that a DNN with input consisting of multiple frames of mel frequency cepstral coefficients (MFCCs) yields drastically lower frame-wise error rates (19.6%) on YouTube videos compared to a conventional GMM based system (40%).,result,3
8577,Reading text from photographs is a challenging problem that has received a significant amount of attention.,background,0
8578,"Two key components of most systems are (i) text detection from images and (ii) character recognition, and many recent methods have been proposed to design better feature representations and models for both.",background,0
8579,"In this paper, we apply methods recently developed in machine learning -- specifically, large-scale algorithms for learning the features automatically from unlabeled data -- and show that they allow us to construct highly effective classifiers for both detection and recognition to be used in a high accuracy end-to-end system.",method,2
8580,"The two dominant schemes for rule-learning, C4.5 and RIPPER, both operate in two stages.",background,0
8581,First they induce an initial rule set and then they refine it using a rather complex optimization stage that discards (C4.5) or adjusts (RIPPER) individual rules to make them work better together.,background,0
8582,"In contrast, this paper shows how good rule sets can be learned one rule at a time, without any need for global optimization.",method,2
8583,"We present an algorithm for inferring rules by repeatedly generating partial decision trees, thus combining the two major paradigms for rule generation—creating rules from decision trees and the separate-and-conquer rule-learning technique.",method,2
8584,"The algorithm is straightforward and elegant: despite this, experiments on standard datasets show that it produces rule sets that are as accurate as and of similar size to those generated by C4.5, and more accurate than RIPPER’s.",method,2
8585,"Moreover, it operates efficiently, and because it avoids postprocessing, does not suffer the extremely slow performance on pathological example sets for which the C4.5 method has been criticized.",method,2
8586,We present an attention-based model for recognizing multiple objects in images.,objective,1
8587,The proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image.,method,2
8588,We show that the model learns to both localize and recognize multiple objects despite being given only class labels during training.,method,2
8589,We evaluate the model on the challenging task of transcribing house number sequences from Google Street View images and show that it is both more accurate than the state-of-the-art convolutional networks and uses fewer parameters and less computation.,result,3
8590,NTechLAB facenx_large Google FaceNet v8 Beijing Faceall Co. FaceAll_Norm_1600 Beijing Faceall Co.,other,4
8591,FaceAll_1600 large 73.300% 70.496% 64.803% 63.977% 85.081% 86.473% 67.118% 63.960% Barebones_FR cnn NTechLAB facenx_small 3DiVi Company – tdvm6 small 59.363% 58.218% 33.705% 59.036% 66.366% 36.927% model AModel BModel C(Proposed) small 41.863% 57.175% 65.234% 41.297% 69.897% 76.516% Method Protocol Identification Acc.,other,4
8592,(Set 1) Verification Acc.,other,4
8593,"(Set 1) For generic object, scene or action recognition.",other,4
8594,The deeply learned features need to be separable.,result,3
8595,"Because the classes of the possible testing samples are within the training set, the predicted labels dominate the performance.",result,3
8596,"For urban driving, knowledge of ego-vehicle's position is a critical piece of information that enables advanced driver-assistance systems or self-driving cars to execute safety-related, autonomous driving maneuvers.",background,0
8597,"This is because, without knowing the current location, it is very hard to autonomously execute any driving maneuvers for the future.",background,0
8598,"The existing solutions for localization rely on a combination of Global Navigation Satellite System (GNSS), an inertial measurement unit, and a digital map.",background,0
8599,"However, on urban driving environments, due to poor satellite geometry and disruption of radio signal reception, their longitudinal and lateral errors are too significant to be used to guide an autonomous system.",background,0
8600,"To enhance the existing system's localization capability, this work presents an effort of developing a vision-based lateral localization algorithm.",objective,1
8601,"The algorithm aims at reliably counting, with or without observations of lane-markings, the number road-lanes and identifying the index of the road-lane on the roadway that our vehicle happens to be driving on.",method,2
8602,Testings the proposed algorithms against inter-city and inter-state highway videos showed promising results in terms of counting the number of road-lanes and the indices of the current road-lanes.,result,3
8603,In this paper we elicit preferences for money-time pairs via experimental techniques.,background,0
8604,"We estimate a general specification of discounting that nests exponential and hyperbolic discounting, as well as various forms of present bias, including quasi-hyperbolic discounting.",background,0
8605,Our experimental data do not appear peculiar in any dimension.,background,0
8606,"In particular, we find clear evidence for present bias, as most of the previous literature.",method,2
8607,"However, no evidence for quasi-hyperbolic discounting is found, and the data strongly favor instead a specification with a small present bias in the form of a fixed cost, of the order of $4 on average across subjects.",method,2
8608,With such a fixed cost the curvature of discounting is imprecisely estimated and exponential discounting is hardly rejected.,result,3
8609,In this specification the present bias tends to vanish for economically relevant monetary rewards.,result,3
8610,"Discovering sequential patterns is an important problem in data mining with a host of application domains including medicine, telecommunications, and the World Wide Web.",background,0
8611,Conventional mining systems provide users with only a very restricted mechanism (based on minimum support) for specifying patterns of interest.,background,0
8612,"In this paper, we propose the use of Regular Expressions (REs) as a flexible constraint specification tool that enables user-controlled focus to be incorporated into the pattern mining process.",objective,1
8613,We develop a family of novel algorithms (termed SPIRIT – Sequential Pattern mIning with Regular expressIon consTraints) for mining frequent sequential patterns that also satisfy user-specified RE constraints.,method,2
8614,The main distinguishing factor among the proposed schemes is the degree to which the RE constraints are enforced to prune the search space of patterns during computation.,method,2
8615,Our solutions provide valuable insights into the tradeoffs that arise when constraints that do not subscribe to nice properties (like anti-monotonicity) are integrated into the mining process.,result,3
8616,A quantitative exploration of these tradeoffs is conducted through an extensive experimental study on synthetic and real-life data sets.,method,2
8617,Gradient descent training of neural networks can be done in either a batch or on-line manner.,background,0
8618,A widely held myth in the neural network community is that batch training is as fast or faster and/or more 'correct' than on-line training because it supposedly uses a better approximation of the true gradient for its weight updates.,background,0
8619,This paper explains why batch training is almost always slower than on-line training-often orders of magnitude slower-especially on large training sets.,background,0
8620,"The main reason is due to the ability of on-line training to follow curves in the error surface throughout each epoch, which allows it to safely use a larger learning rate and thus converge with less iterations through the training data.",method,2
8621,"Empirical results on a large (20,000-instance) speech recognition task and on 26 other learning tasks demonstrate that convergence can be reached significantly faster using on-line training than batch training, with no apparent difference in accuracy.",result,3
8622,Social voting is an emerging new feature in online social networks.,background,0
8623,It poses unique challenges and opportunities for recommendation.,background,0
8624,"In this paper, we develop a set of matrix-factorization (MF) and nearest-neighbor (NN)-based recommender systems (RSs) that explore user social network and group affiliation information for social voting recommendation.",objective,1
8625,"Through experiments with real social voting traces, we demonstrate that social network and group affiliation information can significantly improve the accuracy of popularity-based voting recommendation, and social network information dominates group affiliation information in NN-based approaches.",method,2
8626,We also observe that social and group information is much more valuable to cold users than to heavy users.,result,3
8627,"In our experiments, simple metapath-based NN models outperform computation-intensive MF models in hot-voting recommendation, while users’ interests for nonhot votings can be better mined by MF models.",result,3
8628,"We further propose a hybrid RS, bagging different single approaches to achieve the best top- $k$ hit rate.",result,3
8629,UNLABELLED Electronic patient records (EPRs) contain a wealth of patient-related data and capture clinical problem-solving experiences and decisions.,background,0
8630,Excelicare is such a system which is also a platform for the national generic clinical system in the UK.,background,0
8631,"OBJECTIVE This paper presents, ExcelicareCBR, a case-based reasoning (CBR) system which has been developed to complement Excelicare.",objective,1
8632,Objective of this work is to integrate CBR to support clinical decision making by harnessing electronic patient records for clinical experience reuse.,objective,1
8633,METHODS CBR is a proven problem solving methodology in which past solutions are reused to solve new problems.,method,2
8634,A key challenge that we address in this paper is how to extract and represent a case from an EPR.,method,2
8635,Using an example from the lung cancer domain we demonstrate our generic case representation approach where Excelicare fields are mapped to case features.,method,2
8636,Once the case base is populated with cases containing data from the EPRs database a standard weighted k-nearest neighbour algorithm combined with a genetic algorithm based feature weighting mechanism is used for case retrieval and reuse.,method,2
8637,CONCLUSIONS We conclude that incorporating case authoring functionality and a generic retrieval mechanism were key to successful integration of ExcelicareCBR.,result,3
8638,This paper also demonstrates how the application of CBR can enable sharing of lessons learned through the retrieval and reuse of EPRs captured as cases in a case base.,result,3
8639,"CAN bus will be increasingly used in wide range of applications for its superiority, but it couldn’t communicate with computer directly.",background,0
8640,"The article describes the design of RS232 and CAN bus protocol converter depending on PIC Microcontroller, which solves the problem that CAN networks can not directly communicate with PC.",background,0
8641,"At present, single-chip microcomputer of 51 series with CAN controller SJA1000 are widely used in domestic.",background,0
8642,"Considering cost and converter size, the paper will talk about PIC18F2580 with integrated CAN microcontroller designed for RS232 and CAN protocol converters to facilitate the direct communication between computers and CAN bus.",result,3
8643,Information systems research has been concerned with improving task-related performance.,background,0
8644,The concept of fit is often used to explain how system design results in better performance and overall value.,objective,1
8645,"So far, the literature focuses mainly on performance evaluation criteria that are based on measures of task efficiency, accuracy, or productivity.",method,2
8646,"However, nowadays, productivity gain is no longer the single evaluation criterion.",background,0
8647,"In many instances, computer systems are expected to enhance our creativity, reveal opportunities and open new vistas of uncharted frontiers.",result,3
8648,"To address this void, we introduce the concept of generativity and develop two corresponding design considerations--""generative capacity"" that refers to one’s creativity, ingenuity and mental dexterity, and ""generative fit"" that refers to the extent to which an IT artifact is conducive to evoking and enhancing that generative capacity.",method,2
8649,We offer an extended view of the concept of fit and realign the prevailing approaches to humancomputer interaction design with current leading-edge applications and users' expectations.,method,2
8650,"Our findings guide systems designers who aim to enhance creative work, unstructured syntheses, serendipitous discoveries, and any other form of computer-aided tasks that involve unexplored outcomes, expect fresh configurations or aim to enhance our ability to boldly go where no one has gone before.",result,3
8651,"In this paper, we explore the notion of generativity, review its theoretical background in the context of the social sciences, and argue that it should be included in the evaluation of task-related performance.",objective,1
8652,"Then, we briefly explore the role of fit in IS research, position “generative fit” in that context, explain its role and impact on performance, and provide key design considerations that enhance generative fit.",method,2
8653,"As countries become increasingly urbanized, understanding how urban areas are changing within the landscape becomes increasingly important.",background,0
8654,"Urbanized areas are often the strongest indicators of human interaction with the environment, and understanding how urban areas develop through remotely sensed data allows for more sustainable practices.",background,0
8655,The Google Earth Engine (GEE) leverages cloud computing services to provide analysis capabilities on over 40 years of Landsat data.,background,0
8656,"As a remote sensing platform, its ability to analyze global data rapidly lends itself to being an invaluable tool for studying the growth of urban areas.",objective,1
8657,"Here we present (i) An approach for the automated extraction of urban areas from Landsat imagery using GEE, validated using higher resolution images, (ii) a novel method of validation of the extracted urban extents using changes in the statistical performance of a high resolution population mapping method.",method,2
8658,Temporally distinct urban extractions were classified from the GEE catalog of Landsat patial demography 5 and 7 data over the Indonesian island of Java by using a Normalized Difference Spectral Vector (NDSV) method.,method,2
8659,"Statistical evaluation of all of the tests was performed, and the value of population mapping methods in validating these urban extents was also examined.",result,3
8660,"Results showed that the automated classification from GEE produced accurate urban extent maps, and that the integration of GEE-derived urban extents also improved the quality of the population mapping outputs.",result,3
8661,© 2014 Elsevier B.V.,other,4
8663,Over the last ten years the Internet has become an incredibly important media in everyday life of ordinary people.,background,0
8664,"By now the World Wide Web is not a foreign concept anymore; millions of people make use of the internet in terms of e-mail, online banking, online shops, etc.",background,0
8665,Companies have realised the necessity of user friendly interfaces and software which even an inexperienced user is able to handle.,background,0
8666,"Since the interaction with the Internet becomes ubiquitous, assessing usability of interfaces is a fundamental and necessary part of HCI development.",background,0
8667,"Observing the overt behaviour of users, (which button does a user click on, how is the mouse used), retrospective self report, questionnaires and thinking aloud methods are just examples of traditional and quite successful strategies in order to investigate usability problems.",method,2
8668,"So, why should there be a need for a new method when conventional methods seem sufficient in optimising usability and what is it’s contribution in the evaluation of how usable a particular design is?",objective,1
8669,We will give a short introduction of the eye tracking method in applied marketing research and its benefits.,method,2
8670,Reporting two of our studies we will discuss the limits of traditional usability testing and will show how tracking the eye gaze can fill this gap.,result,3
8671,"The core capabilities of an organization include critical skills of employees, management systems, and norms and values.",background,0
8672,Core capabilities may be transferred fonnally and explicitly.,background,0
8673,"However, much knowledge, particularly knowledge with rich tacit dimensions, is transferred informally through processes of socialization and intemaiization.",background,0
8674,"We focus on two transfer mechanisms—mentoring and storytelling—that can leverage the knowledge of an organization, particularly its tacit knowledge, to build core capabilities.",objective,1
8675,We draw on relevant research in leaming and cognitive psychology to clarify the conditions under which mentoring and storytelling can be most effective as carriers of knowledge.,method,2
8676,"Finally, we present recommendations for specific managerial practices that follow from our analysis.",method,2
8677,"Journal of Management Information Systems /Summer 200\, Vol.",other,4
8678,"18, No. 1, pp.",other,4
8679,"95-114. ©2001 M.E. Sharpe, Inc. 0742-1222 / 2001 $9.50 + 0.00.",other,4
8680,"96 SWAP, LEONARD, SHIELDS, AND ABRAMS",other,4
8681,This study addresses ways in which inmates at the only maximum-security prison for women in Neuse City (in the northeastern United States) redefine their social world in order to survive incarceration.,background,0
8682,An aim of the project is to engage in theory building in order to examine the experiences of a world that is “lived in the round.,objective,1
8683,”,other,4
8684,A life in the round is a public form of life.,background,0
8685,It is a lifestyle with an enormous degree of imprecision.,other,4
8686,"Yet, it is this inexactitude that provides an acceptable level of certainty.",background,0
8687,This way of life sets standards by which one constructs everyday meaning from reality.,method,2
8688,"It is a “takenfor-granted,” “business-as-usual” style of being.",method,2
8689,"Relying on ethnographic research and interviews with 80 women at the prison, the findings revealed that a life in the round was sustaining a “normative” existence.",result,3
8690,In this paper we propose a highly detailed map for the field of autonomous driving.,background,0
8691,We introduce the notion of lanelets to represent the drivable environment under both geometrical and topological aspects.,background,0
8692,"Lanelets are atomic, interconnected drivable road segments which may carry additional data to describe the static environment.",objective,1
8693,"We describe the map specification, an example creation process as well as the access library libLanelet which is available for download.",method,2
8694,"Based on the map, we briefly describe our behavioural layer (which we call behaviour generation) which is heavily exploiting the proposed map structure.",method,2
8695,Both contributions have been used throughout the autonomous journey of the Mercedes Benz S 500 Intelligent Drive following the Bertha Benz Memorial Route in summer 2013.,result,3
8696,"This paper examines the effect of the freemium strategy on Google Play, an online marketplace for Android mobile apps.",background,0
8697,"By analyzing a large panel dataset consisting of 1,597 ranked mobile apps, we found that the freemium strategy is positively associated with increased sales volume and revenue of the paid apps.",background,0
8698,Higher sales rank and review rating of the free version of a mobile app both lead to higher sales rank of its paid version.,result,3
8699,"However, only higher review rating of the free app contributes to higher revenue from the paid version, suggesting that although offering a free version is a viable way to improve the visibility of a mobile app, revenue is largely determined by product quality, not product visibility.",result,3
8700,"Moreover, we found that the impact of review rating is not significant when the free version is offered, or when the mobile app is a hedonic app.",result,3
8701,This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs).,background,0
8704,"Introduction This report summarizes the content of the NIPS 2016 tutorial on generative adversarial networks (GANs) (Goodfellow et al., 2014b).",objective,1
8705,"The tutorial was designed primarily to ensure that it answered most of the questions asked by audience members ahead of time, in order to make sure that the tutorial would be as useful as possible to the audience.",method,2
8706,"This tutorial is not intended to be a comprehensive review of the field of GANs; many excellent papers are not described here, simply because they were not relevant to answering the most frequent questions, and because the tutorial was delivered as a two hour oral presentation and did not have unlimited time cover all subjects.",method,2
8709,The slides for the tutorial are available in PDF and Keynote format at the following URLs: http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf 1This is the arxiv.org version of this tutorial.,result,3
8710,"Some graphics have been compressed to respect arxiv.org’s 10MB limit on paper size, and do not reflect the full image quality.",result,3
8711,"Blockchain, widely known as one of the disruptive technologies emerged in recent years, is experiencing rapid development and has the full potential of revolutionizing the increasingly centralized intelligent transportation systems (ITS) in applications.",background,0
8712,"Blockchain can be utilized to establish a secured, trusted and decentralized autonomous ITS ecosystem, creating better usage of the legacy ITS infrastructure and resources, especially effective for crowdsourcing technology.",background,0
8713,This paper conducts a preliminary study of Blockchain-based ITS (B2ITS).,objective,1
8714,"We outline an ITS-oriented, seven-layer conceptual model for blockchain, and on this basis address the key research issues in B2ITS.",method,2
8715,"We consider that blockchain is one of the secured and trusted architectures for building the newly developed parallel transportation management systems (PtMS) , and thereby discuss the relationship between B2ITS and PtMS.",method,2
8716,"Finally, we present a case study for blockchain-based realtime ride-sharing services.",result,3
8717,"In our viewpoint, B2ITS represents the future trend of ITS research and practice, and this paper is aimed at stimulating further effort and providing helpful guidance and reference for future research works.",result,3
8718,There is an increasing need to bring machine learning to a wide diversity of hardware devices.,background,0
8719,Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs.,background,0
8720,"Deploying workloads to new platforms such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) requires significant manual effort.",background,0
8721,"We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends.",method,2
8722,"TVM solves optimization challenges specific to deep learning such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding.",method,2
8723,TVM also offers automated optimization of lowlevel programs to hardware characteristics by employing a novel learning-based cost modeling method for rapid exploration of code optimizations.,method,2
8724,"Experimental results demonstrate that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art hand tuned libraries for low-power CPU, mobile GPU, and server-class GPUs.",result,3
8725,We also demonstrate TVM’s ability to target new accelerator back-ends by targeting an FPGA-based generic deep learning accelerator.,result,3
8726,The system is open sourced and in production use inside several major companies.,result,3
8727,There are many situations in which it is desirable to be able to distinguish spontaneous speech and speech which is non-spontaneous.,background,0
8728,"Examples of situations in which this problem may arise include forensic evidence situations, sorting voice-mail responses from voice-mail menus, and automatic segmentation of spontaneous responses from prepared questions.",background,0
8729,The later situation can occur if it is desired to create a database of spontaneous data from data which consists of spontaneous discourse responding to prepared prompts.,background,0
8730,This paper outlines and compares three methods for automatically classifying spontaneous and non-spontaneous speech and presents the cxperimcntal results comparing the performance of the methods.,method,2
8731,All three methods are based on an analysis of the probability distributions of prosodic fcatures extracted from the speech signal.,method,2
8732,The first method uses an expansion of the of the probability distribution in terms of the statistical moments.,method,2
8733,The second method is an application of a modifed Hellinger’s method applied to histograms of signal amplitude and other speech features.,method,2
8734,The third method is based on a measure of the nonGaussianity of the data.,method,2
8735,Recommender systems have the effect of guiding users in a personalized way to interesting objects in a large space of possible options.,background,0
8736,Content-based recommendation systems try to recommend items similar to those a given user has liked in the past.,background,0
8737,"Indeed, the basic process performed by a content-based recommender consists in matching up the attributes of a user profile in which preferences and interests are stored, with the attributes of a content object (item), in order to recommend to the user new interesting items.",background,0
8738,"This chapter provides an overview of content-based recommender systems, with the aim of imposing a degree of order on the diversity of the different aspects involved in their design and implementation.",objective,1
8739,"The first part of the chapter presents the basic concepts and terminology of contentbased recommender systems, a high level architecture, and their main advantages and drawbacks.",method,2
8740,"The second part of the chapter provides a review of the state of the art of systems adopted in several application domains, by thoroughly describing both classical and advanced techniques for representing items and user profiles.",method,2
8741,The most widely adopted techniques for learning user profiles are also presented.,method,2
8742,"The last part of the chapter discusses trends and future research which might lead towards the next generation of systems, by describing the role of User Generated Content as a way for taking into account evolving vocabularies, and the challenge of feeding users with serendipitous recommendations, that is to say surprisingly interesting items that they might not have otherwise discovered.",method,2
8743,"Pasquale Lops Department of Computer Science, University of Bari “Aldo Moro”, Via E. Orabona, 4, Bari (Italy) e-mail: lops@di.uniba.it Marco de Gemmis Department of Computer Science, University of Bari “Aldo Moro”, Via E. Orabona, 4, Bari (Italy) e-mail: degemmis@di.uniba.it Giovanni Semeraro Department of Computer Science, University of Bari “Aldo Moro”, Via E. Orabona, 4, Bari (Italy) e-mail: semeraro@di.uniba.it",result,3
8744,The 3GPP has introduced the LTE-M and NB-IoT User Equipment categories and made amendments to LTE release 13 to support the cellular Internet of Things.,background,0
8745,"The contribution of this paper is to analyze the coverage probability, the number of supported devices, and the device battery life in networks equipped with either of the newly standardized technologies.",objective,1
8746,"The study is made for a site specific network deployment of a Danish operator, and the simulation is calibrated using drive test measurements.",method,2
8747,"The results show that LTE-M can provide coverage for 99.9 % of outdoor and indoor devices, if the latter is experiencing 10 dB additional loss.",result,3
8748,"However, for deep indoor users NB-IoT is required and provides coverage for about 95 % of the users.",result,3
8749,The cost is support for more than 10 times fewer devices and a 2-6 times higher device power consumption.,result,3
8750,"Thus both LTE-M and NB- IoT provide extended support for the cellular Internet of Things, but with different trade- offs.",result,3
8751,In this paper we review mobile location-based games for learning.,objective,1
8752,"These games are played in physical space, but at the same time, they are supported by actions and events in an interconnected virtual space.",background,0
8753,"Learning in these games is related to issues like the narrative structure, space and game rules and content that define the virtual game space.",background,0
8754,"First, we introduce the theoretical and empirical considerations of mobile location based games, and then we discuss an analytical framework of their main characteristics through typical examples.",method,2
8755,"In particular, we focus on their narrative structure, the interaction modes that they afford, their use of physical space as prop for action, the way this is linked to virtual space and the possible learning impact the game activities have.",method,2
8756,"Finally we conclude with an outline of future trends and possibilities that these kinds of playful activities can have on learning, especially outside school, like in environmental studies and visits in museums and other sites of cultural and historical value.",result,3
8757,ruptures is a Python library for o ine change point detection.,background,0
8758,This package provides methods for the analysis and segmentation of non-stationary signals.,objective,1
8759,Implemented algorithms include exact and approximate detection for various parametric and non-parametric models.,method,2
8760,ruptures focuses on ease of use by providing a well-documented and consistent interface.,method,2
8761,"In addition, thanks to its modular structure, di erent algorithms and models can be connected and extended within this package.",result,3
8762,"Recently, there has been a tremendous increase in demand for mobile data driven by the wide-spread usage of smartphone like devices.",background,0
8763,"Besides the efforts of studies that propose ways for operators to handle this huge growth, there is also an emerging research area of analyzing this new type of user data.",background,0
8764,"In this paper, we perform an analysis on mobile user data to understand general aggregated user behavior based on several parameters.",objective,1
8765,We also investigate the reasons for the user behavior deviating from its general trend.,method,2
8766,"Finally, we discuss several ways of utilizing the results of the analysis in this study in solving current problems operators face.",result,3
8767,Object co-segmentation aims to segment the common objects in images.,background,0
8768,This paper presents a CNNbased method that is unsupervised and end-to-end trainable to better solve this task.,method,2
8769,Our method is unsupervised in the sense that it does not require any training data in the form of object masks but merely a set of images jointly covering objects of a specific class.,method,2
8770,"Our method comprises two collaborative CNN modules, a feature extractor and a co-attention map generator.",method,2
8771,"The former module extracts the features of the estimated objects and backgrounds, and is derived based on the proposed co-attention loss, which minimizes interimage object discrepancy while maximizing intraimage figure-ground separation.",result,3
8772,The latter module is learned to generate co-attention maps by which the estimated figure-ground segmentation can better fit the former module.,result,3
8773,"Besides the co-attention loss, the mask loss is developed to retain the whole objects and remove noises.",result,3
8774,"Experiments show that our method achieves superior results, even outperforming the state-of-the-art, supervised methods.",result,3
8775,This work concentrates on vision processing for ADAS and intelligent vehicle applications.,objective,1
8776,"We propose a color extension to the disparity-based Stixel World method, so that the road can be robustly distinguished from obstacles with respect to erroneous disparity measurements.",background,0
8777,Our extension learns color appearance models for road and obstacle classes in an online and self-supervised fashion.,method,2
8778,"The algorithm is tightly integrated within the core of the optimization process of the original Stixel World, allowing for strong fusion of the disparity and color signals.",method,2
8779,"We perform an extensive evaluation, including different self-supervised learning strategies and different color models.",result,3
8780,"Our newly recorded, publicly available data set is intentionally focused on challenging traffic scenes with many low-texture regions, causing numerous disparity artifacts.",result,3
8781,"In this evaluation, we increase the F-score of the drivable distance from 0.86 to 0.97, compared to a tuned version of the state-of-the-art baseline method.",result,3
8782,"This clearly shows that our color extension increases the robustness of the Stixel World, by reducing the number of falsely detected obstacles while not deteriorating the detection of true obstacles.",result,3
8783,"The Internet has provided IS researchers with the opportunity to conduct studies with extremely large samples, frequently well over 10,000 observations.",background,0
8784,"There are many advantages to large samples, but researchers using statistical inference must be aware of the p-value problem associated with them.",background,0
8785,"In very large samples, p-values go quickly to zero, and solely relying on pvalues can lead the researcher to claim support for results of no practical significance.",background,0
8786,"In a survey of large sample IS research, we found that a significant number of papers rely on a low pvalue and the sign of a regression coefficient alone to support their hypotheses.",method,2
8787,"This research commentary recommends a series of actions the researcher can take to mitigate the p-value problem in large samples and illustrates them with an example of over 300,000 camera sales on eBay.",result,3
8788,We believe that addressing the p-value problem will increase the credibility of large sample IS research as well as provide more insights for readers.,result,3
8789,Functional magnetic resonance imaging (fMRI) studies of the human brain have suggested that low-frequency fluctuations in resting fMRI data collected using blood oxygen level dependent (BOLD) contrast correspond to functionally relevant resting state networks (RSNs).,background,0
8790,"Whether the fluctuations of resting fMRI signal in RSNs are a direct consequence of neocortical neuronal activity or are low-frequency artifacts due to other physiological processes (e.g., autonomically driven fluctuations in cerebral blood flow) is uncertain.",background,0
8791,"In order to investigate further these fluctuations, we have characterized their spatial and temporal properties using probabilistic independent component analysis (PICA), a robust approach to RSN identification.",objective,1
8792,"Here, we provide evidence that: i. RSNs are not caused by signal artifacts due to low sampling rate (aliasing); ii.",method,2
8793,they are localized primarily to the cerebral cortex; iii.,result,3
8794,similar RSNs also can be identified in perfusion fMRI data; and iv.,result,3
8795,at least 5 distinct RSN patterns are reproducible across different subjects.,result,3
8796,"The RSNs appear to reflect ""default"" interactions related to functional networks related to those recruited by specific types of cognitive processes.",result,3
8797,"RSNs are a major source of non-modeled signal in BOLD fMRI data, so a full understanding of their dynamics will improve the interpretation of functional brain imaging studies more generally.",result,3
8798,"Because RSNs reflect interactions in cognitively relevant functional networks, they offer a new approach to the characterization of state changes with pathology and the effects of drugs.",result,3
8799,To each fuzzy subgroup a fuzzy equivalence relation is associated and it is proved that a fuzzy subgroup is normal if and only if the operation of the group is compatible with its associated fuzzy equivalence relation.,background,0
8800,In the de-nition of fuzzy subgroup only the subset is fuzzy whilst the group operation remains crisp.,background,0
8801,"In an opposite direction, another structure can be constructed maintaining crisp the basic set X of the group and fuzzifying the group operation.",background,0
8802,"When in addition it is imposed to the fuzzy operation to be compatible with a given fuzzy equivalence relation, this structure is called a vague group.",background,0
8803,The results of the paper allow us to associate a vague group to every fuzzy subgroup in such a way that it can be interpreted as the fuzzy quotient group X= .,method,2
8804,Special attention is paid to normal fuzzy groups and vague groups of the additive group (R;+) of the real numbers.,method,2
8805,Two examples related to triangular numbers illustrating the results of the paper are provided.,result,3
8806,c © 2003 Elsevier B.V. All rights reserved.,other,4
8807,Web-based malware is a growing threat to today's Internet security.,background,0
8808,Attacks of this type are prevalent and lead to serious security consequences.,background,0
8809,Millions of malicious URLs are used as distribution channels to propagate malware all over the Web.,background,0
8810,"After being infected, victim systems fall in the control of attackers, who can utilize them for various cyber crimes such as stealing credentials, spamming, and distributed denial-of-service attacks.",method,2
8811,"Moreover, it has been observed that traditional security technologies such as firewalls and intrusion detection systems have only limited capability to mitigate this new problem.",method,2
8812,"In this article, we survey the state-of-the-art research regarding the analysis of—and defense against—Web-based malware attacks.",method,2
8813,"First, we study the attack model, the root cause, and the vulnerabilities that enable these attacks.",result,3
8814,"Second, we analyze the status quo of the Web-based malware problem.",result,3
8815,"Third, three categories of defense mechanisms are discussed in detail: (1) building honeypots with virtual machines or signature-based detection system to discover existing threats; (2) using code analysis and testing techniques to identify the vulnerabilities of Web applications; and (3) constructing reputation-based blacklists or smart sandbox systems to protect end-users from attacks.",result,3
8816,We show that these three categories of approaches form an extensive solution space to the Web-based malware problem.,result,3
8817,Othello is a recent addition to the collection of games that have been examined within artificial intelligence.,background,0
8818,"Advances have been rapid, yielding programs that have reached the level of world-championship play.",background,0
8819,"This article describes the current champion Othello program, Iago.",objective,1
8820,The work described here includes: (1) a task analysis of Othello; (2) the implemenation of a program based on this analysis and state-of-the-art AI gameplaying techniques; and (3) an evaluation of the program's performance through games played against other programs and comparisons with expert human play.,objective,1
8821,"This research was sponsored by the Defense Advanced Research Projects Agency (DOD) , ARPA Order N o .",method,2
8822,"3597, monitored by the Air Force Avionics Laboratory Under Contract F33615-78-C-1551.",method,2
8823,"The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the US Government .",result,3
8824,Table of,other,4
8825,This paper focuses on cyber-security simulations in networks modeled as a Markov game with incomplete information and stochastic elements.,objective,1
8826,"The resulting game is an adversarial sequential decision making problem played with two agents, the attacker and defender.",objective,1
8827,"The two agents pit one reinforcement learning technique, like neural networks, Monte Carlo learning and Q-learning, against each other and examine their effectiveness against learning opponents.",method,2
8828,The results showed that Monte Carlo learning with the Softmax exploration strategy is most effective in performing the defender role and also for learning attacking strategies.,result,3
8829,"We present a new image-based, post-processing antialiasing technique, which offers practical solutions to the common, open problems of existing filter-based real-time antialiasing algorithms.",background,0
8830,"Some of the new features include local contrast analysis for more reliable edge detection, and a simple and effective way to handle sharp geometric features and diagonal lines.",background,0
8831,"This, along with our accelerated and accurate pattern classification allows for a better reconstruction of silhouettes.",method,2
8832,"Our method shows for the first time how to combine morphological antialiasing (MLAA) with additional multi/supersampling strategies (MSAA, SSAA) for accurate subpixel features, and how to couple it with temporal reprojection; always preserving the sharpness of the image.",method,2
8833,"All these solutions combine synergies making for a very robust technique,",method,2
8834,yielding results of better overall quality than previous approaches while more closely converging to MSAA/SSAA references but maintaining extremely fast execution times.,result,3
8835,"Additionally, we propose different presets to better fit the available resources or particular needs of each scenario.",result,3
8836,We present a hybrid neural-network for human face recognition which compares favourably with other methods.,method,2
8837,"The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network.",method,2
8838,"The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation.",method,2
8839,The convolutional network extracts successively larger features in a hierarchical set of layers.,method,2
8840,"We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison.",result,3
8841,"We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details.",result,3
8842,We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.,result,3
8843,"In this paper, we presented a real-time 2D human gesture grading system from monocular images based on OpenPose, a library for real-time multi-person keypoint detection.",background,0
8844,"After capturing 2D positions of a person's joints and skeleton wireframe of the body, the system computed the equation of motion trajectory for every joint.",method,2
8845,Similarity metric was defined as distance between motion trajectories of standard and real-time videos.,result,3
8846,A modifiable scoring formula was used for simulating the gesture grading scenario.,method,2
8847,"Experimental results showed that the system worked efficiently with high real-time performance, low cost of equipment and strong robustness to the interference of noise.",result,3
8848,"Network embedding algorithms to date are primarily designed for static networks, where all nodes are known before learning.",background,0
8849,"How to infer embeddings for out-of-sample nodes, i.e. nodes that arrive after learning, remains an open problem.",background,0
8850,"The problem poses great challenges to existing methods, since the inferred embeddings should preserve intricate network properties such as high-order proximity, share similar characteristics (i.e. be of a homogeneous space) with in-sample node embeddings, and be of low computational cost.",background,0
8851,"To overcome these challenges, we propose a Deeply Transformed High-order Laplacian Gaussian Process (DepthLGP) method to infer embeddings for out-of-sample nodes.",method,2
8852,DepthLGP combines the strength of nonparametric probabilistic modeling and deep learning.,method,2
8853,"In particular, we design a high-order Laplacian Gaussian process (hLGP) to encode network properties, which permits fast and scalable inference.",method,2
8854,"In order to further ensure homogeneity, we then employ a deep neural network to learn a nonlinear transformation from latent states of the hLGP to node embeddings.",method,2
8855,"DepthLGP is general, in that it is applicable to embeddings learned by any network embedding algorithms.",method,2
8856,"We theoretically prove the expressive power of DepthLGP, and conduct extensive experiments on real-world networks.",result,3
8857,Empirical results demonstrate that our approach can achieve significant performance gain over existing approaches.,result,3
8858,"In hopes of motivating consumers to provide larger volumes of useful reviews, many retailers offer financial incentives.",background,0
8859,"Here, we explore an alternative approach, social norms, wherein we inform people about the volume of reviews authored by peers.",background,0
8860,"We test the effectiveness of using financial incentives, social norms, and a combination of both strategies.",method,2
8861,"In two randomized experiments, one in the field conducted in partnership with a large online clothing retailer based in China, and a second on Amazon Mechanical Turk, we compare the effectiveness of each strategy at stimulating online reviews in larger numbers and of greater length.",method,2
8862,"We find that financial incentives are more effective at inducing larger volumes of reviews, but the reviews that result are not particularly lengthy, whereas social norms have a greater effect on the length of reviews.",result,3
8863,"Importantly, we show that the combination of financial incentives and social norms yields the greatest overall benefit, motivating reviews in greater numbers and of greater length.",result,3
8864,We further assess the treatment induced self-selection and sentiment bias by triangulating the experimental results with findings from an observational study.,result,3
8865,This paper presents a no reference image (NR) quality assessment (IQA) method based on a deep convolutional neural network (CNN).,objective,1
8866,The CNN takes unpreprocessed image patches as an input and estimates the quality without employing any domain knowledge.,method,2
8867,"By that, features and natural scene statistics are learnt purely data driven and combined with pooling and regression in one framework.",method,2
8868,We evaluate the network on the LIVE database and achieve a linear Pearson correlation superior to state-of-the-art NR IQA methods.,result,3
8869,We also apply the network to the image forensics task of decoder-sided quantization parameter estimation and also here achieve correlations of r = 0.989.,result,3
8870,"Conversion rate optimization (CRO) means designing an ecommerce web interface so that as many users as possible take a desired action such as registering for an account, requesting a contact, or making a purchase.",background,0
8871,"Such design is usually done by hand, evaluating one change at a time through A/B testing, or evaluating all combinations of two or three variables through multivariate testing.",background,0
8872,Traditional CRO is thus limited to a small fraction of the design space only.,background,0
8873,"This paper describes Sentient Ascend, an automatic CRO system that uses evolutionary search to discover effective web interfaces given a human-designed search space.",objective,1
8874,"Design candidates are evaluated in parallel on line with real users, making it possible to discover and utilize interactions between the design elements that are difficult to identify otherwise.",method,2
8875,"A commercial product since September 2016, Ascend has been applied to numerous web interfaces across industries and search space sizes, with up to four-fold improvements over human design.",method,2
8876,Ascend can therefore be seen as massively multivariate CRO made possible by AI.,result,3
8877,This paper presents the design and validation of a fuzzy logic controller implemented with an industrial programmable logic controller (PLC).,objective,1
8878,"The chosen device belongs to the S7-1200 series of Siemens, whereas the code has been developed in Ladder Diagram language using the software TIA Portal.",result,3
8879,The fuzzy controller is of Mamdani type and is applied to control the speed of a servomotor.,method,2
8880,A comparison with a Simulink/Matlab fuzzy controller is done to validate the developed software module and to show the feasibility of the PLC to manage this kind of control algorithm.,method,2
8881,Standard approaches to functional safety as described in the automotive functional safety standard ISO 26262 are focused on reducing the risk of hazards due to random hardware faults or systematic failures during design (e.g. software bugs).,background,0
8882,"However, as vehicle systems become increasingly complex and ever more connected to the internet of things, a third source of hazard must be considered, that of intentional manipulation of the electrical/electronic control systems either via direct physical contact or via the systems' open interfaces.",background,0
8883,This article describes how the process prescribed by the ISO 26262 can be extended with methods from the domain of embedded security to protect the systems against this third source of hazard.,result,3
8884,"In the past few years, the field of computer vision has gone through a revolution fueled mainly by the advent of large datasets and the adoption of deep convolutional neural networks for end-to-end learning.",background,0
8885,"The person reidentification subfield is no exception to this, thanks to the notable publication of the Market-1501 and MARS datasets and several strong deep learning approaches.",result,3
8886,"Unfortunately, a prevailing belief in the community seems to be that the triplet loss is inferior to using surrogate losses (classification, verification) followed by a separate metric learning step.",result,3
8887,"We show that, for models trained from scratch as well as pretrained ones, using a variant of the triplet loss to perform end-to-end deep metric learning outperforms any other published method by a large margin.",result,3
8888,This paper discusses the limitations of time-based equipment maintenance methods and the advantages of predictive or online maintenance techniques in identifying the onset of equipment failure.,method,2
8889,"The three major predictive maintenance techniques, defined in terms of their source of data, are described as follows: 1) the existing sensor-based technique; 2) the test-sensor-based technique (including wireless sensors); and 3) the test-signal-based technique (including the loop current step response method, the time-domain reflectrometry test, and the inductance-capacitance-resistance test).",method,2
8890,Examples of detecting blockages in pressure sensing lines using existing sensor-based techniques and of verifying calibration using existing-sensor direct current output are given.,method,2
8891,"Three Department of Energy (DOE)-sponsored projects, whose aim is to develop online and wireless hardware and software systems for performing predictive maintenance on critical equipment in nuclear power plants, DOE research reactors, and general industrial applications, are described.",objective,1
8892,We present a new keyword extraction algorithm that applies to a single document without using a corpus.,objective,1
8893,"Frequent terms are extracted first, then a set of co-occurrences between each term and the frequent terms, i.e., occurrences in the same sentences, is generated.",method,2
8894,Co-occurrence distribution shows importance of a term in the document as follows.,method,2
8895,"If the probability distribution of co-occurrence between term a and the frequent terms is biased to a particular subset of frequent terms, then term a is likely to be a keyword.",method,2
8896,The degree of bias of a distribution is measured by the χ2-measure.,method,2
8897,Our algorithm shows comparable performance to tfidf without using a corpus.,method,2
8898,Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers.,background,0
8899,"We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline.",background,0
8900,We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks.,objective,1
8901,"Following this finding – and building on other recent work for finding simple network structures – we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet).",method,2
8902,"To analyze the network we introduce a new variant of the “deconvolution approach” for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.",method,2
8903,The Floyd-Warshall algorithm is a simple and widely used algorithm to compute shortest paths between all pairs of vertices in an edge weighted directed graph.,background,0
8904,It can also be used to detect the presence of negative cycles.,background,0
8905,We will show that for this task many existing implementations of the Floyd-Warshall algorithm will fail because exponentially large numbers can appear during its execution.,other,4
8906,"Social media are gaining popularity and are increasingly used in regular operations of many companies, including start-ups, small, medium-sized, and large organizations.",background,0
8907,The purpose of this research is to explore the impact of social media and to analyze to what extent social media have impact on organizational capabilities and business performance.,objective,1
8908,We develop a research model and two simple propositions based on the resource based view of the firm.,method,2
8909,"We analyze the impact of six social media applications on six business capabilities and on business performance in SponsorPay, a start-up company since 2009 in the on-line game advertising industry.",method,2
8910,We use a mixed research method including qualitative analysis based on interviews and quantitative analysis based on a survey among 60 employees.,result,3
8911,We find that the use of social media enhances business capabilities and business performance.,other,4
8912,"The impact is not due to one (out of six) social media tools only, but due to successfully combining the six social media tools into one effective social media ecosystem that enables coordination between internal and external business processes.",result,3
8913,Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms.,background,0
8914,Relatively little work has focused on learning representations for clustering.,background,0
8915,"In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks.",method,2
8916,DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective.,method,2
8917,Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.,result,3
8918,A novel multivariable laboratory process that consists of four interconnected water tanks is presented.,background,0
8919,The linearized dynamics of the system have a multivariable zero that is possible to move along the real axis by changing a valve.,method,2
8920,The zero can be placed in both the lefr and the right half-plane.,method,2
8921,"I n this way the quadrupletank process is ideal for illustrating many concepts in multivariable control, particularly performance limitations due to multivariable right halfplane zeros.",objective,1
8922,Accurate models are derived from both physical and experimental data and multi-loop control is illustrated.,result,3
8923,"Over the past few years, there has been an increased interest in automatic facial behavior analysis and understanding.",background,0
8924,"We present OpenFace 2.0 - a tool intended for computer vision and machine learning researchers, affective computing community and people interested in building interactive applications based on facial behavior analysis.",objective,1
8925,"OpenFace 2.0 is an extension of OpenFace toolkit and is capable of more accurate facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.",method,2
8926,The computer vision algorithms which represent the core of OpenFace 2.0 demonstrate state-of-the-art results in all of the above mentioned tasks.,result,3
8927,"Furthermore, our tool is capable of real-time performance and is able to run from a simple webcam without any specialist hardware.",result,3
8928,"Finally, unlike a lot of modern approaches or toolkits, OpenFace 2.0 source code for training models and running them is freely available for research purposes.",result,3
8929,"We present ShapeNet: a richly-annotated, large-scale repository of shapes represented by 3D CAD models of objects.",background,0
8930,ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy.,objective,1
8931,"It is a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations.",method,2
8932,"Annotations are made available through a public web-based interface to enable data visualization of object attributes, promote data-driven geometric analysis, and provide a large-scale quantitative benchmark for research in computer graphics and vision.",method,2
8933,"At the time of this technical report, ShapeNet has indexed more than 3,000,000 models, 220,000 models out of which are classified into 3,135 categories (WordNet synsets).",result,3
8934,"In this report we describe the ShapeNet effort as a whole, provide details for all currently available datasets, and summarize future plans.",result,3
8935,"A leaking water pipe bursting high pressure water jet in the soil will create slurry erosion which will eventually erode the adjacent natural gas pipe, thus causing its failure.",background,0
8936,The standard 300 mm safety distance used to place natural gas pipe away from water pipeline facilities needs to be reviewed to consider accidental damage and provide safety cushion to the natural gas pipe.,background,0
8937,This paper presents a study on underground natural gas pipeline safety distance via experimental and numerical approaches.,objective,1
8938,The pressure–distance characteristic curve obtained from this experimental study showed that the pressure was inversely proportional to the square of the separation distance.,method,2
8939,"Experimental testing using water-to-water pipeline system environment was used to represent the worst case environment, and could be used as a guide to estimate appropriate safety distance.",method,2
8940,Dynamic pressures obtained from the experimental measurement and simulation prediction mutually agreed along the high-pressure water jetting path.,result,3
8941,"From the experimental and simulation exercises, zero effect distance for water-to-water medium was obtained at an estimated horizontal distance at a minimum of 1500 mm, while for the water-to-sand medium, the distance was estimated at a minimum of 1200 mm.",result,3
8942,& 2014 Elsevier Ltd. All rights reserved.,other,4
8943,University students are increasingly choosing to purchase e-textbooks for their mobile devices as an alternative to traditional textbooks.,background,0
8944,This study examines the relationship between textbook format and 538 university students’ grades and perceived learning scores.,background,0
8945,"Results demonstrate that there was no difference in cognitive learning and grades between the two groups, suggesting that the electronic textbook is as effective for learning as the traditional textbook.",result,3
8946,The mean scores indicated that students who chose e-textbooks for their education courses had significantly higher perceived affective learning and psychomotor learning than students who chose to use traditional print textbooks.,background,0
8947,Published by Elsevier Ltd.,other,4
8948,This paper presents a model for end-toend learning of task-oriented dialog systems.,objective,1
8949,"The main component of the model is a recurrent neural network (an LSTM), which maps from raw dialog history directly to a distribution over system actions.",method,2
8950,"The LSTM automatically infers a representation of dialog history, which relieves the system developer of much of the manual feature engineering of dialog state.",method,2
8951,"In addition, the developer can provide software that expresses business rules and provides access to programmatic APIs, enabling the LSTM to take actions in the real world on behalf of the user.",method,2
8952,"The LSTM can be optimized using supervised learning (SL), where a domain expert provides example dialogs which the LSTM should imitate; or using reinforcement learning (RL), where the system improves by interacting directly with end users.",method,2
8953,Experiments show that SL and RL are complementary: SL alone can derive a reasonable initial policy from a small number of training dialogs; and starting RL optimization with a policy trained with SL substantially accelerates the learning rate of RL.,result,3
8954,The aim of the current work is to assess the challenges that gamification in education are facing nowadays.,objective,1
8955,Benefits and disadvantages of using gamification in classroom are both discussed to offer a clearer view on the impact of using gamification within learning process.,background,0
8956,Exploratory study –cases are provided to investigate the relation between motivation and engagement of the students and gamification in training.,method,2
8957,"Following this idea, a survey was conducted to assess how students’ behavior and motivation is affected by introducing a single, specific gamification element during a semester learning process.",method,2
8958,"To stimulate competition among students, a ranking type plugin was introduced within the university learning management system used for extramural education.",method,2
8959,The results prove that motivation decreases by comparison to the previous semester.,result,3
8960,This paper presents an overview of two maintenance techniques widely discussed in the literature: timebased maintenance (TBM) and condition-based maintenance (CBM).,background,0
8961,The paper discusses how the TBM and CBM techniques work toward maintenance decision making.,objective,1
8962,Recent research articles covering the application of each technique are reviewed.,background,0
8963,"The paper then compares the challenges of implementing each technique from a practical point of view, focusing on the issues of required data determination and collection, data analysis/modelling, and decision making.",method,2
8964,The paper concludes with significant considerations for future research.,background,0
8965,"Each of the techniques was found to have unique concepts/principles, procedures, and challenges for real industrial practise.",method,2
8966,"It can be concluded that the application of the CBM technique is more realistic, and thus more worthwhile to apply, than the TBM one.",result,3
8967,"However, further research on CBM must be carried out in order to make it more realistic for making maintenance decisions.",background,0
8968,The paper provides useful information regarding the application of the TBM and CBM techniques in maintenance decision making and explores the challenges in implementing each technique from a practical,result,3
8969,Digital inpainting provides a means for reconstruction of small damaged portions of an image.,background,0
8970,"Although the inpainting basics are straightforward, most inpainting techniques published in the literature are complex to understand and implement.",background,0
8971,We present here a new algorithm for digital inpainting based on the fast marching method for level set applications.,objective,1
8972,"Our algorithm is very simple to implement, fast, and produces nearly identical results to more complex, and usually slower, known methods.",method,2
8973,Source code is available online.,other,4
8974,1. Established relevance of authalic spherical parametrization for creating geometry images used subsequently in CNN. 2.,background,0
8975,Robust authalic parametrization of arbitrary shapes using area restoring diffeomorphic flow and barycentric mapping.,background,0
8976,3.,other,4
8977,"Creation of geometry images (a) with appropriate shape feature for rigid/non-rigid shape analysis, (b) which are robust to cut and amenable to learn using CNNs.",method,2
8978,Experiments Cuts & Data Augmentation,result,3
8979,We are concerned with the issues of outlier detection and change point detection from a data stream.,background,0
8980,"In the area of data mining, there have been increased interest in these issues since the former is related to fraud detection, rare event discovery, etc.",background,0
8981,", while the latter is related to event/trend by change detection, activity monitoring, etc.",background,0
8982,"Specifically, it is important to consider the situation where the data source is non-stationary, since the nature of data source may change over time in real applications.",background,0
8983,"Although in most previous work outlier detection and change point detection have not been related explicitly, this paper presents a unifying framework for dealing with both of them on the basis of the theory of on-line learning of non-stationary time series.",method,2
8984,"In this framework a probabilistic model of the data source is incrementally learned using an on-line discounting learning algorithm, which can track the changing data source adaptively by forgetting the effect of past data gradually.",method,2
8985,"Then the score for any given data is calculated to measure its deviation from the learned model, with a higher score indicating a high possibility of being an outlier.",method,2
8986,Further change points in a data stream are detected by applying this scoring method into a time series of moving averaged losses for prediction using the learned model.,method,2
8987,"Specifically we develop an efficient algorithms for on-line discounting learning of auto-regression models from time series data, and demonstrate the validity of our framework through simulation and experimental applications to stock market data analysis.",result,3
8988,"Large-scale Internet of Things (IoT) deployments demand long-range wireless communications, especially in urban and metropolitan areas.",background,0
8989,LoRa is one of the most promising technologies in this context due to its simplicity and flexibility.,background,0
8990,"Indeed, deploying LoRa networks in dense IoT scenarios must achieve two main goals: efficient communications among a large number of devices and resilience against dynamic channel conditions due to demanding environmental settings (e.g., the presence of many buildings).",background,0
8991,This work investigates adaptive mechanisms to configure the communication parameters of LoRa networks in dense IoT scenarios.,objective,1
8992,"To this end, we develop FLoRa, an open-source framework for end-to-end LoRa simulations in OMNeT++.",method,2
8993,We then implement and evaluate the Adaptive Data Rate (ADR) mechanism built into LoRa to dynamically manage link parameters for scalable and efficient network operations.,method,2
8994,"Extensive simulations show that ADR is effective in increasing the network delivery ratio under stable channel conditions, while keeping the energy consumption low.",result,3
8995,Our results also show that the performance of ADR is severely affected by a highly-varying wireless channel.,result,3
8996,We thereby propose an improved version of the original ADR mechanism to cope with variable channel conditions.,result,3
8997,"Our proposed solution significantly increases both the reliability and the energy efficiency of communications over a noisy channel, almost irrespective of the network size.",result,3
8998,ÐThe primary goal of pattern recognition is supervised or unsupervised classification.,background,0
8999,"Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice.",background,0
9000,"More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention.",background,0
9001,"The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation.",method,2
9002,"In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved.",method,2
9003,"New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques.",method,2
9004,The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.,objective,1
9005,"Index TermsÐStatistical pattern recognition, classification, clustering, feature extraction, feature selection, error estimation, classifier combination, neural networks.",result,3
9006,Bottleneck features have been shown to be effective in improving the accuracy of automatic speech recognition (ASR) systems.,objective,1
9007,"Conventionally, bottleneck features are extracted from a multi-layer perceptron (MLP) trained to predict context-independent monophone states.",method,2
9008,The MLP typically has three hidden layers and is trained using the backpropagation algorithm.,method,2
9009,"In this paper, we propose two improvements to the training of bottleneck features motivated by recent advances in the use of deep neural networks (DNNs) for speech recognition.",objective,1
9010,"First, we show how the use of unsupervised pretraining of a DNN enhances the network’s discriminative power and improves the bottleneck features it generates.",method,2
9011,"Second, we show that a neural network trained to predict context-dependent senone targets produces better bottleneck features than one trained to predict monophone states.",result,3
9012,Bottleneck features trained using the proposed methods produced a 16% relative reduction in sentence error rate over conventional bottleneck features on a large vocabulary business search task.,result,3
9013,"In this paper, we derive the Cramér-Rao bound (CRB) for range estimation, which does not only exploit the range information in the time delay, but also in the amplitude of the received signal.",background,0
9014,This new bound is lower than the conventional CRB that only makes use of the range information in the time delay.,method,2
9015,We investigate the new bound in an additive white Gaussian noise (AWGN) channel with attenuation by employing both narrowband (NB) signals and ultra-wideband (UWB) signals.,method,2
9016,"For NB signals, the new bound can be 3dB lower than the conventional CRB under certain conditions.",result,3
9017,"However, there is not much difference between the new bound and the conventional CRB for UWB signals.",result,3
9018,"Further, shadowing effects are added into the data model.",result,3
9019,Several CRB-like bounds for range estimation are derived to take these shadowing effects into account.,result,3
9020,"In the spectrum of vision-based autonomous driving, vanilla end-to-end models are not interpretable and suboptimal in performance, while mediated perception models require additional intermediate representations such as segmentation masks or detection bounding boxes, whose annotation can be prohibitively expensive as we move to a larger scale.",background,0
9021,"Raw images and existing intermediate representations are also loaded with nuisance details that are irrelevant to the prediction of vehicle commands, e.g. the style of the car in front or the view beyond the road boundaries.",background,0
9022,"More critically, all prior works fail to deal with the notorious domain shift if we were to merge data collected from different sources, which greatly hinders the model generalization ability.",background,0
9023,"In this work, we address the above limitations by taking advantage of virtual data collected from driving simulators, and present DU-drive, an unsupervised real to virtual domain unification framework for end-to-end driving.",method,2
9024,"It transforms real driving data to its canonical representation in the virtual domain, from which vehicle control commands are predicted.",method,2
9025,"Our framework has several advantages: 1) it maps driving data collected from different source distributions into a unified domain, 2) it takes advantage of annotated virtual data which is free to obtain, 3) it learns an interpretable, canonical representation of driving image that is specialized for vehicle command prediction.",method,2
9026,Extensive experiments on two public highway driving datasets clearly demonstrate the performance superiority and interpretive capability of DU-drive.,result,3
9027,"In recent years broad community of researchers has emerged, focusing on the original ambitious goals of the AI field – the creation and study of software or hardware systems with general intelligence comparable to, and ultimately perhaps greater than, that of human beings.",background,0
9028,This paper surveys this diverse community and its progress.,background,0
9029,"Approaches to defining the concept of Artificial General Intelligence (AGI) are reviewed including mathematical formalisms, engineering, and biology inspired perspectives.",objective,1
9030,"The spectrum of designs for AGI systems includes systems with symbolic, emergentist, hybrid and universalist characteristics.",method,2
9031,"Metrics for general intelligence are evaluated, with a conclusion that, although metrics for assessing the achievement of human-level AGI may be relatively straightforward (e.g. the Turing Test, or a robot that can graduate from elementary school or university), metrics for assessing partial progress remain more controversial and problematic.",result,3
9032,"| In this paper, we consider path planning for a car-like vehicle.",background,0
9036,"Praxit ele programme on individual urban public transports 1993-1997], and the Inco-Copernicus ERB-IC15-CT96-0702 project \Multi-agent robot systems for industrial applications in the transport domain"" 1997-1999].",method,2
9037,"Abstract: In this paper, we consider path planning for a car-like vehicle.",method,2
9041,Convolutional Neural Networks (CNNs) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals.,background,0
9042,"Since speech signals exhibit both of these properties, CNNs are a more effective model for speech compared to Deep Neural Networks (DNNs).",background,0
9043,"In this paper, we explore applying CNNs to large vocabulary speech tasks.",objective,1
9044,"First, we determine the appropriate architecture to make CNNs effective compared to DNNs for LVCSR tasks.",method,2
9045,"Specifically, we focus on how many convolutional layers are needed, what is the optimal number of hidden units, what is the best pooling strategy, and the best input feature type for CNNs.",method,2
9046,"We then explore the behavior of neural network features extracted from CNNs on a variety of LVCSR tasks, comparing CNNs to DNNs and GMMs.",method,2
9047,"We find that CNNs offer between a 13-30% relative improvement over GMMs, and a 4-12% relative improvement over DNNs, on a 400-hr Broadcast News and 300-hr Switchboard task.",result,3
9048,"Scientific Question Answering (SQA) is a challenging open-domain task which requires the capability to understand questions and choices, collect useful information, and reason over evidence.",background,0
9049,Previous work typically formulates this task as a reading comprehension or entailment problem given evidence retrieved from search engines.,background,0
9050,"However, existing techniques struggle to retrieve indirectly related evidence when no directly related evidence is provided, especially for complex questions where it is hard to parse precisely what the question asks.",method,2
9051,In this paper we propose a retriever-reader model that learns to attend on essential terms during the question answering process.,method,2
9052,"We build 1) an essential-term-aware ‘retriever’ which first identifies the most important words in a question, then reformulates the queries and searches for related evidence 2) an enhanced ‘reader’ to distinguish between essential terms and distracting words to predict the answer.",result,3
9053,We experimentally evaluate our model on the ARC dataset where it outperforms the existing state-of-the-art model by 7.4%.,result,3
9054,"Automatic age and gender classification has become relevant to an increasing amount of applications, particularly since the rise of social platforms and social media.",background,0
9055,"Nevertheless, performance of existing methods on real-world images is still significantly lacking, especially when compared to the tremendous leaps in performance recently reported for the related task of face recognition.",background,0
9056,"In this paper we show that by learning representations through the use of deep-convolutional neural networks (CNN), a significant increase in performance can be obtained on these tasks.",method,2
9057,"To this end, we propose a simple convolutional net architecture that can be used even when the amount of learning data is limited.",method,2
9058,We evaluate our method on the recent Adience benchmark for age and gender estimation and show it to dramatically outperform current state-of-the-art methods.,result,3
9059,"This work describes MATLAB/Simulink implementation of three induction motor tests, namely dc, no-load, and blocked-rotor tests performed to identify equivalent circuit parameters.",background,0
9061,"The proposed tests have been successfully integrated into electric machinery courses at Drexel University, Philadelphia, PA, and Nigde University, Nigde, Turkey.",result,3
9062,The move from hand-designed features to learned features in machine learning has been wildly successful.,background,0
9063,"In spite of this, optimization algorithms are still designed by hand.",background,0
9064,"In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way.",method,2
9065,"Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure.",result,3
9066,"We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.",result,3
9067,The Boeing Employee Credit Union (BECU) has been providing financial assistance to employees since 1935.,background,0
9068,"By 1938, membership had grown to 850 members.",background,0
9069,"During the 1990s, BECU grew from 150,000 members with 362,000 accounts to 260,000 members with 1,170,174 accounts.",background,0
9070,"BECU is the largest financial cooperative in Washington State, and the third largest credit union in the country.",background,0
9071,"Without significant investments in information technology, however, it would be impossible for BECU to deliver personalized service to its members.",background,0
9072,The idea of creating a member-centric information systems capability was first expressed in May 1999.,background,0
9073,"Today, the data warehouse has resulted in many benefits, including plans to leverage the $2 million investment by providing three distinct types of service.",background,0
9074,"This case study details these three types of service, the impact of each service on BECU's performance, and the future directions and the lessons learned from the project.",method,2
9075,We believe that current research in creativity (especially in artificial intelligence and to a great extent psychology) focuses too much on the product and on exceptional (big-C) creativity.,background,0
9076,"In this paper we want to argue that creative thinking and creative behavior result from the continuation of typical human cognitive development and that by looking into the early stages of this development, we can learn more about creativity.",objective,1
9077,"Furthermore, we wish to see analogy as a core mechanism in human cognitive development rather than a special skill among many.",background,0
9078,Some developmental psychology results that support this claim are reviewed.,result,3
9079,Analogy and metaphor are also seen as central for the creative process.,method,2
9080,"Whereas mainstream research in artificial creativity and computational models of reasoning by analogy stresses the importance of matching the structure between the source and the target domains, we suggest that perceptual similarities play a much more important role, at least when it comes to creative problem solving.",result,3
9081,We provide some empirical data to support these claims and discuss their consequences.,other,4
9082,"In this paper, we present the strategy for trajectory planning that was used on-board the vehicle that completed the 103 km of the Bertha-Benz-Memorial-Route fully autonomously.",background,0
9083,"We suggest a local, continuous method that is derived from a variational formulation.",method,2
9084,The solution trajectory is the constrained extremum of an objective function that is designed to express dynamic feasibility and comfort.,method,2
9085,Static and dynamic obstacle constraints are incorporated in the form of polygons.,method,2
9086,"The constraints are carefully designed to ensure that the solution converges to a single, global optimum.",method,2
9087,"Motivated by requirements of Web 2.0 applications, a plethora of non-relational databases raised in recent years.",background,0
9088,"Since it is very difficult to choose a suitable database for a specific use case, this paper evaluates the underlying techniques of NoSQL databases considering their applicability for certain requirements.",background,0
9089,"These systems are compared by their data models, query possibilities, concurrency controls, partitioning and replication opportunities.",background,0
9090,"A large number of 3D models are created and available on the Web, since more and more 3D modelling and digitizing tools are developed for ever increasing applications.",background,0
9091,The techniques for content-based 3D model retrieval then become necessary.,background,0
9092,"In this paper, a visual similarity-based 3D model retrieval system is proposed.",objective,1
9093,"This approach measures the similarity among 3D models by visual similarity, and the main idea is that if two 3D models are similar, they also look similar from all viewing angles.",objective,1
9094,"Therefore, one hundred orthogonal projections of an object, excluding symmetry, are encoded both by Zernike moments and Fourier descriptors as features for later retrieval.",objective,1
9095,"The visual similarity-based approach is robust against similarity transformation, noise, model degeneracy etc., and provides 42%, 94% and 25% better performance (precision-recall evaluation diagram) than three other competing approaches: (1)the spherical harmonics approach developed by Funkhouser et al., (2)the MPEG-7 Shape 3D descriptors, and (3)the MPEG-7 Multiple View Descriptor.",objective,1
9096,"The proposed system is on the Web for practical trial use (http://3d.csie.ntu.edu.tw), and the database contains more than 10,000 publicly available 3D models collected from WWW pages.",method,2
9097,"Furthermore, a user friendly interface is provided to retrieve 3D models by drawing 2D shapes.",method,2
9098,"The retrieval is fast enough on a server with Pentium IV 2.4GHz CPU, and it takes about 2 seconds and 0.1 seconds for querying directly by a 3D model and by hand drawn 2D shapes, respectively.",result,3
9099,"We propose the use of classifiers and machine learning techniques to extract useful information from data sets (e.g., images) to solve important problems in Image Processing and Computer Vision.",objective,1
9100,"We are interested in: two and multiclass image categorization, hidden messages detection, discrimination among natural and forged images, authentication, and multi-classification.",objective,1
9101,Keywords-Machine Learning Techniques; Digital Forensics; Steganalysis; Feature Fusion; Classifier Fusion; Multi-class Classification; Image Categorization.,other,4
9102,Extracting open relational tuples that are mediated by nouns (instead of verbs) is important since titles and entity attributes are often expressed nominally.,background,0
9103,"While appositives and possessives are easy to handle, a difficult and important class of nominal extractions requires interpreting compound noun phrases (e.g., “Google CEO Larry Page”).",background,0
9104,We substantially improve the quality of Open IE from compound noun phrases by focusing on phenomena like demonyms and compound relational nouns.,method,2
9105,"We release RELNOUN 2.2, which obtains 3.5 times yield with over 15 point improvement in precision compared to RELNOUN 1.1, a publicly available nominal Open IE system.",result,3
9106,"The k-anonymity privacy requirement for publishing microdata requires that each equivalence class (i.e., a set of records that are indistinguishable from each other with respect to certain ""identifying"" attributes) contains at least k records.",objective,1
9107,"Recently, several authors have recognized that k-anonymity cannot prevent attribute disclosure.",background,0
9108,The notion of l-diversity has been proposed to address this; l-diversity requires that each equivalence class has at least l well-represented values for each sensitive attribute.,background,0
9109,In this paper we show that l-diversity has a number of limitations.,background,0
9110,"In particular, it is neither necessary nor sufficient to prevent attribute disclosure.",background,0
9111,"We propose a novel privacy notion called t-closeness, which requires that the distribution of a sensitive attribute in any equivalence class is close to the distribution of the attribute in the overall table (i.e., the distance between the two distributions should be no more than a threshold t).",method,2
9112,We choose to use the earth mover distance measure for our t-closeness requirement.,method,2
9113,We discuss the rationale for t-closeness and illustrate its advantages through examples and experiments.,result,3
9114,"A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module.",background,0
9115,Building these components often requires extensive domain expertise and may contain brittle design choices.,background,0
9116,"In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters.",objective,1
9117,"Given <text, audio> pairs, the model can be trained completely from scratch with random initialization.",method,2
9118,We present several key techniques to make the sequence-tosequence framework perform well for this challenging task.,method,2
9121,Energy management means to optimize one of the most complex and important technical creations that we know: the energy system.,background,0
9122,"While there is plenty of experience in optimizing energy generation and distribution, it is the demand side that receives increasing attention by research and industry.",background,0
9123,Demand Side Management (DSM) is a portfolio of measures to improve the energy system at the side of consumption.,background,0
9124,"It ranges from improving energy efficiency by using better materials, over smart energy tariffs with incentives for certain consumption patterns, up to sophisticated real-time control of distributed energy resources.",method,2
9125,"This paper gives an overview and a taxonomy for DSM, analyzes the various types of DSM, and gives an outlook on the latest demonstration projects in this domain.",result,3
9126,In this paper we consider the problem of multi-view face detection.,background,0
9127,"While there has been significant research on this problem, current state-of-the-art approaches for this task require annotation of facial landmarks, e.g. TSM [25], or annotation of face poses [28, 22].",background,0
9128,"They also require training dozens of models to fully capture faces in all orientations, e.g. 22 models in HeadHunter method [22].",background,0
9129,"In this paper we propose Deep Dense Face Detector (DDFD), a method that does not require pose/landmark annotation and is able to detect faces in a wide range of orientations using a single model based on deep convolutional neural networks.",method,2
9130,"The proposed method has minimal complexity; unlike other recent deep learning object detection methods [9], it does not require additional components such as segmentation, bounding-box regression, or SVM classifiers.",method,2
9131,"Furthermore, we analyzed scores of the proposed face detector for faces in different orientations and found that 1) the proposed method is able to detect faces from different angles and can handle occlusion to some extent, 2) there seems to be a correlation between distribution of positive examples in the training set and scores of the proposed face detector.",method,2
9132,The latter suggests that the proposed method's performance can be further improved by using better sampling strategies and more sophisticated data augmentation techniques.,method,2
9133,"Evaluations on popular face detection benchmark datasets show that our single-model face detector algorithm has similar or better performance compared to the previous methods, which are more complex and require annotations of either different poses or facial landmarks.",result,3
9134,Network traffic monitoring and analysis-related research has struggled to scale for massive amounts of data in real time.,background,0
9135,Some of the vertical scaling solutions provide good implementation of signature based detection.,background,0
9136,"Unfortunately these approaches treat network flows across different subnets and cannot apply anomaly-based classification if attacks originate from multiple machines at a lower speed, like the scenario of Peer-to-Peer Botnets.",background,0
9137,"In this paper the authors build up on the progress of open source tools like Hadoop, Hive and Mahout to provide a scalable implementation of quasi-real-time intrusion detection system.",method,2
9138,The implementation is used to detect Peer-to-Peer Botnet attacks using machine learning approach.,method,2
9139,The contributions of this paper are as follows: (1) Building a distributed framework using Hive for sniffing and processing network traces enabling extraction of dynamic network features; (2) Using the parallel processing power of Mahout to build Random Forest based Decision Tree model which is applied to the problem of Peer-to-Peer Botnet detection in quasi-real-time.,method,2
9140,The implementation setup and performance metrics are presented as initial observations and future extensions are proposed.,result,3
9141,2014 Elsevier Inc. All rights reserved.,other,4
9142,"This paper describes experiments, on two domains, to investigate the effect of averaging over predictions of multiple decision trees, instead of using a single tree.",background,0
9143,Other authors have pointed out theoretical and commonsense reasons for preferring· the multiple tree approach.,background,0
9144,"Ideally, we would like to consider predictions from all trees, weighted by their probability.",background,0
9145,"However, there is a vast·number of different trees, and it is difficult to estimate the probability of each tree.",background,0
9146,"We sidestep the estimation problem by using a modified version of the ID3 algorithm to build good trees, and average over only these trees.",method,2
9147,Our results are encouraging.,result,3
9148,"For each domain, we managed to produce a small number of good trees.",result,3
9149,"We fmd that it is best to average across sets of trees with different structure; this usually gives better perfonnance than any of the constituent trees, including the ID3 tree.",result,3
9150,This work introduces a new dataset and framework for the exploration of topological data analysis (TDA) techniques applied to time-series data.,objective,1
9151,We examine the end-toend TDA processing pipeline for persistent homology applied to time-delay embeddings of time series – embeddings that capture the underlying system dynamics from which time series data is acquired.,method,2
9152,"In particular, we consider stability with respect to time series length, the approximation accuracy of sparse filtration methods, and the discriminating ability of persistence diagrams as a feature for learning.",method,2
9153,We explore these properties across a wide range of time-series datasets spanning multiple domains for single source multi-segment signals as well as multi-source single segment signals.,method,2
9154,"Our analysis and dataset captures the entire TDA processing pipeline and includes time-delay embeddings, persistence diagrams, topological distance measures, as well as kernels for similarity learning and classification tasks for a broad set of time-series data sources.",result,3
9155,We outline the TDA framework and rationale behind the dataset and provide insights into the role of TDA for time-series analysis as well as opportunities for new work.,result,3
9156,"The body structure of an anatomically correct tendon-driven musculoskeletal humanoid is complex, and the difference between its geometric model and the actual robot is very large because expressing the complex routes of tendon wires in a geometric model is very difficult.",background,0
9157,"If we move a tendon-driven musculoskeletal humanoid by the tendon wire lengths of the geometric model, unintended muscle tension and slack will emerge.",background,0
9158,"In some cases, this can lead to the wreckage of the actual robot.",background,0
9159,"To solve this problem, we focused on reciprocal innervation in the human nervous system, and then implemented antagonist inhibition control (AIC)-based on the reflex.",method,2
9160,"This control makes it possible to avoid unnecessary internal muscle tension and slack of tendon wires caused by model error, and to perform wide range motion safely for a long time.",method,2
9161,"To verify its effectiveness, we applied AIC to the upper limb of the tendon-driven musculoskeletal humanoid, Kengoro, and succeeded in dangling for 14 min and doing pull-ups.",method,2
9162,It is necessary to understand the content of articles and user preferences to make effective news recommendations.,background,0
9163,"While ID-based methods, such as collaborative filtering and low-rank factorization, are well known for making recommendations, they are not suitable for news recommendations because candidate articles expire quickly and are replaced with new ones within short spans of time.",background,0
9164,"Word-based methods, which are often used in information retrieval settings, are good candidates in terms of system performance but have issues such as their ability to cope with synonyms and orthographical variants and define ""queries"" from users' historical activities.",method,2
9165,"This paper proposes an embedding-based method to use distributed representations in a three step end-to-end manner: (i) start with distributed representations of articles based on a variant of a denoising autoencoder, (ii) generate user representations by using a recurrent neural network (RNN) with browsing histories as input sequences, and (iii) match and list articles for users based on inner-product operations by taking system performance into consideration.",method,2
9166,The proposed method performed well in an experimental offline evaluation using past access data on Yahoo!,result,3
9167,JAPAN's homepage.,other,4
9168,We implemented it on our actual news distribution system based on these experimental results and compared its online performance with a method that was conventionally incorporated into the system.,method,2
9169,"As a result, the click-through rate (CTR) improved by 23% and the total duration improved by 10%, compared with the conventionally incorporated method.",result,3
9170,Services that incorporated the method we propose are already open to all users and provide recommendations to over ten million individual users per day who make billions of accesses per month.,result,3
9171,Crowdsourcing is an umbrella term for a variety of approaches that tap into the potential of a large and open crowd of people.,background,0
9172,"So far, there is no systematic understanding of the processes used to source and aggregate contributions from the crowd.",background,0
9173,"In particular, crowdsourcing organizations striving to achieve a specific goal should be able to evaluate the mechanisms that impact these processes.",objective,1
9174,Following a method of IS taxonomy development we propose a new taxonomic framework for crowdsourcing processes.,method,2
9175,"In contrast to previous work, this classification scheme focuses exclusively on an organizational perspective and on the mechanisms available to these organizations.",method,2
9176,"The resulting dimensions are preselection of contributors, accessibility of peer contributions, aggregation of contributions, and remuneration for contributions.",result,3
9177,"By classifying the processes of 46 crowdsourcing examples, we identify 19 distinct process types.",result,3
9178,A subsequent cluster analysis shows general patterns among these types and indicates a link to certain applications of crowdsourcing.,result,3
9179,"In remote sensing image processing, relaxation is defined as a method that uses the local relationship among neighboring pixels to correct spectral or spatial distortions.",objective,1
9180,"In recent years, relaxation methods have shown great success in classification of remotely sensed data.",method,2
9181,"Relaxation, as a preprocessing step, can reduce noise and improve the class separability in the spectral domain.",result,3
9182,"On the other hand, relaxation (as a postprocessing approach) works on the label image or class probabilities obtained from pixelwise classifiers.",objective,1
9183,"In this work, we develop a discontinuity preserving relaxation strategy, which can be used for postprocessing of class probability estimates, as well as preprocessing of the original hyperspectral image.",method,2
9184,"The newly proposed method is an iterative relaxation procedure, which exploits spatial information in such a way that it considers discontinuities existing in the data cube.",method,2
9185,"Our experimental results indicate that the proposed methodology leads to state-of-the-art classification results when combined with probabilistic classifiers for several widely used hyperspectral data sets, even when very limited training samples are available.",result,3
9186,"This paper presents a model, synthesized from the literature, of factors that explain how business analytics contributes to business value.",background,0
9187,It also reports results from a preliminary test of that model.,objective,1
9188,The model consists of two parts: a process and a variance model.,method,2
9189,The process model depicts the analyze-insight-decision-action process through which use of an organization’s business-analytic capabilities create business value.,method,2
9190,"The variance model proposes that the five factors in Davenport et al.’s (2010) DELTA model of BA success factors, six from Watson and Wixom (2007), and three from Seddon et al.’s (2010) model of organizational benefits from enterprise systems, assist a firm to gain business value from business analytics.",method,2
9191,"A preliminary test of the model was conducted using data from 100 customer-success stories from vendors such as IBM, SAP, and Teradata.",result,3
9192,Our conclusion is that the model is likely to be a useful basis for future research.,result,3
9193,We propose a new decentralized access control scheme for secure data storage in clouds that supports anonymous authentication.,objective,1
9194,"In the proposed scheme, the cloud verifies the authenticity of the series without knowing the user's identity before storing data.",method,2
9195,Our scheme also has the added feature of access control in which only valid users are able to decrypt the stored information.,method,2
9196,"The scheme prevents replay attacks and supports creation, modification, and reading data stored in the cloud.",method,2
9197,We also address user revocation.,method,2
9198,"Moreover, our authentication and access control scheme is decentralized and robust, unlike other access control schemes designed for clouds which are centralized.",method,2
9199,"The communication, computation, and storage overheads are comparable to centralized approaches.",result,3
9200,"In this paper, we propose a simple but effective image prior-dark channel prior to remove haze from a single input image.",background,0
9201,The dark channel prior is a kind of statistics of outdoor haze-free images.,background,0
9202,It is based on a key observation-most local patches in outdoor haze-free images contain some pixels whose intensity is very low in at least one color channel.,objective,1
9203,"Using this prior with the haze imaging model, we can directly estimate the thickness of the haze and recover a high-quality haze-free image.",method,2
9204,Results on a variety of hazy images demonstrate the power of the proposed prior.,result,3
9205,"Moreover, a high-quality depth map can also be obtained as a byproduct of haze removal.",result,3
9206,"We present a set of algorithms that can be used to locate and crop the chess-board/chesspieces from the picture, including every rectangular grid with any pattern.",method,2
9207,"Our method is nonparametric, and thus does not require the prior knowledge from computer vision and machine learning, which is instead inferred from data.",method,2
9208,"We illustrate the application of our method to a variety of examples, such as chess-board cropping and regular grid-pattern localization.",method,2
9209,"In addition, we present two independent algorithms: PAMG (vertices detector) and FAPL (thermal lines) that can be widely used for other tasks in computer vision.",method,2
9210,"In the era of big data, transformation of biomedical big data into valuable knowledge has been one of the most important challenges in bioinformatics.",background,0
9211,Deep learning has advanced rapidly since the early 2000s and now demonstrates state-of-the-art performance in various fields.,background,0
9212,"Accordingly, application of deep learning in bioinformatics to gain insight from data has been emphasized in both academia and industry.",background,0
9213,"Here, we review deep learning in bioinformatics, presenting examples of current research.",background,0
9214,"To provide a useful and comprehensive perspective, we categorize research both by the bioinformatics domain (i.e. omics, biomedical imaging, biomedical signal processing) and deep learning architecture (i.e. deep neural networks, convolutional neural networks, recurrent neural networks, emergent architectures) and present brief descriptions of each study.",method,2
9215,"Additionally, we discuss theoretical and practical issues of deep learning in bioinformatics and suggest future research directions.",method,2
9216,We believe that this review will provide valuable insights and serve as a starting point for researchers to apply deep learning approaches in their bioinformatics studies.,result,3
9217,"This paper introduces SC2LE (StarCraft II Learning Environment), a reinforcement learning environment based on the game StarCraft II.",background,0
9218,"This domain poses a new grand challenge for reinforcement learning, representing a more difficult class of problems than considered in most prior work.",objective,1
9219,It is a multi-agent problem with multiple players interacting; there is imperfect information due to a partially observed map; it has a large action space involving the selection and control of hundreds of units; it has a large state space that must be observed solely from raw input feature planes; and it has delayed credit assignment requiring long-term strategies over thousands of steps.,background,0
9220,"We describe the observation, action, and reward specification for the StarCraft II domain and provide an open source Python-based interface for communicating with the game engine.",objective,1
9221,"In addition to the main game maps, we provide a suite of mini-games focusing on different elements of StarCraft II gameplay.",objective,1
9222,"For the main game maps, we also provide an accompanying dataset of game replay data from human expert players.",method,2
9223,We give initial baseline results for neural networks trained from this data to predict game outcomes and player actions.,method,2
9224,"Finally, we present initial baseline results for canonical deep reinforcement learning agents applied to the StarCraft II domain.",result,3
9225,"On the mini-games, these agents learn to achieve a level of play that is comparable to a novice player.",result,3
9226,"However, when trained on the main game, these agents are unable to make significant progress.",result,3
9227,"In this article, we build models to predict the existence of citations among papers by formulating link prediction for 5 large-scale datasets of citation networks.",background,0
9228,The supervised machine-learning model is applied with 11 features.,method,2
9229,"As a result, our learner performs very well, with the F1 values of between 0.74 and 0.82.",result,3
9230,"Three features in particular, link-based Jaccard coefficient , difference in betweenness centrality , and cosine similarity of term frequency–inverse document frequency vectors, largely affect the predictions of citations.",background,0
9231,The results also indicate that different models are required for different types of research areas—research fields with a single issue or research fields with multiple issues.,method,2
9232,"In the case of research fields with multiple issues, there are barriers among research fields because our results indicate that papers tend to be cited in each research field locally.",result,3
9233,"Therefore, one must consider the typology of targeted research areas when building models for link prediction in citation networks.",result,3
9234,Twitter is one of the biggest platforms where massive instant messages (i.e. tweets) are published every day.,background,0
9235,"Users tend to express their real feelings freely in Twitter, which makes it an ideal source for capturing the opinions towards various interesting topics, such as brands, products or celebrities, etc.",background,0
9236,"Naturally, people may anticipate an approach to receiving the common sentiment tendency towards these topics directly rather than through reading the huge amount of tweets about them.",objective,1
9237,"On the other side, Hashtags, starting with a symbol ""#"" ahead of keywords or phrases, are widely used in tweets as coarse-grained topics.",method,2
9238,"In this paper, instead of presenting the sentiment polarity of each tweet relevant to the topic, we focus our study on hashtag-level sentiment classification.",objective,1
9239,"This task aims to automatically generate the overall sentiment polarity for a given hashtag in a certain time period, which markedly differs from the conventional sentence-level and document-level sentiment analysis.",objective,1
9240,"Our investigation illustrates that three types of information is useful to address the task, including (1) sentiment polarity of tweets containing the hashtag; (2) hashtags co-occurrence relationship and (3) the literal meaning of hashtags.",objective,1
9241,"Consequently, in order to incorporate the first two types of information into a classification framework where hashtags can be classified collectively, we propose a novel graph model and investigate three approximate collective classification algorithms for inference.",result,3
9242,"Going one step further, we show that the performance can be remarkably improved using an enhanced boosting classification setting in which we employ the literal meaning of hashtags as semi-supervised information.",result,3
9243,"Experimental results on a real-life data set consisting of 29,195 tweets and 2,181 hashtags show the effectiveness of the proposed model and algorithms.",result,3
9244,Being able to build a map of the environment and to simultaneously localize within this map is an essential skill for mobile robots navigating in unknown environments in absence of external referencing systems such as GPS.,background,0
9245,This so-called simultaneous localization and mapping (SLAM) problem has been one of the most popular research topics in mobile robotics for the last two decades and efficient approaches for solving this task have been proposed.,background,0
9246,One intuitive way of formulating SLAM is to use a graph whose nodes correspond to the poses of the robot at different points in time and whose edges represent constraints between the poses.,method,2
9247,The latter are obtained from observations of the environment or from movement actions carried out by the robot.,method,2
9248,"Once such a graph is constructed, the map can be computed by finding the spatial configuration of the nodes that is mostly consistent with the measurements modeled by the edges.",method,2
9249,"In this paper, we provide an introductory description to the graph-based SLAM problem.",method,2
9250,"Furthermore, we discuss a state-of-the-art solution that is based on least-squares error minimization and exploits the structure of the SLAM problems during optimization.",method,2
9251,The goal of this tutorial is to enable the reader to implement the proposed methods from scratch.,result,3
9252,We report the results of a survey on music listening and management behaviours.,objective,1
9253,The survey was conducted online with 222 participants with mostly technical backgrounds drawn from a college age population.,method,2
9254,The median size of offline music collections was found to be roughly 2540 songs (both physical media and digital files).,result,3
9255,"The major findings of our survey show that elements such as familiarity of songs, how distracting they are, how much they match the listener’s mood, and the desire of changing the mood within one listening session, are all affected by the activity during which music is listened to.",result,3
9256,"While people want to have options for manipulating the above elements to control their experience, they prefer a minimal amount of interaction in general.",result,3
9257,Current music players lack such flexibility in their controls.,background,0
9258,"Finally, online recommender systems have not gained much popularity thus far.",result,3
9259,Most existing machine learning classifiers are highly vulnerable to adversarial examples.,background,0
9260,An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it.,background,0
9261,"In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake.",background,0
9262,"Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model.",background,0
9263,"Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier.",background,0
9264,"This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input.",background,0
9265,"This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples.",background,0
9266,We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system.,method,2
9267,We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.,result,3
9268,Recently there has been quite a number of independent research activities that investigate the potentialities of integrating social networking concepts into Internet of Things (IoT) solutions.,objective,1
9269,"The resulting paradigm, named Social Internet of Things (SIoT), has the potential to support novel applications and networking services for the IoT in more effective and efficient ways.",objective,1
9270,"In this context, the main contributions of this paper are the following: i) we identify appropriate policies for the establishment and the management of social relationships between objects in such a way that the resulting social network is navigable; ii) we describe a possible architecture for the IoT that includes the functionalities required to integrate things into a social network; iii) we analyze the characteristics of the SIoT network structure by means of simulations.",result,3
9271,This paper presents a scheme for large engineering project risk management using a Bayesian belief network and applies it to the Korean shipbuilding industry.,background,0
9272,Twenty-six different risks were deduced from expert interviews and a literature review.,background,0
9273,A survey analysis was conducted on 252 experts from 11 major Korean shipbuilding companies in April 2007.,background,0
9274,"The overall major risks were design change, design manpower, and raw material supply as internal risks, and exchange rate as external risk in both large-scale and medium-sized shipbuilding companies.",method,2
9275,Differences of project performance risks between large-scale and medium-sized shipbuilding companies were identified.,method,2
9276,"Exceeding time schedule and specification discontent were more important to large-scale shipbuilding companies, while exceeding budget and exceeding time schedule were more important to medium-sized shipbuilding companies.",method,2
9277,"The change of project performance risks was measured by risk reduction activities of quality management, and strikes at headquarters and subcontractors, in both large-scale and medium-sized shipbuilding companies.",method,2
9278,The research results should be valuable in enabling industrial participants to manage their large engineering project risks and in extending our understanding of Korean shipbuilding risks.,result,3
9279,2008 Elsevier Ltd. All rights reserved.,other,4
9280,Online social networks (OSNs) gradually integrate financial capabilities by enabling the usage of real and virtual currency.,background,0
9281,"They serve as new platforms to host a variety of business activities, such as online promotion events, where users can possibly get virtual currency as rewards by participating in such events.",background,0
9282,"Both OSNs and business partners are significantly concerned when attackers instrument a set of accounts to collect virtual currency from these events, which make these events ineffective and result in significant financial loss.",background,0
9283,It becomes of great importance to proactively detecting these malicious accounts before the online promotion activities and subsequently decreases their priority to be rewarded.,background,0
9284,"In this paper, we propose a novel system, namely ProGuard, to accomplish this objective by systematically integrating features that characterize accounts from three perspectives including their general behaviors, their recharging patterns, and the usage of their currency.",method,2
9285,"We have performed extensive experiments based on data collected from the Tencent QQ, a global leading OSN with built-in financial management activities.",method,2
9286,Experimental results have demonstrated that our system can accomplish a high detection rate of 96.67% at a very low false positive rate of 0.3%.,result,3
9287,There is a vast amount of financial information on companies financial performance available to investors today.,background,0
9288,"While automatic analysis of financial figures is common, it has been difficult to automatically extract meaning from the textual part of financial reports.",background,0
9289,The textual part of an annual report contains richer information than the financial ratios.,background,0
9290,"In this paper, we combine data mining methods for analyzing quantitative and qualitative data from financial reports, in order to see if the textual part of the report contains some indication about future financial performance.",method,2
9291,"The quantitative analysis has been performed using selforganizing maps, and the qualitative analysis using prototype-matching text clustering.",method,2
9292,The analysis is performed on the quarterly reports of three leading companies in the telecommunications sector.,result,3
9293,Automatic identification is an efficient technology for the identification of butterfly species and pest control.,background,0
9294,"As the major agriculture and forest pest, butterflies can be accurately classified based on the taxonomic characters.",background,0
9295,"However, such identification can be only achieved by a few insect experts with years of experience.",background,0
9296,"In the study, the shape and texture of butterflies were investigated for the automatic identification of butterfly species in the digital images: Histograms of multi-scale curvature (HoMSC) and gray-level co-occurrence matrix of image blocks (GLCMoIB) were used to describe the shape and texture of butterfly wings, respectively.",result,3
9297,"To get an accurate identification result, a weight-based k-nearest neighbor classifier was designed.",method,2
9298,"In addition, 750 images of 50 butterfly species were used for the identification test.",result,3
9299,The accuracy rate of this automatic identification method reached 98%.,result,3
9300,The result suggested that the HoMSC and GLCMoIB features can be efficient for the identification of butterfly species.,result,3
9301,"Label noise is an important issue in classification, with many potential negative consequences.",background,0
9302,"For example, the accuracy of predictions may decrease, whereas the complexity of inferred models and the number of necessary training samples may increase.",method,2
9303,Many works in the literature have been devoted to the study of label noise and the development of techniques to deal with label noise.,background,0
9304,"However, the field lacks a comprehensive survey on the different types of label noise, their consequences and the algorithms that consider label noise.",method,2
9305,This paper proposes to fill this gap.,objective,1
9306,"First, the definitions and sources of label noise are considered and a taxonomy of the types of label noise is proposed.",objective,1
9307,"Second, the potential consequences of label noise are discussed.",objective,1
9308,"Third, label noise-robust, label noise cleansing, and label noise-tolerant algorithms are reviewed.",method,2
9309,"For each category of approaches, a short discussion is proposed to help the practitioner to choose the most suitable technique in its own particular field of application.",objective,1
9310,"Eventually, the design of experiments is also discussed, what may interest the researchers who would like to test their own algorithms.",method,2
9311,"The face image is the most accessible biometric modality which is used for highly accurate face recognition systems, while it is vulnerable to many different types of presentation attacks.",background,0
9312,Face anti-spoofing is a very critical step before feeding the face image to biometric systems.,background,0
9313,"In this paper, we propose a novel two-stream CNN-based approach for face anti-spoofing, by extracting the local features and holistic depth maps from the face images.",method,2
9314,The local features facilitate CNN to discriminate the spoof patches independent of the spatial face areas.,method,2
9315,"On the other hand, holistic depth map examine whether the input image has a face-like depth.",method,2
9316,"Extensive experiments are conducted on the challenging databases (CASIA-FASD, MSU-USSA, and Replay Attack), with comparison to the state of the art.",method,2
9317,A major challenge for managers in turbulent environments is to make sound decisions quickly.,background,0
9318,"Dynamic capabilities have been proposed as a means for addressing turbulent environments by helping managers extend, modify, and reconfigure existing operational capabilities into new ones that better match the environment.",background,0
9319,"However, because dynamic capabilities have been viewed as an elusive black box, it is difficult for managers to make sound decisions in turbulent environments if they cannot effectively measure dynamic capabilities.",background,0
9320,"Therefore, we first seek to propose a measurable model of dynamic capabilities by conceptualizing, operationalizing, and measuring dynamic capabilities.",method,2
9321,"Specifically, drawing upon the dynamic capabilities literature, we identify a set of capabilities—sensing the environment, learning, coordinating, and integrating— that help reconfigure existing operational capabilities into new ones that better match the environment.",method,2
9322,"Second, we propose a structural model where dynamic capabilities influence performance by reconfiguring existing operational capabilities in the context of new product development (NPD).",method,2
9323,"Data from 180 NPD units support both the measurable model of dynamic capabilities and also the structural model by which dynamic capabilities influence performance in NPD by reconfiguring operational capabilities, particularly in higher levels of environmental turbulence.",result,3
9324,The study’s implications for managerial decision making in turbulent environments by capturing the elusive black box of dynamic capabilities are discussed.,result,3
9325,"Subject Areas: Decision Making in Turbulent Environments, Dynamic Capabilities, Environmental Turbulence, New Product Development, and Operational Capabilities.",other,4
9326,"While deep learning based methods for generic object detection have improved rapidly in the last two years, most approaches to face detection are still based on the R-CNN framework [11], leading to limited accuracy and processing speed.",method,2
9327,"In this paper, we investigate applying the Faster RCNN [26], which has recently demonstrated impressive results on various object detection benchmarks, to face detection.",method,2
9328,"By training a Faster R-CNN model on the large scale WIDER face dataset [34], we report state-of-the-art results on the WIDER test set as well as two other widely used face detection benchmarks, FDDB and the recently released IJB-A.",result,3
9329,"Recently, Convolutional Neural Network (CNN) based models have achieved great success in Single Image Super-Resolution (SISR).",background,0
9330,"Owing to the strength of deep networks, these CNN models learn an effective nonlinear mapping from the low-resolution input image to the high-resolution target image, at the cost of requiring enormous parameters.",background,0
9331,This paper proposes a very deep CNN model (up to 52 convolutional layers) named Deep Recursive Residual Network (DRRN) that strives for deep yet concise networks.,objective,1
9332,"Specifically, residual learning is adopted, both in global and local manners, to mitigate the difficulty of training very deep networks, recursive learning is used to control the model parameters while increasing the depth.",method,2
9333,"Extensive benchmark evaluation shows that DRRN significantly outperforms state of the art in SISR, while utilizing far fewer parameters.",method,2
9334,Code is available at https://github.com/tyshiwo/DRRN_CVPR17.,other,4
9335,"_______________________________________________ This work was supported in part by the U.K. EPSRC, grant number 06R00456 Department of Computer Systems, P.O. Box 325, S-751 05 Uppsala, Sweden (E-mail: ken@docs.uu.se)",other,4
9336,Abstract The increasing use of communication networks in time critical applications presents engineers with fundamental problems with the determination of response times of communicating distributed processes.,background,0
9337,"Although there has been some work on the analysis of communication protocols, most of this is for idealised networks.",background,0
9338,Experience with single processor scheduling analysis has shown that models which abstract away from implementation details are at best very pessimistic and at worst lead to unschedulable system being deemed schedulable.,background,0
9339,"In this paper, we derive idealised scheduling analysis for the CAN network, and then study two actual interface chips to see how the analysis can be applied.",background,0
9340,"A critical decision problem for top management, and the focus of this study, is whether the CEO (chief executive officer) and CIO (chief information officer) should commit their time to formal planning with the expectation of producing an information technology (IT)-based competitive advantage.",background,0
9341,"Using the perspective of the resource-based view, a model is presented that examines how strategic IT alignment can produce enhanced organizational strategies that yield competitive advantage.",background,0
9342,One hundred sixty-one CIOs provided data using a postal survey.,result,3
9343,Results supported seven of the eight hypotheses.,result,3
9344,"They showed that information intensity is an important antecedent to strategic IT alignment, that strategic IT alignment is best explained by multiple constructs which operationalize both process and content measures, and that alignment between the IT plan and the business plan is significantly related to the use of IT for competitive advantage.",result,3
9345,"Study results raise questions about the effect of CEO participation, which appears to be the weak link in the process, and also about the perception of the CIO on the importance of CEO involvement.",result,3
9346,"The paper contributes to our understanding of how knowledge sharing in the alignment process contributes to the creation of superior organizational strategies, provides a framework of the alignment-performance relationship, and furnishes several new constructs.",result,3
9347,"Subject Areas: Competitive Advantage, Information Systems Planning, Knowledge Sharing, Resource-Based View, Strategic Planning, and Structural Equation Modeling.",other,4
9348,"Researchers have made significant progress in disciplines such as scientific and information visualization, statistically based exploratory and confirmatory analysis, data and knowledge representations, and perceptual and cognitive sciences.",background,0
9349,"Although some research is being done in this area, the pace at which new technologies and technical talents are becoming available is far too slow to meet the urgent need.",background,0
9350,"National Visualization and Analytics Center's goal is to advance the state of the science to enable analysts to detect the expected and discover the unexpected from massive and dynamic information streams and databases consisting of data of multiple types and from multiple sources, even though the data are often conflicting and incomplete.",objective,1
9351,"Visual analytics is a multidisciplinary field that includes the following focus areas: (i) analytical reasoning techniques, (ii) visual representations and interaction techniques, (iii) data representations and transformations, (iv) techniques to support production, presentation, and dissemination of analytical results.",method,2
9352,"The R&D agenda for visual analytics addresses technical needs for each of these focus areas, as well as recommendations for speeding the movement of promising technologies into practice.",method,2
9353,This article provides only the concise summary of the R&D agenda.,result,3
9354,"We encourage reading, discussion, and debate as well as active innovation toward the agenda for visual analysis.",result,3
9355,There is significant interest in managing IT resources as a portfolio of assets.,background,0
9356,"The concept of IT portfolio management (ITPM) is relatively new, compared to portfolio management in the context of finance, new product development (NPD), and research and development (R&D).",background,0
9357,"This article compares ITPM with other types of portfolio management, and develops an improved understanding of IT assets and their characteristics.",method,2
9358,It presents a process-oriented framework for identifying critical ITPM decision stages.,method,2
9359,The proposed framework can be used by managers as well as researchers.,result,3
9360,"The relationships between the work products of a security engineering process can be hard to understand, even for persons with a strong technical background but little knowledge of security engineering.",background,0
9361,Market forces are driving software practitioners who are not security specialists to develop software that requires security features.,background,0
9362,"When these practitioners develop software solutions without appropriate security-specific processes and models, they sometimes fail to produce effective solutions.",background,0
9363,"We have adapted a proven object-oriented modeling technique, use cases, to capture and analyze security requirements in a simple way.",method,2
9364,We call the adaptation an abuse case model.,method,2
9365,"Its relationship to other security engineering work products is relatively simple, from a",result,3
9366,"Face-related biometrics research in recent years has moved from attempting merely to recognize faces, and even doing so under varying conditions, to considering a wide variety of aspects such as dynamics, gesture, aging, and expression.",background,0
9367,"The state of an individual's face is a revealing indicator that may be used for soft biometrics, active authentication, deception detection, response feedback, and other areas of interface.",background,0
9368,"One related psychological indicator is the Duchenne smile that usually indicates a genuine, spontaneous, or enjoyed emotional state rather than a forced or posed state, as likely expressed by a non-Duchenne smile.",background,0
9369,Differentiating between these is a useful task to automate for a variety of reasons.,background,0
9370,This paper discusses a classification technique that achieves higher recognition rates than previously published for similar comparisons.,method,2
9371,"Industry 4.0 is characterized by smart manufacturing, implementation of Cyber Physical Systems (CPS) for production, i.e., embedded actuators and sensors, networks of microcomputers, and linking the machines to the value chain.",background,0
9372,It further considers the digital enhancement and reengineering of products.,background,0
9373,"It is also characterized by highly differentiated customized products, and well-coordinated combination of products and services, and also the value added services with the actual product or service, and efficient supply chain.",background,0
9374,"All these challenges require continuous innovation and learning, which is dependent on people and enterprise's capabilities.",background,0
9375,"Appropriate management approaches can play a vital role in the development of dynamic capabilities, and effective learning and innovation climate.",background,0
9376,"This paper aims at offering a viewpoint on best suitable management practices which can promote the climate of innovation and learning in the organization, and hence facilitate the business to match the pace of industry 4.0.",objective,1
9377,"This paper is one of the initial attempts to draw the attention towards the important role of management practices in industry 4.0, as most of the recent studies are discussing the technological aspect.",result,3
9378,This paper also suggests empirical and quantitative investigation on these management approaches in the context of industry 4.0.,result,3
9379,Sudoku is a very simple and well-known puzzle that has achieved international popularity in the recent past.,background,0
9380,"This paper addresses the problem of encoding Sudoku puzzles into conjunctive normal form (CNF), and subsequently solving them using polynomial-time propositional satisfiability (SAT) inference techniques.",objective,1
9381,We introduce two straightforward SAT encodings for Sudoku: the minimal encoding and the extended encoding.,method,2
9382,"The minimal encoding suffices to characterize Sudoku puzzles, whereas the extended encoding adds redundant clauses to the minimal encoding.",method,2
9383,"Experimental results demonstrate that, for thousands of very hard puzzles, inference techniques struggle to solve these puzzles when using the minimal encoding.",result,3
9384,"However, using the extended encoding, unit propagation is able to solve about half of our set of puzzles.",result,3
9385,"Nonetheless, for some puzzles more sophisticated inference techniques are required.",result,3
9386,Brain anatomy is characterized by dramatic growth from the end of the second trimester through the neonatal stage.,background,0
9387,The characterization of normal axonal growth of the white matter tracts has not been well-documented to date and could provide important clues to understanding the extensive inhomogeneity of white matter injuries in cerebral palsy (CP) patients.,background,0
9388,"However, anatomical studies of human brain development during this period are surprisingly scarce and histology-based atlases have become available only recently.",background,0
9389,Diffusion tensor magnetic resonance imaging (DTMRI) can reveal detailed anatomy of white matter.,method,2
9390,We acquired diffusion tensor images (DTI) of postmortem fetal brain samples and in vivo neonates and children.,method,2
9391,"Neural structures were annotated in two-dimensional (2D) slices, segmented, measured, and reconstructed three-dimensionally (3D).",method,2
9392,"The growth status of various white matter tracts was evaluated on cross-sections at 19-20 gestational weeks, and compared with 0-month-old neonates and 5- to 6-year-old children.",method,2
9393,"Limbic, commissural, association, and projection white matter tracts and gray matter structures were illustrated in 3D and quantitatively characterized to assess their dynamic changes.",method,2
9394,The overall pattern of the time courses for the development of different white matter is that limbic fibers develop first and association fibers last and commissural and projection fibers are forming from anterior to posterior part of the brain.,method,2
9395,The resultant DTMRI-based 3D human brain data will be a valuable resource for human brain developmental study and will provide reference standards for diagnostic radiology of premature newborns.,result,3
9396,"In this paper, we presented the design and development of a new integrated device for measuring heart rate using fingertip to improve estimating the heart rate.",objective,1
9397,"As heart related diseases are increasing day by day, the need for an accurate and affordable heart rate measuring device or heart monitor is essential to ensure quality of health.",background,0
9398,"However, most heart rate measuring tools and environments are expensive and do not follow ergonomics.",background,0
9399,Our proposed Heart Rate Measuring (HRM) device is economical and user friendly and uses optical technology to detect the flow of blood through index finger.,method,2
9400,"Three phases are used to detect pulses on the fingertip that include pulse detection, signal extraction, and pulse amplification.",method,2
9401,"Qualitative and quantitative performance evaluation of the device on real signals shows accuracy in heart rate estimation, even under intense of physical activity.",method,2
9402,We compared the performance of HRM device with Electrocardiogram reports and manual pulse measurement of heartbeat of 90 human subjects of different ages.,method,2
9403,The results showed that the error rate of the device is negligible.,result,3
9404,"Since organizational information security policies can only improve security if employees comply with them, understanding the factors that affect employee security compliance is crucial for strengthening information security.",background,0
9405,"Based on a survey with 200 German employees, we find that reward for production goal achievement negatively impacts security compliance.",background,0
9406,"Whereas a distinct error aversion culture also seems to impair security compliance, the results provide no evidence for an impact of error management culture, affective commitment towards the organization, security policy information quality or quality of the goal setting process.",background,0
9407,"Furthermore, the intention to comply with security policies turns out to be a bad predictor for actual security compliance.",method,2
9408,We therefore suggest future studies to measure actual behavior instead of behavioral intention.,other,4
9409,"We introduce the beat spectrum, a new method of automatically characterizing the rhythm and tempo of music and audio.",method,2
9410,The beat spectrum is a measure of acoustic self-similarity as a function of time lag.,background,0
9411,Highly structured or repetitive music will have strong beat spectrum peaks at the repetition times.,background,0
9412,"This reveals both tempo and the relative strength of particular beats, and therefore can distinguish between different kinds of rhythms at the same tempo.",background,0
9413,We also introduce the beat spectrogram which graphically illustrates rhythm variation over time.,method,2
9414,"Unlike previous approaches to tempo analysis, the beat spectrum does not depend on particular attributes such as energy or frequency, and thus will work for any music or audio in any genre.",result,3
9415,We present tempo estimation results which are accurate to within 1% for a variety of musical genres.,result,3
9416,"This approach has a variety of applications, including music retrieval by similarity and automatically generating music videos.",result,3
9417,Virtualization of operating systems provides a common way to run different services in the cloud.,background,0
9418,"Recently, the lightweight virtualization technologies claim to offer superior performance.",background,0
9419,"In this paper, we present a detailed performance comparison of traditional hypervisor based virtualization and new lightweight solutions.",method,2
9420,"In our measurements, we use several benchmarks tools in order to understand the strengths, weaknesses, and anomalies introduced by these different platforms in terms of processing, storage, memory and network.",method,2
9421,Our results show that containers achieve generally better performance when compared with traditional virtual machines and other recent solutions.,result,3
9422,"Albeit containers offer clearly more dense deployment of virtual machines, the performance difference with other technologies is in many cases relatively small.",result,3
9423,This paper presents an extensive study of the software implementation on workstations of the NIST-recommended elliptic curves over prime fields.,background,0
9424,We present the results of our implementation in C and assembler on a Pentium II 400 MHz workstation.,result,3
9425,We also provide a comparison with the NIST-recommended curves over binary fields.,result,3
9426,A simple odd number frequency divider with 50% duty cycle is presented.,background,0
9427,The odd number frequency divider consists of a general odd number counter and the proposed duty cycle trimming circuit.,background,0
9428,The duty cycle trimming circuit can output 50% duty cycle with only additional six transistors.,method,2
9429,A prototype divide-by-5 circuit with 50% duty cycle was implemented for a 500-Mb/s ∼ 5.6-Gb/s 1:10 CDR/DEMUX IC in a 0.13μm 1P8M CMOS process.,result,3
9430,"Internet of Things (IoT), which will create a huge network of billions or trillions of “Things” communicating with one another, are facing many technical and application challenges.",background,0
9431,"This paper introduces the status of IoT development in China, including policies, R&D plans, applications, and standardization.",objective,1
9432,"With China's perspective, this paper depicts such challenges on technologies, applications, and standardization, and also proposes an open and general IoT architecture consisting of three platforms to meet the architecture challenge.",objective,1
9433,"Finally, this paper discusses the opportunity and prospect of IoT.",result,3
9434,"Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system.",background,0
9435,"Nevertheless, our understanding of them remains limited.",background,0
9436,"In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself?",background,0
9437,To answer this question we contribute a general framework to invert representations.,method,2
9438,We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too.,method,2
9439,We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time.,method,2
9440,"Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.",result,3
9441,One of the most important design problems for multi-UAV (Unmanned Air Vehicle) systems is the communication which is crucial for cooperation and collaboration between the UAVs.,background,0
9442,"If all UAVs are directly connected to an infrastructure, such as a ground base or a satellite, the communication between UAVs can be realized through the in-frastructure.",method,2
9443,"However, this infrastructure based communication architecture restricts the capabilities of the multi-UAV systems.",background,0
9444,Ad-hoc networking between UAVs can solve the problems arising from a fully infrastructure based UAV networks.,method,2
9445,"In this paper, Flying Ad-Hoc Networks (FANETs) are surveyed which is an ad hoc network connecting the UAVs.",objective,1
9446,"The differences between FANETs, MANETs (Mobile Ad-hoc Networks) and VANETs (Vehicle Ad-Hoc Networks) are clarified first, and then the main FANET design challenges are introduced.",method,2
9447,"Along with the existing FANET protocols, open research issues are also discussed.",result,3
9448,2013 Published by Elsevier B.V.,other,4
9449,Multi-layer perceptron (MLP) and other artificial neural networks (ANNs) have been widely applied to time series forecasting since 1980s.,background,0
9450,"However, for some problems such as initialization and local optima existing in applications, the improvement of ANNs is, and still will be the most interesting study for not only time series forecasting but also other intelligent computing fields.",background,0
9451,"In this study, we propose a method for time series prediction using Hinton & Salakhutdinov’s deep belief nets (DBN) which are probabilistic generative neural network composed by multiple layers of restricted Boltzmann machine (RBM).",method,2
9452,"We use a 3-layer deep network of RBMs to capture the feature of input space of time series data, and after pretraining of RBMs using their energy functions, gradient descent training, i.e., back-propagation learning algorithm is used for fine-tuning connection weights between “visible layers” and “hidden layers” of RBMs.",method,2
9453,"To decide the sizes of neural networks and the learning rates, Kennedy & Eberhart’s particle swarm optimization (PSO) is adopted during the training processes.",method,2
9454,"Furthermore, “trend removal”, a preprocessing to the original data, is also approached in the forecasting experiment using CATS benchmark data.",method,2
9455,"Additionally, approximating and short-term prediction of chaotic time series such as Lorenz chaos and logistic map were also applied by the proposed method.",other,4
9456,"The productive use of English past tense morphology in school-aged children (N= 74; 3 years, 8 months to 13 years, 5 months) is explored using on elicited production task.",background,0
9457,Errors represented 20% of the responses overall.,background,0
9458,"Virtually all of the children demonstrated productivity with regular (e.g., good) and irregular patterns (zero-marking, e.g., sit + sit; vowel-change, e.g., ride -+ rid).",result,3
9459,"Overall frequency of errors decreased with age, yet the tendency for certain types of irregularizations increased in the older groups.",background,0
9460,"Analyses across items indicated that all error types were predicted by combinations of item frequency, phonological chamcteristics of stems and past tense forms, and aspects of phonological past tense “neighborhoods.",result,3
9461,”,other,4
9462,"Contrary to “hybrid” or dual-mechanism models incorporating a phonologically-insensitive default mechanism (e.g., Prasada & Pinker, 1993), these results suggest that children’s productivity with regular and irregular patterns is consistent with a phonologically-based constraint satisfaction system similar to that implemented in connectionist models (Daugherty & Seidenberg, 1992; Plunkett 81 Marchman, 1991,1993).",result,3
9463,A dynamical extension that makes possible the integration of a kinematic controller and a torque controller for nonholonomic mobile robots is presented.,background,0
9464,"A combined kinematic/torque control law is developed using backstepping, and asymptotic stability is guaranteed by Lyapunov theory.",background,0
9465,"Moreover, this control algorithm can be applied to the three basic nonholonomic navigation problems: tracking a reference trajectory, path following, and stabilization about a desired posture.",method,2
9466,"The result is a general structure for controlling a mobile robot that can accommodate different control techniques, ranging from a conventional computed-torque controller, when all dynamics are known, to robust-adaptive controllers if this is not the case.",result,3
9467,A robust-adaptive controller based on neural networks (NNs) is proposed in this work.,method,2
9468,The NN controller can deal with unmodeled bounded disturbances and/or unstructured unmodeled dynamics in the vehicle.,method,2
9469,On-line NN weight tuning algorithms that do not require off-line learning yet guarantee small tracking errors and bounded control signals are utilized.,method,2
9470," 1997 John Wiley & Sons, Inc.",other,4
9471,"In this paper, we propose a novel approach, 3D-RecGAN++, which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks.",background,0
9472,"Unlike existing work which typically requires multiple views of the same object or class labels to recover the full 3D geometry, the proposed 3D-RecGAN++ only takes the voxel grid representation of a depth view of the object as input, and is able to generate the complete 3D occupancy grid with a high resolution of 2563 by recovering the occluded/missing regions.",background,0
9473,"The key idea is to combine the generative capabilities of autoencoders and the conditional Generative Adversarial Networks (GAN) framework, to infer accurate and fine-grained 3D structures of objects in high-dimensional voxel space.",method,2
9474,"Extensive experiments on large synthetic datasets and real-world Kinect datasets show that the proposed 3D-RecGAN++ significantly outperforms the state of the art in single view 3D object reconstruction, and is able to reconstruct unseen types of objects.",result,3
9475,"The MP4 files has become to most used video media file available, and will mostly likely remain at the top for some time to come.",background,0
9476,This makes MP4 files an interesting candidate for steganography.,background,0
9477,"With its size and structure, it offers a challenge to steganography developers.",background,0
9478,"While some attempts have been made to create a truly covert file, few are as successful as Martin Fiedler's TCSteg.",background,0
9479,TCSteg allows users to hide a TrueCrypt hidden volume in an MP4 file.,method,2
9480,The structure of the file makes it difficult to identify that a volume exists.,background,0
9481,"In our analysis of TCSteg, we will show how Fielder's code works and how we may be able to detect the existence of steganography.",method,2
9482,We will then implement these methods in hope that other steganography analysis can use them to determine if an MP4 file is a carrier file.,method,2
9483,"Finally, we will address the future of MP4 steganography.",result,3
9484,Non-work-related personal use of the Internet within organizations has received increased attention from scholars.,background,0
9485,We increase previous understanding of this phenomenon by proposing a novel model based on the theory of interpersonal behavior (TIB).,background,0
9486,"The TIB includes previous researched constructs (i.e., attitudes, social influence, and intentions) as well as emotional factors, habits, and different sources of social influence.",method,2
9487,Our results (N = 238) suggest that the model well predicts the use of the Internet at work for non-work purposes.,result,3
9488,"Our results shed new light on the influence of habit, affect, role, and self-concept in the use of the Internet.",result,3
9489,2013 Elsevier B.V. All rights reserved.,other,4
9490,"Malaria is a life-threatening disease caused by parasite of genus plasmodium, which is transmitted through the bite of infected Anopheles.",background,0
9491,A rapid and accurate diagnosis of malaria is demanded for proper treatment on time.,background,0
9492,"Mostly, conventional microscopy is followed for diagnosis of malaria in developing countries, where pathologist visually inspects the stained slide under light microscope.",background,0
9493,"However, conventional microscopy has occasionally proved inefficient since it is time consuming and results are difficult to reproduce.",background,0
9494,Alternate techniques for malaria diagnosis based on computer vision were proposed by several researchers.,method,2
9495,"The aim of this paper is to review, analyze, categorize and address the recent developments in the area of computer aided diagnosis of malaria parasite.",objective,1
9496,"Research efforts in quantification of malaria infection include normalization of images, segmentation followed by features extraction and classification, which were reviewed in detail in this paper.",method,2
9497,"At the end of review, the existent challenges as well as possible research perspectives were discussed.",result,3
9498,Abs t r ac t .,other,4
9499,"The PKZIP program is one of the more widely used archive/ compression programs on personM, computers.",background,0
9500,It also has many compatible variants on other computers~ and is used by most BBS's and ftp sites to compress their archives.,background,0
9501,PKZIP provides a stream cipher which allows users to scramble files with variable length keys (passwords).,background,0
9502,"In this paper we describe a known pla.intext attack on this cipher, which can find the internal representation of the key within a few hours on a personal computer using a few hundred bytes of known plaintext.",method,2
9503,"In many cases, the actual user keys can also be found from the internal representation.",result,3
9504,"We conclude that the PKZIP cipher is weak, and should not be used to protect valuable data.",result,3
9505,Will reading habit influence your life?,background,0
9506,Many say yes.,background,0
9507,Reading fuzzy logic and neural network handbook is a good habit; you can develop this habit to be such interesting way.,objective,1
9508,"Yeah, reading habit will not only make you have any favourite activity.",method,2
9509,It will be one of guidance of your life.,method,2
9510,"When reading has become a habit, you will not make it as disturbing activities or as boring activity.",result,3
9511,You can gain many benefits and importances of reading.,result,3
9512,Dynamic difficulty adjustment (DDA) is a technique for adaptively changing a game to make it easier or harder.,background,0
9513,"A common paradigm to achieve DDA is through heuristic prediction and intervention, adjusting game difficulty once undesirable player states (e.g., boredom or frustration) are observed.",background,0
9514,"Without quantitative objectives, it is impossible to optimize the strength of intervention and achieve the best effectiveness.",objective,1
9515,"In this paper, we propose a DDA framework with a global optimization objective of maximizing a player’s engagement throughout the entire game.",objective,1
9516,"Using level-based games as our example, we model a player’s progression as a probabilistic graph.",method,2
9517,Dynamic difficulty reduces to optimizing transition probabilities to maximize a player’s stay time in the progression graph.,other,4
9518,"We have successfully developed a system that applies this technique in multiple games by Electronic Arts, Inc., and have observed up to 9% improvement in player engagement with a neutral impact on monetization.",result,3
9519,An extensive review on warehouse operation planning problems is presented.,background,0
9520,"The problems are classified according to the basic warehouse functions, i.e., receiving, storage, order picking, and shipping.",objective,1
9521,The literature in each category is summarized with an emphasis on the characteristics of various decision support models and solution algorithms.,method,2
9522,"The purpose is to provide a bridge between academic researchers and warehouse practitioners, explaining what planning models and methods are currently available for warehouse operations, and what are the future research opportunities.",objective,1
9523,2006 Elsevier B.V. All rights reserved.,other,4
9524,Learning to solve complex sequences of tasks—while both leveraging transfer and avoiding catastrophic forgetting—remains a key obstacle to achieving human-level intelligence.,background,0
9525,The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features.,method,2
9526,"We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning.",method,2
9527,"Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.",result,3
9528,This paper presents the experimental evaluation of a Bluetooth-based positioning system.,background,0
9529,The method has been implemented in a Bluetooth-capable handheld device.,background,0
9530,Empirical tests of the developed considered positioning system have been realized in different indoor scenarios.,method,2
9531,The range estimation of the positioning system is based on an approximation of the relation between the RSSI (Radio Signal Strength Indicator) and the associated distance between sender and receiver.,method,2
9532,The actual location estimation is carried out by using the triangulation method.,method,2
9533,The implementation of the positioning system in a PDA (Personal Digital Assistant) has been realized by using the Software Microsoft eMbedded Visual C++ Version 3.0.,result,3
9534,Received: 8 February 2006 Revised: 31 March 2006 Accepted: 13 April 2006 Online publication date: 22 June 2006 Abstract,background,0
9535,"In this article, Novak's concept mapping technique is compared to three other types of visualization formats, namely mind maps, conceptual diagrams, and visual metaphors.",background,0
9536,The application parameters and the respective advantages and disadvantages of each format for learning and knowledge sharing are reviewed and discussed.,method,2
9537,It is argued that the combination of these four visualization types can play to the strength of each one.,method,2
9538,The article then provides real-life examples from such a use in undergraduate and graduate university teaching.,background,0
9539,"The results provide first indications that the different visualization formats can be used in complementary ways to enhance motivation, attention, understanding and recall.",background,0
9540,The implications for a complementary use of these visualization formats in class room and meeting contexts are discussed and a future research agenda in this domain is articulated.,result,3
9541,"Information Visualization (2006) 5, 202--210.",other,4
9542,doi:10.1057/palgrave.ivs.9500131,other,4
9543,Demand for business intelligence solutions continues to grow in the industry at record rates to combat competitive pressures and to attain business agility.,background,0
9544,Still organizations continue to struggle on how to implement successful business intelligence solutions.,objective,1
9545,"Despite its growing popularity and maturity as a field, it appears that organizations follow key guidelines that ensure the failure of their business intelligence implementation.",objective,1
9546,"This paper highlights ten major principles that organizations follow to ensure the failure of their BI solution and in so doing describes how to avoid BI failure in terms of strategy and design, implementation management and communication, and technology and resource investment for BI solutions.",method,2
9547,DOI: 10.4018/978-1-4666-2650-8.ch016,other,4
9548,"Mass media sources, specifically the news media, have traditionally informed us of daily events.",background,0
9549,"In modern times, social media services such as Twitter provide an enormous amount of user-generated data, which have great potential to contain informative news-related content.",background,0
9550,"For these resources to be useful, we must find a way to filter noise and only capture the content that, based on its similarity to the news media, is considered valuable.",background,0
9551,"However, even after noise is removed, information overload may still exist in the remaining data—hence, it is convenient to prioritize it for consumption.",objective,1
9552,"To achieve prioritization, information must be ranked in order of estimated importance considering three factors.",method,2
9553,"First, the temporal prevalence of a particular topic in the news media is a factor of importance, and can be considered the media focus (MF) of a topic.",method,2
9554,"Second, the temporal prevalence of the topic in social media indicates its user attention (UA).",method,2
9555,"Last, the interaction between the social media users who mention this topic indicates the strength of the community discussing it, and can be regarded as the user interaction (UI) toward the topic.",method,2
9556,"We propose an unsupervised framework—SociRank—which identifies news topics prevalent in both social media and the news media, and then ranks them by relevance using their degrees of MF, UA, and UI.",method,2
9557,Our experiments show that SociRank improves the quality and variety of automatically identified news topics.,result,3
9558,Synthesizing high-quality images from text descriptions is a challenging problem in computer vision and has many practical applications.,background,0
9559,"Samples generated by existing textto- image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts.",background,0
9560,"In this paper, we propose Stacked Generative Adversarial Networks (StackGAN) to generate 256.256 photo-realistic images conditioned on text descriptions.",objective,1
9561,We decompose the hard problem into more manageable sub-problems through a sketch-refinement process.,method,2
9562,"The Stage-I GAN sketches the primitive shape and colors of the object based on the given text description, yielding Stage-I low-resolution images.",method,2
9563,"The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details.",method,2
9564,It is able to rectify defects in Stage-I results and add compelling details with the refinement process.,method,2
9565,"To improve the diversity of the synthesized images and stabilize the training of the conditional-GAN, we introduce a novel Conditioning Augmentation technique that encourages smoothness in the latent conditioning manifold.",method,2
9566,Extensive experiments and comparisons with state-of-the-arts on benchmark datasets demonstrate that the proposed method achieves significant improvements on generating photo-realistic images conditioned on text descriptions.,result,3
9567,We propose a deep learning method for single image super-resolution (SR).,method,2
9568,Our method directly learns an end-to-end mapping between the low/high-resolution images.,method,2
9569,The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one.,method,2
9570,We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network.,method,2
9571,"But unlike traditional methods that handle each component separately, our method jointly optimizes all layers.",method,2
9573,We explore different network structures and parameter settings to achieve trade-offs between performance and speed.,result,3
9574,"Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.",result,3
9575,We extend continuous assurance research by proposing a novel continuous assurance architecture grounded in information fusion research.,background,0
9576,Existing continuous assurance architectures focus primarily on methods of monitoring assurance clients’ systems to detect anomalous activities and have not addressed the question of how to process the detected anomalies.,background,0
9577,"Consequently, actual implementations of these systems typically detect a large number of anomalies, with the resulting information overload leading to suboptimal decision making due to human information processing limitations.",method,2
9578,"The proposed architecture addresses these issues by performing anomaly detection, aggregation and evaluation.",background,0
9579,"Within the proposed architecture, artifacts developed in prior continuous assurance, ontology, and artificial intelligence research are used to perform the detection, aggregation and evaluation information fusion tasks.",method,2
9580,The architecture contributes to the academic continuous assurance literature and has implications for practitioners involved in the development of more robust and useful continuous assurance systems.,method,2
9581,"This paper describes AutoMashUpper, an interactive system for creating music mashups by automatically selecting and mixing multiple songs together.",background,0
9582,"Given a userspecified input song, the system first identifies the phraselevel structure and then estimates the “mashability” between each phrase section of the input and songs in the user’s music collection.",objective,1
9583,Mashability is calculated based on the harmonic similarity between beat synchronous chromagrams over a user-definable range of allowable key shifts and tempi.,method,2
9584,"Once a match in the collection for a given section of the input song has been found, a pitch-shifting and time-stretching algorithm is used to harmonically and temporally align the sections, after which the loudness of the transformed section is modified to ensure a balanced mix.",method,2
9585,AutoMashUpper has a user interface to allow visualisation and manipulation of mashups.,method,2
9586,"When creating a mashup, users can specify a list of songs to choose from, modify the mashability parameters and change the granularity of the phrase segmentation.",method,2
9587,"Once created, users can also switch, add, or remove sections from the mashup to suit their taste.",method,2
9588,"In this way, AutoMashUpper can assist users to actively create new music content by enabling and encouraging them to explore the mashup space.",method,2
9589,The paper presents a survey and analysis on the current status and concerns of Internet of things (IoT) security.,background,0
9590,The IoT framework aspires to connect anyone with anything at anywhere.,objective,1
9591,"IoT typically has a three layers architecture consisting of Perception, Network, and Application layers.",method,2
9592,A number of security principles should be enforced at each layer to achieve a secure IoT realization.,result,3
9593,The future of IoT framework can only be ensured if the security issues associated with it are addressed and resolved.,method,2
9594,Many researchers have attempted to address the security concerns specific to IoT layers and devices by implementing corresponding countermeasures.,method,2
9595,"This paper presents an overview of security principles, technological and security challenges, proposed countermeasures, and the future directions for securing the IoT.",result,3
9596,The rapid growth in IT in the last two decades has led to a growth in the amount of information available online.,background,0
9597,A new style for sharing information is social media.,background,0
9598,Social media is a continuously instantly updated source of information.,background,0
9599,"In this position paper, we propose a framework for Information Extraction (IE) from unstructured user generated contents on social media.",objective,1
9600,"The framework proposes solutions to overcome the IE challenges in this domain such as the short context, the noisy sparse contents and the uncertain contents.",method,2
9601,"To overcome the challenges facing IE from social media, State-Of-The-Art approaches need to be adapted to suit the nature of social media posts.",method,2
9602,"The key components and aspects of our proposed framework are noisy text filtering, named entity extraction, named entity disambiguation, feedback loops, and uncertainty handling.",result,3
9603,Security is one of the principal and continuing concerns that restrict customers and organizations engaging with e-commerce.,background,0
9604,The aim of this paper is to explore the perception of security in e-commerce B2C and C2C websites from both customer and organisational perspectives.,objective,1
9605,It explores factors that influence customers- perceptions of security.,method,2
9606,It also highlights conflicts between customer concerns with respect to security and those of an organization; existing research has not highlighted this issue greatly.,method,2
9607,"This research provides a better understanding of customer needs and priorities on the subject of security, and enriches the currently available security perception literature, by providing new insights from empirical research conducted in Jordan.",result,3
9608,"A qualitative research approach was adopted, since the research seeks an understanding of human (i.e., customer and organisational employee) perceptions.",result,3
9609,Case research has commanded respect in the information systems (IS) discipline for at least a decade.,background,0
9610,"Notwithstanding the relevance and potential value of case studies, this methodological approach was once considered to be one of the least systematic.",background,0
9611,"Toward the end of the 1980s, the issue of whether IS case research was rigorously conducted was first raised.",background,0
9612,"Researchers from our field (e.g., Benbasat et al. 1987; Lee 1989) and from other disciplines (e.g., Eisenhardt 1989; Yin 1994) called for more rigor in case research and, through theirrecommendations, contributed to the advancement of the case study methodology.",background,0
9613,"Considering these contributions, the present study seeks to determine the extent to which the field of IS has advanced in its operational use of case study method.",objective,1
9614,"Precisely, it investigates the level of methodological rigor in positivist IS case research conducted over the past decade.",objective,1
9615,"To fulfill this objective, we identified and coded 183 case articles from seven major IS journals.",objective,1
9616,"Evaluation attributes or criteria considered in the present review focus on three main areas, namely, design issues, data collection, and data analysis.",method,2
9617,"While the level of methodological rigor has experienced modest progress with respect to some specific attributes, the overall assessed rigor is somewhat equivocal and there are still significant areas for improvement.",method,2
9618,One of the keys is to include better documentation particularly regarding issues related to the data collection and,result,3
9619,Downloading the book in this website lists can give you more advantages.,background,0
9620,It will show you the best book collections and completed collections.,objective,1
9621,So many books can be found in this website.,background,0
9622,"So, this is not only this multiple view geometry in computer vision.",method,2
9623,"However, this book is referred to read because it is an inspiring book to give you more chance to get experiences and also thoughts.",result,3
9624,"This is simple, read the soft file of the book and you get it.",result,3
9625,Traditional approaches to the task of ACE event extraction primarily rely on elaborately designed features and complicated natural language processing (NLP) tools.,background,0
9626,"These traditional approaches lack generalization, take a large amount of human effort and are prone to error propagation and data sparsity problems.",background,0
9627,"This paper proposes a novel event-extraction method, which aims to automatically extract lexical-level and sentence-level features without using complicated NLP tools.",objective,1
9628,We introduce a word-representation model to capture meaningful semantic regularities for words and adopt a framework based on a convolutional neural network (CNN) to capture sentence-level clues.,objective,1
9629,"However, CNN can only capture the most important information in a sentence and may miss valuable facts when considering multiple-event sentences.",objective,1
9630,"We propose a dynamic multi-pooling convolutional neural network (DMCNN), which uses a dynamic multi-pooling layer according to event triggers and arguments, to reserve more crucial information.",method,2
9631,The experimental results show that our approach significantly outperforms other state-of-the-art methods.,result,3
9632,Test case prioritization involves scheduling test cases in an order that increases their effectiveness in meeting some performance goals.,method,2
9633,One of the common performance goals is to run those test cases that achieve total code coverage at the earliest.,objective,1
9634,In this work we propose a model that achieves 100% code coverage optimally during version specific regression testing.,method,2
9635,The diagnosis and treatment of malaria infection requires detecting the presence of the malaria parasite in the patient as well as identification of the parasite species.,background,0
9636,We present an image processing-based approach to detect parasites in microscope images of a blood smear and an ontology-based classification of the stage of the parasite for identifying the species of infection.,objective,1
9637,"This approach is patterned after the diagnosis approach adopted by a pathologist for visual examination, and hence, is expected to deliver similar results.",method,2
9638,"We formulate several rules based on the morphology of the basic components of a parasite, namely, chromatin dot(s) and cytoplasm, to identify the parasite stage and species.",method,2
9639,Numerical results are presented for data taken from various patients.,result,3
9640,A sensitivity of 88% and a specificity of 95% is reported by evaluation of the scheme on 55 images.,result,3
9641,"We propose a novel multi-sensor system for accurate and power-efficient dynamic car-driver hand-gesture recognition, using a short-range radar, a color camera, and a depth camera, which together make the system robust against variable lighting conditions.",background,0
9642,We present a procedure to jointly calibrate the radar and depth sensors.,objective,1
9643,We employ convolutional deep neural networks to fuse data from multiple sensors and to classify the gestures.,method,2
9644,Our algorithm accurately recognizes 10 different gestures acquired indoors and outdoors in a car during the day and at night.,method,2
9645,It consumes significantly less power than purely vision-based systems.,result,3
9646,Read more and get great!,other,4
9647,That's what the book enPDFd probability and statistics with reliability queuing and computer science applications will give for every reader to read this book.,objective,1
9648,This is an on-line book provided in this website.,background,0
9649,"Even this book becomes a choice of someone to read, many in the world also loves it so much.",objective,1
9650,"As what we talk, when you read more every page of this probability and statistics with reliability queuing and computer science applications, what you will obtain is something great.",objective,1
9651,In this paper it is shown that the principal eigenvector is a necessary representation of the priorities derived from a positive reciprocal pairwise comparison judgment matrix A 1⁄4 ðaijÞ when A is a small perturbation of a consistent matrix.,background,0
9652,"When providing numerical judgments, an individual attempts to estimate sequentially an underlying ratio scale and its equivalent consistent matrix of ratios.",background,0
9653,"Near consistent matrices are essential because when dealing with intangibles, human judgment is of necessity inconsistent, and if with new information one is able to improve inconsistency to near consistency, then that could improve the validity of the priorities of a decision.",background,0
9654,"In addition, judgment is much more sensitive and responsive to large rather than to small perturbations, and hence once near consistency is attained, it becomes uncertain which coefficients should be perturbed by small amounts to transform a near consistent matrix to a consistent one.",background,0
9655,"If such perturbations were forced, they could be arbitrary and thus distort the validity of the derived priority vector in representing the underlying decision.",method,2
9656,2002 Elsevier Science B.V. All rights reserved.,other,4
9657,Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases.,background,0
9658,"To this end, this paper has three main contributions.",objective,1
9659,"First, we propose a new clustering method called CLARANS, whose aim is to identify spatial structures that may be present in the data.",method,2
9660,"Experimental results indicate that, when compared with existing clustering methods, CLARANS is very efficient and effective.",result,3
9661,"Second, we investigate how CLARANS can handle not only points objects, but also polygon objects efficiently.",method,2
9662,"One of the methods considered, called the IR-approximation, is very efficient in clustering convex and nonconvex polygon objects.",method,2
9663,"Third, building on top of CLARANS, we develop two spatial data mining algorithms that aim to discover relationships between spatial and nonspatial attributes.",method,2
9664,Both algorithms can discover knowledge that is difficult to find with existing spatial data mining algorithms.,result,3
9665,"In this work we introduce a novel solution to the semantic image labelling problem, i.e. the task of assigning semantic object class labels to individual pixels in a test image.",objective,1
9666,Conventional methods are typically relying on random fields for modelling interactions between neighboring pixels and obtaining smooth labelling results using unary and pairwise cost functions.,method,2
9667,"Instead, we consider the labelling problem as a puzzle game, where the final labelling is obtained by assembling discriminatively learned candidate sets of label puzzle pieces, each representing a topological and semantically plausible label configuration.",method,2
9668,"The puzzle game is set up by means of a modified random forest classifier, designed to learn the local, topological label-structure and hence the local context associated to the training data.",method,2
9669,To solve the puzzle game we propose an iterative optimization technique that maximizes an agreement function by alternatingly seeking for the best label puzzle piece per pixel and the resulting semantic labelling per image.,method,2
9670,"We provide both, theoretical properties of our puzzle solver algorithm as well as experimental results on the challenging MSRC and CamVid databases.",method,2
9671,"In a direct comparison with a conditional random field we obtain superior results, indicating the practicability of our proposed method.",result,3
9672,Convolutional neural network (CNN) has been widely employed for image recognition because it can achieve high accuracy by emulating behavior of optic nerves in living creatures.,background,0
9673,"Recently, rapid growth of modern applications based on deep learning algorithms has further improved research and implementations.",background,0
9674,"Especially, various accelerators for deep CNN have been proposed based on FPGA platform because it has advantages of high performance, reconfigurability, and fast development round, etc.",background,0
9675,"Although current FPGA accelerators have demonstrated better performance over generic processors, the accelerator design space has not been well exploited.",background,0
9676,One critical problem is that the computation throughput may not well match the memory bandwidth provided an FPGA platform.,background,0
9677,"Consequently, existing approaches cannot achieve best performance due to under-utilization of either logic resource or memory bandwidth.",background,0
9678,"At the same time, the increasing complexity and scalability of deep learning applications aggravate this problem.",background,0
9679,"In order to overcome this problem, we propose an analytical design scheme using the roofline model.",objective,1
9680,"For any solution of a CNN design, we quantitatively analyze its computing throughput and required memory bandwidth using various optimization techniques, such as loop tiling and transformation.",method,2
9681,"Then, with the help of rooine model, we can identify the solution with best performance and lowest FPGA resource requirement.",method,2
9682,The main contribution of our work is in combining the methods for parametric urban design of highly specialized software such as CityEngine and general-purpose parametric modeling platform such as Grasshopper.,method,2
9683,Our work facilitates and prompts the use of parametric tools by architects and planners for urban design.,objective,1
9684,In this paper we present a custom grasshopper component for street network generation and block subdivision.,background,0
9685,The component was developed in C# using the RhinoCommon SDK.,result,3
9686,We used Grasshopper for the development of an urban design proposal at a teaching exercise.,method,2
9687,"To meet the requirements of the urban design project, additional functionalities had to be added to the range of existing Grasshopper components.",method,2
9688,"In particular, we needed components for street network generation and block subdivision.",method,2
9689,"To develop the component we implemented the street expansion strategies described in (Weber et al., 2009) and the methods for block subdivision described in (Vanegas et al., 2009).",method,2
9690,"Additionally, we adapted and enhanced the strategies to meet the NURBS modeling capabilities of Rhinoceros.",method,2
9691,This study aimed to verify whether achieving a dist inctive academic performance is unlikely for students at high risk of smartphone addiction.,objective,1
9692,"Additionally, it verified whether this phenomenon was equally applicable to male and femal e students.",method,2
9693,"After implementing systematic random sampling, 293 university students participated by completing an online survey questionnaire posted on the university’s stu dent information system.",result,3
9694,The survey questionnaire collected demographic information and responses to the Smartphone Addiction Scale-Short Version (SAS-SV) items.,method,2
9695,The results sho wed that male and female university students were equally susceptible to smartphone add iction.,result,3
9696,"Additionally, male and female university students were equal in achieving cumulat ive GPAs with distinction or higher within the same levels of smartphone addiction.",result,3
9697,"Fur thermore, undergraduate students who were at a high risk of smartphone addiction were le ss likely to achieve cumulative GPAs of distinction or higher.",result,3
9698,Cellular systems of the fourth generation (4G) have been optimized to provide high data rates and reliable coverage to mobile users.,background,0
9699,Cellular systems of the next generation will face more diverse application requirements: the demand for higher data rates exceeds 4G capabilities; battery-driven communication sensors need ultra-low power consumption; and control applications require very short response times.,background,0
9700,"We envision a unified physical layer waveform, referred to as generalized frequency division multiplexing (GFDM), to address these requirements.",background,0
9701,"In this paper, we analyze the main characteristics of the proposed waveform and highlight relevant features.",objective,1
9702,"After introducing the principles of GFDM, this paper contributes to the following areas: 1) the means for engineering the waveform's spectral properties; 2) analytical analysis of symbol error performance over different channel models; 3) concepts for MIMO-GFDM to achieve diversity; 4) preamble-based synchronization that preserves the excellent spectral properties of the waveform; 5) bit error rate performance for channel coded GFDM transmission using iterative receivers; 6) relevant application scenarios and suitable GFDM parameterizations; and 7) GFDM proof-of-concept and implementation aspects of the prototype using hardware platforms available today.",background,0
9703,"In summary, the flexible nature of GFDM makes this waveform a suitable candidate for future 5G networks.",result,3
9704,"Compared with depth-based 3D hand pose estimation, it is more challenging to infer 3D hand pose from monocular RGB images, due to substantial depth ambiguity and the difficulty of obtaining fullyannotated training data.",background,0
9705,"Different from existing learning-based monocular RGB-input approaches that require accurate 3D annotations for training, we propose to leverage the depth images that can be easily obtained from commodity RGB-D cameras during training, while during testing we take only RGB inputs for 3D joint predictions.",background,0
9706,"In this way, we alleviate the burden of the costly 3D annotations in real-world dataset.",objective,1
9707,"Particularly, we propose a weakly-supervised method, adaptating from fully-annotated synthetic dataset to weakly-labeled real-world dataset with the aid of a depth regularizer, which generates depth maps from predicted 3D pose and serves as weak supervision for 3D pose regression.",objective,1
9708,Extensive experiments on benchmark datasets validate the effectiveness of the proposed depth regularizer in both weakly-supervised and fullysupervised settings.,result,3
9709,The FlowNet demonstrated that optical flow estimation can be cast as a learning problem.,background,0
9710,"However, the state of the art with regard to the quality of the flow has still been defined by traditional methods.",method,2
9711,"Particularly on small displacements and real-world data, FlowNet cannot compete with variational methods.",background,0
9712,"In this paper, we advance the concept of end-to-end learning of optical flow and make it work really well.",objective,1
9713,"The large improvements in quality and speed are caused by three major contributions: first, we focus on the training data and show that the schedule of presenting data during training is very important.",result,3
9714,"Second, we develop a stacked architecture that includes warping of the second image with intermediate optical flow.",result,3
9715,"Third, we elaborate on small displacements by introducing a subnetwork specializing on small motions.",method,2
9716,FlowNet 2.0 is only marginally slower than the original FlowNet but decreases the estimation error by more than 50%.,method,2
9717,"It performs on par with state-of-the-art methods, while running at interactive frame rates.",method,2
9718,"Moreover, we present faster variants that allow optical flow computation at up to 140fps with accuracy matching the original FlowNet.",result,3
9719,This paper presents an FPGA architecture for a new version of the Advanced Encryption Standard (AES) algorithm.,background,0
9720,The efficient hardware that implements the algorithm is also proposed.,objective,1
9721,The new algorithm (AES-512) uses input block size and key size of 512-bits which makes it more resistant to cryptanalysis with tolerated area increase.,method,2
9722,AES-512 will be suitable for applications with high security and throughput requirements and with less chip area constrains such as multimedia and satellite communication systems.,method,2
9723,"An FPGA architectural for AES-512 was developed using VHDL, and synthesized using Virtix-6 and Virtex-7 chips.",method,2
9724,AES-512 show tremendous throughput increase of 230% when compared with the implementation of the original AES-128.,result,3
9725,"In this paper, we propose STag, a fiducial marker system that provides stable pose estimation.",background,0
9726,The outer square border of the marker is used for detection and pose estimation.,background,0
9727,This is followed by a novel pose refinement step using the inner circular border.,method,2
9728,The refined pose is more stable and robust across viewing conditions compared to the state of the art.,method,2
9729,"In addition, the lexicographic generation algorithm is adapted for fiducial markers, and libraries with various sizes are created.",objective,1
9730,"This makes the system suitable for applications that require many unique markers, or few unique markers with high occlusion resistance.",objective,1
9731,"The edge segment-based detection algorithm is of low complexity, and returns few false candidates.",result,3
9732,"These features are demonstrated with experiments on real images, including comparisons with the state of the art fiducial marker systems.",result,3
9733,A typical bandgap voltage reference based on CSMC 0.35 μm CMOS technology is designed and fabricated.,objective,1
9734,The overall bandgap architecture is optimized to achieve high accuracy temperature and power supply independent voltage reference.,method,2
9735,"The design consists of the bandgap core circuit, op-amp, and start-up circuit.",objective,1
9736,"The test results show that the bandgap reference circuit provides reference voltage of 1.2128 V to 1.2175 V with 3.3 V power supply and temperature range from -40°C to 80°C simultaneously, and the temperature coefficient is 32.2ppm/°C.",result,3
9737,The total layout area including dummy structures is 135 um×236 um.,result,3
9738,"Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation.",background,0
9739,Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems.,background,0
9740,"However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient.",background,0
9741,That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales.,result,3
9742,"Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion.",result,3
9743,"The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm.",result,3
9744,"These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of techniques that have been developed in the neuroevolution community to improve performance on RL problems.",result,3
9745,"To demonstrate the latter, we show that combining DNNs with novelty search, which was designed to encourage exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C, ES, and the GA) fail.",result,3
9746,"Additionally, the Deep GA parallelizes better than ES, A3C, and DQN, and enables a state-of-the-art compact encoding technique that can represent million-parameter DNNs in thousands of bytes.",result,3
9747,"Mechanical devices such as engines, vehicles, aircrafts, etc.",background,0
9748,", are typically instrumented with numerous sensors to capture the behavior and health of the machine.",background,0
9749,"However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable.",background,0
9750,"For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series.",background,0
9751,"Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies.",method,2
9752,"We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct ‘normal’ time-series behavior, and thereafter uses reconstruction error to detect anomalies.",method,2
9753,"We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two realworld engine datasets with both predictive and unpredictable behavior.",method,2
9754,"We show that EncDecAD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series.",method,2
9755,"Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).",result,3
9756,"The alternative fuel butanol can be produced via acetone-butanol-ethanol (ABE) fermentation from renewable resources, i.e. biomass.",background,0
9757,Expensive feedstocks and the high costs for the separation of ABE from the dilute fermentation broth in the downstream processing have so far prohibited the industrial-scale production of bio-butanol.,background,0
9758,The low productivities and butanol yields of ABE batch fermentation can be increased by continuous fermentation with cell recycle and integrated product removal.,background,0
9759,"In order to facilitate an effective and energy-efficient product removal, we suggest to apply a hybrid extraction-distillation process with ABE extraction in an external column.",method,2
9760,The removal of ABE outside the fermenter in an extraction column is favored from an operational point of view.,method,2
9761,"By means of computer-aided molecular design (CAMD), mesitylene has been identified as a new solvent for ABE extraction from the fermentation broth.",method,2
9762,"The solvent properties of mesitylene are compared to those of oleyl alcohol, which is the most common solvent for ABE extraction.",method,2
9763,"Subsequently, we propose a hybrid extraction-distillation downstream process for product removal and purification.",method,2
9764,It is shown that the specific energy demand of this process is significantly lower when mesitylene is used as extraction solvent instead of oleyl alcohol.,result,3
9765,"Multi-tiered storage, where each tier consists of one type of storage device (e.g., SSD, HDD, or disk arrays), is a commonly used approach to achieve both high performance and cost efficiency in large-scale systems that need to store data with vastly different access characteristics.",background,0
9766,"By aligning the access characteristics of the data, either fixed-sized extents or variable-sized files, to the characteristics of the storage devices, a higher performance can be achieved for any given cost.",objective,1
9767,"This article presents ExaPlan, a method to determine both the data-to-tier assignment and the number of devices in each tier that minimize the system’s mean response time for a given budget and workload.",method,2
9768,"In contrast to other methods that constrain or minimize the system load, ExaPlan directly minimizes the system’s mean response time estimated by a queueing model.",method,2
9769,Minimizing the mean response time is typically intractable as the resulting optimization problem is both nonconvex and combinatorial in nature.,method,2
9770,ExaPlan circumvents this intractability by introducing a parameterized data placement approach that makes it a highly scalable method that can be easily applied to exascale systems.,method,2
9771,"Through experiments that use parameters from real-world storage systems, such as CERN and LOFAR, it is demonstrated that ExaPlan provides solutions that yield lower mean response times than previous works.",result,3
9772,"It supports standalone SSDs and HDDs as well as disk arrays as storage tiers, and although it uses a static workload representation, we provide empirical evidence that underlying dynamic workloads have invariant properties that can be deemed static for the purpose of provisioning a storage system.",result,3
9773,"ExaPlan is also effective as a load-balancing tool used for placing data across devices within a tier, resulting in an up to 3.6-fold reduction of response time compared with a traditional load-balancing algorithm, such as the Longest Processing Time heuristic.",result,3
9774,Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variabl es are available.,background,0
9775,"These areas include text processing of internet documents, gene expression arr ay nalysis, and combinatorial chemistry.",background,0
9776,"The objective of variable selection is three-fold: improvi ng the prediction performance of the predictors, providing faster and more cost-effective predict ors, and providing a better understanding of the underlying process that generated the data.",objective,1
9777,"The contrib utions of this special issue cover a wide range of aspects of such problems: providing a better definit ion of the objective function, feature construction, feature ranking, multivariate feature sele ction, efficient search methods, and feature validity assessment methods.",objective,1
9778,"We address the problems of contour detection, bottom-up grouping and semantic segmentation using RGB-D data.",background,0
9779,"We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27].",background,0
9780,We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb-ucm approach of [2] by making effective use of depth information.,method,2
9781,"We show that our system can label each contour with its type (depth, normal or albedo).",method,2
9782,We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping.,method,2
9783,We then turn to the problem of semantic segmentation and propose a simple approach that classifies super pixels into the 40 dominant object categories in NYUD2.,method,2
9784,We use both generic and class-specific features to encode the appearance and geometry of objects.,method,2
9785,"We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition.",method,2
9786,"In all of these tasks, we report significant improvements over the state-of-the-art.",result,3
9787,The acceleration in developments in communication technology has led to a consequent increase in the vulnerability of data due to penetration attacks.,background,0
9788,These attacks often came from outside where non-qualified companies develop IT projects.,background,0
9789,"Cryptography can offer high levels of security but has recently shown vulnerabilities such as the man-in-the-middle (MITM) attack in areas of key exchange protocols, especially in the Diffie-Hellman (DH) protocol.",background,0
9790,"Firstly, this paper presents an overview of MITM attacks targeted at the DH protocol then discusses some of the shortcomings of current defenses.",objective,1
9791,"A proposed method to secure DH, which helps secure systems against MITM attacks, is then presented.",method,2
9792,This method involves the use of Geffe generation of binary sequences.,method,2
9793,The use of Geffe generator offers high levels of randomness.,method,2
9794,Data hashed and encrypted using this proposed method will be so difficult to intercept and decrypt without the appropriate keys.,method,2
9795,This offers high levels of security and helps prevent MITM attacks.,result,3
9796,Many CEOs and managers understand the importance of knowledge sharing among their employees and are eager to introduce the knowledge management paradigm in their organizations.,background,0
9797,However little is known about the determinants of the individuals knowledge sharing behavior.,background,0
9798,The purpose of this study is to develop an understanding of the factors affecting the individuals knowledge sharing behavior in the organizational context.,objective,1
9799,"The research model includes various constructs based on social exchange theory, self-efficacy, and theory of reasoned action.",method,2
9800,"Research results from the field survey of 467 employees of four large, public organizations show that expected associations and contribution are the major determinants of the individuals attitude toward knowledge sharing.",result,3
9801,"Expected rewards, believed by many as the most important motivating factor for knowledge sharing, are not significantly related to the attitude toward knowledge sharing.",result,3
9802,"As expected, positive attitude toward knowledge sharing is found to lead to positive intention to share knowledge and, finally, to actual knowledge sharing behaviors.",result,3
9803,"In this article, a system to detect rooms in architectural floor plan images is described.",objective,1
9804,We first present a primitive extraction algorithm for line detection.,objective,1
9805,It is based on an original coupling of classical Hough transform with image vectorization in order to perform robust and efficient line detection.,method,2
9806,We show how the lines that satisfy some graphical arrangements are combined into walls.,result,3
9807,We also present the way we detect some door hypothesis thanks to the extraction of arcs.,method,2
9808,Walls and door hypothesis are then used by our room segmentation strategy; it consists in recursively decomposing the image until getting nearly convex regions.,result,3
9809,"The notion of convexity is difficult to quantify, and the selection of separation lines between regions can also be rough.",result,3
9810,We take advantage of knowledge associated to architectural floor plans in order to obtain mostly rectangular rooms.,result,3
9811,Qualitative and quantitative evaluations performed on a corpus of real documents show promising results.,result,3
9812,"Internet and networks applications are growing very fast, so the needs to protect such applications are increased.",background,0
9813,Encryption algorithms play a main role in information security systems.,background,0
9814,"On the other side, those algorithms consume a significant amount of computing resources such as CPU time, memory, and battery power.",background,0
9815,"This paper provides evaluation of six of the most common encryption algorithms namely: AES (Rijndael), DES, 3DES, RC2, Blowfish, and RC6.",result,3
9816,"A comparison has been conducted for those encryption algorithms at different settings for each algorithm such as different sizes of data blocks, different data types, battery power consumption, different key size and finally encryption/decryption speed.",method,2
9817,Experimental results are given to demonstrate the effectiveness of each algorithm.,result,3
9818,This paper introduces a generic dynamic programming function for Matlab.,background,0
9819,This function solves discretetime optimal-control problems using Bellman's dynamic programming algorithm.,objective,1
9820,The function is implemented such that the user only needs to provide the objective function and the model equations.,background,0
9821,The function includes several options for solving optimal-control problems.,objective,1
9822,The model equations can include several state variables and input variables.,method,2
9823,"Furthermore, the model equations can be time-variant and include time-variant state and input constraints.",method,2
9824,The syntax of the function is explained using two examples.,background,0
9825,The first is the well-known Lotka-Volterra fishery problem and the second is a parallel hybrid-electric vehicle optimization problem.,method,2
9826,"Current approaches to measuring people's everyday usage of technology-based media and other computer-related activities have proved to be problematic as they use varied outcome measures, fail to measure behavior in a broad range of technology-related domains and do not take into account recently developed types of technology including smartphones.",background,0
9827,"In the present study, a wide variety of items, covering a range of up-to-date technology and media usage behaviors.",background,0
9828,"Sixty-six items concerning technology and media usage, along with 18 additional items assessing attitudes toward technology, were administered to two independent samples of individuals, comprising 942 participants.",method,2
9829,"Factor analyses were used to create 11 usage subscales representing smartphone usage, general social media usage, Internet searching, e-mailing, media sharing, text messaging, video gaming, online friendships, Facebook friendships, phone calling, and watching television in addition to four attitude-based subscales: positive attitudes, negative attitudes, technological anxiety/dependence, and attitudes toward task-switching.",objective,1
9830,All subscales showed strong reliabilities and relationships between the subscales and pre-existing measures of daily media usage and Internet addiction were as predicted.,objective,1
9831,"Given the reliability and validity results, the new Media and Technology Usage and Attitudes Scale was suggested as a method of measuring media and technology involvement across a variety of types of research studies either as a single 60-item scale or any subset of the 15 subscales.",result,3
9832,Roadway traffic safety is a major concern for transportation governing agencies as well as ordinary citizens.,background,0
9833,"In order to give safe driving suggestions, careful analysis of roadway traffic data is critical to find out variables that are closely related to fatal accidents.",background,0
9834,In this paper we apply statistics analysis and data mining algorithms on the FARS Fatal Accident dataset as an attempt to address this problem.,objective,1
9835,"The relationship between fatal rate and other attributes including collision manner, weather, surface condition, light condition, and drunk driver were investigated.",method,2
9836,"Association rules were discovered by Apriori algorithm, classification model was built by Naive Bayes classifier, and clusters were formed by simple K-means clustering algorithm.",method,2
9837,"Certain safety driving suggestions were made based on statistics, association rules, classification model, and clusters obtained.",result,3
9838,"The ability to recognize emotion is one of the hallmarks of emotional intelligence, an aspect of human intelligence that has been argued to be even more important than mathematical and verbal intelligences.",background,0
9839,This paper proposes that machine intelligence needs to include emotional intelligence and demonstrates results toward this goal: developing a machine's ability to recognize human aaective state given four physiological signals.,objective,1
9840,"We describe diicult issues unique to obtaining reliable aaective data, and collect a large set of data from a subject trying to elicit and experience each of eight emotional states, daily, over multiple weeks.",method,2
9841,This paper presents and compares multiple algorithms for feature-based recognition of emotional state from this data.,method,2
9842,We analyze four physiological signals that exhibit problematic day-today variations: the features of diierent emotions on the same day tend to cluster more tightly than do the features of the same emotion on diierent days.,method,2
9843,"To handle the daily variations, we propose new features and algorithms and compare their performance.",method,2
9844,"We nd that the technique of seeding a Fisher Projection with the results of Sequential Floating Forward Search improves the performance of the Fisher Projection, and provides the highest recognition rates reported to date for classiication of aaect from physiology: 81% recognition accuracy on eight classes of emotion, including neutral.",result,3
9845,The use of object proposals is an effective recent approach for increasing the computational efficiency of object detection.,background,0
9846,We propose a novel method for generating object bounding box proposals using edges.,method,2
9847,Edges provide a sparse yet informative representation of an image.,method,2
9848,Our main observation is that the number of contours that are wholly contained in a bounding box is indicative of the likelihood of the box containing an object.,method,2
9849,We propose a simple box objectness score that measures the number of edges that exist in the box minus those that are members of contours that overlap the box’s boundary.,method,2
9850,"Using efficient data structures, millions of candidate boxes can be evaluated in a fraction of a second, returning a ranked set of a few thousand top-scoring proposals.",method,2
9851,"Using standard metrics, we show results that are significantly more accurate than the current state-of-the-art while being faster to compute.",method,2
9852,"In particular, given just 1000 proposals we achieve over 96% object recall at overlap threshold of 0.5 and over 75% recall at the more challenging overlap of 0.7.",result,3
9853,Our approach runs in 0.25 seconds and we additionally demonstrate a near real-time variant with only minor loss in accuracy.,result,3
9854,"Four methods for reviewing a body of research literature – narrative review, descriptive review, vote-counting, and meta-analysis – are compared.",background,0
9855,"Meta-analysis as a formalized, systematic review method is discussed in detail in terms of its history, current status, advantages, common analytic methods, and recent developments.",method,2
9856,Meta-analysis is found to be underutilized in IS.,result,3
9857,Suggestions on encouraging the use of metaanalysis in IS research and procedures recommended for meta-analysis are also provided.,result,3
9858,Quality uncertainty and high search costs for identifying relevant information from an ocean of information may prevent customers from making purchases.,background,0
9859,"Recognizing potential negative impacts of this search cost for quality information and relevant information, firms began to invest in creating a virtual community that enables consumers to share their opinions and experiences to reduce quality uncertainty, and in developing recommendation systems that help customers identify goods in which they might have an interest.",background,0
9860,"However, not much is known regarding the effectiveness of these efforts.",background,0
9861,"In this paper, we empirically investigate the impacts of recommendations and consumer feedbacks on sales based on data gathered from Amazon.com.",result,3
9862,"Our results indicate that more recommendations indeed improve sales at Amazon.com; however, consumer ratings are not found to be related to sales.",result,3
9863,"On the other hand, number of consumer reviews is positively associated with sales.",result,3
9864,We also find that recommendations work better for less-popular books than for more-popular books.,result,3
9865,"This is consistent with the search cost argument: a consumer’s search cost for less-popular books may be higher, and thus they may rely more on recommendations to locate a product of interest.",result,3
9866,Customer reviews are increasingly available online for a wide range of products and services.,background,0
9867,"They supplement other information provided by electronic storefronts such as product descriptions, reviews from experts, and personalized advice generated by automated recommendation systems.",background,0
9868,"While researchers have demonstrated the benefits of the presence of customer reviews to an online retailer, a largely uninvestigated issue is what makes customer reviews helpful Carol Saunders was the accepting senior editor for this paper.",background,0
9869,Both authors contributed equally to this paper.,other,4
9870,to a consumer in the process of making a purchase decision.,objective,1
9871,"Drawing on the paradigm of search and experience goods from information economics, we develop and test a model of customer review helpfulness.",method,2
9872,"An analysis of 1,587 reviews from Amazon.com across six products indicated that review extremity, review depth, and product type affect the perceived helpfulness of the review.",method,2
9873,Product type moderates the effect of review extremity on the helpfulness of the review.,result,3
9874,"For experience goods, reviews with extreme ratings are less helpful than reviews with moderate ratings.",result,3
9875,"For both product types, review depth has a positive effect on the helpfulness of the review, but the product type moderates the effect of review depth on the helpfulness of the review.",result,3
9876,This paper aims at high-accuracy 3D object detection in autonomous driving scenario.,background,0
9877,"We propose Multi-View 3D networks (MV3D), a sensory-fusion framework that takes both LIDAR point cloud and RGB images as input and predicts oriented 3D bounding boxes.",background,0
9878,We encode the sparse 3D point cloud with a compact multi-view representation.,method,2
9879,The network is composed of two subnetworks: one for 3D object proposal generation and another for multi-view feature fusion.,method,2
9880,The proposal network generates 3D candidate boxes efficiently from the birds eye view representation of 3D point cloud.,method,2
9881,We design a deep fusion scheme to combine region-wise features from multiple views and enable interactions between intermediate layers of different paths.,result,3
9882,Experiments on the challenging KITTI benchmark show that our approach outperforms the state-of-the-art by around 25% and 30% AP on the tasks of 3D localization and 3D detection.,result,3
9883,"In addition, for 2D detection, our approach obtains 14.9% higher AP than the state-of-the-art on the hard data among the LIDAR-based methods.",result,3
9884,"Time series are recorded values of an interesting phenomenon such as stock prices, household incomes, or patient heart rates over a period of time.",background,0
9885,Time series data mining focuses on discovering interesting patterns in such data.,background,0
9886,This article introduces a wavelet-based time series data analysis to interested readers.,method,2
9887,"It provides a systematic survey of various analysis techniques that use discrete wavelet transformation (DWT) in time series data mining, and outlines the benefits of this approach demonstrated by previous studies performed on diverse application domains, including image classification, multimedia retrieval, and computer network anomaly detection.",method,2
9888,"Whereas the penetration of mobile phones inAsian countries keeps climbing, little research has explored the application of the short message service (SMS) in second language learning.",background,0
9889,This study aims to examine the effectiveness of SMS vocabulary lessons of limited lexical information on the small screens of mobile phones.,objective,1
9890,Thirty high school students were randomly distributed into two groups and given two sets of English words either on paper or through SMS messages during two weeks.,method,2
9891,Students recognized more vocabulary during the post-test after reading the regular and brief SMS lessons than they did after reading the relatively more detailed print material.,method,2
9892,Qualitative data from interviews offer information about the learning process as well as the benefits and limitations of m-learning.,result,3
9893,Results of the questionnaires show that students in general hold positive attitudes towards learning vocabulary via mobile phone.,result,3
9894,"On the other hand, technological limitations, unfamiliar presentations and learning activities may prevent students from reading SMS lessons.",result,3
9895,Procedural Content Generation in Games (PCG) is a thriving field of research and application.,background,0
9896,"Recent presented examples range from levels, stories and race tracks to complete rulesets for games.",background,0
9897,"However, there is not much research to date on procedural 3D modeling of caves, and similar enclosed natural spaces.",background,0
9898,"In this paper, we present a modular pipeline to procedurally generate underground caves in realtime, to be used as part of larger landscapes in game worlds.",objective,1
9899,"We propose a three step approach, which can be fully implemented using General-Purpose Computing on Graphics Processing (GPGPU) technology: 1) an L-System to emulate the expanded cracks and passages which form cave structures in nature, 2) a noise-perturbed metaball approach for virtual 3D carving, and 3) a rendering component for isosurface extraction of the modeled voxel data, and further mesh enhancement through shader programming.",method,2
9900,"We demonstrate how the interaction between these components produce results comparable to real world caves, and show that the solution is viable for video game environments.",result,3
9901,"For this, we present the findings of a user study we conducted among indie-game developers and players, using our results.",result,3
9902,"Purpose – To explore the current literature base of critical success factors (CSFs) of ERP implementations, prepare a compilation, and identify any gaps that might exist.",objective,1
9903,Design/methodology/approach – Hundreds of journals were searched using key terms identified in a preliminary literature review.,background,0
9904,Successive rounds of article abstract reviews resulted in 45 articles being selected for the compilation.,background,0
9905,CSF constructs were then identified using content analysis methodology and an inductive coding technique.,method,2
9906,A subsequent critical analysis identified gaps in the literature base.,method,2
9907,Findings – The most significant finding is the lack of research that has focused on the identification of CSFs from the perspectives of key stakeholders.,method,2
9908,"Additionally, there appears to be much variance with respect to what exactly is encompassed by change management, one of the most widely cited CSFs, and little detail of specific implementation tactics.",background,0
9909,Research limitations/implications – There is a need to focus future research efforts on the study of CSFs as they apply to the perspectives of key stakeholders and to ensure that this stakeholder approach is also comprehensive in its coverage of CSFs.,result,3
9910,"As well, there is need to conduct more in-depth research into the concept of change management.",result,3
9911,One key limitation of this research is the occurrence of duplication in the frequency analysis of the success factors.,result,3
9912,"One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language, in particular building an intelligent dialogue agent.",objective,1
9913,"To measure progress towards that goal, we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering.",method,2
9914,"Our tasks measure understanding in several ways: whether a system is able to answer questions via chaining facts, simple induction, deduction and many more.",method,2
9915,The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human.,method,2
9916,"We believe many existing learning systems can currently not solve them, and hence our aim is to classify these tasks into skill sets, so that researchers can identify (and then rectify) the failings of their systems.",method,2
9917,"We also extend and improve the recently introduced Memory Networks model, and show it is able to solve some, but not all, of the tasks.",background,0
9918,The creation of a labelled dataset for machine learning purposes is a costly process.,background,0
9919,"In recent works, it has been shown that a mix of crowdsourcing and active learning approaches can be used to annotate objects at an a↵ordable cost.",objective,1
9920,"In this paper, we study the gamification of machine learning techniques; in particular, the problem of classification of objects.",objective,1
9921,"In this first pilot study, we designed a simple game, based on a visual interpretation of probabilistic classifiers, that consists in separating two sets of coloured points on a two-dimensional plane by means of a straight line.",method,2
9922,"We present the current results of this first experiment that we used to collect the requirements for the next version of the game and to analyze i) what is the ‘price’ to build a reasonably accurate classifier with a small amount of labelled objects, ii) and compare the accuracy of the player to the state-of-the-art classification algorithms.",result,3
9923,"Recommender system is a specific type of intelligent systems, which exploits historical user ratings on items and/or auxiliary information to make recommendations on items to the users.",background,0
9924,"It plays a critical role in a wide range of online shopping, e-commercial services and social networking applications.",background,0
9925,"Collaborative filtering (CF) is the most popular approaches used for recommender systems, but it suffers from complete cold start (CCS) problem where no rating record are available and incomplete cold start (ICS) problem where only a small number of rating records are available for some new items or users in the system.",method,2
9926,"In this paper, we propose two recommendation models to solve the CCS and ICS problems for new items, which are based on a framework of tightly coupled CF approach and deep learning neural network.",method,2
9927,A specific deep neural network SADE is used to extract the content features of the items.,method,2
9928,"The state of the art CF model, timeSVD++, which models and utilizes temporal dynamics of user preferences and item features, is modified to take the content features into prediction of ratings for cold start items.",method,2
9929,"Extensive experiments on a large Netflix rating dataset of movies are performed, which show that our proposed recommendation models largely outperform the baseline models for rating prediction of cold start items.",result,3
9930,"The two proposed recommendation models are also evaluated and compared on ICS items, and a flexible scheme of model retraining and switching is proposed to deal with the transition of items from cold start to non-cold start status.",result,3
9931,The experiment results on Netflix movie recommendation show the tight coupling of CF approach and deep learning neural network is feasible and very effective for cold start item recommendation.,result,3
9932,The design is general and can be applied to many other recommender,background,0
9933,Size and cost reduction are among the main issues of electric motor design and fabrication.,background,0
9934,This paper proposes an original layout for an axial flux permanent-magnet motor with printed circuit board (PCB) winding.,objective,1
9935,"In contrast to other axial flux motors of the same type, which are generally made with a three-phase fractional slot winding, the proposed motor has a two-phase wave winding printed on either side of the PCB.",method,2
9936,This configuration allows increasing the number of pole pairs and the supply frequency so to reduce the stator and rotor core widths.,method,2
9937,"The winding is also characterized by a large copper percentage on the board, which improves the torque density of the motor.",method,2
9938,"The results of the mathematical analysis, of the numerical simulation and of the experiments are compared.",result,3
9939,A method for the computation of the phase inductances is also proposed and validated.,result,3
9940,The main dimensions of the magnets are optimized via the finite-element method.,result,3
9941,The experimental comparison shows the advantages of the proposed motor in comparison to the traditional shaded pole motor for household applications.,result,3
9942,Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task.,background,0
9943,"The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations at multiple rates and multiple effective fields-of-view, while the latter networks can capture sharper object boundaries by gradually recovering the spatial information.",background,0
9944,"In this work, we propose to combine the advantages from both methods.",background,0
9945,"Specifically, our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries.",objective,1
9946,"We further explore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network.",method,2
9947,"We demonstrate the effectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets, achieving the test set performance of 89.0% and 82.1% without any post-processing.",method,2
9948,Our paper is accompanied with a publicly available reference implementation of the proposed models in Tensorflow at https: //github.com/tensorflow/models/tree/master/research/deeplab.,result,3
9949,Fog Computing is a paradigm that extends Cloud computing and services to the edge of the network.,background,0
9950,"Similar to Cloud, Fog provides data, compute, storage, and application services to end-users.",background,0
9951,"In this article, we elaborate the motivation and advantages of Fog computing, and analyse its applications in a series of real scenarios, such as Smart Grid, smart traffic lights in vehicular networks and software defined networks.",method,2
9952,We discuss the state-of-the-art of Fog computing and similar work under the same umbrella.,method,2
9953,Security and privacy issues are further disclosed according to current Fog computing paradigm.,method,2
9954,"As an example, we study a typical attack, man-in-the-middle attack, for the discussion of security in Fog computing.",result,3
9955,We investigate the stealthy features of this attack by examining its CPU and memory consumption on Fog device.,result,3
9956,We present persona-based models for handling the issue of speaker consistency in neural response generation.,background,0
9957,A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style.,background,0
9958,A dyadic speakeraddressee model captures properties of interactions between two interlocutors.,background,0
9959,"Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gains in speaker consistency as measured by human judges.",result,3
9960,Organizations use Role-Based Access Control (RBAC) to protect information resources from unauthorized access.,background,0
9961,"We propose an approach, based on the Unified Modeling Language (UML), that shows how RBAC policies can be systematically incorporated into an application design.",objective,1
9962,We consider an RBAC model to be a pattern which we express using UML diagram templates; RBAC policies for an application conforming to this model can be generated by instantiating these templates with values obtained from the application.,objective,1
9963,The constraints of the RBAC model are expressed using the Object Constraint Language (OCL).,method,2
9964,"OCL constraints, based on first-order logic, are difficult to understand.",method,2
9965,"To alleviate this problem, we show how violation of such constraints can be visually represented using object diagram templates.",method,2
9966,"With adequate tool support, developers can use these to demonstrate constraint violations in their applications.",result,3
9967,Our approach is illustrated using a small banking application.,result,3
9968,0957-4174/$ see front matter 2012 Elsevier Ltd. A doi:10.1016/j.eswa.2012.02.063 ⇑ Corresponding author.,other,4
9969,"E-mail address: michael@mail.tku.edu.tw (S.-H. Li In order to determine how data mining techniques (DMT) and their applications have developed, during the past decade, this paper reviews data mining techniques and their applications and development, through a survey of literature and the classification of articles, from 2000 to 2011.",background,0
9970,"Keyword indices and article abstracts were used to identify 216 articles concerning DMT applications, from 159 academic journals (retrieved from five online databases), this paper surveys and classifies DMT, with respect to the following three areas: knowledge types, analysis types, and architecture types, together with their applications in different research and practical domains.",background,0
9971,A discussion deals with the direction of any future developments in DMT methodologies and applications: (1) DMT is finding increasing applications in expertise orientation and the development of applications for DMT is a problem-oriented domain.,objective,1
9972,"(2) It is suggested that different social science methodologies, such as psychology, cognitive science and human behavior might implement DMT, as an alternative to the methodologies already on offer.",method,2
9973,(3) The ability to continually change and acquire new understanding is a driving force for the application of DMT and this will allow many new future applications.,result,3
9974,2012 Elsevier Ltd. All rights reserved.,other,4
9975,Open data has become an important new direction in information technology.,background,0
9976,Governments are releasing data so as to be more transparent and also claiming that open data has substantial economic value.,background,0
9977,"However, there appear to be many issues about open data that are not being discussed.",background,0
9978,"This paper uses several practical examples in an attempt to illustrate many of these issues and allied opportunities, and through them to suggest the beginning of a research agenda around open data.",objective,1
9979,Acknowledgements I want to thank Bernhard Steffen for guiding me during the past five years.,background,0
9980,"Clearly, this dis-sertation is a result of having being challenged, motivated, and supported in a truly unique environment, created by the persons that gathered at the Chair of Programming Systems to create and cooperate.",background,0
9981,"Thus I would also like to thank my colleagues, and in particular Falk Howar, with whom I had the pleasure of sharing an office for three years.",background,0
9982,"Hilarity sure ensued, as did pleasant traveling and countless hours of fruitful discussion.",method,2
9983,"Last but not least, thanks also go to my family, which was both supportive and patient.",background,0
9984,"Status of this Memo This document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements.",background,0
9985,"Please refer to the current edition of the ""Internet Official Protocol Standards"" (STD 1) for the standardization state and status of this protocol.",background,0
9986,Distribution of this memo is unlimited.,other,4
9987,"Abstract Modern implementations of TCP contain four intertwined algorithms that have never been fully documented as Internet standards: slow start, congestion avoidance, fast retransmit, and fast recovery.",method,2
9988,"[2] and [3] provide some details on these algorithms, [4] provides examples of the algorithms in action, and [5] provides the source code for the 4.4BSD implementation.",method,2
9989,"RFC 1122 requires that a TCP must implement slow start and congestion avoidance (Section 4.2.2.15 of [1]), citing [2] as the reference, but fast retransmit and fast recovery were implemented after RFC 1122.",result,3
9990,The purpose of this document is to document these four algorithms for the Internet.,objective,1
9991,"The present paper focuses on Cyber Security Awareness Campaigns, and aims to identify key factors regarding security which may lead them to failing to appropriately change people’s behaviour.",background,0
9992,Past and current efforts to improve information-security practices and promote a sustainable society have not had the desired impact.,background,0
9993,"It is important therefore to critically reflect on the challenges involved in improving information-security behaviours for citizens, consumers and employees.",objective,1
9994,"In particular, our work considers these challenges from a Psychology perspective, as we believe that understanding how people perceive risks is critical to creating effective awareness campaigns.",objective,1
9995,"Changing behaviour requires more than providing information about risks and reactive behaviours – firstly, people must be able to understand and apply the advice, and secondly, they must be motivated and willing to do so – and the latter requires changes to attitudes and intentions.",objective,1
9996,These antecedents of behaviour change are identified in several psychological models of behaviour.,method,2
9997,"We review the suitability of persuasion techniques, including the widely used ‘fear appeals’.",method,2
9998,"From this range of literature, we extract essential components for an awareness campaign as well as factors which can lead to a campaign’s success or failure.",method,2
9999,"Finally, we present examples of existing awareness campaigns in different cultures (the UK and Africa) and reflect on these.",result,3
10000,"Direct Sparse Odometry (DSO) is a visual odometry method based on a novel, highly accurate sparse and direct structure and motion formulation.",method,2
10001,"It combines a fully direct probabilistic model (minimizing a photometric error) with consistent, joint optimization of all model parameters, including geometry-represented as inverse depth in a reference frame-and camera motion.",method,2
10002,This is achieved in real time by omitting the smoothness prior used in other direct methods and instead sampling pixels evenly throughout the images.,method,2
10003,"Since our method does not depend on keypoint detectors or descriptors, it can naturally sample pixels from across all image regions that have intensity gradient, including edges or smooth intensity variations on essentially featureless walls.",method,2
10004,"The proposed model integrates a full photometric calibration, accounting for exposure time, lens vignetting, and non-linear response functions.",background,0
10005,We thoroughly evaluate our method on three different datasets comprising several hours of video.,result,3
10006,"The experiments show that the presented approach significantly outperforms state-of-the-art direct and indirect methods in a variety of real-world settings, both in terms of tracking accuracy and robustness.",result,3
10007,Geometry reasoning and proof form a major and challenging component in the K-121 mathematics curriculum.,background,0
10008,"Although several computerized systems exist that help students learn and practice general geometry concepts, they do not target geometry proof problems, which are more advanced and difficult.",background,0
10009,"Powerful geometry theorem provers also exist, however they typically employ advanced algebraic methods and generate complex, difficult to understand proofs, and thus do not meet general K-12 students’ educational needs.",background,0
10010,"This paper tackles these weaknesses of prior systems by introducing a geometry proof system, iGeoTutor, capable of generating human-readable elementary proofs, i.e. proofs using standard Euclidean axioms.",objective,1
10011,"We have gathered 77 problems in total from various sources, including ones unsolvable by other systems and from Math competitions.",objective,1
10012,"iGeoTutor solves all but two problems in under two minutes each, and more importantly, demonstrates a much more effective and intelligent proof search than prior systems.",result,3
10013,"We have also conducted a pilot study with 12 high school students, and the results show that iGeoTutor provides a clear benefit in helping students learn geometry proofs.",result,3
10014,We are in active discussions with Khan Academy and local high schools for possible adoption of iGeoTutor in real learning environments.,result,3
10015,Video demo: https://www.youtube.com/watch?v=KL0dUb6hKxU,other,4
10016,Goal: Cataracts are a clouding of the lens and the leading cause of blindness worldwide.,objective,1
10017,"Assessing the presence and severity of cataracts is essential for diagnosis and progression monitoring, as well as to facilitate clinical research and management of the disease.",objective,1
10018,"Methods: Existing automatic methods for cataract grading utilize a predefined set of image features that may provide an incomplete, redundant, or even noisy representation.",method,2
10019,"In this study, we propose a system to automatically learn features for grading the severity of nuclear cataracts from slit-lamp images.",method,2
10020,Local filters are first acquired through clustering of image patches from lenses within the same grading class.,method,2
10021,"The learned filters are fed into a convolutional neural network, followed by a set of recursive neural networks, to further extract higher order features.",method,2
10022,"With these features, support vector regression is applied to determine the cataract grade.",method,2
10023,"Results: The proposed system is validated on a large population-based dataset of 5378 images, where it outperforms the state of the art by yielding with respect to clinical grading a mean absolute error (ε) of 0.304, a 70.7% exact integral agreement ratio (R0), an 88.4% decimal grading error ≤0.5 (Re0.5), and a 99.0% decimal grading error ≤1.0 (Re1.0).",result,3
10024,Significance: The proposed method is useful for assisting and improving clinical management of the disease in the context of large-population screening and has the potential to be applied to other eye diseases.,result,3
10025,"To date, there is almost no work on the use of adverbs in sentiment analysis, nor has there been any work on the use of adverb-adjective combinations (AACs).",background,0
10026,We propose an AAC-based sentiment analysis technique that uses a linguistic analysis of adverbs of degree.,objective,1
10027,We define a set of general axioms (based on a classification of adverbs of degree into five categories) that all adverb scoring techniques must satisfy.,objective,1
10028,"Instead of aggregating scores of both adverbs and adjectives using simple scoring functions, we propose an axiomatic treatment of AACs based on the linguistic classification of adverbs.",method,2
10029,Three specific AAC scoring methods that satisfy the axioms are presented.,method,2
10030,We describe the results of experiments on an annotated set of 200 news articles (annotated by 10 students) and compare our algorithms with some existing sentiment analysis algorithms.,result,3
10031,We show that our results lead to higher accuracy based on Pearson correlation with human subjects.,result,3
10032,Railway standards prescribe the use of Safety-related Application Conditions (SACs).,background,0
10033,SACs are demands to be observed when using a safety related system or a sub-system.,background,0
10034,"The use of SACs can, however, easily be associated with difficulties.",background,0
10035,SACs of sub-systems can imply high efforts regarding their fulfillment at system level.,method,2
10036,"Furthermore, SACs at sub-system level may become very obstructive for the user of the sub-system, if the safe application on system level has strong restrictions.",background,0
10037,"Additionally, a large number of SACs may be very difficult to manage.",method,2
10038,"In this way, SACs may obstruct the introduction of a system or a sub-system into the field.",method,2
10039,"Particular hazards could arise from SACs, if they are formulated ambiguously, so that the originally intended safety-related measures are not taken at all.",method,2
10040,This paper presents the objectives and benefits of SACs and depicts difficulties and challenges associated with the use of SACs.,method,2
10041,"The paper not only explains what should be the SAC content but also the quality criteria, the conditions for SAC creation and SAC fulfillment are described.",method,2
10042,"From the oversexualized characters in fighting games, such as Dead or Alive or Ninja Gaiden, to the overuse of the damsel in distress trope in popular titles, such as the Super Mario series, the under- and misrepresentation of females in video games has been well documented in several content analyses.",background,0
10043,"Cultivation theory suggests that long-term exposure to media content can affect perceptions of social realities in a way that they become more similar to the representations in the media and, in turn, impact one's beliefs and attitudes.",background,0
10044,"Previous studies on video games and cultivation have often been cross-sectional or experimental, and the limited longitudinal work in this area has only considered time intervals of up to 1 month.",background,0
10045,"Additionally, previous work in this area has focused on the effects of violent content and relied on self-selected or convenience samples composed mostly of adolescents or college students.",background,0
10046,"Enlisting a 3 year longitudinal design, the present study assessed the relationship between video game use and sexist attitudes, using data from a representative sample of German players aged 14 and older (N=824).",method,2
10047,"Controlling for age and education, it was found that sexist attitudes--measured with a brief scale assessing beliefs about gender roles in society--were not related to the amount of daily video game use or preference for specific genres for both female and male players.",method,2
10048,Implications for research on sexism in video games and cultivation effects of video games in general are discussed.,result,3
10049,In agriculture sector where farmers and agribusinesses have to make innumerable decisions every day and intricate complexities involves the various factors influencing them.,background,0
10050,An essential issue for agricultural planning intention is the accurate yield estimation for the numerous crops involved in the planning.,background,0
10051,Data mining techniques are necessary approach for accomplishing practical and effective solutions for this problem.,background,0
10052,Agriculture has been an obvious target for big data.,objective,1
10053,"Environmental conditions, variability in soil, input levels, combinations and commodity prices have made it all the more relevant for farmers to use information and get help to make critical farming decisions.",method,2
10054,"This paper focuses on the analysis of the agriculture data and finding optimal parameters to maximize the crop production using data mining techniques like PAM, CLARA, DBSCAN and Multiple Linear Regression.",method,2
10055,"Mining the large amount of existing crop, soil and climatic data, and analysing new, non-experimental data optimizes the production and makes agriculture more resilient to climatic change.",result,3
10056,This paper describes a representation of gait appearance for the purpose of person identification and classification.,objective,1
10057,This gait representation is based on simple features such as moments extracted from orthogonal view video silhouettes of human walking motion.,background,0
10058,"Despite its simplicity, the resulting feature vector contains enough information to perform well on human identification and gender classification tasks.",method,2
10059,We explore the recognition behaviors of two different methods to aggregate features over time under different recognition tasks.,method,2
10060,We demonstrate the accuracy of recognition using gait video sequences collected over different days and times and under varying lighting environments.,method,2
10061,"In addition, we show results for gender classification based our gait appearance features using a support-vector machine.",result,3
10062,Music in India has very ancient roots.,background,0
10063,"Indian classical music is considered to be one of the oldest musical traditions in the world but compared to Western music very little work has been done in the areas of genre recognition, classification, automatic tagging, comparative studies etc.",background,0
10064,"In this work, we investigate the structural differences between Indian and Western music forms and compare the two forms of music in terms of harmony, rhythm, microtones, timbre and other spectral features.",objective,1
10065,"To capture the temporal and static structure of the spectrogram, we form a set of global and local frame-wise features for 5genres of each music form.",background,0
10066,We then apply Adaboost classification and GMM based Hidden Markov Models for four types of feature sets and observe that Indian Music performs better as compared to Western Music.,method,2
10067,We have achieved a best accuracy of 98.0% and 77.5% for Indian and Western musical genres respectively.,result,3
10068,Our comparative analysis indicates that features that work well with one form of music may not necessarily perform well with the other form.,result,3
10069,The results obtained on Indian Music Genres are better than the previous state-of-the-art.,result,3
10070,A comprehensive study of ultrahigh-speed current-mode logic (CML) buffers along with the design of novel regenerative CML latches will be illustrated.,method,2
10071,"First, a new design procedure to systematically design a chain of tapered CML buffers is proposed.",objective,1
10072,"Next, two new high-speed regenerative latch circuits capable of operating at ultrahigh-speed data rates will be introduced.",method,2
10073,Experimental results show a higher performance for the new latch architectures compared to the conventional CML latch circuit at ultrahigh-frequencies.,result,3
10074,"It is also shown, both through the experiments and by using efficient analytical models, why CML buffers are better than CMOS inverters in high-speed low-voltage applications.",result,3
10075,"Mobile augmented reality (mobile AR) enables virtual content such as 3D models, animations and annotations to be placed on top of a real world objects in any context.",background,0
10076,We applied mobile AR to develop the Calory Battle AR exergame to tackle worldwide childhood obesity.,objective,1
10077,In this game the player finds and defuses virtual calory bombs in a real world environment.,objective,1
10078,"Specifically, we present the development of two game versions.",method,2
10079,First prototype was created without a third party game engine and it led to many challenges.,method,2
10080,"To explore solutions to these challenges, we created a new version of game with the Unity 3D game engine.",method,2
10081,"Using the Unity 3D, the game development process was simplified.",method,2
10082,A mixed-method usability evaluation on children and university students indicated that especially interaction with AR content and user interface clarity were improved in the Unity 3D version.,result,3
10083,This study produced three important contributions: 1) a novel mobile AR exergame to motivate children to move; 2) reimplementation of the game using the Unity 3D; and 3) results of a usability evaluation comparing two game versions.,result,3
10084,We expect that game engines such as the Unity 3D will become essential for AR game development in the future.,result,3
10085,"Computational models of single pacemaker neuron and neural population in the pre-Bötzinger Complex (pBC) were developed based on the previous models by Butera et al. (1999a,b).",background,0
10086,Our modeling study focused on the conditions that could define endogenous bursting vs. tonic activity in single pacemaker neurons and population bursting vs. asynchronous firing in populations of pacemaker neurons.,objective,1
10087,We show that both bursting activity in single pacemaker neurons and population bursting activity may be released or suppressed depending on the expression of persistent sodium (I Na P) and delayed-rectifier potassium (I K ) currents.,result,3
10088,"Specifically, a transition from asynchronous firing to population bursting could be induced by a reduction of I K via a direct suppression of the potassium conductance or through an elevation of extracellular potassium concentration.",method,2
10089,Similar population bursting activity could be triggered by an augmentation of I Na P.,background,0
10090,These findings are discussed in the context of the possible role of population bursting activity in the pBC in the respiratory rhythm generation in vivo vs. in vitro and during normal breathing in vivo vs. gasping.,result,3
10091,It is increasingly acknowledged that many threats to an organisation’s computer systems can be attributed to the behaviour of computer users.,background,0
10092,"To quantify these human-based information security vulnerabilities, we are developing the Human Aspects of Information Security Questionnaire (HAIS-Q).",background,0
10093,The aim of this paper was twofold.,objective,1
10094,"The first aim was to outline the conceptual development of the HAIS-Q, including validity and reliability testing.",objective,1
10095,"The second aim was to examine the relationship between knowledge of policy and procedures, attitude towards policy and procedures and behaviour when using a work computer.",objective,1
10096,Results from 500 Australian employees indicate that knowledge of policy and procedures had a stronger influence on attitude towards policy and procedure than selfreported behaviour.,result,3
10097,This finding suggests that training and education will be more effective if it outlines not only what is expected (knowledge) but also provides an understanding of why this is important (attitude).,result,3
10098,Plans for future research to further develop and test the HAIS-Q are outlined.,result,3
10099,Crown Copyright a 2014 Published by Elsevier Ltd.,other,4
10101,We discuss distributed denial of service attacks in the Internet.,background,0
10102,"We were motivated by the widely known February 2000 distributed attacks on Yahoo!, Amazon.com, CNN.com, and other major Web sites.",background,0
10103,A denial of service is characterized by an explicit attempt by an attacker to prevent legitimate users from using resources.,background,0
10104,"An attacker may attempt to: “flood” a network and thus reduce a legitimate user’s bandwidth, prevent access to a service, or disrupt service to a specific system or a user.",background,0
10105,"We describe methods and techniques used in denial of service attacks, and we list possible defenses.",method,2
10106,"In our study, we simulate a distributed denial of service attack using ns-2 network simulator.",method,2
10107,"We examine how various queuing algorithms implemented in a network router perform during an attack, and whether legitimate users can obtain desired bandwidth.",result,3
10108,"We find that under persistent denial of service attacks, class based queuing algorithms can guarantee bandwidth for certain classes of input flows.",result,3
10109,Predicting trends in stock market prices has been an area of interest for researchers for many years due to its complex and dynamic nature.,background,0
10110,Intrinsic volatility in stock market across the globe makes the task of prediction challenging.,background,0
10111,"Forecasting and diffusion modeling, although effective can’t be the panacea to the diverse range of problems encountered in prediction, short-term or otherwise.",objective,1
10112,"Market risk, strongly correlated with forecasting errors, needs to be minimized to ensure minimal risk in investment.",method,2
10113,"The authors propose to minimize forecasting error by treating the forecasting problem as a classification problem, a popular suite of algorithms in Machine learning.",method,2
10114,"In this paper, we propose a novel way to minimize the risk of investment in stock market by predicting the returns of a stock using a class of powerful machine learning algorithms known as ensemble learning.",method,2
10115,"Some of the technical indicators such as Relative Strength Index (RSI), stochastic oscillator etc are used as inputs to train our model.",method,2
10116,The learning model used is an ensemble of multiple decision trees.,method,2
10117,The algorithm is shown to outperform existing algorithms found in the literature.,method,2
10118,Out of Bag (OOB) error estimates have been found to be encouraging.,result,3
10119,We present an overview of the last ten years of research on visualizations that support close and distant reading of textual data in the digital humanities.,background,0
10120,We look at various works published within both the visualization and digital humanities communities.,objective,1
10121,"We provide a taxonomy of applied methods for close and distant reading, and illustrate approaches that combine both reading techniques to provide a multifaceted view of the data.",method,2
10122,"Furthermore, we list toolkits and potentially beneficial visualization approaches for research in the digital humanities.",method,2
10123,"Finally, we summarize collaboration experiences when developing visualizations for close and distant reading, and give an outlook on future challenges in that research area.",result,3
10124,"In this paper, we propose an attention-aware deep reinforcement learning (ADRL) method for video face recognition, which aims to discard the misleading and confounding frames and find the focuses of attentions in face videos for person recognition.",objective,1
10125,We formulate the process of finding the attentions of videos as a Markov decision process and train the attention model through a deep reinforcement learning framework without using extra labels.,method,2
10126,"Unlike existing attention models, our method takes information from both the image space and the feature space as the input to make better use of face information that is discarded in the feature learning process.",method,2
10127,"Besides, our approach is attention-aware, which seeks different attentions of videos for the recognition of different pairs of videos.",method,2
10128,Our approach achieves very competitive video face recognition performance on three widely used video face datasets.,result,3
10129,This paper presents a comprehensive performance comparison between CUDA and OpenCL.,background,0
10130,We have selected 16 benchmarks ranging from synthetic applications to real-world ones.,method,2
10131,"We make an extensive analysis of the performance gaps taking into account programming models, ptimization strategies, architectural details, and underlying compilers.",method,2
10132,"Our results show that, for most applications, CUDA performs at most 30\% better than OpenCL.",method,2
10133,"We also show that this difference is due to unfair comparisons: in fact, OpenCL can achieve similar performance to CUDA under a fair comparison.",method,2
10134,"Therefore, we define a fair comparison of the two types of applications, providing guidelines for more potential analyses.",method,2
10135,We also investigate OpenCL's portability by running the benchmarks on other prevailing platforms with minor modifications.,objective,1
10136,"Overall, we conclude that OpenCL's portability does not fundamentally affect its performance, and OpenCL can be a good alternative to CUDA.",result,3
10137,"Organizational structures are complex and vary according to sector, field, and type of business or service.",background,0
10138,"In order to be effective, an organization needs to tailor its activities to the environment in which is it located.",background,0
10139,"Based on contingency perspectives, this study is focused on investigating effective ways to design team diversity and maximize team creativity according to task difficulty levels.",objective,1
10140,"Considering the organizational team member as an agent, the study employed a multi-agent simulation method to understand the progress of creative manifestation, by observing the exploration and exploitation activity of team members over certain periods of time.",method,2
10141,"The results first reveal that the level of team diversity influences the amount of creativity manifested by team members’ activities, such as exploration and exploitation.",result,3
10142,"Second, managers have to properly facilitate either exploration or exploitation depending on task difficulty by striking a balance between them.",result,3
10144,Humans use their hands for a large variety of tasks during daily life.,background,0
10145,"In this chapter, a discussion of human hand use is presented, including classification schemes for grasping and manipulation behaviors.",background,0
10146,"First, a simple classification of the Activities of Daily Living (ADLs) is presented, providing some structure to a terminology that is typically used in an ad hoc manner.",method,2
10147,"Next, an overview of work related to classifications and taxonomies of static grasp types is presented, followed by a study investigating the frequency of use of various grasp types by a housekeeper and machinist.",method,2
10148,"Finally, a taxonomy classifying hand-based manipulation is presented, providing a hand-centric and motion-centric categorization of hand use.",method,2
10149,"These descriptions and classifications of hand use should prove useful to researchers interested in robotic manipulation, prosthetics, rehabilitation, and biomechanics.",result,3
10150,"Between June 1985 and January 1987, the Therac-25 medical electron accelerator was involved in six massive radiation overdoses.",background,0
10151,"As a result, several people died and others were seriously injured.",background,0
10152,"A detailed investigation of the factors involved in the software-related overdoses and attempts by users, manufacturers, and government agencies to deal with the accidents is presented.",background,0
10153,The authors demonstrate the complex nature of accidents and the need to investigate all aspects of system development and operation in order to prevent future accidents.,method,2
10154,"The authors also present some lessons learned in terms of system engineering, software engineering, and government regulation of safety-critical systems containing software components.<<ETX>>",method,2
10155,"In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL).",background,0
10156,Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress.,background,0
10157,"Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward.",background,0
10158,"In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret.",background,0
10159,"Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful.",background,0
10160,"In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures.",objective,1
10161,We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep RL more reproducible.,method,2
10162,We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted.,result,3
10163,Ranking fraud in the mobile App market refers to fraudulent or deceptive activities which have a purpose of bumping up the Apps in the popularity list.,background,0
10164,"Indeed, it becomes more and more frequent for App developers to use shady means, such as inflating their Apps' sales or posting phony App ratings, to commit ranking fraud.",background,0
10165,"While the importance of preventing ranking fraud has been widely recognized, there is limited understanding and research in this area.",background,0
10166,"To this end, in this paper, we provide a holistic view of ranking fraud and propose a ranking fraud detection system for mobile Apps.",method,2
10167,"Specifically, we first propose to accurately locate the ranking fraud by mining the active periods, namely leading sessions, of mobile Apps.",method,2
10168,Such leading sessions can be leveraged for detecting the local anomaly instead of globalanomaly of App rankings.,method,2
10169,"Furthermore, we investigate three types of evidences, i.e., ranking based evidences, rating based evidences and review based evidences, by modeling Apps' ranking, rating and review behaviors through statistical hypotheses tests.",result,3
10170,"In addition, we propose an optimization based aggregation method to integrate all the evidences for fraud detection.",method,2
10171,"Finally, we evaluate the proposed system with real-world App data collected from the iOS App Store for a long time period.",result,3
10172,"In the experiments, we validate the effectiveness of the proposed system, and show the scalability of the detection algorithm as well as some regularity of ranking fraud activities.",result,3
10173,We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing.,background,0
10174,"This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data.",background,0
10175,"However, such methods are also known to converge quite slowly.",method,2
10176,"In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be significantly better, both theoretically and practically.",method,2
10177,Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude.,result,3
10178,Video games have dramatically increased in realism over the past several years.,objective,1
10179,"With an increase in both graphical fidelity and gameplay realism, this increase has been used to further immersion in video games on many levels.",background,0
10180,"Video games have been subject to the term “immersion” for many years now, used in both the context of entertainment and marketing.",background,0
10181,"This paper explores the effects of realism on immersion in video games, as well as considering what immersion means to a video game and gameplay in general.",objective,1
10182,The adoption of Smart Grid devices throughout utility networks will effect tremendous change in grid operations and usage of electricity over the next two decades.,background,0
10183,"The changes in ways to control loads, coupled with increased penetration of renewable energy sources, offer a new set of challenges in balancing consumption and generation.",background,0
10184,Increased deployment of energy storage devices in the distribution grid will help make this process happen more effectively and improve system performance.,objective,1
10185,This paper addresses the new types of storage being utilized for grid support and the ways they are integrated into the grid.,method,2
10186,"Research proposing the application of blockchain technology in accounting assumes the utilization of decentralized consensus mechanisms based on the exertion of scarce resources (Proof-of-Work; PoW), leading to the validation of transactions without the need of any third party.",background,0
10187,"Together with the blockchain, a shared database, PoW is expected to lead to nearly immutable and, therefore, fraud-resistant, real-time financial registers.",objective,1
10188,"This conclusion must be reconsidered, taking into account recurrent top-management involvement in accounting scandals, often conducted through deliberate exposures of internal and external control systems.",result,3
10189,"This paper asserts that blockchain-based accounting using PoW-based consensus paves the way for the suspension of controls by the management, since exerting the majority of computer power is easier than circumventing internal and external control systems in conventional accounting systems.",method,2
10190,"Alternatives to PoW must be considered for blockchain-based accounting that prevents the management from conducting fraud and, thereby, qualifies the blockchain for its application in accounting.",result,3
10191,Ensemble methods for classification and regression have focused a great deal of attention in recent years.,background,0
10192,"They have shown, both theoretically and empirically, that they are able to perform substantially better than single models in a wide range of tasks.",background,0
10193,We have adapted an ensemble method to the problem of predicting future values of time series using recurrent neural networks (RNNs) as base learners.,method,2
10194,"The improvement is made by combining a large number of RNNs, each of which is generated by training on a different set of examples.",method,2
10195,"This algorithm is based on the boosting algorithm where difficult points of the time series are concentrated on during the learning process however, unlike the original algorithm, we introduce a new parameter for tuning the boosting influence on available examples.",method,2
10196,We test our boosting algorithm for RNNs on single-step-ahead and multi-step-ahead prediction problems.,method,2
10197,"The results are then compared to other regression methods, including those of different local approaches.",result,3
10198,"The overall results obtained through our ensemble method are more accurate than those obtained through the standard method, backpropagation through time, on these datasets and perform significantly better even when long-range dependencies play an important role.",result,3
10199,2006 Elsevier B.V. All rights reserved.,other,4
10200,User comments are the most popular but also extremely controversial form of communication on YouTube.,background,0
10201,Their public image is very poor; users generally expect that most comments will be of little value or even in thoroughly bad taste.,background,0
10202,"Nevertheless, heaps of comments continue to be posted every day.",background,0
10203,We propose an explanation for this contradiction in user attitudes and behaviour based on a new comment classification approach which captures salient aspects of YouTube comments.,method,2
10204,"We show that, based on our new classification, we are able to perform very fast lightweight semantic video analysis.",method,2
10205,"In addition, our results indicate that users’ video perceptions (Likes and Dislikes) are indeed influenced by the dispersion of valuable and inferior comments.",result,3
10206,"This electronic document is a ""live"" template.",background,0
10207,"The various components of your paper [title, text, heads, etc.]",background,0
10208,"are Abstract—Object detection in natural scenes has been widely researched in the past decade, and many deep learning based methods have achieved good performance on this task.",objective,1
10209,"This paper focuses on how to transfer and refine those object detection approaches from natural scene images to documents images, and proposes a deep learning-based page object (e.g., tables, formulae, figures) detection method.",method,2
10210,"On the basis of traditional Convolutional Neural Network (CNN) based object detection methods, we redesign the region proposal method, the training strategy, the network structure and replace the Non-Maximum Suppression (NMS) with a dynamic programming algorithm.",method,2
10211,The experimental results show that it is essential to adjust some modules of the natural scene object detection approaches in order to better process the document images.,result,3
10212,The proposed method also achieved better performance compared with existing page object detection methods.,result,3
10213,"Much has been written about the explosion of data, also known as the “data deluge”.",background,0
10214,"Similarly, much of today's research and decision making are based on the de facto acceptance that knowledge and insight can be gained from analyzing and contextualizing the vast (and growing) amount of “open” or “raw” data.",background,0
10215,The concept that the large number of data sources available today facilitates analyses on combinations of heterogeneous information that would not be achievable via “siloed” data maintained in warehouses is very powerful.,background,0
10216,The term data lake has been coined to convey the concept of a centralized repository containing virtually inexhaustible amounts of raw (or minimally curated) data that is readily made available anytime to anyone authorized to perform analytical activities.,background,0
10217,"The often unstated premise of a data lake is that it relieves users from dealing with data acquisition and maintenance issues, and guarantees fast access to local, accurate and updated data without incurring development costs (in terms of time and money) typically associated with structured data warehouses.",background,0
10218,"However appealing this premise, practically speaking, it is our experience, and that of our customers, that “raw” data is logistically difficult to obtain, quite challenging to interpret and describe, and tedious to maintain.",background,0
10219,"Furthermore, these challenges multiply as the number of sources grows, thus increasing the need to thoroughly describe and curate the data in order to make it consumable.",background,0
10220,"In this paper, we present and describe some of the challenges inherent in creating, filling, maintaining, and governing a data lake, a set of processes that collectively define the actions of data wrangling, and we propose that what is really needed is a curated data lake, where the lake contents have undergone a curation process that enable its use and deliver the promise of ad-hoc data accessibility to users beyond the enterprise IT staff.",result,3
10221,"Let A be a linear bounded operator in a Hilbert space H, N(A) and R(A) its null-space and range, and A∗ its adjoint.",background,0
10222,The operator A is called Fredholm iff dim N(A) = dim N(A∗) := n < ∞ and R(A) and R(A∗) are closed subspaces of H. A simple and short proof is given of the following known result: A is Fredholm,background,0
10223,"iff A = B + F , where B is an isomorphism and F is a finite-rank operator.",method,2
10224,The proof consists in reduction to a finite-dimensional linear algebraic system which is equivalent to the equation Au = f in the case of Fredholm operators.,result,3
10225,This paper surveys the eld of reinforcement learning from a computer-science perspective.,objective,1
10226,It is written to be accessible to researchers familiar with machine learning.,objective,1
10227,Both the historical basis of the eld and a broad selection of current work are summarized.,objective,1
10228,Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment.,method,2
10229,"The work described here has a resemblance to work in psychology, but di ers considerably in the details and in the use of the word \neinforcement.",method,2
10230,""" The paper discusses central issues of reinforcement learning, including trading o exploration and exploitation, establishing the foundations of the eld via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state.",method,2
10231,It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.,result,3
10232,"This paper presents Conflux, a fast, scalable and decentralized blockchain system that optimistically process concurrent blocks without discarding any as forks.",background,0
10233,The Conflux consensus protocol represents relationships between blocks as a direct acyclic graph and achieves consensus on a total order of the blocks.,background,0
10234,"Conflux then, from the block order, deterministically derives a transaction total order as the blockchain ledger.",method,2
10235,We evaluated Conflux on Amazon EC2 clusters with up to 20k full nodes.,result,3
10236,Conflux achieves a transaction throughput of 5.76GB/h while confirming transactions in 4.5-7.4 minutes.,result,3
10237,The throughput is equivalent to 6400 transactions per second for typical Bitcoin transactions.,result,3
10238,"Our results also indicate that when running Conflux, the consensus protocol is no longer the throughput bottleneck.",result,3
10239,The bottleneck is instead at the processing capability of individual nodes.,result,3
10240,"In recent years, theoretical and computational linguistics has paid much attention to linguistic items that form scales.",background,0
10241,"In NLP, much research has focused on ordering adjectives by intensity (tiny < small).",background,0
10242,"Here, we address the task of automatically ordering English adverbs by their intensifying or diminishing effect on adjectives (e.g. extremely small < very small).",objective,1
10243,We experiment with 4 different methods: 1) using the association strength between adverbs and adjectives; 2) exploiting scalar patterns (such as not only X but Y); 3) using the metadata of product reviews; 4) clustering.,method,2
10244,The method that performs best is based on the use of metadata and ranks adverbs by their scaling factor relative to unmodified adjectives.,result,3
10245,"Twitter as a new form of social media can potentially contain much useful information, but content analysis on Twitter has not been well studied.",background,0
10246,"In particular, it is not clear whether as an information source Twitter can be simply regarded as a faster news feed that covers mostly the same information as traditional news media.",background,0
10247,"In This paper we empirically compare the content of Twitter with a traditional news medium, New York Times, using unsupervised topic modeling.",method,2
10248,We use a Twitter-LDA model to discover topics from a representative sample of the entire Twitter.,method,2
10249,"We then use text mining techniques to compare these Twitter topics with topics from New York Times, taking into consideration topic categories and types.",method,2
10250,We also study the relation between the proportions of opinionated tweets and retweets and topic categories and types.,method,2
10251,Our comparisons show interesting and useful findings for downstream IR or DM applications.,result,3
10252,The purpose of this article is to develop a design theory of blended learning curriculum in ways of establishing a model for designing such a curriculum and a model for designing an activity in a blended learning curriculum as well as demonstrating how these models can be utilized in a curriculum design.,objective,1
10253,It first attempts to define what the essence of blended learning is by drawing on definitions of previous studies.,method,2
10254,"Then, it goes on to identify the characteristics and rationales of blended learning.",method,2
10255,"Finally, it exemplifies the devised BLC activity model, which is supported by the BLC design model and the BLC process model.",result,3
10256,The Bitcoin cryptocurrency records its transactions in a public log called the blockchain.,background,0
10257,"Its security rests critically on the distributed protocol that maintains the blockchain, run by participants called miners.",background,0
10258,"Conventional wisdom asserts that the mining protocol is incentive-compatible and secure against colluding minority groups, that is, it incentivizes miners to follow the protocol as prescribed.",background,0
10259,We show that the Bitcoin mining protocol is not incentive-compatible.,background,0
10260,We present an attack with which colluding miners' revenue is larger than their fair share.,method,2
10261,"The attack can have significant consequences for Bitcoin: Rational miners will prefer to join the attackers, and the colluding group will increase in size until it becomes a majority.",method,2
10262,"At this point, the Bitcoin system ceases to be a decentralized currency.",result,3
10263,"Unless certain assumptions are made, selfish mining may be feasible for any coalition size of colluding miners.",method,2
10264,We propose a practical modification to the Bitcoin protocol that protects Bitcoin in the general case.,method,2
10265,It prohibits selfish mining by a coalition that command less than 1/4 of the resources.,result,3
10266,"Gate current in metal–oxide–semiconductor (MOS) devices, caused by carriers tunneling through a classically forbidden energy barrier, is studied in this paper.",objective,1
10267,"The physical mechanisms of tunneling in an MOS structure are reviewed, along with the particularities of tunneling in modern MOS transistors, including effects such as direct tunneling, polysilicon depletion, hole tunneling and valence band tunneling and gate current partitioning.",method,2
10268,The modeling approach to gate current used in several compact MOS models is presented and compared.,method,2
10269,"Also, some of the effects of this gate current in the performance of digital, analog and RF circuits is discussed, and it is shown how new effects and considerations will come into play when designing circuits that use MOSFETs with ultra-thin oxides.",method,2
10270,2006 Published by Elsevier Ltd.,other,4
10271,Information technology practitioners are required to make calls of judgement in both a technical and a professional capacity.,background,0
10272,Professional codes of conduct and codes of ethics are intended to provide guidance in making such calls of judgement.,background,0
10273,This paper looks at the Australian Computer Society code of ethics in the light of the information technology strategies employed by the Australian telecommunications company One.,method,2
10274,Tel Limited.,result,3
10275,"The failure of the company can be seen at least partly as an information systems failure, in particular the failure of its billing system, and we examine where IT practice at One.",result,3
10276,Tel might have deviated from the ACS code of ethics and discuss issues concerning this deviance.,result,3
10277,"We present Fashion-MNIST, a new dataset comprising of 28 × 28 grayscale images of 70, 000 fashion products from 10 categories, with 7, 000 images per category.",objective,1
10278,"The training set has 60, 000 images and the test set has 10, 000 images.",background,0
10279,"Fashion-MNIST is intended to serve as a direct dropin replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits.",objective,1
10280,The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist.,result,3
10281,This article describes MATLAB/Simulink realization of open-circuit and short-circuit tests of transformers that are performed to identify equivalent circuit parameters.,background,0
10283,"The proposed tests have been successfully integrated into electric machinery courses at Drexel University, Philadelphia, PA and Nigde University, Nigde, Turkey.",background,0
10284,"2006 Wiley Periodicals, Inc. Comput Appl Eng Educ 14: 142 150, 2006; Published online in Wiley InterScience (www.interscience.wiley.com); DOI 10.1002/cae.20077",result,3
10285,Stock market or equity market have a profound impact in today's economy.,background,0
10286,A rise or fall in the share price has an important role in determining the investor's gain.,background,0
10287,"The existing forecasting methods make use of both linear (AR, MA, ARIMA) and non-linear algorithms (ARCH, GARCH, Neural Networks), but they focus on predicting the stock index movement or price forecasting for a single company using the daily closing price.",method,2
10288,The proposed method is a model independent approach.,method,2
10289,"Here we are not fitting the data to a specific model, rather we are identifying the latent dynamics existing in the data using deep learning architectures.",method,2
10290,In this work we use three different deep learning architectures for the price prediction of NSE listed companies and compares their performance.,method,2
10291,We are applying a sliding window approach for predicting future values on a short term basis.,method,2
10292,The performance of the models were quantified using percentage error.,objective,1
10293,"A technique for syntactic error correction, called pattern mapping, is developed.",background,0
10294,A pattern is used to describe how to map or change one string into another.,method,2
10295,"Using a preconstructed list of patterns, for each detected error, the first pattern with successful mapping is found and a correction is made based on this pattern.",result,3
10296,"Business models that rely on social media and user-generated content have shifted from the more traditional business model, where value for the organization is derived from the one-way delivery of products and/or services, to the provision of intangible value based on user engagement.",background,0
10297,"This research builds a model that hypothesizes that the user experiences from social interactions among users, operationalized as personalization, transparency, access to social resources, critical mass of social acquaintances, and risk, as well as with the technical features of the social media platform, operationalized as the completeness, flexibility, integration, and evolvability, influence user engagement and subsequent usage behavior.",objective,1
10298,"Using survey responses from 408 social media users, findings suggest that both social and technical factors impact user engagement and ultimately usage with additional direct impacts on usage by perceptions of the critical mass of social acquaintances and risk.",method,2
10299,"KEywORdS Social Interactions, Social Media, Social Networking, Technical Features, Use, User Engagement, User Experience",result,3
10300,"In recent years, communication in public social media increasingly affected enterprises.",background,0
10301,"Internet users began to share information about products, brands, and companies.",background,0
10302,Research currently focuses on investigating this form of communication by using quantitative methods in order to get a better understanding of it and of its relevance for companies and society.,objective,1
10303,"However, little is known about how enterprises themselves spread information in social media and how stakeholders talk about brands and products.",background,0
10304,"In our work, we investigate communication genres directed from stakeholderto-stakeholder, from business-to-stakeholder, and from stakeholder-to-business.",result,3
10305,"By doing this, we were able to broadly analyze the content of communication in social media.",result,3
10306,"In our research, we focus on the company adidas, an international manufacturer of sports clothes.",result,3
10307,We concentrate on the awareness aspect and adapted a theoretical model in order to evaluate companyrelated communication in Twitter.,method,2
10308,"Our case study includes 289,513 tweets which were collected on 60 consecutive days.",result,3
10309,"In order to identify genres and to answer the research questions, we manually analyzed 500 randomly chosen tweets as well as all those tweets published by official corporate accounts.",result,3
10310,This article surveys the current state of security issues and available defense mechanisms regarding popular online social networks.,background,0
10311,"It covers a wide variety of attacks and the corresponding defense mechanisms, if available.",background,0
10312,"The authors organize these attacks into four categories - privacy breaches, viral marketing, network structural attacks, and malware attacks - and focus primarily on privacy concerns.",method,2
10313,They offer an in-depth discussion of each category and analyze the connections among the different security issues involved.,result,3
10314,"Summarization based on text extraction is inherently limited, but generation-style abstractive methods have proven challenging to build.",background,0
10315,"In this work, we propose a fully data-driven approach to abstractive sentence summarization.",objective,1
10316,Our method utilizes a local attention-based model that generates each word of the summary conditioned on the input sentence.,method,2
10317,"While the model is structurally simple, it can easily be trained end-to-end and scales to a large amount of training data.",result,3
10318,The model shows significant performance gains on the DUC-2004 shared task compared with several strong baselines.,result,3
10319,The ever increasing gap between processor and memory speeds on one side and disk systems on the other side has exposed the I/O subsystems as a bottleneck for the applications with intensive I/O requirements.,background,0
10320,"Consequently, file systems, as low-level managers of storage resources, have to offer flexible and efficient services in order to allow a high utilization of disks.",background,0
10321,A storage device is typically seen by users as a contiguous linear space that can be accessed in blocks of fixed length.,background,0
10322,"It is obvious that this simple uniform interface can not address the requirements of complex multi-user, multi-process or distributed environments.",background,0
10323,"Therefore, file systems have been created as a layer of software that implements a more sophisticated disk management.",background,0
10324,The most important tasks of file systems are:,other,4
10325,Supply Chain Risk Management has increasingly becoming a more popular research area recently.,background,0
10326,"Various papers, with different focus and approaches, have been published.",background,0
10327,This paper aims to survey supply chain risk management (SCRM) literature.,objective,1
10328,"Paper published in relevant journals from 2000 to 2006 will be analyzed and classified into five categories: conceptual, descriptive, empirical, exploratory cross-sectional, and exploratory longitudinal.",method,2
10329,The literature review will provide the basis for outlining future research opportunities in this field.,background,0
10330,"In response to rapid change and fierce competition, creativity is an imperative factor to develop and implement innovation.",background,0
10331,"Hence, most firms have pursued diverse strategies to promote individual and team creativity in the workplace.",background,0
10332,"Shared leadership is a voluntarily, informally emergent structure beyond vertical leadership.",background,0
10333,"A team is composed of individual members, and shared leadership and demographic diversity exist within the team, influencing team creativity.",background,0
10334,"In this respect, we introduced shared leadership as a social network perspective as well as diversity into a team creativity model.",method,2
10335,"In sum, we examined the influence of shared leadership and diversity on knowledge sharing and the subsequent effects on team creativity.",result,3
10336,"Our results showed that role diversity directly influences team creativity, with shared leadership and knowledge sharing positively contributing to team creativity.",result,3
10337,"Thus, knowledge sharing had a partially mediating role between shared leadership and team creativity.",result,3
10338,"Apart from our hypotheses, the present results implied that if gender diversity (as a differentiated factor) is not a minority status, knowledge sharing may have a fully mediating effect between gender diversity and team creativity.",result,3
10340,"While “big data” has become a highlighted buzzword since last year, “big data mining”, i.e., mining from big data, has almost immediately followed up as an emerging, interrelated research area.",background,0
10341,This paper provides an overview of big data mining and discusses the related challenges and the new opportunities.,background,0
10342,The discussion includes a review of state-of-the-art frameworks and platforms for processing and managing big data as well as the efforts expected on big data mining.,method,2
10343,"We address broad issues related to big data and/or big data mining, and point out opportunities and research topics as they shall duly flesh out.",method,2
10344,We hope our effort will help reshape the subject area of today’s data mining technology toward solving tomorrow’s bigger challenges emerging in accordance with big data.,result,3
10345,"Since the Software Engineering Institute has launch ed the Capability Maturity Model almost twenty years ago, hundreds of maturity models have been pr oposed by researchers and practitioners across multiple application domains.",background,0
10346,"With process orientat ion being a central paradigm of organizational design and continuous process improvement taking to p positions on CIO agendas, maturity models are also prospering in business process management.",background,0
10347,"Although the application of maturity models is increasing in quantity and breadth, the concept of maturity models is frequently subject to criticism.",background,0
10348,"Indeed, numerous shortcomings have been disclosed r ef rring to both maturity models as design products and the process of maturity model design.",background,0
10349,"Whereas research has already substantiated the design process, there is no holistic understanding of the principles of form and function – that is, t he design principles – maturity models should meet.",background,0
10350,"We therefore propose a pragmatic, yet well-founded framework of general design principles justified by existing literature and grouped according to typical purposes of use.",objective,1
10351,The framework is demonstrated using an exemplary set of maturity models related to business process management.,method,2
10352,We finally give a b rief outlook on implications and topics for further research.,result,3
10353,We present and discuss several novel applications of deep learning for the physical layer.,background,0
10354,"By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process.",objective,1
10355,We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model.,method,2
10356,"Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features.",result,3
10357,This paper is concluded with a discussion of open challenges and areas for future investigation.,result,3
10358,"Programming is more than just coding, for, it exposes students to computational thinking which involves problem-solving using computer science concepts like abstraction and decomposition.",background,0
10359,"Even for non-computing majors, computational thinking is applicable and useful in their daily lives.",background,0
10360,"The three dimensions of computational thinking are computational concepts, computational practices and computational perspectives.",background,0
10361,"In recent years, the availability of free and user-friendly programming languages has fuelled the interest of researchers and educators to explore how computational thinking can be introduced in K-12 contexts.",objective,1
10362,"Through an analysis of 27 available intervention studies, this paper presents the current trends of empirical research in the development of computational thinking through programming and suggests possible research and instructional implications.",objective,1
10363,"From the review, we propose that more K-12 intervention studies centering on computational practices and computational perspectives could be conducted in the regular classroom.",method,2
10364,"To better examine these two dimensions, students could be asked to verbalize their thought process using think aloud protocol while programming and their on-screen programming activity could be captured and analyzed.",method,2
10365,Predetermined categories based on both past and recent programming studies could be used to guide the analysis of the qualitative data.,result,3
10366,"As for the instructional implication, it is proposed that a constructionism-based problem-solving learning environment, with information processing, scaffolding and reflection activities, could be designed to foster computational practices and computational perspectives.",result,3
10368,"Double dispatch is the ability of selecting dynamically a method not only according to the run-time type of the receiver (single dispatch), but also to the run-time type of the argument.",background,0
10369,"This mechanism unleashes the power of dynamic binding in object-oriented languages, so enhancing re-usability and separation of responsibilities.",objective,1
10370,"However, many mainstream languages, such as, e.g., C++ and Java, do not provide it, resorting to only single dispatch.",background,0
10371,In this paper we propose an extension of C++ (applicable also to other OO languages) that enables double dispatch as a language feature.,method,2
10372,This yields dynamic overloading and covariant specialization of methods.,background,0
10373,"We define a translation from the new constructs to standard C++ and we present the preprocessor implementing this translation, called doublecpp.",method,2
10374,"The translated code enjoys static type safety and implements the semantics of double dispatch by using only standard mechanisms of static overloading and dynamic binding, with minimal impact on the performance of the program.",method,2
10375,A new compensation technique known as tail compensation is applied to a two-stage CMOS operational amplifier.,background,0
10376,The compensation is established by a capacitor connected between the output node and the source node of the differential amplifier.,background,0
10377,"For the selected opamp topology, tail compensation allows better performance in terms of bandwidth and power supply rejection ratio (PSRR) when compared to Miller and cascode compensation.",background,0
10378,"Operational amplifiers using Miller, cascode and tail compensation were fabricated in a 0.5-μm 2P3M CMOS process.",method,2
10379,The circuits operate at a total quiescent current of 90 μA with ±1.5V power supplies.,method,2
10380,"Experimental results show that tail compensation increases the unity-gain frequency by 60% and 25% and improves PSRR from the positive rail by 22 dB and 26 dB over a frequency range from 23 kHz to 3.0 MHz compared to Miller and cascode compensation, respectively.",result,3
10381,"In this paper, we provide an introduction to machine learning tasks that address important problems in genomic medicine.",objective,1
10382,"One of the goals of genomic medicine is to determine how variations in the DNA of individuals can affect the risk of different diseases, and to find causal explanations so that targeted therapies can be designed.",objective,1
10383,"Here we focus on how machine learning can help to model the relationship between DNA and the quantities of key molecules in the cell, with the premise that these quantities, which we refer to as cell variables, may be associated with disease risks.",objective,1
10384,"Modern biology allows high-throughput measurement of many such cell variables, including gene expression, splicing, and proteins binding to nucleic acids, which can all be treated as training targets for predictive models.",method,2
10385,"With the growing availability of large-scale data sets and advanced computational techniques such as deep learning, researchers can help to usher in a new era of effective genomic medicine.",other,4
10386,We explore using Convolutional Neural Networks (CNNs) for a small-footprint keyword spotting (KWS) task.,background,0
10387,CNNs are attractive for KWS since they have been shown to outperform DNNs with far fewer parameters.,objective,1
10388,"We consider two different applications in our work, one where we limit the number of multiplications of the KWS system, and another where we limit the number of parameters.",result,3
10389,We present new CNN architectures to address the constraints of each applications.,method,2
10390,"We find that the CNN architectures offer between a 27-44% relative improvement in false reject rate compared to a DNN, while fitting into the constraints of each application.",result,3
10391,Information technology applications that support decision-making processes and problem-solving activities have proliferated and evolved.,background,0
10392,Distributing used cars to various automobile auctions is a complicated problem with multiple variables.,background,0
10393,We developed a software system to address these complexities and implemented it on a real distribution problem for a large car manufacturer.,result,3
10394,"The system detects data trends in a dynamic environment, incorporates optimization modules to recommend a near-optimum decision, and includes self-learning modules to improve future recommendations.",method,2
10395,"A software system that combines prediction, optimization, and adaptation techniques has generated impressive profits for a large auto manufacturer.",result,3
10396,Cryptographic standards serve two important goals: making different implementations interoperable and avoiding various known pitfalls in commonly used schemes.,objective,1
10397,This chapter discusses Public-Key Cryptography Standards (PKCS) which have significant impact on the use of public key cryptography in practice.,objective,1
10398,"PKCS standards are a set of standards, called PKCS #1 through #15.",method,2
10399,"These standards cover RSA encryption, RSA signature, password-based encryption, cryptographic message syntax, private-key information syntax, selected object classes and attribute types, certification request syntax, cryptographic token interface, personal information exchange syntax, and cryptographic token information syntax.",method,2
10400,The PKCS standards are published by RSA Laboratories.,background,0
10401,"Though RSA Laboratories solicits public opinions and advice for PKCS standards, RSA Laboratories retain sole decision-making authority on all aspects of PKCS standards.",result,3
10402,PKCS has been the basis for many other standards such as S/MIME.,other,4
10403,"Steganography involves hiding of text, image or any sensitive information inside another image, video or audio in such a way that an attacker will not be able to detect its presence.",background,0
10404,"Steganography is, many times, confused with cryptography as both the techniques are used to secure information.",background,0
10405,"The difference lies in the fact that steganography hides the data so that nothing appears out of ordinary while cryptography encrypts the text, making it difficult for an outsider to infer anything from it even if they do attain the encrypted text.",background,0
10406,Both of them are combined to increase the security against various malicious attacks.,objective,1
10407,Image Steganography uses an image as the cover media to hide the secret message.,result,3
10408,"In this paper, we propose an image steganography method which clusters the image into various segments and hides data in each of the segment.",objective,1
10409,Various clustering algorithms can be used for image segmentation.,method,2
10410,"Segmentation involves huge set of data in the form of pixels, where each pixel further has three components namely red, green and blue.",method,2
10411,K-means clustering technique is used to get accurate results.,method,2
10412,"Therefore, we use K-means clustering technique to get accurate results in a small time period.",result,3
10413,Recent years have seen a major push for face recognition technology due to the large expansion of image sharing on social networks.,background,0
10414,"In this paper, we consider the difficult task of determining parent-offspring resemblance using deep learning to answer the question ""Who do I look like?""",background,0
10415,"Although humans can perform this job at a rate higher than chance, it is not clear how they do it [2].",background,0
10416,"However, recent studies in anthropology [24] have determined which features tend to be the most discriminative.",background,0
10417,"In this study, we aim to not only create an accurate system for resemblance detection, but bridge the gap between studies in anthropology with computer vision techniques.",objective,1
10418,"Further, we aim to answer two key questions: 1) Do offspring resemble their parents?",objective,1
10419,and 2) Do offspring resemble one parent more than the other?,objective,1
10420,"We propose an algorithm that fuses the features and metrics discovered via gated autoencoders with a discriminative neural network layer that learns the optimal, or what we call genetic, features to delineate parent-offspring relationships.",method,2
10421,We further analyze the correlation between our automatically detected features and those found in anthropological studies.,method,2
10422,"Meanwhile, our method outperforms the state-of-the-art in kinship verification by 3-10% depending on the relationship using specific (father-son, mother-daughter, etc.) and generic models.",method,2
10423,"We consider the problem of learning from examples in layered linear feed-forward neural networks using optimization methods, such as back propagation, with respect to the usual quadratic error function E of the connection weights.",background,0
10424,Our main result is a complete description of the landscape attached to E in terms of principal component analysis.,result,3
10425,We show that E has a unique minimum corresponding to the projection onto the subspace generated by the first principal vectors of a covariance matrix associated with the training patterns.,result,3
10426,All the additional critical points of E are saddle points (corresponding to projections onto subspaces generated by higher order vectors).,method,2
10427,The auto-associative case is examined in detail.,method,2
10428,Extensions and implications for the learning algorithms are discussed.,method,2
10429,"The backbone of the information age is digital information which may be searched, accessed, and transferred instantaneously.",background,0
10430,Therefore the digitization of paper documents is extremely interesting.,background,0
10431,"This chapter describes approaches for document structure recognition detecting the hierarchy of physical components in images of documents, such as pages, paragraphs, and figures, and transforms this into a hierarchy of logical components, such as titles, authors, and sections.",objective,1
10432,This structural information improves readability and is useful for indexing and retrieving information contained in documents.,method,2
10433,First we present a rule-based system segmenting the document image and estimating the logical role of these zones.,method,2
10434,It is extensively used for processing newspaper collections showing world-class performance.,method,2
10435,In the second part we introduce several machine learning approaches exploring large numbers of interrelated features.,method,2
10436,"They can be adapted to geometrical models of the document structure, which may be set up as a linear sequence or a general graph.",method,2
10437,These advanced models require far more computational resources but show a better performance than simpler alternatives and might be used in future.,result,3
10438,"Due to the high number and cost of interruptions at work, several approaches have been suggested to reduce this cost for knowledge workers.",background,0
10439,"These approaches predominantly focus either on a manual and physical indicator, such as headphones or a closed office door, or on the automatic measure of a worker's interruptibilty in combination with a computer-based indicator.",background,0
10440,Little is known about the combination of a physical indicator with an automatic interruptibility measure and its long-term impact in the workplace.,background,0
10441,"In our research, we developed the FlowLight, that combines a physical traffic-light like LED with an automatic interruptibility measure based on computer interaction data.",method,2
10442,"In a large-scale and long-term field study with 449 participants from 12 countries, we found, amongst other results, that the FlowLight reduced the interruptions of participants by 46%, increased their awareness on the potential disruptiveness of interruptions and most participants never stopped using it.",result,3
10443,This paper drew upon a recent book (Rethinking Education in the Age of Technology) to summarize a number of prospects and challenges arising from the appropriation of digital technology into learning and educational practice.,background,0
10444,"Tensions between traditional models of schooling and the affordances of digital media were noted, while the promise of these technologies for shaping a new system of education was reviewed.",background,0
10445,It was argued that new technology brings radical opportunities but also significant challenges.,background,0
10446,The urgency of seeking a coherent model for the future of education in a technological age was stressed.,result,3
10447,"As we are moving towards the Internet of Things (IoT), the number of sensors deployed around the world is growing at a rapid pace.",background,0
10448,Market research has shown a significant growth of sensor deployments over the past decade and has predicted a significant increment of the growth rate in the future.,background,0
10449,These sensors continuously generate enormous amounts of data.,background,0
10450,"However, in order to add value to raw sensor data we need to understand it.",background,0
10451,"Collection, modelling, reasoning, and distribution of context in relation to sensor data plays critical role in this challenge.",background,0
10452,Context-aware computing has proven to be successful in understanding sensor data.,background,0
10453,"In this paper, we survey context awareness from an IoT perspective.",result,3
10454,We present the necessary background by introducing the IoT paradigm and context-aware fundamentals at the beginning.,method,2
10455,Then we provide an in-depth analysis of context life cycle.,method,2
10456,We evaluate a subset of projects (50) which represent the majority of research and commercial solutions proposed in the field of context-aware computing conducted over the last decade (2001-2011) based on our own taxonomy.,result,3
10457,Few prior works study deep learning on point sets.,background,0
10458,PointNet [20] is a pioneer in this direction.,background,0
10459,"However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes.",background,0
10460,"In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set.",objective,1
10461,"By exploiting metric space distances, our network is able to learn local features with increasing contextual scales.",method,2
10462,"With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales.",result,3
10463,Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly.,result,3
10464,"In particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds.",result,3
10465,"Default logic is one of the most prominent approaches to nonmonotonic reasoning, and allows one to make plausible conjectures when faced with incomplete information about the problem at hand.",background,0
10466,Default rules prevail in many application domains such as medical and legal reasoning.,method,2
10467,"Several variants have been developed over the past year, either to overcome some perceived deficiencies of the original presentation, or to realize somewhat different intuitions.",method,2
10468,This paper provides a tutorial-style introduction to some important approaches of Default Logic.,method,2
10469,"The presentation is based on operational models for these approaches, thus making them easily accessible to a broader audience, and more easily usable in practical applications.",method,2
10470,We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case.,background,0
10471,"After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection.",method,2
10472,"We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results.",background,0
10473,"The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.",result,3
10474,In this paper an eco-driving assistance system for reducing the energy consumption in electric vehcles is proposed.,background,0
10475,An accurate electric vehicle model is developed and an optimal control problem is formulated.,background,0
10476,The optimal control problem is solved based on dynamic programming.,method,2
10477,As a result an energy-optimal speed profile is obtained.,result,3
10478,This speed profile is displayed to the driver for eco-drving assistance.,result,3
10479,Experiments indicate that the speed profile can be tracked well by the driver and that the energy consumption can be reduced substantially.,result,3
10480,A momentum term is usually included in the simulations of connectionist learning algorithms.,background,0
10481,"Although it is well known that such a term greatly improves the speed of learning, there have been few rigorous studies of its mechanisms.",background,0
10482,"In this paper, I show that in the limit of continuous time, the momentum parameter is analogous to the mass of Newtonian particles that move through a viscous medium in a conservative force field.",method,2
10483,The behavior of the system near a local minimum is equivalent to a set of coupled and damped harmonic oscillators.,method,2
10484,The momentum term improves the speed of convergence by bringing some eigen components of the system closer to critical damping.,method,2
10485,Similar results can be obtained for the discrete time case used in computer simulations.,result,3
10486,"In particular, I derive the bounds for convergence on learning-rate and momentum parameters, and demonstrate that the momentum term can increase the range of learning rate over which the system converges.",result,3
10487,The optimal condition for convergence is also analyzed.,result,3
10488,"In this paper we consider a periodic review, reorder point, order-up-to-level system, a type commonly used in practice.",background,0
10489,"Motivated by a specific practical context, we present a novel approach to determining the reorder point and order-up-to-level (for a given review interval) so as to target desired values of i) customer fill rate and ii) average time between consecutive replenishments.",objective,1
10490,"Specifically, by using a diffusion model (producing normally distributed demand) we convert a periodic review, constant lead time setting into one having continuous review and a random lead time.",method,2
10491,The method is simple to implement and produces quite reasonable results.,method,2
10492,A robust adaptive control approach is proposed to solve the consensus problem of multiagent systems.,objective,1
10493,"Compared with the previous work, the agent's dynamics includes the uncertainties and external disturbances, which is more practical in real-world applications.",method,2
10494,"Due to the approximation capability of neural networks, the uncertain dynamics is compensated by the adaptive neural network scheme.",objective,1
10495,The effects of the approximation error and external disturbances are counteracted by employing the robustness signal.,method,2
10496,The proposed algorithm is decentralized because the controller for each agent only utilizes the information of its neighbor agents.,method,2
10497,"By the theoretical analysis, it is proved that the consensus error can be reduced as small as desired.",method,2
10498,"The proposed method is then extended to two cases: agents form a prescribed formation, and agents have the higher order dynamics.",result,3
10499,"Finally, simulation examples are given to demonstrate the satisfactory performance of the proposed method.",result,3
10500,We investigate the numerical approximation of the semiconductor Boltzmann transport equation using an expansion of the distribution function in spherical harmonics.,background,0
10501,"A complexity analysis shows that traditional implementations of higher order spherical harmonics expansions suffer from huge memory requirements, especially for two and three dimensional devices.",method,2
10502,"To overcome these complexity limitations, a compressed matrix storage scheme using Kronecker products is proposed, which reduces the memory requirements for the storage of the system matrix significantly.",method,2
10503,"Furthermore, the total memory requirements are asymptotically dominated only by the memory required for the unknowns.",method,2
10504,We discuss the increased importance of the selection of an appropriate linear solver and show that execution times for matrix-vector multiplications using the compressed matrix scheme are even smaller than those for an uncompressed system matrix.,method,2
10505,Numerical results demonstrate the applicability of our method and confirm our theoretical results.,result,3
10506,"This study investigated how celebrities' self-disclosure on personal social media accounts, particularly Twitter, affects fans' perceptions.",background,0
10507,An online survey was utilized among a sample of 429 celebrity followers on Twitter.,background,0
10508,"Results demonstrated that celebrities' professional self-disclosure (e.g., sharing their work-related life), personal self-disclosure (e.g., sharing their personal life such as friends and family), and fans' retweeting behavior, enhanced fans’ feeling of social presence, thereby positively affecting parasocial interaction with celebrities.",result,3
10509,"Further, the study found that the effects of self-disclosure and retweeting on parasocial interaction were mediated by social presence.",method,2
10510,Implications and future research directions are provided.,method,2
10511,© 2016 Elsevier Ltd.,other,4
10513,How can a machine learn from experience?,other,4
10514,"Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience.",method,2
10515,"The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence.",method,2
10516,"This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.",result,3
10517,The purpose of this study is to identify several areas of forensic interest within the Yahoo!,objective,1
10518,"Messenger application, which are of forensic significance.",objective,1
10519,This study focuses on new areas of interest within the file structure of Windows Vista and Windows 7.,objective,1
10520,One of the main issues with this topic is that little research has been previously conducted on the new Windows platforms.,background,0
10521,"Previously conducted research indicates the evidence found on older file structures, such as Windows XP, as well as outdated versions of Yahoo!",result,3
10522,Messenger.,other,4
10523,Several differences were found within the Yahoo Messenger’s registry keys and directory structure on Windows Vista and Windows 7 as compared to Windows XP.,result,3
10524,"This research analyses the suburban expansion in the metropolitan area of Tehran, Iran.",background,0
10525,"A hybrid model consisting of logistic regression model, Markov chain (MC), and cellular automata (CA) was designed to improve the performance of the standard logistic regression model.",method,2
10526,"Environmental and socio-economic variables dealing with urban sprawl were operationalised to create a probability surface of spatiotemporal states of built-up land use for the years 2006, 2016, and 2026.",background,0
10527,"For validation, the model was evaluated by means of relative operating characteristic values for different sets of variables.",method,2
10528,The approach was arkov chain ellular automata ehran calibrated for 2006 by cross comparing of actual and simulated land use maps.,method,2
10529,"The achieved outcomes represent a match of 89% between simulated and actual maps of 2006, which was satisfactory to approve the calibration process.",result,3
10530,"Thereafter, the calibrated hybrid approach was implemented for forthcoming years.",result,3
10531,"Finally, future land use maps for 2016 and 2026 were predicted by means of this hybrid approach.",background,0
10532,The simulated maps illustrate a new wave of suburban development in the vicinity of Tehran at the tropo western border of the me,result,3
10533,Five years of experimenting with Personal Health Records has not yielded the results that big companies like Google and Microsoft expected.,background,0
10534,"Whereas Google pulled the plug on its product offering, Microsoft struggles to reach sufficient critical mass.",background,0
10535,"This study adopts a user perspective (51 interviews) in conjunction with grounded theory, to offer explanations why Google Health failed and predictions relative to Microsoft's ability to reach a tipping point with respect to product/service viability.",background,0
10536,"Noteworthy, vendors ignore relevance, or perceived usefulness when designing PHRs.",background,0
10537,"Moreover, low trust and high risks do not bode well for long-term success, with the widely used information systems success models often neglecting the latter two critical dimensions.",result,3
10538,"This study is designed to determine the most important project management core competencies, including both hard skills and soft skills.",background,0
10539,"The study determines the importance of these competencies to job success, and the current performance of project managers with respect to these core competencies.",background,0
10540,The gaps between importance and performance represent opportunities for professional development courses and programs.,method,2
10541,It is not—unless it triggers feelings of envy.,background,0
10542,This study uses the framework of social rank theory of depression and conceptualizes Facebook envy as a possible link between Facebook surveillance use and depression among college students.,method,2
10543,"Using a survey of 736 college students, we found that the effect of surveillance use of Facebook on depression is mediated by Facebook envy.",method,2
10544,"However, when Facebook envy is controlled for, Facebook use actually lessens depression.",result,3
10545,2014 Elsevier Ltd.,other,4
10547,The paper deals with trajectory tracking of the differential drive robot with a mathematical model governing dynamics and kinematics.,background,0
10548,Motor dynamics and chassis dynamics are considered for deriving a linear state-space dynamic model.,objective,1
10549,Basic nonlinear kinematic equations are linearized into a successively linearized state-space model.,objective,1
10550,The dynamic and kinematic models are augmented to derive a single state-space linear model.,background,0
10551,The deviation variables are reference variables which are variables of an ideal robot following a reference trajectory which can be pre-calculated.,method,2
10552,Reference tracking is achieved by model predictive control of supply voltage of both the drive motors by considering constraints on controlled variables and manipulated variables.,method,2
10553,Simulation results are provided to demonstrate the performance of proposed control strategy in the MATLAB simulation environment.,result,3
10554,"This paper presents a method of learning qualitatively interpretable models in object detection using popular two-stage region-based ConvNet detection systems (i.e., R-CNN) [22, 61, 9, 26].",background,0
10555,R-CNN consists of a region proposal network and a RoI (Region-of-Interest) prediction network.,background,0
10556,"By interpretable models, we focus on weaklysupervised extractive rationale generation, that is learning to unfold latent discriminative part configurations of object instances automatically and simultaneously in detection without using any supervision for part configurations.",objective,1
10557,We utilize a top-down hierarchical and compositional grammar model embedded in a directed acyclic AND-OR Graph (AOG) to explore and unfold the space of latent part configurations of RoIs.,method,2
10558,"We propose an AOGParsing operator to substitute the RoIPooling operator widely used in RCNN, so the proposed method is applicable to many stateof-the-art ConvNet based detection systems.",method,2
10559,The AOGParsing operator aims to harness both the explainable rigor of top-down hierarchical and compositional grammar models and the discriminative power of bottom-up deep neural networks through end-to-end training.,method,2
10560,"In detection, a bounding box is interpreted by the best parse tree derived from the AOG on-the-fly, which is treated as the extractive rationale generated for interpreting detection.",result,3
10561,"In learning, we propose a folding-unfolding method to train the AOG and ConvNet end-to-end.",result,3
10562,"In experiments, we build on top of the R-FCN [9] and test the proposed method on the PASCAL VOC 2007 and 2012 datasets with performance comparable to state-of-the-art methods.",result,3
10563,Multi-objective formulations are realistic models for many complex engineering optimization problems.,background,0
10564,"In many real-life problems, objectives under consideration conflict with each other, and optimizing a particular solution with respect to a single objective can result in unacceptable results with respect to the other objectives.",background,0
10565,"A reasonable solution to a multi-objective problem is to investigate a set of solutions, each of which satisfies the objectives at an acceptable level without being dominated by any other solution.",background,0
10566,"In this paper, an overview and tutorial is presented describing genetic algorithms (GA) developed specifically for problems with multiple objectives.",objective,1
10567,They differ primarily from traditional GA by using specialized fitness functions and introducing methods to promote solution diversity.,method,2
10568,r 2005 Elsevier Ltd.,other,4
10570,"In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest.",background,0
10571,"To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact.",background,0
10572,We explore the relation between optimal feature subset selection and relevance.,objective,1
10573,Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain.,method,2
10574,We study the strengths and weaknesses of the wrapper approach and show a series of improved designs.,method,2
10575,"We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection.",method,2
10576,Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.,result,3
10577,@ 1997 Elsevier Science B.V.,other,4
10578,Augmented reality (AR) as an emerging technology in the mobile computing domain is becoming mature enough to engender publicly available applications for end users.,background,0
10579,"Various commercial applications have recently been emerging in the mobile consumer domain at an increasing pace — Layar, Junaio, Google Goggles, and Wikitude are perhaps the most prominent ones.",background,0
10580,"However, the research community lacks an understanding of how well such timely applications have been accepted, what kind of user experiences they have evoked, and what the users perceive as the weaknesses of the various applications overall.",background,0
10581,During the spring of 2011 we conducted an online survey to study the overall acceptance and user experience of the mobile AR-like consumer applications currently existing on the market.,method,2
10582,This paper reports the first analyses of the qualitative and quantitative survey data of 90 respondents.,method,2
10583,"We highlight an extensive set of user-oriented issues to be considered in developing the applications further, as well as in directing future user research in AR.",result,3
10584,"The results indicate that the experiences have been inconsistent: generally positive evaluations are overshadowed by mentions of applications' pragmatic uselessness in everyday life and technical unreliability, as well as excessive or limited and irrelevant content.",result,3
10585,Assessing the relatedness of documents is at the core of many applications such as document retrieval and recommendation.,background,0
10586,"Most similarity approaches operate on word-distribution-based document representations fast to compute, but problematic when documents differ in language, vocabulary or type, and neglecting the rich relational knowledge available in Knowledge Graphs.",background,0
10587,"In contrast, graph-based document models can leverage valuable knowledge about relations between entities however, due to expensive graph operations, similarity assessments tend to become infeasible in many applications.",background,0
10588,This paper presents an efficient semantic similarity approach exploiting explicit hierarchical and transversal relations.,method,2
10589,"We show in our experiments that (i) our similarity measure provides a significantly higher correlation with human notions of document similarity than comparable measures, (ii) this also holds for short documents with few annotations, (iii) document similarity can be calculated efficiently compared to other graph-traversal based approaches.",method,2
10590,"Leveraging large historical data in electronic health record (EHR), we developed Doctor AI, a generic predictive model that covers observed medical conditions and medication uses.",background,0
10591,Doctor AI is a temporal model using recurrent neural networks (RNN) and was developed and applied to longitudinal time stamped EHR data from 260K patients over 8 years.,method,2
10592,"Encounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to RNN to predict (all) the diagnosis and medication categories for a subsequent visit.",method,2
10593,Doctor AI assesses the history of patients to make multilabel predictions (one label for each diagnosis or medication category).,method,2
10594,"Based on separate blind test set evaluation, Doctor AI can perform differential diagnosis with up to 79% recall@30, significantly higher than several baselines.",method,2
10595,"Moreover, we demonstrate great generalizability of Doctor AI by adapting the resulting models from one institution to another without losing substantial accuracy.",result,3
10596,"The problem of arbitrary object tracking has traditionally been tackled by learning a model of the object’s appearance exclusively online, using as sole training data the video itself.",background,0
10597,"Despite the success of these methods, their online-only approach inherently limits the richness of the model they can learn.",background,0
10598,"Recently, several attempts have been made to exploit the expressive power of deep convolutional networks.",background,0
10599,"However, when the object to track is not known beforehand, it is necessary to perform Stochastic Gradient Descent online to adapt the weights of the network, severely compromising the speed of the system.",background,0
10600,In this paper we equip a basic tracking algorithm with a novel fully-convolutional Siamese network trained end-to-end on the ILSVRC15 dataset for object detection in video.,result,3
10601,"Our tracker operates at frame-rates beyond real-time and, despite its extreme simplicity, achieves state-of-the-art performance in multiple benchmarks.",result,3
10602,"In this paper, we discuss the method of Bayesian regression and its efficacy for predicting price variation of Bitcoin, a recently popularized virtual, cryptographic currency.",background,0
10603,Bayesian regression refers to utilizing empirical data as proxy to perform Bayesian inference.,background,0
10604,We utilize Bayesian regression for the so-called “latent source model”.,method,2
10605,"The Bayesian regression for “latent source model” was introduced and discussed by Chen, Nikolov and Shah [1] and Bresler, Chen and Shah [2] for the purpose of binary classification.",method,2
10606,They established theoretical as well as empirical efficacy of the method for the setting of binary classification.,method,2
10607,"In this paper, instead we utilize it for predicting real-valued quantity, the price of Bitcoin.",result,3
10608,"Based on this price prediction method, we devise a simple strategy for trading Bitcoin.",result,3
10609,The strategy is able to nearly double the investment in less than 60 day period when run against real data trace.,result,3
10610,The Raven’s Progressive Matrices (RPM) test is a commonly used test of general human intelligence.,background,0
10611,"The RPM is somewhat unique as a general intelligence test in that it focuses on visual problem solving, and in particular, on visual similarity and analogy.",background,0
10612,"We are developing a small set of methods for problem solving in the RPM which use propositional, imagistic, and multimodal representations, respectively, to investigate how different representations can contribute to visual problem solving and how the effects of their use might emerge in behavior.",method,2
10613,Time series is an important class of temporal data objects and it can be easily obtained from scientific and financial applications.,background,0
10614,A time series is a collection of observations made chronologically.,background,0
10615,"The nature of time series data includes: large in data size, high dimensionality and necessary to update continuously.",background,0
10616,"Moreover time series data, which is characterized by its numerical and continuous nature, is always considered as a whole instead of individual numerical field.",background,0
10617,The increasing use of time series data has initiated a great deal of research and development attempts in the field of data mining.,background,0
10618,"The abundant research on time series data mining in the last decade could hamper the entry of interested researchers, due to its complexity.",background,0
10619,"In this paper, a comprehensive revision on the existing time series data mining research is given.",objective,1
10620,"They are generally categorized into representation and indexing, similarity measure, segmentation, visualization and mining.",method,2
10621,Moreover state-of-the-art research issues are also highlighted.,method,2
10622,The primary objective of this paper is to serve as a glossary for interested researchers to have an overall picture on the current time series data mining development and identify their potential research direction to further investigation.,objective,1
10623,One of the most used methods to forecast price volatility is the generalized autoregressive conditional heteroskedasticity (GARCH) model.,background,0
10624,"Nonetheless, the errors in prediction using this approach are often quite high.",background,0
10625,"Hence, continued research is conducted to improve forecasting models employing a variety of techniques.",background,0
10626,"In this paper, we extend the field of expert systems, forecasting, and model by applying an Artificial Neural Network (ANN) to the GARCH method generating an ANN–GARCH.",method,2
10627,The hybrid ANN–GARCH model is applied to forecast the gold price volatility (spot and future).,method,2
10628,The results show an overall improvement in forecasting using the ANN–GARCH as compared to a GARCH method alone.,result,3
10629,An overall reduction of 25% in the mean average percent error was realized using the ANN–GARCH.,result,3
10630,"The results are realized using the Euro/Dollar and Yen/Dollar exchange rates, the DJI and FTSE stock market indexes, and the oil price return as inputs.",result,3
10631,We discuss the implications of the study within the context of the discipline as well as practical applications.,result,3
10632,2015 Elsevier Ltd.,other,4
10633,Malware programs that incorporate trigger-based behavior initiate malicious activities based on conditions satisfied only by specific inputs.,background,0
10634,"State-of-the-art malware analyzers discover code guarded by triggers via multiple path exploration, symbolic execution, or forced conditional execution, all without knowing the trigger inputs.",background,0
10635,We present a malware obfuscation technique that automatically conceals specific trigger-based behavior from these malware analyzers.,objective,1
10636,Our technique automatically transforms a program by encrypting code that is conditionally dependent on an input value with a key derived from the input and then removing the key from the program.,method,2
10637,We have implemented a compiler-level tool that takes a malware source program and automatically generates an obfuscated binary.,method,2
10638,Experiments on various existing malware samples show that our tool can hide a significant portion of trigger based code.,result,3
10639,"We provide insight into the strengths, weaknesses, and possible ways to strengthen current analysis approaches in order to defeat this malware obfuscation technique.",result,3
10640,Requirements engineering (RE) has attracted a great deal of attention from researchers and practitioners in recent years.,background,0
10641,Requirements engineering education (REE) is therefore an important undertaking if the field is to have professionals who are capable of successfully accomplishing software projects.,objective,1
10642,This increasing interest demands that academia should provide software engineering students with a solid foundation in the subject matter.,objective,1
10643,"This paper aims to identify and to present the current research on REE that is available at present, and to select useful approaches and needs for future research.",objective,1
10644,"A systematic mapping study was therefore performed to classify the selected studies into five classification criteria: research type, empirical type, contribution type, RE activity, and curricula.",method,2
10645,A total of 79 papers were selected and classified according to these criteria.,method,2
10646,"The results of this systematic mapping study are discussed, and a list of advice obtained from the REE literature for instructors is provided.",result,3
10647,Neural network models are capable of generating extremely natural sounding conversational interactions.,background,0
10648,"However, these models have been mostly applied to casual scenarios (e.g., as “chatbots”) and have yet to demonstrate they can serve in more useful conversational applications.",background,0
10649,"This paper presents a novel, fully data-driven, and knowledge-grounded neural conversation model aimed at producing more contentful responses.",background,0
10650,"We generalize the widely-used Sequence-toSequence (SEQ2SEQ) approach by conditioning responses on both conversation history and external “facts”, allowing the model to be versatile and applicable in an open-domain setting.",method,2
10651,Our approach yields significant improvements over a competitive SEQ2SEQ baseline.,method,2
10652,Human judges found that our outputs are significantly more informative.,result,3
10653,"Harmonic and cycloid drives are both compact, high ratio transmissions appropriate for use in anthropomorphic robots, although cycloid drives are rarely used in the field.",background,0
10654,This paper describes the design parameters for cycloid drives and shows the results of six cycloid models designed to match corresponding harmonic drives.,objective,1
10655,"Cycloid drive models were compared with manufacturing data from corresponding harmonic drives with respect to maximum gear ratio, transmission thickness, efficiency, backlash/gear ratio ripple, and reflected inertia.",method,2
10656,"Cycloid drive designs were found to be thinner, more efficient, and to have lower reflected inertia than corresponding harmonic drives.",method,2
10657,"However, the cycloid designs had larger gear ratio ripple and substantial backlash, and they could not meet the maximum gear ratio provided by the corresponding harmonic drives in two out of six models for equal applied torques.",method,2
10658,Two cycloid drives were manufactured to confirm efficiency predictions and demonstrated moderate to high efficiency across a range of output torques.,method,2
10659,Cycloid drives should be considered for robotic and prosthetic applications where smaller thickness/higher efficiency requirements dominate over low backlash/gear ratio ripple considerations.,result,3
10660,"Facial/voice-based authentication is becoming increasingly popular (e.g., already adopted by MasterCard and AliPay), because it is easy to use.",background,0
10661,"In particular, users can now authenticate themselves to online services by using their mobile phone to show themselves performing simple tasks like blinking or smiling in front of its built-in camera.",background,0
10662,Our study shows that many of the publicly available facial/voice recognition services (e.g. Microsoft Cognitive Services or Amazon Rekognition) are vulnerable to even the most primitive attacks.,background,0
10663,"Furthermore, recent work on modeling a person’s face/voice (e.g. Face2Face [1]) allows an adversary to create very authentic video/audio of any target victim to impersonate that target.",method,2
10664,"All it takes to launch such attacks are a few pictures and voice samples of a victim, which can all be obtained by either abusing the camera and microphone of the victim’s phone, or through the victim’s social media account.",method,2
10665,"In this work, we propose the Real Time Captcha (rtCaptcha) system, which stops/slows down such an attack by turning the adversary’s task from creating authentic video/audio of the target victim performing known authentication tasks (e.g., smile, blink) to figuring out what is the authentication task, which is encoded as a Captcha.",method,2
10666,"Specifically, when a user tries to authenticate using rtCaptcha, they will be presented a Captcha and will be asked to take a “selfie” video while announcing the answer to the Captcha.",method,2
10667,"As such, the security guarantee of our system comes from the strength of Captcha, and not how well we can distinguish real faces/voices from synthesized ones.",method,2
10668,"To demonstrate the usability and security of rtCaptcha, we conducted a user study to measure human response times to the most popular Captcha schemes.",method,2
10669,"Our experiments show that, thanks to the humans’ speed of solving Captchas, adversaries will have to solve Captchas in less than 2 seconds in order to appear live/human and defeat rtCaptcha, which is not possible for the best settings on the attack side.",result,3
10670,Biometric identification has become increasingly popular in recent years.,background,0
10671,"With the development of cloud computing, database owners are motivated to outsource the large size of biometric data and identification tasks to the cloud to get rid of the expensive storage and computation costs, which, however, brings potential threats to users’ privacy.",background,0
10672,"In this paper, we propose an efficient and privacy-preserving biometric identification outsourcing scheme.",objective,1
10673,"Specifically, the biometric To execute a biometric identification, the database owner encrypts the query data and submits it to the cloud.",method,2
10674,The cloud performs identification operations over the encrypted database and returns the result to the database owner.,method,2
10675,A thorough security analysis indicates that the proposed scheme is secure even if attackers can forge identification requests and collude with the cloud.,result,3
10676,"Compared with previous protocols, experimental results show that the proposed scheme achieves a better performance in both preparation and identification procedures.",result,3
10677,"This paper presents the construction of a multimodal dataset for deception detection, including physiological, thermal, and visual responses of human subjects under three deceptive scenarios.",background,0
10678,"We present the experimental protocol, as well as the data acquisition process.",method,2
10679,"To evaluate the usefulness of the dataset for the task of deception detection, we present a statistical analysis of the physiological and thermal modalities associated with the deceptive and truthful conditions.",method,2
10680,Initial results show that physiological and thermal responses can differentiate between deceptive and truthful states.,result,3
10681,The increasing influence of social media and enormous participation of users creates new opportunities to study human social behavior along with the capability to analyze large amount of data streams.,background,0
10682,"One of the interesting problems is to distinguish between different kinds of users, for example users who are leaders and introduce new issues and discussions on social media.",background,0
10683,"Furthermore, positive or negative attitudes can also be inferred from those discussions.",background,0
10684,Such problems require a formal interpretation of social media logs and unit of information that can spread from person to person through the social network.,background,0
10685,"Once the social media data such as user messages are parsed and network relationships are identified, data mining techniques can be applied to group different types of communities.",method,2
10686,"However, the appropriate granularity of user communities and their behavior is hardly captured by existing methods.",method,2
10687,"In this paper, we present a framework for the novel task of detecting communities by clustering messages from large streams of social data.",method,2
10688,Our framework uses K-Means clustering algorithm along with Genetic algorithm and Optimized Cluster Distance (OCD) method to cluster data.,method,2
10689,"The goal of our proposed framework is twofold that is to overcome the problem of general K-Means for choosing best initial centroids using Genetic algorithm, as well as to maximize the distance between clusters by pairwise clustering using OCD to get an accurate clusters.",objective,1
10690,We used various cluster validation metrics to evaluate the performance of our algorithm.,method,2
10691,Patent (on behalf of Nokia Siemens Networks),background,0
10692,"“An adaptive Mechanism for Dynamic Reconfiguration of Wireless Mesh to Conserve Power,” Sudhir Dixit and Suman Sarkar [Filed on October, 2007, Granted].",objective,1
10693,"“Cascaded Source-driven Node Wake-up and Routing in Wireless Mesh,” Sudhir Dixit and Suman Sarkar [Filed on October, 2007, pending].",method,2
10694,“,other,4
10695,"A method and Apparatus to Minimize Power/Battery Consumption in Wireless Mesh,” Suman Sarkar, et al. [Filed on November, 2007, pending].",method,2
10696,"As global virtual teams become more common, the need to better understand how groups composed of individuals from different cultural backgrounds perform has never been more pressing.",background,0
10697,This study compares groups from the same cultural background with groups from varied cultural backgrounds when they used two different communication media (face-to-face and an asynchronous conferencing system).,method,2
10698,"Data was collected on 46 groups, which included a total of 268 subjects representing 39 countries.",background,0
10699,Research questions regarding group process and consensus were addressed specifically as they relate to cross-cultural group work.,method,2
10700,"The results of this study suggest that distributed, asynchronous GSS may be effectively used by mixed cultural groups facing a value-based cognitive conflict (negotiation) task.",result,3
10701,Information theory is rapidly approaching its 70th birthday.,result,3
10702,What are promising future directions for research in information theory?,background,0
10703,Where will information theory be having the most impact in 10–20 years?,objective,1
10704,"What new and emerging areas are ripe for the most impact, of the sort that information theory has had on the telecommunications industry over the last 60 years?",result,3
10705,"How should the IEEE Information Theory Society promote high-risk new research directions and broaden the reach of information theory, while continuing to be true to its ideals and insisting on the intellectual rigor that makes its breakthroughs so powerful?",result,3
10706,These are some of the questions that an ad hoc committee (composed of the present authors) explored over the past two years.,objective,1
10707,"We have discussed and debated these questions, and solicited detailed inputs from experts in fields including genomics, biology, economics, and neuroscience.",method,2
10708,This report is the result of these discussions.,result,3
10709,The Internet of Things (IoT) is aimed at enabling the interconnection and integration of the physical world and the cyber space.,background,0
10710,"It represents the trend of future networking, and leads the third wave of the IT industry revolution.",background,0
10711,"In this article, we first introduce some background and related technologies of IoT and discuss the concepts and objectives of IoT. Then, we present the challenges and key scientific problems involved in IoT development.",objective,1
10712,"Moreover, we introduce the current research project supported by the National Basic Research Program of China (973 Program).",method,2
10713,"Finally, we outline future research directions.",result,3
10714,The goal of Risk Management activities is to define prevention and control mechanisms to address the risks attached to specify activities and valuable assets.,objective,1
10715,"Many Risk Management efforts operate in silos with narrowly focused, functionally driven, and disjointed activities.",background,0
10716,"That fact leads to a fragmented view of risks, where each activity uses its own language, customs and metrics.",objective,1
10717,"The lack of interconnection and holistic view of risks limits an organization-wide perception of risks, where interdependent risks are not anticipated, controlled or managed.",background,0
10718,"In order to address the Risk Management interoperability and standardization issues, this paper proposes an alignment between Risk Management, Governance and Enterprise Architecture activities, providing a systematic support to map and trace identified risks to enterprise artifacts modeled within the Enterprise Architecture, supporting the overall strategy of any organization.",objective,1
10719,We discuss the main relationships between Risk Management and Enterprise Architecture and propose an architecture to integrate risks concerns into the overall organization environment.,method,2
10720,"With the ever-increasing cost for healthcare and increased health insurance premiums, there is a need for proactive healthcare and wellness.",background,0
10721,"In addition, the new wave of digitizing medical records has seen a paradigm shift in the healthcare industry.",background,0
10722,"As a result, the healthcare industry is witnessing an increase in sheer volume of data in terms of complexity, diversity and timeliness.",background,0
10723,"As healthcare experts look for every possible way to lower costs while improving care process, delivery and management, big data emerges as a plausible solution with the promise to transform the healthcare industry.",background,0
10724,This paradigm shift from reactive to proactive healthcare can result in an overall decrease in healthcare costs and eventually lead to economic growth.,method,2
10725,"While the healthcare industry harnesses the power of big data, security and privacy issues are at the focal point as emerging threats and vulnerabilities continue to grow.",method,2
10726,"In this paper, we present the state-of-the-art security and privacy issues in big data as applied to healthcare industry.",result,3
10727,"Strategic alignment focuses on the activities that management performs to achieve cohesive goals across the IT (Information Technology) and other functional organizations (e.g., finance, marketing, H/R, manufacturing).",background,0
10728,"Therefore, alignment addresses both how IT is in harmony with the business, and how the business should, or could be in harmony with IT.",background,0
10729,Alignment evolves into a relationship where the function of IT and other business functions adapt their strategies together.,background,0
10730,Achieving alignment is evolutionary and dynamic.,result,3
10731,"It requires strong support from senior management, good working relationships, strong leadership, appropriate prioritization, trust, and effective communication, as well as a thorough understanding of the business and technical environments.",result,3
10732,Achieving and sustaining alignment demands focusing on maximizing the enablers and minimizing the inhibitors that cultivate alignment.,result,3
10733,The strategic alignment maturity assessment provides organizations with a vehicle to evaluate these activities.,method,2
10734,Knowing the maturity of its strategic choices and alignment practices make it possible for a firm to see where it stands and how it can improve.,method,2
10735,This paper discusses an approach for assessing the maturity of the business-IT alignment.,method,2
10736,"Once maturity is understood, an organization can identify opportunities for enhancing the harmonious relationship of business and IT.",result,3
10737,"In recent years, organizations have invested heavily in e-procurement technology solutions.",background,0
10738,"However, an estimation of the value of the technology-enabled procurement process is often lacking.",background,0
10739,Our paper presents a rigorous methodological approach to the analysis of e-procurement benefits.,objective,1
10740,Business process simulations are used to analyze the benefits of both technological and organizational changes related to e-procurement.,objective,1
10741,"The approach enables an estimation of both the average and variability of procurement costs and benefits, workload, and lead times.",objective,1
10742,"In addition, the approach enables optimization of a procurement strategy (e.g., approval levels).",objective,1
10743,"Finally, an innovative approach to estimation of value at risk is shown.",result,3
10744,"Much research has been done to understand the motivations of consumers to choose among online retailers and the retailer factors driving customer satisfaction (e.g., Kim et al. 2009; Kotha et al. 2004; Pan et al. 2002; Qu",background,0
10745,et al. 2008; Smith et al. 2000; Wolfinbarger and Gilly 2003).,other,4
10746,"Concentrating on e-tailing service quality, Wolfinbarger and Gilly (2003) argue that four factors—website design, fulfillment/reliability, privacy/security, and customer service—strongly predict customer satisfaction.",background,0
10747,"Kotha et al. (2004) study the role of online buying experience as a competitive advantage along five dimensions: website usability, customer confidence in the web business, the selection of goods and services on the site, the effectiveness of relationship services such as virtual community building and site personalization, and the extent of price leadership.",background,0
10748,"They conclude that website usability and product selection can be easily competed away via imitation, while superior customer service can lead to a sustainable competitive advantage.",result,3
10749,"Devaraj et al. (2002) find that the usefulness and ease-of-use of online shopping, together with high service quality, are factors affecting consumer satisfaction and, subsequently, their channel preference.",result,3
10750,Price can also play a role in customer satisfaction.,background,0
10751,"Because online stores are only a mouse click away, many studies have argued that price is an important factor in a customer’s decision-making process (Lee and Overby 2004).",background,0
10752,"Using BizRate data, Jiang and Rosenbloom (2005) find that after-delivery satisfaction and price perception have a stronger impact on customer satisfaction than at-checkout satisfaction.",result,3
10753,"Combining the aforementioned studies while integrating their similar dimensions, we review three retailer characteristics, namely website design, customer service, and pricing, and we provide theoretical background for this research.",result,3
10754,"Researchers have previously examined the technology acceptance model (TAM) in many contexts, including the Internet.",background,0
10755,More recently TAM has been enhanced to include a hedonic component of enjoyment but the effect has rarely been investigated in a mobile commerce context.,background,0
10756,"In addition, specific antecedents of TAM related to design aesthetics have not been examined within the mobile domain.",background,0
10757,"Our research filled these gaps, and discovered that visual design aesthetics did significantly impact perceived usefulness, ease of use, and enjoyment, all of which ultimately influenced users’ loyalty intentions towards a mobile service.",result,3
10758,# 2006 Elsevier B.V. All rights reserved.,other,4
10759,"Security and privacy are huge challenges in Internet of Things (IoT) environments, but unfortunately, the harmonization of the IoT-related standards and protocols is hardly and slowly widespread.",background,0
10760,"In this paper, we propose a new framework for access control in IoT based on the blockchain technology.",background,0
10761,"Our first contribution consists in providing a reference model for our proposed framework within the Objectives, Models, Architecture and Mechanism specification in IoT. In addition, we introduce FairAccess as a fully decentralized pseudonymous and privacy preserving authorization management framework that enables users to own and control their data.",objective,1
10762,"To implement our model, we use and adapt the blockchain into a decentralized access control manager.",method,2
10763,"Unlike financial bitcoin transactions, FairAccess introduces new types of transactions that are used to grant, get, delegate, and revoke access.",method,2
10764,"As a proof of concept, we establish an initial implementation with a Raspberry PI device and local blockchain.",method,2
10765,"Finally, we discuss some limitations and propose further opportunities.",result,3
10766,"Copyright © 2017 John Wiley & Sons, Ltd.",result,3
10767,Find loads of the can system engineering from theory to practical applications book catalogues in this site as the choice of you visiting this page.,background,0
10768,You can also join to the website book library that will show you numerous books from any types.,background,0
10769,"Literature, science, politics, and many more catalogues are presented to offer you the best book to find.",background,0
10770,The book that really makes you feels satisfied.,other,4
10771,Or that's the book that will save you from your job deadline.,other,4
10772,Fraud detection is of great importance to financial institutions.,background,0
10773,"This paper is concerned with the problem of finding outliers in time series financial data using Peer Group Analysis (PGA), which is an unsupervised technique for fraud detection.",objective,1
10774,"The objective of PGA is to characterize the expected pattern of behavior around the target sequence in terms of the behavior of similar objects, and then to detect any difference in evolution between the expected pattern and the target.",objective,1
10775,"The tool has been applied to the stock market data, which has been collected from Bangladesh Stock Exchange to assess its performance in stock fraud detection.",method,2
10776,We observed PGA can detect those brokers who suddenly start selling the stock in a different way to other brokers to whom they were previously similar.,method,2
10777,We also applied t-statistics to find the deviations effectively.,result,3
10778,"White LED offers advantageous properties such as high brightness, reliability, lower power consumption and long lifetime.",background,0
10779,White LEDs are expected to serve in the next generation of lamps.,objective,1
10780,An indoor visible-light communication system utilizing white LED lights has been proposed from our laboratory.,method,2
10781,"In the proposed system, these devices are used not only for illuminating rooms but also for an optical wireless communication system.",method,2
10782,"Generally, plural lights are installed in our room.",method,2
10783,"So, their optical path difference must be considered.",result,3
10784,"In this paper, we discuss about the influence of interference and reflection.",result,3
10785,"Based on numerical analyses, we show that the system is expected to be the indoor communication of the next generation.",result,3
10786,"Most collaborative robots use high-power motors for a good weight-to-payload ratio, thus leading to not only an increase in manufacturing cost but also possibility of injury at a collision between a human and a robot.",background,0
10787,"To maintain high-performance with low-power driving units, a spring-based counterbalance mechanism (CBM) and a robot arm based on these CBMs were developed in our previous study.",objective,1
10788,"In this study, a 6-DOF collaborative robot equipped with a multi-DOF CBM is proposed.",result,3
10789,A double parallelogram linkage and a slider-crank mechanism are employed for a compact and durable design of a multi-DOF CBM.,method,2
10790,"Unlike the previous prototypes in which some portions of CBMs were protruded out of the robot body due to their large volume, the proposed CBMs can be embedded inside the robot links.",method,2
10791,The performance of the developed CBM and collaborative robot were verified based on simulations using dynamic simulation software.,result,3
10792,Simulation results show that the proposed CBMs can effectively reduce the joint torques required to operate the robot.,result,3
10793,"This reduction in the torque enables low-power motors to be used in a collaborative robot, thus significantly improving collision safety and energy efficiency.",result,3
10794,The weighted linear combination (WLC) technique is a decision rule for deriving composite maps using GIS.,background,0
10795,It is one of the most often used decision models in GIS.,background,0
10796,"The method, however, is frequently applied without full understanding of the assumptions underling this approach.",method,2
10797,"In many case studies, the WLC model has been applied incorrectly and with dubious results because analysts (decision makers) have ignored or been unaware of the assumptions.",background,0
10798,This paper provides a critical overview of the current practice with respect to GIS/WLC and suggests the best practice approach.,objective,1
10799,Floating-point computing with more than one TFLOP of peak performance is already a reality in recent Field-Programmable Gate Arrays (FPGA).,background,0
10800,General-Purpose Graphics Processing Units (GPGPU) and recent many-core CPUs have also taken advantage of the recent technological innovations in integrated circuit (IC) design and had also dramatically improved their peak performances.,background,0
10801,"In this paper, we compare the trends of these computing architectures for high-performance computing and survey these platforms in the execution of algorithms belonging to different scientific application domains.",objective,1
10802,"Trends in peak performance, power consumption and sustained performances, for particular applications, show that FPGAs are increasing the gap to GPUs and many-core CPUs moving them away from high-performance computing with intensive floating-point calculations.",result,3
10803,"FPGAs become competitive for custom floating-point or fixed-point representations, for smaller input sizes of certain algorithms, for combinational logic problems and parallel map-reduce problems.",result,3
10804,"In order to compete successfully, operations in any type of firm need to be strategically aligned to the market requirements.",background,0
10805,This concerns both manufacturing and supply chain operations.,background,0
10806,The customer order decoupling point (CODP) is getting increasing attention as an important input to the design of manufacturing operations as well as supply chains.,background,0
10807,This paper investigates the impact of the position and role of the CODP on issues of concern for production and supply chain management.,objective,1
10808,"The focus is on the design and strategic planning aspects of the supply chain, and the design of manufacturing planning and control systems.",objective,1
10809,The paper proposes a dual design approach for production and supply chain planning systems; one type of system for operations upstream the CODP and another type of system for downstream operations in order to fully support the characteristics and objectives of each respective part of the supply chain.,method,2
10810,2010 Elsevier B.V. All rights reserved.,other,4
10811,* Tel.,other,4
10812,: +46 13 281000; fax: +46 13 281101.,other,4
10813,E-mail address: jan.olhager@liu.se.,other,4
10814,"The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data.",method,2
10815,"Although domain knowledge can be used to help design representations, learning can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms.",objective,1
10816,"This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, manifold learning, and deep learning.",result,3
10817,"This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.",result,3
10818,—Authentication establishes the identity of one party to another.,background,0
10819,"Most commonly authentication establishes the identity of a user to some part of the system, typically by means of a password.",background,0
10820,"More generally, authentication can be computer-to-computer or process-toprocess and mutual in both directions.",method,2
10821,—Access control determines what one party will allow another to do with respect to resources and objects mediated by the former.,method,2
10822,Access control usually requires authentication as a prerequisite.,method,2
10823,—The audit process gathers data about activity in the system and analyzes it to discover security violations or diagnose their cause.,objective,1
10824,Analysis can occur offline after the fact or online in real time.,result,3
10825,"In the latter case, the process is usually called intrusion detection.",result,3
10826,We consider topic detection without any prior knowledge of category structure or possible categories.,background,0
10827,Keywords are extracted and clustered based on different similarity measures using the induced k-bisecting clustering algorithm.,method,2
10828,Evaluation on Wikipedia articles shows that clusters of keywords correlate strongly with the Wikipedia categories of the articles.,method,2
10829,"In addition, we find that a distance measure based on the Jensen-Shannon divergence of probability distributions outperforms the cosine similarity.",method,2
10830,"In particular, a newly proposed term distribution taking co-occurrence of terms into account gives best results.",result,3
10831,Literature reviews play an important role in the development of knowledge.,background,0
10832,"Yet, we observe a lack of theoretical underpinning of and epistemological insights into how literature reviews can contribute to knowledge creation and have actually contributed in the IS discipline.",background,0
10833,"To address these theoretical and empirical research gaps, we suggest a novel epistemological model of literature reviews.",method,2
10834,This model allows us to align different contributions of literature reviews with their underlying knowledge conversions thereby building a bridge between the previously largely unconnected fields of literature reviews and epistemology.,method,2
10835,We evaluate the appropriateness of the model by conducting an empirical analysis of 173 IS literature reviews which were published in 39 pertinent IS journals between 2000 and 2014.,result,3
10836,"Based on this analysis, we derive an epistemological taxonomy of IS literature reviews, which complements previously suggested typologies.",result,3
10837,"This paper surveys the current state of the art in Natural Language Generation (nlg), defined as the task of generating text or speech from non-linguistic input.",objective,1
10838,"A survey of nlg is timely in view of the changes that the field has undergone over the past two decades, especially in relation to new (usually data-driven) methods, as well as new applications of nlg technology.",method,2
10839,"This survey therefore aims to (a) give an up-to-date synthesis of research on the core tasks in nlg and the architectures adopted in which such tasks are organised; (b) highlight a number of recent research topics that have arisen partly as a result of growing synergies between nlg and other areas of artificial intelligence; (c) draw attention to the challenges in nlg evaluation, relating them to similar challenges faced in other areas of nlp, with an emphasis on different evaluation methods and the relationships between them.",result,3
10840,The purpose of this article is to propose a fruitful analytical framework for data supposedly related to the concept of the socalled “digital divide.,objective,1
10841,”,other,4
10842,The extent and the nature of this divide depend on the kind of access defined.,background,0
10843,"Considering the possession of hardware, growing divides among different categories of income, employment, education, age, and ethnicity can be proved to have existed in the 1980s and 1990s according to official American and Dutch statistics.",background,0
10844,"If only by effects of saturation, these gaps will more or less close.",background,0
10845,"However, it is shown that differential access of skills and usage is likely to increase.",background,0
10846,The growth of a usage gap is projected.,objective,1
10847,Multivariate analyses of Dutch official statistics reveal the striking effect of age and gender as compared to education.,result,3
10848,The usage gap is related to the evolution of the information and network society.,background,0
10849,"Finally, policy perspectives are discussed.",result,3
10850,"Text categorization (also known as text classification, or topic spotting) is the task of automatically sorting a set of documents into categories from a predefined set.",background,0
10851,"This task has several applications, including automated indexing of scientific articles according to predefined thesauri of technical terms, filing patents into patent directories, selective dissemination of information to information consumers, automated population of hierarchical catalogues of Web resources, spam filtering, identification of document genre, authorship attribution, survey coding, and even automated essay grading.",background,0
10852,"Automated text classification is attractive because it frees organizations from the need of manually organizing document bases, which can be too expensive, or simply infeasible given the time constraints of the application or the number of documents involved.",background,0
10853,"The accuracy of modern text classification systems rivals that of trained human professionals, thanks to a combination of information retrieval (IR) technology and machine learning (ML) technology.",background,0
10854,"This will outline the fundamental traits of the technologies involved, of the applications that can feasibly be tackled through text classification, and of the tools and resources that are available to the researcher and developer wishing to take up these technologies for deploying real-world applications.",result,3
10855,"With today‘s ubiquity and popularity of social network applications, the ability to analyze and understand large networks in an ef cient manner becomes critically important.",background,0
10856,"However, as networks become larger and more complex, reasoning about social dynamics via simple statistics is not a feasible option.",background,0
10857,"To overcome these limitations, we can rely on visual metaphors.",background,0
10858,Visualization nowadays is no longer a passive process that produces images from a set of numbers.,method,2
10859,"Recent years have witnessed a convergence of social network analytics and visualization, coupled with interaction, that is changing the way analysts understand and characterize social networks.",background,0
10860,"In this chapter, we discuss the main goal of visualization and how different metaphors are aimed towards elucidating different aspects of social networks, such as structure and semantics.",objective,1
10861,We also describe a number of methods where analytics and visualization are interwoven towards providing a better comprehension of social structure and dynamics.,method,2
10862,"In this study, we assess the causal impact of stakeholder orientation on innovation.",objective,1
10863,"To obtain exogenous variation in stakeholder orientation, we exploit the enactment of state-level constituency statutes, which allow directors to consider stakeholders’ interests when making business decisions.",objective,1
10864,"Using a difference-indifferences methodology, we find that the enactment of constituency statutes leads to a significant increase in the number of patents and citations per patent.",method,2
10865,We further assess the mechanisms through which stakeholder orientation fosters innovation.,method,2
10866,"In particular, we argue that stakeholder orientation sparks innovation by promoting a secure work environment and enhancing the satisfaction of various stakeholders, including employees and customers.",method,2
10867,"Consistent with this argument, we find that the positive impact of stakeholder orientation on innovation is greater in industries with lower job security as well as industries and firms with lower stakeholder satisfaction.",result,3
10868,"Cryptocurrencies, such as Bitcoin and 250 similar alt-coins, embody at their core a blockchain protocol --- a mechanism for a distributed network of computational nodes to periodically agree on a set of new transactions.",background,0
10869,"Designing a secure blockchain protocol relies on an open challenge in security, that of designing a highly-scalable agreement protocol open to manipulation by byzantine or arbitrarily malicious nodes.",background,0
10870,"Bitcoin's blockchain agreement protocol exhibits security, but does not scale: it processes 3--7 transactions per second at present, irrespective of the available computation capacity at hand.",background,0
10871,"In this paper, we propose a new distributed agreement protocol for permission-less blockchains called ELASTICO.",objective,1
10872,"ELASTICO scales transaction rates almost linearly with available computation for mining: the more the computation power in the network, the higher the number of transaction blocks selected per unit time.",method,2
10873,ELASTICO is efficient in its network messages and tolerates byzantine adversaries of up to one-fourth of the total computational power.,objective,1
10874,"Technically, ELASTICO uniformly partitions or parallelizes the mining network (securely) into smaller committees, each of which processes a disjoint set of transactions (or ""shards"").",method,2
10875,"While sharding is common in non-byzantine settings, ELASTICO is the first candidate for a secure sharding protocol with presence of byzantine adversaries.",method,2
10876,"Our scalability experiments on Amazon EC2 with up to $1, 600$ nodes confirm ELASTICO's theoretical scaling properties.",result,3
10877,This paper describes a real-time online prototype driver-fatigue monitor.,background,0
10878,It uses remotely located charge-coupled-device cameras equipped with active infrared illuminators to acquire video images of the driver.,objective,1
10879,Various visual cues that typically characterize the level of alertness of a person are extracted in real time and systematically combined to infer the fatigue level of the driver.,method,2
10880,"The visual cues employed characterize eyelid movement, gaze movement, head movement, and facial expression.",method,2
10881,A probabilistic model is developed to model human fatigue and to predict fatigue based on the visual cues obtained.,method,2
10882,The simultaneous use of multiple visual cues and their systematic combination yields a much more robust and accurate fatigue characterization than using a single visual cue.,method,2
10883,"This system was validated under real-life fatigue conditions with human subjects of different ethnic backgrounds, genders, and ages; with/without glasses; and under different illumination conditions.",method,2
10884,"It was found to be reasonably robust, reliable, and accurate in fatigue characterization.",result,3
10885,"Existing single view, 3D face reconstruction methods can produce beautifully detailed 3D results, but typically only for near frontal, unobstructed viewpoints.",background,0
10886,"We describe a system designed to provide detailed 3D reconstructions of faces viewed under extreme conditions, out of plane rotations, and occlusions.",background,0
10887,"Motivated by the concept of bump mapping, we propose a layered approach which decouples estimation of a global shape from its mid-level details (e.g., wrinkles).",objective,1
10888,We estimate a coarse 3D face shape which acts as a foundation and then separately layer this foundation with details represented by a bump map.,objective,1
10889,We show how a deep convolutional encoder-decoder can be used to estimate such bump maps.,method,2
10890,We further show how this approach naturally extends to generate plausible details for occluded facial regions.,method,2
10891,"We test our approach and its components extensively, quantitatively demonstrating the invariance of our estimated facial details.",method,2
10892,We further provide numerous qualitative examples showing that our method produces detailed 3D face shapes in viewing conditions where existing state of the art often break down.,method,2
10893,"With an upsurge in financial accounting fraud in the current economic scenario experienced, financial accounting fraud detection (FAFD) has become an emerging topic of great importance for academic, research and industries.",background,0
10894,"The failure of internal auditing system of the organization in identifying the accounting frauds has lead to use of specialized procedures to detect financial accounting fraud, collective known as forensic accounting.",background,0
10895,"Data mining techniques are providing great aid in financial accounting fraud detection, since dealing with the large data volumes and complexities of financial data are big challenges for forensic accounting.",method,2
10896,This paper presents a comprehensive review of the literature on the application of data mining techniques for the detection of financial accounting fraud and proposes a framework for data mining techniques based accounting fraud detection.,method,2
10897,The systematic and comprehensive literature review of the data mining techniques applicable to financial accounting fraud detection may provide a foundation to future research in this field.,method,2
10898,"The findings of this review show that data mining techniques like logistic models, neural networks, Bayesian belief network, and decision trees have been applied most extensively to provide primary solutions to the problems inherent in the detection and classification of fraudulent data.",result,3
10899,"Sentiment analysis from text consists of extracting information about opinions, sentiments, and even emotions conveyed by writers towards topics of interest.",background,0
10900,"It is often equated to opinion mining, but it should also encompass emotion mining.",background,0
10901,Opinion mining involves the use of natural language processing and machine learning to determine the attitude of a writer towards a subject.,method,2
10902,Emotion mining is also using similar technologies but is concerned with detecting and classifying writers emotions toward events or topics.,method,2
10903,"Textual emotion-mining methods have various applications, including gaining information about customer satisfaction, helping in selecting teaching materials in e-learning, recommending products based on users emotions, and even predicting mental-health disorders.",method,2
10904,"In surveys on sentiment analysis, which are often old or incomplete, the strong link between opinion mining and emotion mining is understated.",result,3
10905,"This motivates the need for a different and new perspective on the literature on sentiment analysis, with a focus on emotion mining.",result,3
10906,"We present the state-of-the-art methods and propose the following contributions: (1) a taxonomy of sentiment analysis; (2) a survey on polarity classification methods and resources, especially those related to emotion mining; (3) a complete survey on emotion theories and emotion-mining research; and (4) some useful resources, including lexicons and datasets.",method,2
10907,"Tracking by detection based object tracking methods encounter numerous complications including object appearance changes, size and shape deformations, partial and full occlusions, which make online adaptation of classifiers and object models a substantial challenge.",background,0
10908,"In this paper, we employ an object proposal network that generates a small yet refined set of bounding box candidates to mitigate the this object model refitting problem by concentrating on hard negatives when we update the classifier.",objective,1
10909,This helps improving the discriminative power as hard negatives are likely to be due to background and other distractions.,objective,1
10910,"Another intuition is that, in each frame, applying the classifier only on the refined set of object-like candidates would be sufficient to eliminate most of the false positives.",method,2
10911,Incorporating an object proposal makes the tracker robust against shape deformations since they are handled naturally by the proposal stage.,method,2
10912,We demonstrate evaluations on the PETS 2016 dataset and compare with the state-of-theart trackers.,result,3
10913,Our method provides the superior results.,result,3
10914,HE TECHNIQUE described in this paper has been deT veloped to correct frequency offset errors in digital communications systems employing orthogonal frequency division multiplexing (OFDM) as the method of modulation.,background,0
10915,The aim of the paper is twofold; to show the effect offset errors have on the signal-to-noise ratio of the OFDM carriers and to present an algorithm to estimate offset so that it may be removed prior to demodulhhn.,objective,1
10916,OFDM is a bandwidth efficient signalling scheme for digital communications that was first proposed by Chang [l].,method,2
10917,"The main difference bepeen frequency division multiplexing (FDM) and OFDM, is that in OFDM the spectrum of the individual carriers mutually overlap, giving therefore an optimun spectrum efficiency (asymptotically Q b/Hz for 2Q-ary modulation of each carrier).",method,2
10918,"Nevertheless, the OFDM carriers exhibit orthogonality on a symbol interval if synthesized such that they are spaced in frequency exactly at the reciprocal of the symbol interval.",method,2
10919,"Fortunately, this synthesis can be accomplished perfectly, in principle, utilizing the discrete Fourier ttansform (dft) as first described by Darlington [2] and later, for data modems, by Weinstein and Ebert [3].",background,0
10920,"With the recent evolution of integrated circuit digital signal processing (dsp) chips, OFDM has become practical to implement and",result,3
10921,Grasping and manipulating uncooperative objects in space is an emerging challenge for robotic systems.,background,0
10922,Many traditional robotic grasping techniques used on Earth are infeasible in space.,background,0
10923,"Vacuum grippers require an atmosphere, sticky attachments fail in the harsh environment of space, and handlike opposed grippers are not suited for large, smooth space debris.",background,0
10924,"We present a robotic gripper that can gently grasp, manipulate, and release both flat and curved uncooperative objects as large as a meter in diameter while in microgravity.",method,2
10925,"This is enabled by (i) space-qualified gecko-inspired dry adhesives that are selectively turned on and off by the application of shear forces, (ii) a load-sharing system that scales small patches of these adhesives to large areas, and (iii) a nonlinear passive wrist that is stiff during manipulation yet compliant when overloaded.",method,2
10926,We also introduce and experimentally verify a model for determining the force and moment limits of such an adhesive system.,method,2
10927,Tests in microgravity show that robotic grippers based on dry adhesion are a viable option for eliminating space debris in low Earth orbit and for enhancing missions in space.,result,3
10928,"Source code plagiarism is an easy to do task, but very difficult to detect without proper tool support.",background,0
10929,Various source code similarity detection systems have been developed to help detect source code plagiarism.,background,0
10930,Those systems need to recognize a number of lexical and structural source code modifications.,background,0
10931,"For example, by some structural modifications (e.g. modification of control structures, modification of data structures or structural redesign of source code) the source code can be changed in such a way that it almost looks genuine.",background,0
10932,Most of the existing source code similarity detection systems can be confused when these structural modifications have been applied to the original source code.,background,0
10933,"To be considered effective, a source code similarity detection system must address these issues.",method,2
10934,"To address them, we designed and developed the source code similarity system for plagiarism detection.",method,2
10935,"To demonstrate that the proposed system has the desired effectiveness, we performed a well-known conformism test.",method,2
10936,The proposed system showed promising results as compared with the JPlag system in detecting source code similarity when various lexical or structural modifications are applied to plagiarized code.,result,3
10937,"As a confirmation of these results, an independent samples t-test revealed that there was a statistically significant difference between average values of F -measures for the test sets that we used and for the experiments that we have done in the practically usable range of cut-off threshold values of 35–70%.",result,3
10938,We present a mobile robot navigation system guided by a novel vision-based road recognition approach.,background,0
10939,The system represents the road as a set of lines extrapolated from the detected image contour segments.,method,2
10940,"These lines enable the robot to maintain its heading by centering the vanishing point in its field of view, and to correct the long term drift from its original lateral position.",method,2
10941,We integrate odometry and our visual road recognition system into a grid-based local map that estimates the robot pose as well as its surroundings to generate a movement path.,method,2
10942,"Our road recognition system is able to estimate the road center on a standard dataset with 25,076 images to within 11.42 cm (with respect to roads at least 3 m wide).",result,3
10943,It outperforms three other state-of-the-art systems.,result,3
10944,"In addition, we extensively test our navigation system in four busy college campus environments using a wheeled robot.",result,3
10945,Our tests cover more than 5 km of autonomous driving without failure.,result,3
10946,"This demonstrates robustness of the proposed approach against challenges that include occlusion by pedestrians, non-standard complex road markings and shapes, shadows, and miscellaneous obstacle objects.",result,3
10947,Understanding land use land cover change (LULCC) is a prerequisite for urban planning and environment management.,objective,1
10948,"For LULCC studies in urban/suburban environments, the abundance and spatial distributions of bare soil are essential due to its biophysically different properties when compared to anthropologic materials.",background,0
10949,"Soil, however, is very difficult to be identified using remote sensing technologies majorly due to its complex physical and chemical compositions, as well as the lack of a direct relationship between soil abundance and its spectral signatures.",background,0
10950,This paper presents an empirical approach to enhance soil information through developing the ratio normalized difference soil index (RNDSI).,objective,1
10951,"The first step involves the generation of random samples of three major land cover types, namely soil, impervious surface areas (ISAs), and vegetation.",method,2
10952,"With spectral signatures of these samples, a normalized difference soil index (NDSI) was proposed using the combination of bands 7 and 2 of Landsat Thematic Mapper Image.",method,2
10953,"Finally, a ratio index was developed to further highlight soil covers through dividing the NDSI by the first component of tasseled cap transformation (TC1).",method,2
10954,"Qualitative (e.g., frequency histogram and box charts) and quantitative analyses (e.g., spectral discrimination index and classification accuracy) were adopted to examine the performance of the developed RNDSI.",result,3
10955,"Analyses of results and comparative analyses with two other relevant indices, biophysical composition index (BCI) and enhanced built-up and bareness Index (EBBI), indicate that RNDSI is promising in separating soil from ISAs and vegetation, and can serve as an input to LULCC models.",result,3
10957,3D Mask face spoofing attack becomes new challenge and attracts more research interests in recent years.,background,0
10958,"However, due to the deficiency number and limited variations of database, there are few methods be proposed to aim on it.",background,0
10959,"Meanwhile, most of existing databases only concentrate on the anti-spoofing of different kinds of attacks and ignore the environmental changes in real world applications.",background,0
10960,"In this paper, we build a new 3D mask anti-spoofing database with more variations to simulate the real world scenario.",background,0
10961,The proposed database contains 12 masks from two companies with different appearance quality.,method,2
10962,7 Cameras from the stationary and mobile devices and 6 lighting settings that cover typical illumination conditions are also included.,method,2
10963,"Therefore, each subject contains 42 (7 cameras * 6 lightings) genuine and 42 mask sequences and the total size is 1008 videos.",method,2
10964,"Through the benchmark experiments, directions of the future study are pointed out.",result,3
10965,We plan to release the database as an platform to evaluate methods under different variations.,result,3
10966,The emergence of synchronization in a network of coupled oscillators is a fascinating subject of multidisciplinary research.,background,0
10967,This survey reviews the vast literature on the theory and the applications of complex oscillator networks.,background,0
10968,"We focus on phase oscillator models that are widespread in real-world synchronization phenomena, that generalize the celebrated Kuramoto model, and that feature a rich phenomenology.",objective,1
10969,We review the history and the countless applications of this model throughout science and engineering.,objective,1
10970,"We justify the importance of the widespread coupled oscillator model as a locally canonical model and describe some selected applications relevant to control scientists, including vehicle coordination, electric power networks, and clock synchronization.",result,3
10971,We introduce the reader to several synchronization notions and performance estimates.,method,2
10972,"We propose analysis approaches to phase and frequency synchronization, phase balancing, pattern formation, and partial synchronization.",method,2
10973,"We present the sharpest known results about synchronization in networks of homogeneous and heterogeneous oscillators, with complete or sparse interconnection topologies, and in finite-dimensional and infinitedimensional settings.",method,2
10974,We conclude by summarizing the limitations of existing analysis methods and by highlighting some directions for future research.,result,3
10975,© 2014 Elsevier Ltd.,other,4
10976,The internet provides information media and social media for online consumers to seek information on the websites and opinions from other consumers.,background,0
10977,"This study examined how the three dimensions of interactivity (control, communication direction, and synchronicity) affected users’ online information seeking process.",objective,1
10978,"Particularly, this study assessed how cognitive involvement and perceived social presence mediated the effects of interactivity onto satisfaction of websites, purchase intention and spreading word-of-mouth.",objective,1
10979,"Moreover, we also investigated how users’ opinion leadership moderated the effects of interactivity.",method,2
10980,This study recruited 511 respondents to participate in the survey.,method,2
10981,"The results showed that control and synchronicity positively influenced consumers’ involvement, which further mediated the effects of these two dimensions of interactivity onto user satisfaction of the website, purchase intention and spreading word-of-mouth.",result,3
10982,"On the other hand, communication direction and synchronicity positively affected their social presence, which only mediated the effect of synchronicity onto those three dependent variables.",result,3
10983,"Lastly, users’ opinion leadership moderated the effects of communication direction and synchronicity on social presence, but did not moderate the effects of control and synchronicity on involvement.",result,3
10984,A wide variety of systems requires reliable personal recognition schemes to either confirm or determine the identity of an individual requesting their services.,background,0
10985,The purpose of such schemes is to ensure that the rendered services are accessed only by a legitimate user and no one else.,objective,1
10986,"Examples of such applications include secure access to buildings, computer systems, laptops, cellular phones, and ATMs.",method,2
10987,"In the absence of robust personal recognition schemes, these systems are vulnerable to the wiles of an impostor.",method,2
10988,"Biometric recognition, or, simply, biometrics, refers to the automatic recognition of individuals based on their physiological and/or behavioral characteristics.",method,2
10989,"By using biometrics, it is possible to confirm or establish an individual's identity based on ""who she is"", rather than by ""what she possesses"" (e.g., an ID card) or ""what she remembers"" (e.g., a password).",result,3
10990,"We give a brief overview of the field of biometrics and summarize some of its advantages, disadvantages, strengths, limitations, and related privacy concerns.",result,3
10991,This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time.,objective,1
10992,The effectiveness of a “modularization” is dependent upon the criteria used in dividing the system into modules.,method,2
10993,A system design problem is presented and both a conventional and unconventional decomposition are described.,method,2
10994,It is shown that the unconventional decompositions have distinct advantages for the goals outlined.,method,2
10995,The criteria used in arriving at the decompositions are discussed.,method,2
10996,"The unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases.",method,2
10997,An alternative approach to implementation which does not have this effect is sketched.,method,2
10998,"Machine learning (ML) and pattern matching (PM) are powerful computer science techniques which can derive knowledge from big data, and provide prediction and matching.",background,0
10999,"Since nanometer VLSI design and manufacturing have extremely high complexity and gigantic data, there has been a surge recently in applying and adapting machine learning and pattern matching techniques in VLSI physical design (including physical verification), e.g., lithography hotspot detection and data/pattern-driven physical design, as ML and PM can raise the level of abstraction from detailed physics-based simulations and provide reasonably good quality-of-result.",method,2
11000,"In this paper, we will discuss key techniques and recent results of machine learning and pattern matching, with their applications in physical design.",method,2
11001,The task of colorizing black and white images has previously been explored for natural images.,background,0
11002,In this paper we look at the task of colorization on a different domain: webtoons.,background,0
11003,To our knowledge this type of dataset hasn't been used before.,background,0
11004,Webtoons are usually produced in color thus they make a good dataset for analyzing different colorization models.,background,0
11005,"Comics like webtoons also present some additional challenges over natural images, such as occlusion by speech bubbles and text.",background,0
11006,First we look at some of the previously introduced models' performance on this task and suggest modifications to address their problems.,method,2
11007,We propose a new model composed of two networks; one network generates sparse color information and a second network uses this generated color information as input to apply color to the whole image.,method,2
11008,These two networks are trained end-to-end.,result,3
11009,"Our proposed model solves some of the problems observed with other architectures, resulting in better colorizations.",result,3
11010,Visual understanding of complex urban street scenes is an enabling factor for a wide range of applications.,background,0
11011,"Object detection has benefited enormously from large-scale datasets, especially in the context of deep learning.",background,0
11012,"For semantic urban scene understanding, however, no current dataset adequately captures the complexity of real-world urban scenes.",background,0
11013,"To address this, we introduce Cityscapes, a benchmark suite and large-scale dataset to train and test approaches for pixel-level and instance-level semantic labeling.",objective,1
11014,"Cityscapes is comprised of a large, diverse set of stereo video sequences recorded in streets from 50 different cities.",method,2
11015,"5000 of these images have high quality pixel-level annotations, 20 000 additional images have coarse annotations to enable methods that leverage large volumes of weakly-labeled data.",method,2
11016,"Crucially, our effort exceeds previous attempts in terms of dataset size, annotation richness, scene variability, and complexity.",result,3
11017,"Our accompanying empirical study provides an in-depth analysis of the dataset characteristics, as well as a performance evaluation of several state-of-the-art approaches based on our benchmark.",result,3
11018,"Texting has been shown to be cognitively distracting for students in lecture settings, but few have done empirical work, or looked at moderating effects between texting and academic outcomes.",background,0
11019,"This experimental study compared the proportion of correct answers on a lecture quiz between students who were randomly assigned to text message during a pre-recorded lecture and those who were not, while investigating possible moderators.",background,0
11020,"The participants who text messaged throughout the lecture scored significantly lower in percent of correct responses (t(95) = 4.6, p < .001, d = .93).",result,3
11021,"No moderating effects were found, including: perceived distraction, perceived texting ability, number of text messages sent and received during the lecture, age, and gender.",result,3
11022,Published by Elsevier Ltd.,other,4
11023,Deep learning has proven itself as a successful set of models for learning useful semantic representations of data.,background,0
11024,"These, however, are mostly implicitly learned as part of a classification task.",background,0
11025,"In this paper we propose the triplet network model, which aims to learn useful representations by distance comparisons.",objective,1
11026,"A similar model was defined by Wang et al. (2014), tailor made for learning a ranking for image information retrieval.",method,2
11027,"Here we demonstrate using various datasets that our model learns a better representation than that of its immediate competitor, the Siamese network.",result,3
11028,We also discuss future possible usage as a framework for unsupervised learning.,result,3
11029,Rapid development of information technology (IT) has brought with it many new applications such as e-commerce and global business.,background,0
11030,"The past few years have seen activities in the legislative arena covering issues such as digital signatures, the international recognition of electronic documents and privacy and data protection.",background,0
11031,Both the developed and developing countries have exhibited keenness to embrace the IT environment.,background,0
11032,"Securing this electronic environment from intrusion, however, continues to be problematic.",background,0
11033,A particular favorite form of computer crime would be ‘hacking’.,background,0
11034,"As more computer systems move on to on-line processing and improved telecommunications, computer hackers are now a real threat.",background,0
11035,Legislation criminalizing intrusion and destruction activities directed at computers are needed.,result,3
11036,Malaysia joined the list of countries with computer-specific legislation with the enactment of its Computer Crime Act 1997 (CCA).,result,3
11037,"This paper focuses on hacking as a criminal act, and compares the Malaysian CCA with legislation from other countries.",result,3
11038,The current computer crime situation in Malaysia is looked at and exposes the difficulties and obstacles Malaysia faces in enforcing the Act.,background,0
11039,Depression is one of the most common mental disorder that at its worst can lead to suicide.,background,0
11040,Diagnosing depression in the early curable stage is very important.,objective,1
11041,In this paper we study performance of different classification techniques for classifying depression patients from normal subjects.,objective,1
11042,"For this aim, power spectrum of three frequency band (alpha, beta, theta) and the whole bands of EEG are used as features.",method,2
11043,We have shown that Support Vector Machine (SVM) classifier using Genetic algorithm for feature selection can achieve accuracy of 88.6% on classifying depression patients.,result,3
11044,Behavioral logs are traces of human behavior seen through the lenses of sensors that capture and record user activity.,background,0
11045,They include behavior ranging from low-level keystrokes to rich audio and video recordings.,background,0
11046,"Traces of behavior have been gathered in psychology studies since the 1930s (Skinner, 1938 ), and with the advent of computerbased applications it became common practice to capture a variety of interaction behaviors and save them to log fi les for later analysis.",background,0
11047,"In recent years, the rise of centralized, web-based computing has made it possible to capture human interactions with web services on a scale previously unimaginable.",background,0
11048,"Largescale log data has enabled HCI researchers to observe how information diffuses through social networks in near real-time during crisis situations (Starbird & Palen, 2010 ), characterize how people revisit web pages over time (Adar, Teevan, & Dumais, 2008 ), and compare how different interfaces for supporting email organization infl uence initial uptake and sustained use (Dumais, Cutrell, Cadiz, Jancke, Sarin, & Robbins, 2003 ; Rodden & Leggett, 2010 ).",background,0
11049,In this chapter we provide an overview of behavioral log use in HCI.,objective,1
11050,"We highlight what can be learned from logs that capture people’s interactions with existing computer systems and from experiments that compare new, alternative systems.",objective,1
11051,"We describe how to design and analyze web experiments, and how to collect, clean and use log data responsibly.",method,2
11052,The goal of this chapter is to enable the reader to design log studies and to understand results from log studies that they read about.,objective,1
11053,Understanding User Behavior Through Log Data and Analysis,objective,1
11054,"This paper introduces an extended set of Haarlike features beyond the standard vertically and horizontally aligned Haar-like features [Viola and Jones, 2001a; 2001b] and the 45 twisted Haar-like features [Lienhart and Maydt, 2002; Lienhart et al., 2003a; 2003b].",background,0
11055,The extended rotated Haar-like features are based on the standard Haar-like features that have been rotated based on whole integer pixel based rotations.,background,0
11056,These rotated feature values can also be calculated using rotated integral images which means that they can be fast and efficiently calculated with just 8 operations irrespective of the feature size.,background,0
11057,In general each feature requires another 8 operations based on an identity integral image so that appropriate scaling corrections can be applied.,method,2
11058,These scaling corrections are needed due to the rounding errors associated with scaling the features.,background,0
11059,The errors introduced by these rotated features on natural images are small enough to allow rotated classifiers to be implemented using a classifier trained on only vertically aligned images.,background,0
11060,This is a significant improvement in training time for a classifier that is invariant to the rotations represented in the parallel classifier.,background,0
11061,Figure 1.,other,4
11062,Standard Haar-like features.,other,4
11063,"We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions.",method,2
11064,Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function.,method,2
11065,"This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation).",method,2
11066,"We also present two detailed extensions of Bayesian optimization, with experiments—active user modelling with preferences, and hierarchical reinforcement learning— and a discussion of the pros and cons of Bayesian optimization based on our experiences.",method,2
11067,SYM-ILDL is a numerical software package that computes incomplete LDLT (ILDL) factorizations of symmetric indefinite and real skew-symmetric matrices.,background,0
11068,"The core of the algorithm is a Crout variant of incomplete LU (ILU), originally introduced and implemented for symmetric matrices by Li and Saad [2005].",background,0
11069,"Our code is economical in terms of storage, and it deals with real skew-symmetric matrices as well as symmetric ones.",background,0
11070,"The package is written in C++ and is templated, is open source, and includes a Matlab™ interface.",background,0
11071,"The code includes built-in RCM and AMD reordering, two equilibration strategies, threshold Bunch-Kaufman pivoting, and rook pivoting, as well as a wrapper to MC64, a popular matching-based equilibration and reordering algorithm.",background,0
11072,"We also include two built-in iterative solvers: SQMR, preconditioned with ILDL, and MINRES, preconditioned with a symmetric positive definite preconditioner based on the ILDL factorization.",result,3
11073,A user study was conducted to investigate how people deal with the flow of information in their workspaces.,background,0
11074,"Subjects reported that, in an attempt to quickly and informally manage their information, they created piles of documents.",result,3
11075,"Piles were seen as complementary to the folder filing system, which was used for more formal archiving.",background,0
11076,A new desktop interface element–the pile– was developed and prototyped through an iterative process.,method,2
11077,"The design includes direct manipulation techniques and support for browsing, and goes beyond physical world functionality by providing system assistance for automatic pile construction and reorganization.",result,3
11078,Preliminary user tests indicate the design is promising and raise issues that will be addressed in future work.,result,3
11079,Behavioral and neurophysiological effects of word imageability and concreteness remain a topic of central interest in cognitive neuroscience and could provide essential clues for understanding how the brain processes conceptual knowledge.,background,0
11080,We examined these effects using event-related functional magnetic resonance imaging while participants identified concrete and abstract words.,method,2
11081,"Relative to nonwords, concrete and abstract words both activated a left-lateralized network of multimodal association areas previously linked with verbal semantic processing.",result,3
11082,"Areas in the left lateral temporal lobe were equally activated by both word types, whereas bilateral regions including the angular gyrus and the dorsal prefrontal cortex were more strongly engaged by concrete words.",result,3
11083,"Relative to concrete words, abstract words activated left inferior frontal regions previously linked with phonological and verbal working memory processes.",result,3
11084,"The results show overlapping but partly distinct neural systems for processing concrete and abstract concepts, with greater involvement of bilateral association areas during concrete word processing, and processing of abstract concepts almost exclusively by the left hemisphere.",result,3
11085,Recent work linking deep neural networks and dynamical systems opened up new avenues to analyze deep learning.,background,0
11086,"In particular, it is observed that new insights can be obtained by recasting deep learning as an optimal control problem on difference or differential equations.",background,0
11087,"However, the mathematical aspects of such a formulation have not been systematically explored.",background,0
11088,This paper introduces the mathematical formulation of the population risk minimization problem in deep learning as a mean-field optimal control problem.,objective,1
11089,"Mirroring the development of classical optimal control, we state and prove optimality conditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type.",method,2
11090,These mean-field results reflect the probabilistic nature of the learning problem.,result,3
11091,"In addition, by appealing to the mean-field Pontryagin’s maximum principle, we establish some quantitative relationships between population and empirical learning problems.",result,3
11092,This serves to establish a mathematical foundation for investigating the algorithmic and theoretical connections between optimal control and deep learning.,result,3
11093,Managing project success is an ongoing concern in both research and practice.,background,0
11094,The existing literature suggests theoretical frameworks for defining project success; however there is a lack of studies exploring how to apply these frameworks into a particular organisation.,background,0
11095,"Additionally, there is a lack of practical processes for managing project success.",background,0
11096,"Furthermore, the extant literature does not pay adequate attention to value assessment in public sector projects.",background,0
11097,This research addresses the aforementioned deficiencies through an exploratory case study with a public sector organisation in South Australia.,objective,1
11098,A conceptual framework for defining project success and a practical model for managing project success across the lifecycle were developed and some preliminary validation provided within the context of this organisation.,method,2
11099,The present study offers both theoretical and practical contributions towards managing IT projects to deliver business value.,result,3
11100,"Over the last couple of decades, there have been a large variety of approaches towards modeling student knowledge within intelligent tutoring systems.",background,0
11101,"With the booming development of deep learning and large-scale artificial neural networks, there have been empirical successes in a number of machine learning and data mining applications, including student knowledge modeling.",background,0
11102,"Deep Knowledge Tracing (DKT), a pioneer algorithm that utilizes recurrent neural networks to model student learning, reports substantial improvements in prediction performance.",background,0
11103,"To help the EDM community better understand the promising techniques of deep learning, we examine DKT alongside two well-studied models for knowledge modeling, PFA and BKT.",objective,1
11104,"In addition to sharing a primer on the internal computational structures of DKT, we also report on potential issues that arise from data formatting.",method,2
11105,We take steps to reproduce the experiments of Deep Knowledge Tracing by implementing a DKT algorithm using Google’s TensorFlow framework; we also reproduce similar results on new datasets.,objective,1
11106,"We determine that the DKT findings don't hold an overall edge when compared to the PFA model, when applied to properly prepared datasets that are limited to main (i.e. nonscaffolding) questions.",result,3
11107,"More importantly, during the investigation of DKT, we not only discovered a data quality issue in a public available data set, but we also detected a vulnerability of DKT at how it handles multiple skill sequences.",result,3
11108,This paper presents a set of segmentation methods for various types of 3D point clouds.,background,0
11109,Segmentation of dense 3D data (e.g. Riegl scans) is optimised via a simple yet efficient voxelisation of the space.,background,0
11110,Prior ground extraction is empirically shown to significantly improve segmentation performance.,method,2
11111,"Segmentation of sparse 3D data (e.g. Velodyne scans) is addressed using ground models of non-constant resolution either providing a continuous probabilistic surface or a terrain mesh built from the structure of a range image, both representations providing close to real-time performance.",method,2
11112,All the algorithms are tested on several hand labeled data sets using two novel metrics for segmentation evaluation.,result,3
11113,Have you ever observed the following situation?,other,4
11114,A computer system is built to satisfy well-specified requirements.,background,0
11115,"The requirements clearly describe the task to be supported, and the system satisfies them.",background,0
11116,"Despite all this care and attention, the system is universally condemned by management and users.",objective,1
11117,Why does this happen?,other,4
11118,"Surprisingly often, the task supported is not one that users actually perform.",method,2
11119,"More likely, the model of work underlying the computer system interferes with other tasks the user wants to perform.",result,3
11120,The aim of this paper is to investigate the rules and constraints of code-switching (CS) in Hindi-English mixed language data.,objective,1
11121,"In this paper, we’ll discuss how we collected the mixed language corpus.",background,0
11122,This corpus is primarily made up of student interview speech.,background,0
11123,The speech was manually transcribed and verified by bilingual speakers of Hindi and English.,method,2
11124,The code-switching cases in the corpus are discussed and the reasons for code-switching are explained.,method,2
11125,The enhancements being developed by the Time-Sensitive Networking Task Group as part of IEEE 802.1 emerge as the future of real-time communication over Ethernet networks for automotive and industrial application domains.,background,0
11126,In particular IEEE 802.1Qbv is key to enabling timeliness guarantees via so-called time-aware shapers.,background,0
11127,"In this paper, we address the computation of fully deterministic schedules for 802.1Qbv-compliant multi-hop switched networks.",objective,1
11128,"We identify and analyze key functional parameters affecting the deterministic behaviour of real-time communication under 802.1Qbv and, based on a generalized configuration of these parameters, derive the required constraints for computing offline schedules guaranteeing low and bounded jitter and deterministic end-to-end latency for critical communication flows.",objective,1
11129,"Furthermore, we discuss several optimization directions and concrete configurations exposing trade-offs against the required computation time.",method,2
11130,We also show the performance of our approach via synthetic network workloads on top of different network configurations.,method,2
11131,"In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density.",background,0
11132,An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents.,method,2
11133,"Typical evaluation results are shown, demonstating the usefulness of the model.",result,3
11134,The ever growing traffic explosion in mobile communications has recently drawn increased attention to the large amount of underutilized spectrum in the millimeter-wave frequency bands as a potentially viable solution for achieving tens to hundreds of times more capacity compared to current 4G cellular networks.,background,0
11135,"Historically, mmWave bands were ruled out for cellular usage mainly due to concerns regarding short-range and non-line-of-sight coverage issues.",result,3
11136,"In this article, we present recent results from channel measurement campaigns and the development of advanced algorithms and a prototype, which clearly demonstrate that the mmWave band may indeed be a worthy candidate for next generation (5G) cellular systems.",result,3
11137,The results of channel measurements carried out in both the United States and Korea are summarized along with the actual free space propagation measurements in an anechoic chamber.,result,3
11138,Then a novel hybrid beamforming scheme and its link- and system-level simulation results are presented.,result,3
11139,"Finally, recent results from our mmWave prototyping efforts along with indoor and outdoor test results are described to assert the feasibility of mmWave bands for cellular usage.",result,3
11140,The explosive growth in popularity of social networking leads to the problematic usage.,background,0
11141,"An increasing number of social network mental disorders (SNMDs), such as Cyber-Relationship Addiction, Information Overload, and Net Compulsion, have been recently noted.",background,0
11142,"Symptoms of these mental disorders are usually observed passively today, resulting in delayed clinical intervention.",background,0
11143,"In this paper, we argue that mining online social behavior provides an opportunity to actively identify SNMDs at an early stage.",objective,1
11144,It is challenging to detect SNMDs because the mental status cannot be directly observed from online social activity logs.,method,2
11145,"Our approach, new and innovative to the practice of SNMD detection, does not rely on self-revealing of those mental factors via questionnaires in Psychology.",method,2
11146,"Instead, we propose a machine learning framework, namely, Social Network Mental Disorder Detection (SNMDD), that exploits features extracted from social network data to accurately identify potential cases of SNMDs.",method,2
11147,We also exploit multi-source learning in SNMDD and propose a new SNMD-based Tensor Model (STM) to improve the accuracy.,method,2
11148,"To increase the scalability of STM, we further improve the efficiency with performance guarantee.",method,2
11149,"Our framework is evaluated via a user study with 3,126 online social network users.",method,2
11150,"At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society.",background,0
11151,"However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency.",background,0
11152,"Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained.",background,0
11153,This issue has triggered a new debate on explainable AI (XAI).,result,3
11154,A research field holds substantial promise for improving trust and transparency of AI-based systems.,objective,1
11155,It is recognized as the sine qua non for AI to continue making steady progress without disruption.,result,3
11156,This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI.,result,3
11157,"Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.",result,3
11158,In this paper we provide a conceptual approach to modelling value propositions.,background,0
11159,We argue that rigorous modelling in an ontological style could improve several aspects of business.,background,0
11160,Modelling and mapping value propositions helps better understanding the value a company wants to offer its customers and makes it communicable between various stakeholders.,method,2
11161,Using a common language (ontology) in defining a company's offering brings manager's mental models into a common form.,objective,1
11162,"Further, conceptually seized value propositions are comparable to the value propositions of a firm's competitors because the follow a rigid framework and make it possible to identify the competitive position of a firm's value proposition.",result,3
11163,"Traffic sign detection plays an important role in a number of practical applications, such as intelligent driver assistance and roadway inventory management.",background,0
11164,"In order to process the large amount of data from either real-time videos or large off-line databases, a high-throughput traffic sign detection system is required.",background,0
11165,"In this paper, we propose an FPGA-based hardware accelerator for traffic sign detection based on cascade classifiers.",method,2
11166,"To maximize the throughput and power efficiency, we propose several novel ideas, including: 1) rearranged numerical operations; 2) shared image storage; 3) adaptive workload distribution; and 4) fast image block integration.",method,2
11167,The proposed design is evaluated on a Xilinx ZC706 board.,result,3
11168,"When processing high-definition (1080p) video, it achieves the throughput of 126 frames/s and the energy efficiency of 0.041 J/frame.",result,3
11169,"We introduce the syntactic scaffold, an approach to incorporating syntactic information into semantic tasks.",method,2
11170,"Syntactic scaffolds avoid expensive syntactic processing at runtime, only making use of a treebank during training, through a multitask objective.",method,2
11171,"We improve over strong baselines on PropBank semantics, frame semantics, and coreference resolution, achieving competitive performance on all three tasks.",result,3
11172,Cyclic redundancy codes (CRCs) provide a first line of defense against data corruption in many networks.,background,0
11173,"Unfortunately, many commonly used CRC polynomials provide significantly less error detection capability than they might.",background,0
11174,An exhaustive exploration reveals that most previously published CRC polynomials are either inferior to alternatives or are only good choices for particular message lengths.,method,2
11175,Unfortunately these shortcomings and limitations often seem to be overlooked.,background,0
11176,This paper describes a polynomial selection process for embedded network applications and proposes a set of good general-purpose polynomials.,objective,1
11177,A set of 35 new polynomials in addition to 13 previously published polynomials provides good performance for 3- to 16-bit CRCs for data word lengths up to 2048 bits.,result,3
11178,The rise and fall of artificial neural networks is well documented in the scientific literature of both computer science and computational chemistry.,background,0
11179,"Yet almost two decades later, we are now seeing a resurgence of interest in deep learning, a machine learning algorithm based on multilayer neural networks.",background,0
11180,"Within the last few years, we have seen the transformative impact of deep learning in many domains, particularly in speech recognition and computer vision, to the extent that the majority of expert practitioners in those field are now regularly eschewing prior established models in favor of deep learning models.",background,0
11181,"In this review, we provide an introductory overview into the theory of deep neural networks and their unique properties that distinguish them from traditional machine learning algorithms used in cheminformatics.",method,2
11182,"By providing an overview of the variety of emerging applications of deep neural networks, we highlight its ubiquity and broad applicability to a wide range of challenges in the field, including quantitative structure activity relationship, virtual screening, protein structure prediction, quantum chemistry, materials design, and property prediction.",method,2
11183,"In reviewing the performance of deep neural networks, we observed a consistent outperformance against non-neural networks state-of-the-art models across disparate research topics, and deep neural network-based models often exceeded the ""glass ceiling"" expectations of their respective tasks.",objective,1
11184,"Coupled with the maturity of GPU-accelerated computing for training deep neural networks and the exponential growth of chemical data on which to train these networks on, we anticipate that deep learning algorithms will be a valuable tool for computational chemistry.",result,3
11185,"© 2017 Wiley Periodicals, Inc.",other,4
11186,Several opinion polls have found that many consumers resist making purchases via the Internet because of their concerns about the privacy of the personal information they provide to Internet merchants.,background,0
11187,"Using the theory of planned behavior as its basis, this study investigated the relationships among beliefs about Internet privacy and trustworthiness, along with beliefs about perceived behavioral control and the expectations of important others, and online purchasing behavior.",background,0
11188,Data were collected from 193 college students.,result,3
11189,"Analysis of the data indicates that beliefs about trustworthiness positively affect attitudes toward buying online, which in turn positively affect purchasing behavior.",result,3
11190,"Beliefs about self-efficacy regarding purchasing positively affect perceived behavioral control, which in turn affects online purchasing behavior.",result,3
11191,"In short, respondents who believed in the trustworthiness of the Internet and in their own abilities to buy online were more likely to make Internet purchases than were those without such beliefs.",result,3
11192,"Random forests have emerged as a versatile and highly accurate classification and regression methodology, requiring little tuning and providing interpretable outputs.",background,0
11193,"Here, we briefly outline the genesis of, and motivation for, the random forest paradigm as an outgrowth from earlier tree-structured techniques.",background,0
11194,We elaborate on aspects of prediction error and attendant tuning parameter issues.,method,2
11195,"However, our emphasis is on extending the random forest schema to the multiple response setting.",objective,1
11196,We provide a simple illustrative example from ecology that showcases the improved fit and enhanced interpretation afforded by the random forest framework.,result,3
11197,"C © 2011 John Wiley & Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 80–87 DOI: 10.1002/widm.12",other,4
11198,This paper extends previous work with Dyna a class of architectures for intelligent systems based on approximating dynamic program ming methods Dyna architectures integrate trial and error reinforcement learning and execution time planning into a single process operating alternately on the world and on a learned model of the world In this paper I present and show results for two Dyna archi tectures The Dyna PI architecture is based on dynamic programming s policy iteration method and can be related to existing AI ideas such as evaluation functions and uni versal plans reactive systems Using a nav igation task results are shown for a simple Dyna PI system that simultaneously learns by trial and error learns a world model and plans optimal routes using the evolving world model The Dyna Q architecture is based on Watkins s Q learning a new kind of rein forcement learning Dyna Q uses a less famil iar set of data structures than does Dyna PI but is arguably simpler to implement and use We show that Dyna Q architectures are easy to adapt for use in changing environments Introduction to Dyna How should a robot decide what to do The traditional answer in AI has been that it should deduce its best action in light of its current goals and world model i e that it should plan However it is now widely recognized that planning s usefulness is limited by its computational complexity and by its dependence on an accurate world model An alternative approach is to do the planning in advance and compile its result into a set of rapid reactions or situation action rules which are then used for real time decision making Yet a third approach is to learn a good set of reactions by trial and error this has the advantage of eliminating the dependence on a world model In this paper,background,0
11199,I brie y introduce Dyna a class of simple architectures integrating and permitting tradeo s among these three approaches,background,0
11200,Dyna architectures use machine learning algo rithms to approximate the conventional optimal con trol technique known as dynamic programming DP Bellman Ross DP itself is not a learn ing method but rather a computational method for determining optimal behavior given a complete model of the task to be solved,other,4
11201,It is very similar to state space search but di ers in that it is more incremental and never considers actual action sequences explicitly only single actions at a time This makes DP more amenable to incremental planning at execution time and also makes it more suitable for stochastic or in completely modeled environments as it need not con sider the extremely large number of sequences possi ble in an uncertain environment Learned world mod els are likely to be stochastic and uncertain making DP approaches particularly promising for learning sys tems Dyna architectures are those that learn a world model online while using approximations to DP to learn and plan optimal behavior Intuitively Dyna is based on the old idea that planning is like trial and error learning from hypothet ical experience Craik Dennett,objective,1
11202,The theory of Dyna is based on the theory of DP e g Ross and on DP s relationship to reinforcement learning Watkins Barto Sutton Watkins to temporal di erence learning Sutton and to AI methods for planning and search Korf Werbos has previously argued for the general idea of building AI systems that approx imate dynamic programming and Whitehead and others Sutton Barto Sutton Pinette Rumelhart et,objective,1
11203,al have presented results for the speci c idea of augmenting a reinforcement learning system with a world model used for planning Dyna PI Dyna by Approximating Policy Iteration,result,3
11204,I call the rst Dyna architecture Dyna PI because it is based on approximating a DP method known as pol icy iteration Howard The Dyna PI architec ture consists of four components interacting as shown in Figure The policy is simply the function formed by the current set of reactions it receives as input a description of the current state of the world and pro duces as output an action to be sent to the world The world represents the task to be solved prototypi cally it is the robot s external environment The world receives actions from the policy and produces a next state output and a reward output,method,2
11205,The overall task is de ned as maximizing the long term average reward per time step cf Russell,method,2
11206,The architecture also includes an explicit world model The world model is intended to mimic the one step input output behavior of the real world Finally the Dyna PI architecture in cludes an evaluation function that rapidly maps states to values much as the policy rapidly maps states to actions The evaluation function the policy and the world model are each updated by separate learning processes WORLD Action Reward (scalar),method,2
11207,Heuristic Reward (scalar) State EVALUATION FUNCTION,result,3
11208,"Levels are the space where a player explores the rules and mechanics of a game; as such, good level design is critical to the game design process.",background,0
11209,"While there are many broad design principles, level design is inherently genre-specific due to the wide variety of rules and types of challenge found between genres.",background,0
11210,Determining genre-specific design principles requires an in-depth analysis of games within the genre.,objective,1
11211,"We present such an analysis for the 2D platformer genre, examining level components and structure with a view to better understanding their level design.",method,2
11212,"We then use this analysis to present a model for platformer levels, specifically focusing on areas of challenge.",method,2
11213,Our framework provides a common vocabulary for these items and provides level designers with a method for thinking about elements of platformers and how to compose them to create interesting and challenging levels.,result,3
11214,Previous research has shown a relationship between use of social networking sites and feelings of social capital.,background,0
11215,"However, most studies have relied on self-reports by college students.",background,0
11216,"The goals of the current study are to (1) validate the common self-report scale using empirical data from Facebook, (2) test whether previous findings generalize to older and international populations, and (3) delve into the specific activities linked to feelings of social capital and loneliness.",objective,1
11217,"In particular, we investigate the role of directed interaction between pairs---such as wall posts, comments, and ""likes"" --- and consumption of friends' content, including status updates, photos, and friends' conversations with other friends.",method,2
11218,"We find that directed communication is associated with greater feelings of bonding social capital and lower loneliness, but has only a modest relationship with bridging social capital, which is primarily related to overall friend network size.",result,3
11219,"Surprisingly, users who consume greater levels of content report reduced bridging and bonding social capital and increased loneliness.",other,4
11220,Implications for designs to support well-being are discussed.,result,3
11221,Many forensic computing practitioners work in a high workload and low resource environment.,background,0
11222,"With the move by the discipline to seek ISO 17025 laboratory accreditation, practitioners are finding it difficult to meet the demands of validation and verification of their tools and still meet the demands of the accreditation framework.",background,0
11223,Many agencies are ill-equipped to reproduce tests conducted by organizations such as NIST since they cannot verify the results with their equipment and in many cases rely solely on an independent validation study of other peoples' equipment.,background,0
11224,This creates the issue of tools in reality never being tested.,background,0
11225,"Studies have shown that independent validation and verification of complex forensic tools is expensive and time consuming, and many practitioners also use tools that were not originally designed for forensic purposes.",method,2
11226,This paper explores the issues of validation and verification in the accreditation environment and proposes a paradigm that will reduce the time and expense required to validate and verify forensic software tools,result,3
11227,Imagine the following situation.,other,4
11228,"You’re in your car, listening to the radio and suddenly you hear a song that catches your attention.",background,0
11229,"It’s the best new song you have heard for a long time, but you missed the announcement and don’t recognize the artist.",background,0
11230,"Still, you would like to know more about this music.",background,0
11231,What should you do?,background,0
11232,"You could call the radio station, but that’s too cumbersome.",background,0
11233,Wouldn’t it be nice if you could push a few buttons on your mobile phone and a few seconds later the phone would respond with the name of the artist and the title of the music you’re listening to?,background,0
11234,Perhaps even sending an email to your default email address with some supplemental information.,method,2
11235,"In this paper we present an audio fingerprinting system, which makes the above scenario possible.",objective,1
11236,"By using the fingerprint of an unknown audio clip as a query on a fingerprint database, which contains the fingerprints of a large library of songs, the audio clip can be identified.",method,2
11237,The following formalization is inspired from [2].,background,0
11238,"We first describe notations, assumptions, and meta-variables required for defining the abstract syntax and the semantics of the MultiDim model.",method,2
11239,"Next, we give the abstract syntax of the model that allows the translation from the graphical representation to the equivalent textual representation.",objective,1
11240,"Finally, after describing the auxiliary functions, we define the semantics of the MultiDim model.",result,3
11241,"In recent years, social media are said to have an impact on the public discourse and communication in the society.",background,0
11242,"In particular, social media are increasingly used in political context.",background,0
11243,"More recently, microblogging services (e.g., Twitter) and social network sites (e.g., Facebook) are believed to have the potential for increasing political participation.",background,0
11244,"While Twitter is an ideal platform for users to spread not only information in general but also political opinions publicly through their networks, political institutions (e.g., politicians, political parties, political foundations, etc.) have also begun to use Facebook pages or groups for the purpose of entering into direct dialogs with citizens and encouraging more political discussions.",background,0
11245,"Previous studies have shown that from the perspective of political institutions, there is an emerging need to continuously collect, monitor, analyze, summarize, and visualize politically relevant information from social media.",background,0
11246,"These activities, which are subsumed under “social media analytics,” are considered difficult tasks due to a large numbers of different social media platforms as well as the large amount and complexity of information and data.",method,2
11247,Systematic tracking and analysis approaches along with appropriate scientific methods and techniques in political domain are still lacking.,result,3
11248,"In this paper, we propose a methodological framework for social media analytics in political context.",method,2
11249,"More specifically, our framework summarizes most important politically relevant issues from the perspective of political institutions and corresponding methodologies from different scientific disciplines.",result,3
11250,We present MILABOT: a deep reinforcement learning chatbot developed by the Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize competition.,background,0
11251,MILABOT is capable of conversing with humans on popular small talk topics through both speech and text.,background,0
11252,"The system consists of an ensemble of natural language generation and retrieval models, including template-based models, bag-of-words models, sequence-to-sequence neural network and latent variable neural network models.",method,2
11253,"By applying reinforcement learning to crowdsourced data and real-world user interactions, the system has been trained to select an appropriate response from the models in its ensemble.",method,2
11254,"The system has been evaluated through A/B testing with real-world users, where it performed significantly better than many competing systems.",result,3
11255,"Due to its machine learning architecture, the system is likely to improve with additional data.",result,3
11256,We propose a training framework for sequence-to-sequence voice conversion (SVC).,background,0
11257,"A well-known problem regarding a conventional VC framework is that acoustic-feature sequences generated from a converter tend to be over-smoothed, resulting in buzzy-sounding speech.",background,0
11258,This is because a particular form of similarity metric or distribution for parameter training of the acoustic model is assumed so that the generated feature sequence that averagely fits the training target example is considered optimal.,background,0
11259,This over-smoothing occurs as long as a manually constructed similarity metric is used.,background,0
11260,"To overcome this limitation, our proposed SVC framework uses a similarity metric implicitly derived from a generative adversarial network, enabling the measurement of the distance in the high-level abstract space.",method,2
11261,This would enable the model to mitigate the oversmoothing problem caused in the low-level data space.,method,2
11262,"Furthermore, we use convolutional neural networks to model the long-range context-dependencies.",objective,1
11263,"This also enables the similarity metric to have a shift-invariant property; thus, making the model robust against misalignment errors involved in the parallel data.",method,2
11264,We tested our framework on a non-native-to-native VC task.,result,3
11265,"The experimental results revealed that the use of the proposed framework had a certain effect in improving naturalness, clarity, and speaker individuality.",result,3
11266,The development of Industry 4.0 will be accompanied by changing tasks and demands for the human in the factory.,background,0
11267,"As the most flexible entity in cyber-physical production systems, workers will be faced with a large variety of jobs ranging from specification and monitoring to verification of production strategies.",background,0
11268,Through technological support it is guaranteed that workers can realize their full potential and adopt the role of strategic decision-makers and flexible problem-solvers.,background,0
11269,The use of established interaction technologies and metaphors from the consumer goods market seems to be promising.,method,2
11270,"This paper demonstrates solutions for the technological assistance of workers, which implement the representation of a cyber-physical world and the therein occurring interactions in the form of intelligent user interfaces.",result,3
11271,"Besides technological means, the paper points out the requirement for adequate qualification strategies, which will create the required, inter-disciplinary understanding for Industry 4.0.",result,3
11272,This paper presents a novel vehicle detection approach for detecting vehicles from static images using color and edges.,objective,1
11273,"Different from traditional methods which use motion features to detect vehicles, this method introduces a new color transform model to find important ""vehicle color"" from images for quickly locating possible vehicle candidates.",method,2
11274,"Since vehicles have different colors under different lighting conditions, there were seldom works proposed for detecting vehicles using colors.",method,2
11275,This paper proves that the new color transform model has extreme abilities to identify vehicle pixels from backgrounds even though they are lighted under various illumination conditions.,method,2
11276,Each detected pixel corresponds to a possible vehicle candidate.,method,2
11277,"Then, two important features including edge maps and coefficients of wavelet transform are used for constructing a multi-channel classifier to verify this candidate.",method,2
11278,"According to this classifier, we can perform an effective scan to detect all desired vehicles from static images.",method,2
11279,"Since the color feature is first used to filter out most background pixels, this scan can be extremely quickly achieved.",method,2
11280,Experimental results show that the integrated scheme is very powerful in detecting vehicles from static images.,result,3
11281,The average accuracy of vehicle detection is 94.5%.,result,3
11282,This paper presents a simple two-branch transmit diversity scheme.,background,0
11283,"Using two transmit antennas and one receive antenna the scheme provides the same diversity order as maximal-ratio receiver combining (MRRC) with one transmit antenna, and two receive antennas.",background,0
11284,It is also shown that the scheme may easily be generalized to two transmit antennas and M receive antennas to provide a diversity order of 2M .,method,2
11285,The new scheme does not require any bandwidth expansion any feedback from the receiver to the transmitter and its computation complexity is similar to MRRC.,method,2
11286,New product development is indeed very important for companies.,background,0
11287,"However, developing new products is a risky and uncertain process.",background,0
11288,"In order to reduce the risks and uncertainties, companies need to evaluate their new product initiatives carefully and make accurate decisions.",result,3
11289,"Although the outcome of a new product evaluation decision can be influenced by the environmental uncertainties that are beyond a company s control, companies can successfully improve the accuracy of their new product evaluation decisions.",result,3
11290,This article presents an integrated framework for understanding how various factors affect decision making in new product evaluation and provides guidelines for reducing their negative impacts on new product decisions.,result,3
11291,"The results indicate that the quality of new product evaluation decisions is affected by four major sets of factors, namely the nature of the task, the type of individuals who are involved in the decisions, the way the individuals opinions are elicited and the way the opinions are aggregated.",result,3
11292,2003 Elsevier B.V. All rights reserved.,other,4
11293,This paper introduces a new dimension to the alignment between business and information technology.,background,0
11294,"Besides alignment of strategies, objectives, and processes, the paper argues that modelling languages for the description of organizational domains during requirements engineering must be aligned with the organizational paradigm.",objective,1
11295,This paper examines five organizational paradigms and their ontologies.,method,2
11296,"Current conceptual modelling languages are shown to be poorly aligned with the paradigms, pointing to a need for further research into adapting or creating suitable languages.",result,3
11297,The lack of a written representation for American sign language (ASL) makes it difficult to do something as commonplace as looking up an unknown word in a dictionary.,background,0
11298,"The majority of printed dictionaries organize ASL signs (represented in drawings or pictures) based on their nearest English translation; so unless one already knows the meaning of a sign, dictionary look-up is not a simple proposition.",background,0
11299,"In this paper we introduce the ASL lexicon video dataset, a large and expanding public dataset containing video sequences of thousands of distinct ASL signs, as well as annotations of those sequences, including start/end frames and class label of every sign.",objective,1
11300,This dataset is being created as part of a project to develop a computer vision system that allows users to look up the meaning of an ASL sign.,objective,1
11301,"At the same time, the dataset can be useful for benchmarking a variety of computer vision and machine learning methods designed for learning and/or indexing a large number of visual classes, and especially approaches for analyzing gestures and human communication.",objective,1
11302,The Spring Loaded Inverted Pendulum (SLIP) describes the dynamic walking of humans and animals in a simplified manner.,background,0
11303,"However, realizing such movements by means of a combination of typical articulated legs and linear actuators has some limitations.",background,0
11304,This paper proposes a leg mechanism that accurately reflects the SLIP based on its mechanical constitution.,objective,1
11305,The SLIP design based leg is able to do decoupled swing motion and extension motion.,method,2
11306,Also this study has focused on improving the straightness of extension motion.,method,2
11307,Production planning and control in printed wiring board (PWB) manufacturing is becoming more difficult as PWB's technology is developing and the production routings become more complex.,background,0
11308,"Simultaneously, the strategic importance of delivery accuracy, short delivery times, and production flexibility is increasing with the highly fluctuating demand and short product life cycles of end products.",background,0
11309,"New principles, that minimize throughput time while guaranteeing excellent customer service and adequate capacity utilization, are needed for production planning and control.",background,0
11310,Simulation is needed in order to develop the new principles and test their superiority.,background,0
11311,This paper presents an ongoing simulation project that aims at developing the production planning and control of a PWB manufacturer.,objective,1
11312,"In the project, a discrete event simulation model is built of a pilot case factory.",method,2
11313,"The model is used for comparing the effect of scheduling, queuing rules, buffer policies, and lot sizes on customer service and cost efficiency.",method,2
11314,"In this paper, we propose a direction-of-arrival (DOA) estimation method by combining multiple signal classification (MUSIC) of two decomposed linear arrays for the corresponding coprime array signal processing.",background,0
11315,"The title “DECOM” means that, first, the nonlinear coprime array needs to be DECOMposed into two linear arrays, and second, Doa Estimation is obtained by COmbining the MUSIC results of the linear arrays, where the existence and uniqueness of the solution are proved.",objective,1
11316,"To reduce the computational complexity of DECOM, we design a two-phase adaptive spectrum search scheme, which includes a coarse spectrum search phase and then a fine spectrum search phase.",method,2
11317,Extensive simulations have been conducted and the results show that the DECOM can achieve accurate DOA estimation under different SNR conditions.,result,3
11318,We consider real-life smart parking systems where parking lot occupancy data are collected from field sensor devices and sent to backend servers for further processing and usage for applications.,background,0
11319,"Our objective is to make these data useful to end users, such as parking managers, and, ultimately, to citizens.",objective,1
11320,"To this end, we concoct and validate an automated classification algorithm having two objectives: (1) outlier detection: to detect sensors with anomalous behavioral patterns, i.e., outliers; and (2) clustering: to group the parking sensors exhibiting similar patterns into distinct clusters.",method,2
11321,"We first analyze the statistics of real parking data, obtaining suitable simulation models for parking traces.",method,2
11322,We then consider a simple classification algorithm based on the empirical complementary distribution function of occupancy times and show its limitations.,method,2
11323,"Hence, we design a more sophisticated algorithm exploiting unsupervised learning techniques (self-organizing maps).",method,2
11324,"These are tuned following a supervised approach using our trace generator and are compared against other clustering schemes, namely expectation maximization, k-means clustering and DBSCAN, considering six months of data from a real sensor deployment.",method,2
11325,"Our approach is found to be superior in terms of classification accuracy, while also being capable of identifying all of the outliers in the dataset.",result,3
11326,"A fundamental objective of human–computer interaction research is to make systems more usable, more useful, and to provide users with experiences fitting their specific background knowledge and objectives.",objective,1
11327,"The challenge in an information-rich world is not only to make information available to people at any time, at any place, and in any form, but specifically to say the “right” thing at the “right” time in the “right” way.",background,0
11328,Designers of collaborative human–computer systems face the formidable task of writing software for millions of users (at design time) while making it work as if it were designed for each individual user (only known at use time).,objective,1
11329,User modeling research has attempted to address these issues.,method,2
11330,"In this article, I will first review the objectives, progress, and unfulfilled hopes that have occurred over the last ten years, and illustrate them with some interesting computational environments and their underlying conceptual frameworks.",method,2
11331,"A special emphasis is given to high-functionality applications and the impact of user modeling to make them more usable, useful, and learnable.",method,2
11332,"Finally, an assessment of the current state of the art followed by some future challenges is given.",result,3
